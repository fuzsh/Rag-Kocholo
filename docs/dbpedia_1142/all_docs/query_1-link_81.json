{
    "id": "dbpedia_1142_1",
    "rank": 81,
    "data": {
        "url": "https://www.science.gov/topicpages/p/plate%2Bcount%2Bhpc",
        "read_more_link": "",
        "language": "en",
        "title": "plate count hpc: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "HETEROTROPHIC PLATE COUNT BACTERIA - WHAT IS THEIR SIGNIFICANCE IN DRINKING WATER?\n\nEPA Science Inventory\n\nThe possible health significance of heterotrophic plate count (HPC) bacteria, also know in earlier terminology as standard plate count (SPC) bacteria, in drinking water has been debated for decades. While the literature documents the universal occurrence of HPC bacteria in soil, ...\n\nA THUMBNAIL HISTORY OF HETEROTROPHIC PLATE COUNT (HPC) METHODOLOGY IN THE UNITED STATES\n\nEPA Science Inventory\n\nOver the past 100 years, the method of determining the number of bacteria in water, foods or other materials has been termed variously as: bacterial plate count, total plate count, total viable plate count, aerobic plate count, standard plate cound and more recently, heterotrophi...\n\nHETEROTROPHIC PLATE COUNT (HPC) METHODOLOGY IN THE UNITED STATES\n\nEPA Science Inventory\n\nABSTRACT\n\nIn the United States (U.S.), the history of bacterial plate counting methods used for water can be traced largely through Standard Methods for the Examination of Water and Wastewater (Standard Methods). The bacterial count method has evolved from the original St...\n\nEstablishment of HPC(R2A) for regrowth control in non-chlorinated distribution systems.\n\nPubMed\n\nUhl, Wolfgang; Schaule, Gabriela\n\n2004-05-01\n\nDrinking water distributed without disinfection and without regrowth problems for many years may show bacterial regrowth when the residence time and/or temperature in the distribution system increases or when substrate and/or bacterial concentration in the treated water increases. An example of a regrowth event in a major German city is discussed. Regrowth of HPC bacteria occurred unexpectedly at the end of a very hot summer. No pathogenic or potentially pathogenic bacteria were identified. Increased residence times in the distribution system and temperatures up to 25 degrees C were identified as most probable causes and the regrowth event was successfully overcome by changing flow regimes and decreasing residence times. Standard plate counts of HPC bacteria using the spread plate technique on nutrient rich agar according to German Drinking Water Regulations (GDWR) had proven to be a very good indicator of hygienically safe drinking water and to demonstrate the effectiveness of water treatment. However, the method proved insensitive for early regrowth detection. Regrowth experiments in the lab and sampling of the distribution system during two summers showed that spread plate counts on nutrient-poor R2A agar after 7-day incubation yielded 100 to 200 times higher counts. Counts on R2A after 3-day incubation were three times less than after 7 days. As the precision of plate count methods is very poor for counts less than 10 cfu/plate, a method yielding higher counts is better suited to detect upcoming regrowth than a method yielding low counts. It is shown that for the identification of regrowth events HPC(R2A) gives a further margin of about 2 weeks for reaction before HPC(GDWR). Copyright 2003 Elsevier B.V.\n\nPathogenic features of heterotrophic plate count bacteria from drinking-water boreholes.\n\nPubMed\n\nHorn, Suranie; Pieters, Rialet; Bezuidenhout, Carlos\n\n2016-12-01\n\nEvidence suggests that heterotrophic plate count (HPC) bacteria may be hazardous to humans with weakened health. We investigated the pathogenic potential of HPC bacteria from untreated borehole water, consumed by humans, for: their haemolytic properties, the production of extracellular enzymes such as DNase, proteinase, lipase, lecithinase, hyaluronidase and chondroitinase, the effect simulated gastric fluid has on their survival, as well as the bacteria's antibiotic-susceptible profile. HuTu-80 cells acted as model for the human intestine and were exposed to the HPC isolates to determine their effects on the viability of the cells. Several HPC isolates were Î±- or Î²-haemolytic, produced two or more extracellular enzymes, survived the SGF treatment, and showed resistance against selected antibiotics. The isolates were also harmful to the human intestinal cells to varying degrees. A novel pathogen score was calculated for each isolate. Bacillus cereus had the highest pathogen index: the pathogenicity of the other bacteria declined as follows: Aeromonas taiwanensis > Aeromonas hydrophila > Bacillus thuringiensis > Alcaligenes faecalis > Pseudomonas sp. > Bacillus pumilus > Brevibacillus sp. > Bacillus subtilis > Bacillus sp. These results demonstrated that the prevailing standards for HPCs in drinking water may expose humans with compromised immune systems to undue risk.\n\nFlow cytometric bacterial cell counts challenge conventional heterotrophic plate counts for routine microbiological drinking water monitoring.\n\nPubMed\n\nVan Nevel, S; Koetzsch, S; Proctor, C R; Besmer, M D; Prest, E I; Vrouwenvelder, J S; Knezev, A; Boon, N; Hammes, F\n\n2017-04-15\n\nDrinking water utilities and researchers continue to rely on the century-old heterotrophic plate counts (HPC) method for routine assessment of general microbiological water quality. Bacterial cell counting with flow cytometry (FCM) is one of a number of alternative methods that challenge this status quo and provide an opportunity for improved water quality monitoring. After more than a decade of application in drinking water research, FCM methodology is optimised and established for routine application, supported by a considerable amount of data from multiple full-scale studies. Bacterial cell concentrations obtained by FCM enable quantification of the entire bacterial community instead of the minute fraction of cultivable bacteria detected with HPC (typicallyÂ <Â 1% of all bacteria). FCM measurements are reproducible with relative standard deviations below 3% and can be available within 15Â min of samples arriving in the laboratory. High throughput sample processing and complete automation are feasible and FCM analysis is arguably less expensive than HPC when measuring more than 15 water samples per day, depending on the laboratory and selected staining procedure(s). Moreover, many studies have shown FCM total (TCC) and intact (ICC) cell concentrations to be reliable and robust process variables, responsive to changes in the bacterial abundance and relevant for characterising and monitoring drinking water treatment and distribution systems. The purpose of this critical review is to initiate a constructive discussion on whether FCM could replace HPC in routine water quality monitoring. We argue that FCM provides a faster, more descriptive and more representative quantification of bacterial abundance in drinking water. Copyright Â© 2017 Elsevier Ltd. All rights reserved.\n\nEvaluation of Petrifilm Lactic Acid Bacteria Plates for Counting Lactic Acid Bacteria in Food.\n\nPubMed\n\nKanagawa, Satomi; Ohshima, Chihiro; Takahashi, Hajime; Burenqiqige; Kikuchi, Misato; Sato, Fumina; Nakamura, Ayaka; Mohamed, Shimaa M; Kuda, Takashi; Kimura, Bon\n\n2018-06-01\n\nAlthough lactic acid bacteria (LAB) are used widely as starter cultures in the production of fermented foods, they are also responsible for food decay and deterioration. The undesirable growth of LAB in food causes spoilage, discoloration, and slime formation. Because of these adverse effects, food companies test for the presence of LAB in production areas and processed foods and consistently monitor the behavior of these bacteria. The 3M Petrifilm LAB Count Plates have recently been launched as a time-saving and simple-to-use plate designed for detecting and quantifying LAB. This study compares the abilities of Petrifilm LAB Count Plates and the de Man Rogosa Sharpe (MRS) agar medium to determine the LAB count in a variety of foods and swab samples collected from a food production area. Bacterial strains isolated from Petrifilm LAB Count Plates were identified by 16S rDNA sequence analysis to confirm the specificity of these plates for LAB. The results showed no significant difference in bacterial counts measured by using Petrifilm LAB Count Plates and MRS medium. Furthermore, all colonies growing on Petrifilm LAB Count Plates were confirmed to be LAB, while yeast colonies also formed in MRS medium. Petrifilm LAB Count Plates eliminated the plate preparation and plate inoculation steps, and the cultures could be started as soon as a diluted food sample was available. Food companies are required to establish quality controls and perform tests to check the quality of food products; the use of Petrifilm LAB Count Plates can simplify this testing process for food companies.\n\nComparison of plate counts, Petrifilm, dipslides, and adenosine triphosphate bioluminescence for monitoring bacteria in cooling-tower waters.\n\nPubMed\n\nMueller, Sherry A; Anderson, James E; Kim, Byung R; Ball, James C\n\n2009-04-01\n\nEffective bacterial control in cooling-tower systems requires accurate and timely methods to count bacteria. Plate-count methods are difficult to implement on-site, because they are time- and labor-intensive and require sterile techniques. Several field-applicable methods (dipslides, Petrifilm, and adenosine triphosphate [ATP] bioluminescence) were compared with the plate count for two sample matrices--phosphate-buffered saline solution containing a pure culture of Pseudomonas fluorescens and cooling-tower water containing an undefined mixed bacterial culture. For the pure culture, (1) counts determined on nutrient agar and plate-count agar (PCA) media and expressed as colony-forming units (CFU) per milliliter were equivalent to those on R2A medium (p = 1.0 and p = 1.0, respectively); (2) Petrifilm counts were not significantly different from R2A plate counts (p = 0.99); (3) the dipslide counts were up to 2 log units higher than R2A plate counts, but this discrepancy was not statistically significant (p = 0.06); and (4) a discernable correlation (r2 = 0.67) existed between ATP readings and plate counts. For cooling-tower water samples (n = 62), (1) bacterial counts using R2A medium were higher (but not significant; p = 0.63) than nutrient agar and significantly higher than tryptone-glucose yeast extract (TGE; p = 0.03) and PCA (p < 0.001); (2) Petrifilm counts were significantly lower than nutrient agar or R2A (p = 0.02 and p < 0.001, respectively), but not statistically different from TGE, PCA, and dipslides (p = 0.55, p = 0.69, and p = 0.91, respectively); (3) the dipslide method yielded bacteria counts 1 to 3 log units lower than nutrient agar and R2A (p < 0.001), but was not significantly different from Petrifilm (p = 0.91), PCA (p = 1.00) or TGE (p = 0.07); (4) the differences between dipslides and the other methods became greater with a 6-day incubation time; and (5) the correlation between ATP readings and plate counts varied from system to system, was poor\n\nEnumeration of total aerobic microorganisms in foods by SimPlate Total Plate Count-Color Indicator methods and conventional culture methods: collaborative study.\n\nPubMed\n\nFeldsine, Philip T; Leung, Stephanie C; Lienau, Andrew H; Mui, Linda A; Townsend, David E\n\n2003-01-01\n\nThe relative efficacy of the SimPlate Total Plate Count-Color Indicator (TPC-CI) method (SimPlate 35 degrees C) was compared with the AOAC Official Method 966.23 (AOAC 35 degrees C) for enumeration of total aerobic microorganisms in foods. The SimPlate TPC-CI method, incubated at 30 degrees C (SimPlate 30 degrees C), was also compared with the International Organization for Standardization (ISO) 4833 method (ISO 30 degrees C). Six food types were analyzed: ground black pepper, flour, nut meats, frozen hamburger patties, frozen fruits, and fresh vegetables. All foods tested were naturally contaminated. Nineteen laboratories throughout North America and Europe participated in the study. Three method comparisons were conducted. In general, there was <0.3 mean log count difference in recovery among the SimPlate methods and their corresponding reference methods. Mean log counts between the 2 reference methods were also very similar. Repeatability (Sr) and reproducibility (SR) standard deviations were similar among the 3 method comparisons. The SimPlate method (35 degrees C) and the AOAC method were comparable for enumerating total aerobic microorganisms in foods. Similarly, the SimPlate method (30 degrees C) was comparable to the ISO method when samples were prepared and incubated according to the ISO method.\n\nShifter: Containers for HPC\n\nNASA Astrophysics Data System (ADS)\n\nGerhardt, Lisa; Bhimji, Wahid; Canon, Shane; Fasel, Markus; Jacobsen, Doug; Mustafa, Mustafa; Porter, Jeff; Tsulaia, Vakho\n\n2017-10-01\n\nBringing HEP computing to HPC can be difficult. Software stacks are often very complicated with numerous dependencies that are difficult to get installed on an HPC system. To address this issue, NERSC has created Shifter, a framework that delivers Docker-like functionality to HPC. It works by extracting images from native formats and converting them to a common format that is optimally tuned for the HPC environment. We have used Shifter to deliver the CVMFS software stack for ALICE, ATLAS, and STAR on the supercomputers at NERSC. As well as enabling the distribution multi-TB sized CVMFS stacks to HPC, this approach also offers performance advantages. Software startup times are significantly reduced and load times scale with minimal variation to 1000s of nodes. We profile several successful examples of scientists using Shifter to make scientific analysis easily customizable and scalable. We will describe the Shifter framework and several efforts in HEP and NP to use Shifter to deliver their software on the Cori HPC system.\n\nHPC in a HEP lab: lessons learned from setting up cost-effective HPC clusters\n\nNASA Astrophysics Data System (ADS)\n\nHusejko, Michal; Agtzidis, Ioannis; Baehler, Pierre; Dul, Tadeusz; Evans, John; Himyr, Nils; Meinhard, Helge\n\n2015-12-01\n\nIn this paper we present our findings gathered during the evaluation and testing of Windows Server High-Performance Computing (Windows HPC) in view of potentially using it as a production HPC system for engineering applications. The Windows HPC package, an extension of Microsofts Windows Server product, provides all essential interfaces, utilities and management functionality for creating, operating and monitoring a Windows-based HPC cluster infrastructure. The evaluation and test phase was focused on verifying the functionalities of Windows HPC, its performance, support of commercial tools and the integration with the users work environment. We describe constraints imposed by the way the CERN Data Centre is operated, licensing for engineering tools and scalability and behaviour of the HPC engineering applications used at CERN. We will present an initial set of requirements, which were created based on the above constraints and requests from the CERN engineering user community. We will explain how we have configured Windows HPC clusters to provide job scheduling functionalities required to support the CERN engineering user community, quality of service, user- and project-based priorities, and fair access to limited resources. Finally, we will present several performance tests we carried out to verify Windows HPC performance and scalability.\n\nHeterotrophic plate count and consumer's health under special consideration of water softeners.\n\nPubMed\n\nHambsch, Beate; SacrÃ©, Clara; Wagner, Ivo\n\n2004-05-01\n\nThe phenomenon of bacterial growth in water softeners is well known since years. To upgrade the hygienic safety of water softeners, the German DIN Standard 19636 was developed, to assure that the distribution system could not be contaminated by these devices and that the drinking water to be used in the household still meets the microbiological standards according to the German drinking water guidelines, i.e. among others heterotrophic plate count (HPC) below 100 CFU/ml. Moreover, the standard for the water softeners includes a test for contamination with Pseudomonas aeruginosa which has to be disinfected during the regeneration phase. This is possible by sanitizing the resin bed during regeneration by producing chlorine. The results of the last 10 years of tests of water softeners according to DIN 19636 showed that it is possible to produce water softeners that comply with that standard. Approximately 60% of the tested models were accepted. P. aeruginosa is used as an indicator for potentially pathogenic bacteria being able to grow also in low nutrient conditions which normally prevail in drinking water. Like other heterotrophs, the numbers of P. aeruginosa increase rapidly as stagnation occurs. Normally P. aeruginosa is not present in the distributed drinking water. However, under certain conditions, P. aeruginosa can be introduced into the drinking water distribution system, for instance, during construction work. The occurrence of P. aeruginosa is shown in different cases in treatment plants, public drinking water systems and in-house installations. The compliance with DIN 19636 provides assurance that a water softener will not be a constant source of contamination, even if it is once inoculated with a potentially pathogenic bacterium like P. aeruginosa. Copyright 2003 Elsevier B.V.\n\nRELATIONSHIPS BETWEEN LEVELS OF HETEROTROPHIC BACTERIA AND WATER QUALITY PARAMETERS IN A DRINKING WATER DISTRIBUTION SYSTEM\n\nEPA Science Inventory\n\nConventional plating methods were used to quantify heterotrophic bacteria from a drinking water distribution system. Three media, plate count agar (PCA), R2A agar and sheep blood agar (TSA-SB) were used to determine heterotrophic plate count (HPC) levels. Grab samples were collec...\n\nTechnical note: enumeration of mesophilic aerobes in milk: evaluation of standard official protocols and Petrifilm aerobic count plates.\n\nPubMed\n\nFreitas, R; Nero, L A; Carvalho, A F\n\n2009-07-01\n\nEnumeration of mesophilic aerobes (MA) is the main quality and hygiene parameter for raw and pasteurized milk. High levels of these microorganisms indicate poor conditions in production, storage, and processing of milk, and also the presence of pathogens. Fifteen raw and 15 pasteurized milk samples were submitted for MA enumeration by a conventional plating method (using plate count agar) and Petrifilm Aerobic Count plates (3M, St. Paul, MN), followed by incubation according to 3 official protocols: IDF/ISO (incubation at 30 degrees C for 72 h), American Public Health Association (32 degrees C for 48 h), and Brazilian Ministry of Agriculture (36 degrees C for 48 h). The results were compared by linear regression and ANOVA. Considering the results from conventional methodology, good correlation indices and absence of significant differences between mean counts were observed, independent of type of milk sample (raw or pasteurized) and incubation conditions (IDF/ISO, American Public Health Association, or Ministry of Agriculture). Considering the results from Petrifilm Aerobic Count plates, good correlation indices and absence of significant differences were only observed for raw milk samples. The microbiota of pasteurized milk interfered negatively with the performance of Petrifilm Aerobic Count plates, probably because of the presence of microorganisms that poorly reduce the dye indicator of this system.\n\nShort communication: Repeatability of differential goat bulk milk culture and associations with somatic cell count, total bacterial count, and standard plate count.\n\nPubMed\n\nKoop, G; Dik, N; Nielen, M; Lipman, L J A\n\n2010-06-01\n\nThe aims of this study were to assess how different bacterial groups in bulk milk are related to bulk milk somatic cell count (SCC), bulk milk total bacterial count (TBC), and bulk milk standard plate count (SPC) and to measure the repeatability of bulk milk culturing. On 53 Dutch dairy goat farms, 3 bulk milk samples were collected at intervals of 2 wk. The samples were cultured for SPC, coliform count, and staphylococcal count and for the presence of Staphylococcus aureus. Furthermore, SCC (Fossomatic 5000, Foss, HillerÃ¸d, Denmark) and TBC (BactoScan FC 150, Foss) were measured. Staphylococcal count was correlated to SCC (r=0.40), TBC (r=0.51), and SPC (r=0.53). Coliform count was correlated to TBC (r=0.33), but not to any of the other variables. Staphylococcus aureus did not correlate to SCC. The contribution of the staphylococcal count to the SPC was 31%, whereas the coliform count comprised only 1% of the SPC. The agreement of the repeated measurements was low. This study indicates that staphylococci in goat bulk milk are related to SCC and make a significant contribution to SPC. Because of the high variation in bacterial counts, repeated sampling is necessary to draw valid conclusions from bulk milk culturing. 2010 American Dairy Science Association. Published by Elsevier Inc. All rights reserved.\n\nHPC Software Stack Testing Framework\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nGarvey, Cormac\n\nThe HPC Software stack testing framework (hpcswtest) is used in the INL Scientific Computing Department to test the basic sanity and integrity of the HPC Software stack (Compilers, MPI, Numerical libraries and Applications) and to quickly discover hard failures, and as a by-product it will indirectly check the HPC infrastructure (network, PBS and licensing servers).\n\nDetection of Salmonella sp., Vibrio sp. and total plate count bacteria on blood cockle (Anadara granosa)\n\nNASA Astrophysics Data System (ADS)\n\nEkawati, ER; Yusmiati, S. N. H.\n\n2018-01-01\n\nBlood cockle (Anadara granosa) has high level of zinc and protein, which is beneficial for therapeutic function for malnourished particularly stunting case in children. Zinc in animal foods is more absorbable than that from vegetable food. Blood cockle (Anadara granosa) is rich in nutrient and an excellent environment for the growth of microorganisms. This research aimed to identify the contamination of Salmonella sp., Vibrio sp. and total plate count bacteria on blood cockle (Anadara granosa). This was observation research with laboratory analysis. Salmonella sp. and Vibrio sp. were detected from blood cockle. Total plate count was determine of the total amount of the bacteria. Results detected from 20 samples of blood cockle showed that all samples were negative of Salmonella sp. and 1 sample positive Vibrio sp. The result of total plate count bacteria was < 5 x 105 colony/g sample.\n\nOptimization of high count rate event counting detector with Microchannel Plates and quad Timepix readout\n\nNASA Astrophysics Data System (ADS)\n\nTremsin, A. S.; Vallerga, J. V.; McPhate, J. B.; Siegmund, O. H. W.\n\n2015-07-01\n\nMany high resolution event counting devices process one event at a time and cannot register simultaneous events. In this article a frame-based readout event counting detector consisting of a pair of Microchannel Plates and a quad Timepix readout is described. More than 104 simultaneous events can be detected with a spatial resolution of 55 Î¼m, while >103 simultaneous events can be detected with <10 Î¼m spatial resolution when event centroiding is implemented. The fast readout electronics is capable of processing >1200 frames/sec, while the global count rate of the detector can exceed 5Ã108 particles/s when no timing information on every particle is required. For the first generation Timepix readout, the timing resolution is limited by the Timepix clock to 10-20 ns. Optimization of the MCP gain, rear field voltage and Timepix threshold levels are crucial for the device performance and that is the main subject of this article. These devices can be very attractive for applications where the photon/electron/ion/neutron counting with high spatial and temporal resolution is required, such as energy resolved neutron imaging, Time of Flight experiments in lidar applications, experiments on photoelectron spectroscopy and many others.\n\nA generalized plate method for estimating total aerobic microbial count.\n\nPubMed\n\nHo, Kai Fai\n\n2004-01-01\n\nThe plate method outlined in Chapter 61: Microbial Limit Tests of the U.S. Pharmacopeia (USP 61) provides very specific guidance for assessing total aerobic bioburden in pharmaceutical articles. This methodology, while comprehensive, lacks the flexibility to be useful in all situations. By studying the plate method as a special case within a more general family of assays, the effects of each parameter in the guidance can be understood. Using a mathematical model to describe the plate counting procedure, a statistical framework for making more definitive statements about total aerobic bioburden is developed. Such a framework allows the laboratory scientist to adjust the USP 61 methods to satisfy specific practical constraints. In particular, it is shown that the plate method can be conducted, albeit with stricter acceptance criteria, using a test specimen quantity that is smaller than the 10 g or 10 mL prescribed in the guidance. Finally, the interpretation of results proffered by the guidance is re-examined within this statistical framework and shown to be overly aggressive.\n\nHPC: Rent or Buy\n\nERIC Educational Resources Information Center\n\nFredette, Michelle\n\n2012-01-01\n\n\"Rent or buy?\" is a question people ask about everything from housing to textbooks. It is also a question universities must consider when it comes to high-performance computing (HPC). With the advent of Amazon's Elastic Compute Cloud (EC2), Microsoft Windows HPC Server, Rackspace's OpenStack, and other cloud-based services, researchers now haveâ¦\n\nEvaluation of heterotrophic plate and chromogenic agar colony counting in water quality laboratories.\n\nPubMed\n\nHallas, Gary; Monis, Paul\n\n2015-01-01\n\nThe enumeration of bacteria using plate-based counts is a core technique used by food and water microbiology testing laboratories. However, manual counting of bacterial colonies is both time and labour intensive, can vary between operators and also requires manual entry of results into laboratory information management systems, which can be a source of data entry error. An alternative is to use automated digital colony counters, but there is a lack of peer-reviewed validation data to allow incorporation into standards. We compared the performance of digital counting technology (ProtoCOL3) against manual counting using criteria defined in internationally recognized standard methods. Digital colony counting provided a robust, standardized system suitable for adoption in a commercial testing environment. The digital technology has several advantages:â¢Improved measurement of uncertainty by using a standard and consistent counting methodology with less operator error.â¢Efficiency for labour and time (reduced cost).â¢Elimination of manual entry of data onto LIMS.â¢Faster result reporting to customers.\n\nATLAS computing on CSCS HPC\n\nNASA Astrophysics Data System (ADS)\n\nFilipcic, A.; Haug, S.; Hostettler, M.; Walker, R.; Weber, M.\n\n2015-12-01\n\nThe Piz Daint Cray XC30 HPC system at CSCS, the Swiss National Supercomputing centre, was the highest ranked European system on TOP500 in 2014, also featuring GPU accelerators. Event generation and detector simulation for the ATLAS experiment have been enabled for this machine. We report on the technical solutions, performance, HPC policy challenges and possible future opportunities for HEP on extreme HPC systems. In particular a custom made integration to the ATLAS job submission system has been developed via the Advanced Resource Connector (ARC) middleware. Furthermore, a partial GPU acceleration of the Geant4 detector simulations has been implemented.\n\nThe effect of microchannel plate gain depression on PAPA photon counting cameras\n\nNASA Astrophysics Data System (ADS)\n\nSams, Bruce J., III\n\n1991-03-01\n\nPAPA (precision analog photon address) cameras are photon counting imagers which employ microchannel plates (MCPs) for image intensification. They have been used extensively in astronomical speckle imaging. The PAPA camera can produce artifacts when light incident on its MCP is highly concentrated. The effect is exacerbated by adjusting the strobe detection level too low, so that the camera accepts very small MCP pulses. The artifacts can occur even at low total count rates if the image has highly a concentrated bright spot. This paper describes how to optimize PAPA camera electronics, and describes six techniques which can avoid or minimize addressing errors.\n\n[Analysis on 2011 quality control results on aerobic plate count of microbiology laboratories in China].\n\nPubMed\n\nHan, Haihong; Li, Ning; Li, Yepeng; Fu, Ping; Yu, Dongmin; Li Zhigang; Du, Chunming; Guo, Yunchang\n\n2015-01-01\n\nTo test the aerobic plate count examining capability of microbiology laboratories, to ensure the accuracy and comparability of quantitative bacteria examination results, and to improve the quality of monitoring. The 4 different concentration aerobic plate count piece samples were prepared and noted as I, II, III and IV. After homogeneity and stability tests, the samples were delivered to monitoring institutions. The results of I, II, III samples were logarithmic transformed, and evaluated with Z-score method using the robust average and standard deviation. The results of IV samples were evaluated as \"satisfactory\" when reported as < 10 CFU/piece or as \"not satisfactory\" otherwise. Pearson Ï2 test was used to analyze the ratio results. 309 monitoring institutions, which was 99.04% of the total number, reported their results. 271 institutions reported a satisfactory result, and the satisfactory rate was 87.70%. There was no statistical difference in satisfactory rates of I, II and III samples which were 81.52%, 88.30% and 91.40% respectively. The satisfactory rate of IV samples was 93.33%. There was no statistical difference in satisfactory rates between provincial and municipal CDC. The quality control program has provided scientific data that the aerobic plate count capability of the laboratories meets the requirements of monitoring tasks.\n\n[Endotoxin Contamination and Correlation with Other Water Quality Parameters of Groundwater from Self-Contained Wells in Beijing].\n\nPubMed\n\nZhang, Can; Liu, Wen-jun; Ao, Lu; Shi, Yun; An, Dai-zhi; Liu, Zhi-ping\n\n2015-12-01\n\nA survey of endotoxin activity in groundwater from 14 self-contained wells in PLA units stationed in Beijing was conducted by the kinetic-turbid assay of Tachypleus Amebocyte Lysate (TAL). Bacteriological parameters, including total cell counts detected by flow cytometry, heterotrophic plate counts (HPC), standard plate counts and total coliforms were analyzed. Additionally, suspended particles, turbidity, dissolved organic carbon (DOC), and UVââ â were investigated. Total endotoxin activities ranged from 0. 15 to 13.20 EU Â· mLâ»Â¹, free endotoxin activities ranged from 0.10 to 5.29 EU Â· mLâ»Â¹ and bound endotoxin activities ranged from 0.01 to 8.60 EU Â· mLâ»Â¹. Most of the endotoxins in heavily contaminated groundwater existed as bound endotoxins. As for total endotoxins, the sequence of correlation coefficients with other parameters was total cell counts (r = 0.88 ) > HPC (r = 0.79) > DOC (r = 0.77) > UVââ â (r = 0.57) > total coliforms (r = 0.50) > standard plate counts (r = 0.49) = turbidity (r = 0. 49) > total particles (r = 0.41). The sequence of correlations of the bound endotoxins with other parameters was total cell counts (r = 0.81) > HPC (r = 0.66) > total coliforms (r = 0.65) > turbidity (r = 0.62) > total particles (r = 0.58) > standard plate counts (r = 0.22). Free endotoxins were correlated with DOC and UVââ â, r = 0.58 and 0.26, respectively. Result showed free endotoxins had a higher correlation with DOC, and a lower correlation with UVââ â.\n\nPotentially pathogenic features of heterotrophic plate count bacteria isolated from treated and untreated drinking water.\n\nPubMed\n\nPavlov, D; de Wet, C M E; Grabow, W O K; Ehlers, M M\n\n2004-05-01\n\nHeterotrophic plate counts (HPCs) are commonly used to assess the general microbiological quality of drinking water. Drinking water quality specifications worldwide recommend HPC limits from 100 to 500 cfu ml(-1). A number of recent studies revealed evidence that these bacteria may not be as harmless as generally accepted. It appears that immuno-compromised individuals are particularly at risk. This would include the very young and very old patients with diseases such as AIDS and patients on therapy for purposes such as organ transplantation and cancer treatment. In this study, 339 bacterial colonies were isolated at random from selected treated and untreated drinking water in South Africa using routine heterotrophic plate count tests. In a first step to screen for potentially pathogenic properties, 188 (55.5%) of the isolates showed alpha- or beta-haemolysis on human- and horse-blood agar media. Subsequent analysis of the haemolytic isolates for enzymatic properties associated with pathogenicity revealed the presence of chondroitinase in 5.3% of the isolates, coagulase in 16.0%, DNase in 60.6%, elastase in 33.0%, fibrinolysin in 53.7%, gelatinase in 62.2%, hyaluronidase in 21.3%, lecithinase in 47.9%, lipase in 54.8% and proteinase in 64.4%. Fluorescein and pyocyanin were not produced by any of the isolates. Among the haemolytic isolates, 77.7% were resistant to oxacillin 1 microg, 59.6% to penicillin G 2 units, 47.3% to penicillin G 10 units, 54.3% to ampicillin 10 microg and 43.1% to ampicillin 25 microg. Cell culture studies revealed that 96% of haemolytic isolates were cytotoxic to HEp-2 cells, and 98.9% of the 181 cytotoxic isolates adhered to HEp-2 or Caco-2 cells. HEp-2 cells were invaded by 43.6%, and Caco-2 cells by 49.7%, of the 181 cytotoxic isolates. The invasion index on HEp-2 cells ranged from 1.9 x 10(-1) to 8.9 x 10(-6), whereas the invasion index on Caco-2 cells varied between 7.7 x 10(-2) and 8.3 x 10(-6). The most commonly isolated genera with\n\nPhoton-counting detector arrays based on microchannel array plates. [for image enhancement\n\nNASA Technical Reports Server (NTRS)\n\nTimothy, J. G.\n\n1975-01-01\n\nThe recent development of the channel electron multiplier (CEM) and its miniaturization into the microchannel array plate (MCP) offers the possibility of fully combining the advantages of the photographic and photoelectric detection systems. The MCP has an image-intensifying capability and the potential of being developed to yield signal outputs superior to those of conventional photomultipliers. In particular, the MCP has a photon-counting capability with a negligible dark-count rate. Furthermore, the MCP can operate stably and efficiently at extreme-ultraviolet and soft X-ray wavelengths in a windowless configuration or can be integrated with a photo-cathode in a sealed tube for use at ultraviolet and visible wavelengths. The operation of one- and two-dimensional photon-counting detector arrays based on the MCP at extreme-ultraviolet wavelengths is described, and the design of sealed arrays for use at ultraviolet and visible wavelengths is briefly discussed.\n\nHigh Speed Large Format Photon Counting Microchannel Plate Imaging Sensors\n\nNASA Astrophysics Data System (ADS)\n\nSiegmund, O.; Ertley, C.; Vallerga, J.; Craven, C.; Popecki, M.; O'Mahony, A.; Minot, M.\n\nThe development of a new class of microchannel plate technology, using atomic layer deposition (ALD) techniques applied to a borosilicate microcapillary array is enabling the implementation of larger, more stable detectors for Astronomy and remote sensing. Sealed tubes with MCPs with SuperGenII, bialkali, GaAs and GaN photocathodes have been developed to cover a wide range of optical/UV sensing applications. Formats of 18mm and 25mm circular, and 50mm (Planacon) and 20cm square have been constructed for uses from night time remote reconnaissance and biological single-molecule fluorescence lifetime imaging microscopy, to large area focal plane imagers for Astronomy, neutron detection and ring imaging Cherenkov detection. The large focal plane areas were previously unattainable, but the new developments in construction of ALD microchannel plates allow implementation of formats of 20cm or more. Continuing developments in ALD microchannel plates offer improved overall sealed tube lifetime and gain stability, and furthermore show reduced levels of radiation induced background. High time resolution astronomical and remote sensing applications can be addressed with microchannel plate based imaging, photon time tagging detector sealed tube schemes. Photon counting imaging readouts for these devices vary from cross strip (XS), cross delay line (XDL), to stripline anodes, and pad arrays depending on the intended application. The XS and XDL readouts have been implemented in formats from 22mm, and 50mm to 20cm. Both use MCP charge signals detected on two orthogonal layers of conductive fingers to encode event X-Y positions. XDL readout uses signal propagation delay to encode positions while XS readout uses charge cloud centroiding. Spatial resolution readout of XS detectors can be better than 20 microns FWHM, with good image linearity while using low gain (<10^6), allowing high local counting rates and longer overall tube lifetime. XS tubes with electronics can encode event\n\nWinHPC System | High-Performance Computing | NREL\n\nScience.gov Websites\n\nSystem WinHPC System NREL's WinHPC system is a computing cluster running the Microsoft Windows operating system. It allows users to run jobs requiring a Windows environment such as ANSYS and MATLAB\n\nBacteriocidal activity of sanitizers against Enterococcus faecium attached to stainless steel as determined by plate count and impedance methods.\n\nPubMed\n\nAndrade, N J; Bridgeman, T A; Zottola, E A\n\n1998-07-01\n\nEnterococcus faecium attached to stainless steel chips (100 mm2) was treated with the following sanitizers: sodium hypochlorite, peracetic acid (PA), peracetic acid plus an organic acid (PAS), quaternary ammonium, organic acid, and anionic acid. The effectiveness of sanitizer solutions on planktonic cells (not attached) was evaluated by the Association of Official Analytical Chemists (AOAC) suspension test. The number of attached cells was determined by impedance measurement and plate count method after vortexing. The decimal reduction (DR) in numbers of the E. faecium population was determined for the three methods and was analyzed by analysis of variance (P < 0.05) using Statview software. The adhered cells were more resistant (P < 0.05) than nonadherent cells. The DR averages for all of the sanitizers for 30 s of exposure were 6.4, 2.2, and 2.5 for the AOAC suspension test, plate count method after vortexing, and impedance measurement, respectively. Plate count and impedance methods showed a difference (P < 0.05) after 30 s of sanitizer exposure but not after 2 min. The impedance measurement was the best method to measure adherent cells. Impedance measurement required the development of a quadratic regression. The equation developed from 82 samples is as follows: log CFU/chip = 0.2385T2-0.96T + 9.35, r2 = 0.92, P < 0.05, T = impedance detection time in hours. This method showed that the sanitizers PAS and PA were more effective against E. faecium than the other sanitizers. At 30 s, the impedance method recovered about 25 times more cells than the plate count method after vortexing. These data suggest that impedance measurement is the method of choice when evaluating the number of bacterial cells adhered to a surface.\n\nThe clinical phenotype of hereditary versus sporadic prostate cancer: HPC definition revisited.\n\nPubMed\n\nCremers, Ruben G; Aben, Katja K; van Oort, Inge M; Sedelaar, J P Michiel; Vasen, Hans F; Vermeulen, Sita H; Kiemeney, Lambertus A\n\n2016-07-01\n\nThe definition of hereditary prostate cancer (HPC) is based on family history and age at onset. Intuitively, HPC is a serious subtype of prostate cancer but there are only limited data on the clinical phenotype of HPC. Here, we aimed to compare the prognosis of HPC to the sporadic form of prostate cancer (SPC). HPC patients were identified through a national registry of HPC families in the Netherlands, selecting patients diagnosed from the year 2000 onward (nâ=â324). SPC patients were identified from the Netherlands Cancer Registry (NCR) between 2003 and 2006 for a population-based study into the genetic susceptibility of PC (nâ=â1,664). Detailed clinical data were collected by NCR-registrars, using a standardized registration form. Follow-up extended up to the end of 2013. Differences between the groups were evaluated by cross-tabulations and tested for statistical significance while accounting for familial dependency of observations by GEE. Differences in progression-free and overall survival were evaluated using Ï(2) testing with GEE in a proportional-hazards model. HPC patients were on average 3 years younger at diagnosis, had lower PSA values, lower Gleason scores, and more often locally confined disease. Of the HPC patients, 35% had high-risk disease (NICE-criteria) versus 51% of the SPC patients. HPC patients were less often treated with active surveillance. Kaplan-Meier 5-year progression-free survival after radical prostatectomy was comparable for HPC (78%) and SPC (74%; Pâ=â0.30). The 5-year overall survival was 85% (95%CI 81-89%) for HPC versus 80% (95%CI 78-82%) for SPC (Pâ=â0.03). HPC has a favorable clinical phenotype but patients more often underwent radical treatment. The major limitation of HPC is the absence of a genetics-based definition of HPC, which may lead to over-diagnosis of PC in men with a family history of prostate cancer. The HPC definition should, therefore, be re-evaluated, aiming at a reduction of over-diagnosis and\n\nGraphMeta: Managing HPC Rich Metadata in Graphs\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nDai, Dong; Chen, Yong; Carns, Philip\n\nHigh-performance computing (HPC) systems face increasingly critical metadata management challenges, especially in the approaching exascale era. These challenges arise not only from exploding metadata volumes, but also from increasingly diverse metadata, which contains data provenance and arbitrary user-defined attributes in addition to traditional POSIX metadata. This ârichâ metadata is becoming critical to supporting advanced data management functionality such as data auditing and validation. In our prior work, we identified a graph-based model as a promising solution to uniformly manage HPC rich metadata due to its flexibility and generality. However, at the same time, graph-based HPC rich metadata anagement also introducesmoreÂ Â» significant challenges to the underlying infrastructure. In this study, we first identify the challenges on the underlying infrastructure to support scalable, high-performance rich metadata management. Based on that, we introduce GraphMeta, a graphbased engine designed for this use case. It achieves performance scalability by introducing a new graph partitioning algorithm and a write-optimal storage engine. We evaluate GraphMeta under both synthetic and real HPC metadata workloads, compare it with other approaches, and demonstrate its advantages in terms of efficiency and usability for rich metadata management in HPC systems.Â«Â less\n\nTwo-dimensional photon-counting detector arrays based on microchannel array plates\n\nNASA Technical Reports Server (NTRS)\n\nTimothy, J. G.; Bybee, R. L.\n\n1975-01-01\n\nThe production of simple and rugged photon-counting detector arrays has been made possible by recent improvements in the performance of the microchannel array plate (MCP) and by the parallel development of compatible electronic readout systems. The construction of proximity-focused MCP arrays of novel design in which photometric information from (n x m) picture elements is read out with a total of (n + m) amplifier and discriminator circuits is described. Results obtained with a breadboard (32 x 32)-element array employing 64 charge-sensitive amplifiers are presented, and the application of systems of this type in spectrometers and cameras for use with ground-based telescopes and on orbiting spacecraft discussed.\n\nUse of simulation tools to illustrate the effect of data management practices for low and negative plate counts on the estimated parameters of microbial reduction models.\n\nPubMed\n\nGarcÃ©s-Vega, Francisco; Marks, Bradley P\n\n2014-08-01\n\nIn the last 20 years, the use of microbial reduction models has expanded significantly, including inactivation (linear and nonlinear), survival, and transfer models. However, a major constraint for model development is the impossibility to directly quantify the number of viable microorganisms below the limit of detection (LOD) for a given study. Different approaches have been used to manage this challenge, including ignoring negative plate counts, using statistical estimations, or applying data transformations. Our objective was to illustrate and quantify the effect of negative plate count data management approaches on parameter estimation for microbial reduction models. Because it is impossible to obtain accurate plate counts below the LOD, we performed simulated experiments to generate synthetic data for both log-linear and Weibull-type microbial reductions. We then applied five different, previously reported data management practices and fit log-linear and Weibull models to the resulting data. The results indicated a significant effect (Î± = 0.05) of the data management practices on the estimated model parameters and performance indicators. For example, when the negative plate counts were replaced by the LOD for log-linear data sets, the slope of the subsequent log-linear model was, on average, 22% smaller than for the original data, the resulting model underpredicted lethality by up to 2.0 log, and the Weibull model was erroneously selected as the most likely correct model for those data. The results demonstrate that it is important to explicitly report LODs and related data management protocols, which can significantly affect model results, interpretation, and utility. Ultimately, we recommend using only the positive plate counts to estimate model parameters for microbial reduction curves and avoiding any data value substitutions or transformations when managing negative plate counts to yield the most accurate model parameters.\n\nModular HPC I/O characterization with Darshan\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nSnyder, Shane; Carns, Philip; Harms, Kevin\n\n2016-11-13\n\nContemporary high-performance computing (HPC) applications encompass a broad range of distinct I/O strategies and are often executed on a number of different compute platforms in their lifetime. These large-scale HPC platforms employ increasingly complex I/O subsystems to provide a suitable level of I/O performance to applications. Tuning I/O workloads for such a system is nontrivial, and the results generally are not portable to other HPC systems. I/O profiling tools can help to address this challenge, but most existing tools only instrument specific components within the I/O subsystem that provide a limited perspective on I/O performance. The increasing diversity of scientificmoreÂ Â» applications and computing platforms calls for greater flexibililty and scope in I/O characterization.Â«Â less\n\nUsing Performance Tools to Support Experiments in HPC Resilience\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nNaughton, III, Thomas J; Boehm, Swen; Engelmann, Christian\n\n2014-01-01\n\nThe high performance computing (HPC) community is working to address fault tolerance and resilience concerns for current and future large scale computing platforms. This is driving enhancements in the programming environ- ments, specifically research on enhancing message passing libraries to support fault tolerant computing capabilities. The community has also recognized that tools for resilience experimentation are greatly lacking. However, we argue that there are several parallels between performance tools and resilience tools . As such, we believe the rich set of HPC performance-focused tools can be extended (repurposed) to benefit the resilience community. In this paper, we describe the initialmoreÂ Â» motivation to leverage standard HPC per- formance analysis techniques to aid in developing diagnostic tools to assist fault tolerance experiments for HPC applications. These diagnosis procedures help to provide context for the system when the errors (failures) occurred. We describe our initial work in leveraging an MPI performance trace tool to assist in provid- ing global context during fault injection experiments. Such tools will assist the HPC resilience community as they extend existing and new application codes to support fault tolerances.Â«Â less\n\nComparison of Primary Models to Predict Microbial Growth by the Plate Count and Absorbance Methods.\n\nPubMed\n\nPla, MarÃ­a-Leonor; Oltra, Sandra; Esteban, MarÃ­a-Dolores; Andreu, Santiago; Palop, Alfredo\n\n2015-01-01\n\nThe selection of a primary model to describe microbial growth in predictive food microbiology often appears to be subjective. The objective of this research was to check the performance of different mathematical models in predicting growth parameters, both by absorbance and plate count methods. For this purpose, growth curves of three different microorganisms (Bacillus cereus, Listeria monocytogenes, and Escherichia coli) grown under the same conditions, but with different initial concentrations each, were analysed. When measuring the microbial growth of each microorganism by optical density, almost all models provided quite high goodness of fit (r(2) > 0.93) for all growth curves. The growth rate remained approximately constant for all growth curves of each microorganism, when considering one growth model, but differences were found among models. Three-phase linear model provided the lowest variation for growth rate values for all three microorganisms. Baranyi model gave a variation marginally higher, despite a much better overall fitting. When measuring the microbial growth by plate count, similar results were obtained. These results provide insight into predictive microbiology and will help food microbiologists and researchers to choose the proper primary growth predictive model.\n\nA streamlined build system foundation for developing HPC software\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nWhite, Chris; Harrison, Cyrus; Hornung, Richard\n\n2017-02-09\n\nBLT bundles custom CMake macros, unit testing frameworks for C++ and Fortran, and a set of smoke tests for common HPC dependencies. The combination of these three provides a foundation for quickly bootstrapping a CMale-based system for developing HPC softward.\n\nRunning ANSYS Fluent on the WinHPC System | High-Performance Computing |\n\nScience.gov Websites\n\n. If you don't have one, see WinHPC system user basics. Check License Use Status Start > All Jason Lustbader. Run Using Fluent Launcher Start Fluent launcher by opening: Start > All Programs &gt . Available node groups can be found from HPC Job Manager. Start > All Programs > Microsoft HPC Pack\n\nLinux containers for fun and profit in HPC\n\nDOE PAGES\n\nPriedhorsky, Reid; Randles, Timothy C.\n\n2017-10-01\n\nThis article outlines options for user-defined software stacks from an HPC perspective. Here, we argue that a lightweight approach based on Linux containers is most suitable for HPC centers because it provides the best balance between maximizing service of user needs and minimizing risks. We also discuss how containers work and several implementations, including Charliecloud, our own open-source solution developed at Los Alamos.\n\nLinux containers for fun and profit in HPC\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nPriedhorsky, Reid; Randles, Timothy C.\n\nThis article outlines options for user-defined software stacks from an HPC perspective. Here, we argue that a lightweight approach based on Linux containers is most suitable for HPC centers because it provides the best balance between maximizing service of user needs and minimizing risks. We also discuss how containers work and several implementations, including Charliecloud, our own open-source solution developed at Los Alamos.\n\nSelective enumeration of propionibacteria in Emmental-type cheese using Petrifilmâ¢ aerobic count plates added to lithium glycerol broth.\n\nPubMed\n\nde Freitas, RosÃ¢ngela; Luiz, LÃ­via M Pinheiro; Alves, Maura Pinheiro; Valence-Bertel, Florence; Nero, LuÃ­s Augusto; de Carvalho, AntÃ´nio Fernandes\n\n2013-08-01\n\nPropionibacteria derived from dairy products are relevant starter cultures for the production of Swiss and Emmental-type cheeses, and the monitoring of which is mandatory for proper quality control. This study aimed to evaluate an alternative procedure to enumerate propionibacteria, in order to develop a reliable and practical methodology to be employed by dairy industries. 2,3,5-triphenyltetrazolium chloride (TTC) inhibitory activity was tested against five reference strains (CIRM 09, 38, 39, 40 and 116); TTC at 0Â·0025% (w/v) was not inhibitory, with the exception of one strain (CIRM 116). Subsequently, the four TTC-resistant strains, three commercial starter cultures (PS-1, PB-I, and CHOO) and twelve Emmental-type cheese samples were subjected to propionibacteria enumeration using Lithium Glycerol (LG) agar, and Petrifilmâ¢ Aerobic Count (AC) plates added to LG broth (anaerobic incubation at 30 Â°C for 7 d). Petrifilmâ¢ AC added to LG broth presented high counts than LG agar (P<0Â·05) for only two reference strains (CIRM 39, and 40) and for all commercial starter cultures. Cheese sample counts obtained by both procedures did not show significant differences (P<0Â·05). Significant correlation indexes were observed between the counts recorded by both methods (P<0Â·05). These results demonstrate the reliability of Petrifilmâ¢ AC plates added to LG broth in enumerating select Propionibacterium spp., despite some limitations observed for specific commercial starter cultures.\n\nMethod for Performing Aerobic Plate Counts of Anhydrous Cosmetics Utilizing Tween 60 and Arlacel 80 as Dispersing Agents\n\nPubMed Central\n\nMcConville, John F.; Anger, Claude B.; Anderson, David W.\n\n1974-01-01\n\nAn aqueous diluent containing Tween 60 and Arlacel 80 gave greater recovery of microorganisms when compared with two common diluents as determined by aerobic plate count of inoculated anhydrous cosmetics. The greater recovery was caused by better dispersion of the anhydrous cosmetics in the diluents. Images PMID:4203790\n\nMixing HTC and HPC Workloads with HTCondor and Slurm\n\nNASA Astrophysics Data System (ADS)\n\nHollowell, C.; Barnett, J.; Caramarcu, C.; Strecker-Kellogg, W.; Wong, A.; Zaytsev, A.\n\n2017-10-01\n\nTraditionally, the RHIC/ATLAS Computing Facility (RACF) at Brookhaven National Laboratory (BNL) has only maintained High Throughput Computing (HTC) resources for our HEP/NP user community. Weâve been using HTCondor as our batch system for many years, as this software is particularly well suited for managing HTC processor farm resources. Recently, the RACF has also begun to design/administrate some High Performance Computing (HPC) systems for a multidisciplinary user community at BNL. In this paper, weâll discuss our experiences using HTCondor and Slurm in an HPC context, and our facilityâs attempts to allow our HTC and HPC processing farms/clusters to make opportunistic use of each otherâs computing resources.\n\nNew Ultra-Efficient HPC Data Center Debuts | News | NREL\n\nScience.gov Websites\n\n. Credit: Dennis Schroeder Scientists and researchers at the U.S. Department of Energy's National Renewable supports the HPC data center and ties its waste heat to the rest of the ESIF. Credit: Dennis Schroeder Warm will be accomplished using NREL's HPC. Credit: Dennis Schroeder Expanding NREL's View into the Unseen\n\nWinHPC System User Basics | High-Performance Computing | NREL\n\nScience.gov Websites\n\nguidance for starting to use this high-performance computing (HPC) system at NREL. Also see WinHPC policies ) when you are finished. Simply quitting Remote Desktop will keep your session active and using resources node). 2. Log in with your NREL.gov username/password. Remember to log out when finished. Mac 1. If you\n\nHPC simulations of shock front evolution for a study of the shock precursor decay in a submicron thick nanocrystalline aluminum\n\nNASA Astrophysics Data System (ADS)\n\nValisetty, R.; Rajendran, A.; Agarwal, G.; Dongare, A.; Ianni, J.; Namburu, R.\n\n2018-07-01\n\nThe Hugoniot elastic limit (HEL, or the shock precursor) decay phenomenon was investigated under an uniaxial strain condition, in a plate-on-plate impact configuration, using large-scale molecular dynamics (MD) high performance computing (HPC) simulations on a multi-billion 5000 Ã thick nanocrystalline aluminum (nc-Al) system with an average grain size of 1000 Ã and at five impact velocities ranging from 0.7 to 1.5 km sâ1.â¯The averaged stress and strain distributions were obtained in the shock frontsâ travel direction using a material conserving atom slicing method. The loading paths in terms of the Rayleigh lines experienced by the atom system in the evolving shock fronts exhibited a strong dependency on the shock stress levels. This dependency decreased as the impact velocity increased from 0.7 to 1.5 km sâ1. By combining the HELs from MD results with plate impact experimental data, the precursor decay for the nc-Al was predicted from nano-to-macro scale thickness range. The evolving shock fronts were characterized in terms of parameters such as the shock front thickness, shock rise time and strain rate. The MD results were further analyzed using a crystal analysis algorithm and a twin dislocation identification method to obtain the densities of the atomistic defects evolving behind the evolving shock fronts. High-fidelity large-scale HPC simulation results showed that certain dislocation partials strongly influenced the elasticâplastic transition response across the HELs. The twinning dislocations increased by more than a factor of 10 during the transition and remained constant under further shock compression.\n\nbirgHPC: creating instant computing clusters for bioinformatics and molecular dynamics.\n\nPubMed\n\nChew, Teong Han; Joyce-Tan, Kwee Hong; Akma, Farizuwana; Shamsir, Mohd Shahir\n\n2011-05-01\n\nbirgHPC, a bootable Linux Live CD has been developed to create high-performance clusters for bioinformatics and molecular dynamics studies using any Local Area Network (LAN)-networked computers. birgHPC features automated hardware and slots detection as well as provides a simple job submission interface. The latest versions of GROMACS, NAMD, mpiBLAST and ClustalW-MPI can be run in parallel by simply booting the birgHPC CD or flash drive from the head node, which immediately positions the rest of the PCs on the network as computing nodes. Thus, a temporary, affordable, scalable and high-performance computing environment can be built by non-computing-based researchers using low-cost commodity hardware. The birgHPC Live CD and relevant user guide are available for free at http://birg1.fbb.utm.my/birghpc.\n\nCorrelation between standard plate count and somatic cell count milk quality results for Wisconsin dairy producers.\n\nPubMed\n\nBorneman, Darand L; Ingham, Steve\n\n2014-05-01\n\nThe objective of this study was to determine if a correlation exists between standard plate count (SPC) and somatic cell count (SCC) monthly reported results for Wisconsin dairy producers. Such a correlation may indicate that Wisconsin producers effectively controlling sanitation and milk temperature (reflected in low SPC) also have implemented good herd health management practices (reflected in low SCC). The SPC and SCC results for all grade A and B dairy producers who submitted results to the Wisconsin Department of Agriculture, Trade, and Consumer Protection, in each month of 2012 were analyzed. Grade A producer SPC results were less dispersed than grade B producer SPC results. Regression analysis showed a highly significant correlation between SPC and SCC, but the R(2) value was very small (0.02-0.03), suggesting that many other factors, besides SCC, influence SPC. Average SCC (across 12 mo) for grade A and B producers decreased with an increase in the number of monthly SPC results (out of 12) that were â¤ 25,000 cfu/mL. A chi-squared test of independence showed that the proportion of monthly SCC results >250,000 cells/mL varied significantly depending on whether the corresponding SPC result was â¤ 25,000 or >25,000 cfu/mL. This significant difference occurred in all months of 2012 for grade A and B producers. The results suggest that a generally consistent level of skill exists across dairy production practices affecting SPC and SCC. Copyright Â© 2014 American Dairy Science Association. Published by Elsevier Inc. All rights reserved.\n\nDevelopment and test of photon-counting microchannel plate detector arrays for use on space telescopes\n\nNASA Technical Reports Server (NTRS)\n\nTimothy, J. G.\n\n1976-01-01\n\nThe full sensitivity, dynamic range, and photometric stability of microchannel array plates(MCP) are incorporated into a photon-counting detection system for space operations. Components of the system include feedback-free MCP's for high gain and saturated output pulse-height distribution with a stable response; multi-anode readout arrays mounted in proximity focus with the output face of the MCP; and multi-layer ceramic headers to provide electrical interface between the anode array in a sealed detector tube and the associated electronics.\n\nA miniaturized counting technique for anaerobic bacteria.\n\nPubMed\n\nSharpe, A N; Pettipher, G L; Lloyd, G R\n\n1976-12-01\n\nA miniaturized counting technique gave results as good as the pour-plate and Most Probable Number (MPN) techniques for enumeration of clostridia spp. and anaerobic isolates from the gut. Highest counts were obtained when ascorbic acid (1%) and dithiothreitol (0.015%) were added to the reinforced clostridial medium used for counting. This minimized the effect of exposure to air before incubation. The miniature technique allowed up to 40 samples to be plated and incubated in one McIntosh-Filde's-type anaerobic jar, compared with 3 or 4 by the normal pour plate.\n\nPATHOGENICITY OF DRINKING WATER ISOLATES OF HETEROTROPHIC BACTERIA WITH PUTATIVE VIRULENCE FACTORS\n\nEPA Science Inventory\n\nAlthough the heterotrophic plate count (HPC) bacteria normally found in potable water are not a threat to the healthy population, some of them may be opportunistic pathogens that could cause adverse health effects in individuals with impaired immune systems. Earlier studies of t...\n\nHigh Performance Computing Innovation Service Portal Study (HPC-ISP)\n\nDTIC Science & Technology\n\n2009-04-01\n\nthreatened by global competition. It is essential that these suppliers remain competitive and maintain their technological advantage . In this increasingly...place themselves, as well as customers who rely on them, in competitive jeopardy. Despite the potential competitive advantage associated with adopting...computing users into the HPC fold and to enable more entry-level users to exploit HPC more fully for competitive advantage . About half of the surveyed\n\nComparison of bulk-tank standard plate count and somatic cell count for Wisconsin dairy farms in three size categories.\n\nPubMed\n\nIngham, S C; Hu, Y; AnÃ©, C\n\n2011-08-01\n\nThe objective of this study was to evaluate possible claims by advocates of small-scale dairy farming that milk from smaller Wisconsin farms is of higher quality than milk from larger Wisconsin farms. Reported bulk tank standard plate count (SPC) and somatic cell count (SCC) test results for Wisconsin dairy farms were obtained for February to December, 2008. Farms were sorted into 3 size categories using available size-tracking criteria: small (â¤118 cows; 12,866 farms), large (119-713 cattle; 1,565 farms), and confined animal feeding operations (â¥714 cattle; 160 farms). Group means were calculated (group=farm size category) for the farms' minimum, median, mean, 90th percentile, and maximum SPC and SCC. Statistical analysis showed that group means for median, mean, 90th percentile, and maximum SPC and SCC were almost always significantly higher for the small farm category than for the large farm and confined animal feeding operations farm categories. With SPC and SCC as quality criteria and the 3 farm size categories of â¤118, 119 to 713, and â¥714 cattle, the claim of Wisconsin smaller farms producing higher quality milk than Wisconsin larger farms cannot be supported. Copyright Â© 2011 American Dairy Science Association. Published by Elsevier Inc. All rights reserved.\n\nEnabling parallel simulation of large-scale HPC network systems\n\nDOE PAGES\n\nMubarak, Misbah; Carothers, Christopher D.; Ross, Robert B.; ...\n\n2016-04-07\n\nHere, with the increasing complexity of todayâs high-performance computing (HPC) architectures, simulation has become an indispensable tool for exploring the design space of HPC systemsâin particular, networks. In order to make effective design decisions, simulations of these systems must possess the following properties: (1) have high accuracy and fidelity, (2) produce results in a timely manner, and (3) be able to analyze a broad range of network workloads. Most state-of-the-art HPC network simulation frameworks, however, are constrained in one or more of these areas. In this work, we present a simulation framework for modeling two important classes of networks usedmoreÂ Â» in todayâs IBM and Cray supercomputers: torus and dragonfly networks. We use the Co-Design of Multi-layer Exascale Storage Architecture (CODES) simulation framework to simulate these network topologies at a flit-level detail using the Rensselaer Optimistic Simulation System (ROSS) for parallel discrete-event simulation. Our simulation framework meets all the requirements of a practical network simulation and can assist network designers in design space exploration. First, it uses validated and detailed flit-level network models to provide an accurate and high-fidelity network simulation. Second, instead of relying on serial time-stepped or traditional conservative discrete-event simulations that limit simulation scalability and efficiency, we use the optimistic event-scheduling capability of ROSS to achieve efficient and scalable HPC network simulations on todayâs high-performance cluster systems. Third, our models give network designers a choice in simulating a broad range of network workloads, including HPC application workloads using detailed network traces, an ability that is rarely offered in parallel with high-fidelity network simulationsÂ«Â less\n\nEnabling parallel simulation of large-scale HPC network systems\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nMubarak, Misbah; Carothers, Christopher D.; Ross, Robert B.\n\nHere, with the increasing complexity of todayâs high-performance computing (HPC) architectures, simulation has become an indispensable tool for exploring the design space of HPC systemsâin particular, networks. In order to make effective design decisions, simulations of these systems must possess the following properties: (1) have high accuracy and fidelity, (2) produce results in a timely manner, and (3) be able to analyze a broad range of network workloads. Most state-of-the-art HPC network simulation frameworks, however, are constrained in one or more of these areas. In this work, we present a simulation framework for modeling two important classes of networks usedmoreÂ Â» in todayâs IBM and Cray supercomputers: torus and dragonfly networks. We use the Co-Design of Multi-layer Exascale Storage Architecture (CODES) simulation framework to simulate these network topologies at a flit-level detail using the Rensselaer Optimistic Simulation System (ROSS) for parallel discrete-event simulation. Our simulation framework meets all the requirements of a practical network simulation and can assist network designers in design space exploration. First, it uses validated and detailed flit-level network models to provide an accurate and high-fidelity network simulation. Second, instead of relying on serial time-stepped or traditional conservative discrete-event simulations that limit simulation scalability and efficiency, we use the optimistic event-scheduling capability of ROSS to achieve efficient and scalable HPC network simulations on todayâs high-performance cluster systems. Third, our models give network designers a choice in simulating a broad range of network workloads, including HPC application workloads using detailed network traces, an ability that is rarely offered in parallel with high-fidelity network simulationsÂ«Â less\n\n40 CFR 141.72 - Disinfection.\n\nCode of Federal Regulations, 2011 CFR\n\n2011-07-01\n\n... serves water to the public. Water in the distribution system with a heterotrophic bacteria concentration... heterotrophic bacteria plate count (HPC) is measured; c=number of instances where the residual disinfectant... system with a heterotrophic bacteria concentration less than or equal to 500/ml, measured as...\n\n40 CFR 141.72 - Disinfection.\n\nCode of Federal Regulations, 2013 CFR\n\n2013-07-01\n\n... serves water to the public. Water in the distribution system with a heterotrophic bacteria concentration... heterotrophic bacteria plate count (HPC) is measured; c=number of instances where the residual disinfectant... system with a heterotrophic bacteria concentration less than or equal to 500/ml, measured as...\n\nCould Blobs Fuel Storage-Based Convergence between HPC and Big Data?\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nMatri, Pierre; Alforov, Yevhen; Brandon, Alvaro\n\nThe increasingly growing data sets processed on HPC platforms raise major challenges for the underlying storage layer. A promising alternative to POSIX-IO- compliant file systems are simpler blobs (binary large objects), or object storage systems. Such systems offer lower overhead and better performance at the cost of largely unused features such as file hierarchies or permissions. Similarly, blobs are increasingly considered for replacing distributed file systems for big data analytics or as a base for storage abstractions such as key-value stores or time-series databases. This growing interest in such object storage on HPC and big data platforms raises the question:moreÂ Â» Are blobs the right level of abstraction to enable storage-based convergence between HPC and Big Data? In this paper we study the impact of blob-based storage for real-world applications on HPC and cloud environments. The results show that blobbased storage convergence is possible, leading to a significant performance improvement on both platformsÂ«Â less\n\nMicrobiological assessment of house and imported bottled water by comparison of bacterial endotoxin concentration, heterotrophic plate count, and fecal coliform count.\n\nPubMed\n\nReyes, Mayra I; PÃ©rez, Cynthia M; NegrÃ³n, Edna L\n\n2008-03-01\n\nConsumers increasingly use bottled water and home water treatment systems to avoid direct tap water. According to the International Bottled Water Association (IBWA), an industry trade group, 5 billion gallons of bottled water were consumed by North Americans in 2001. The principal aim of this study was to assess the microbial quality of in-house and imported bottled water for human consumption, by measurement and comparison of the concentration of bacterial endotoxin and standard cultivable methods of indicator microorganisms, specifically, heterotrophic and fecal coliform plate counts. A total of 21 brands of commercial bottled water, consisting of 10 imported and 11 in-house brands, selected at random from 96 brands that are consumed in Puerto Rico, were tested at three different time intervals. The Standard Limulus Amebocyte Lysate test, gel clot method, was used to measure the endotoxin concentrations. The minimum endotoxin concentration in 63 water samples was less than 0.0625 EU/mL, while the maximum was 32 EU/mL. The minimum bacterial count showed no growth, while the maximum was 7,500 CFU/mL. Bacterial isolates like P. fluorescens, Corynebacterium sp. J-K, S. paucimobilis, P. versicularis, A. baumannii, P. chlororaphis, F. indologenes, A. faecalis and P. cepacia were identified. Repeated measures analysis of variance demonstrated that endotoxin concentration did not change over time, while there was a statistically significant (p < 0.05) decrease in bacterial count over time. In addition, multiple linear regression analysis demonstrated that a unit change in the concentration of endotoxin across time was associated with a significant (p < 0.05) reduction in the bacteriological cell count. This analysis evidenced a significant time effect in the average log bacteriological cell count. Although bacterial growth was not detected in some water samples, endotoxin was present. Measurement of Gram-negative bacterial endotoxins is one of the methods that have been\n\nComparison of viable plate count, turbidity measurement and real-time PCR for quantification of Porphyromonas gingivalis.\n\nPubMed\n\nClais, S; Boulet, G; Van Kerckhoven, M; Lanckacker, E; Delputte, P; Maes, L; Cos, P\n\n2015-01-01\n\nThe viable plate count (VPC) is considered as the reference method for bacterial enumeration in periodontal microbiology but shows some important limitations for anaerobic bacteria. As anaerobes such as Porphyromonas gingivalis are difficult to culture, VPC becomes time-consuming and less sensitive. Hence, efficient normalization of experimental data to bacterial cell count requires alternative rapid and reliable quantification methods. This study compared the performance of VPC with that of turbidity measurement and real-time PCR (qPCR) in an experimental context using highly concentrated bacterial suspensions. Our TaqMan-based qPCR assay for P.Â gingivalis 16S rRNA proved to be sensitive and specific. Turbidity measurements offer a fast method to assess P.Â gingivalis growth, but suffer from high variability and a limited dynamic range. VPC was very time-consuming and less repeatable than qPCR. Our study concludes that qPCR provides the most rapid and precise approach for P.Â gingivalis quantification. Although our data were gathered in a specific research context, we believe that our conclusions on the inferior performance of VPC and turbidity measurements in comparison to qPCR can be extended to other research and clinical settings and even to other difficult-to-culture micro-organisms. Various clinical and research settings require fast and reliable quantification of bacterial suspensions. The viable plate count method (VPC) is generally seen as 'the gold standard' for bacterial enumeration. However, VPC-based quantification of anaerobes such as Porphyromonas gingivalis is time-consuming due to their stringent growth requirements and shows poor repeatability. Comparison of VPC, turbidity measurement and TaqMan-based qPCR demonstrated that qPCR possesses important advantages regarding speed, accuracy and repeatability. Â© 2014 The Society for Applied Microbiology.\n\nNREL, Sandia, and Johnson Controls See Significant Water Savings for HPC\n\nScience.gov Websites\n\nCooling | Energy Systems Integration Facility | NREL NREL, Sandia and Johnson Controls save 1M Gallons of Water a Year for HPC Cooling NREL, Sandia, and Johnson Controls See Significant Water Savings for HPC Cooling NREL partnered with Sandia National Laboratories and Johnson Controls to install the\n\nTrends in data locality abstractions for HPC systems\n\nDOE PAGES\n\nUnat, Didem; Dubey, Anshu; Hoefler, Torsten; ...\n\n2017-05-10\n\nThe cost of data movement has always been an important concern in high performance computing (HPC) systems. It has now become the dominant factor in terms of both energy consumption and performance. Support for expression of data locality has been explored in the past, but those efforts have had only modest success in being adopted in HPC applications for various reasons. However, with the increasing complexity of the memory hierarchy and higher parallelism in emerging HPC systems, locality management has acquired a new urgency. Developers can no longer limit themselves to low-level solutions and ignore the potential for productivity andmoreÂ Â» performance portability obtained by using locality abstractions. Fortunately, the trend emerging in recent literature on the topic alleviates many of the concerns that got in the way of their adoption by application developers. Data locality abstractions are available in the forms of libraries, data structures, languages and runtime systems; a common theme is increasing productivity without sacrificing performance. Furthermore, this paper examines these trends and identifies commonalities that can combine various locality concepts to develop a comprehensive approach to expressing and managing data locality on future large-scale high-performance computing systems.Â«Â less\n\nFingerprinting Communication and Computation on HPC Machines\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nPeisert, Sean\n\n2010-06-02\n\nHow do we identify what is actually running on high-performance computing systems? Names of binaries, dynamic libraries loaded, or other elements in a submission to a batch queue can give clues, but binary names can be changed, and libraries provide limited insight and resolution on the code being run. In this paper, we present a method for\"fingerprinting\" code running on HPC machines using elements of communication and computation. We then discuss how that fingerprint can be used to determine if the code is consistent with certain other types of codes, what a user usually runs, or what the user requestedmoreÂ Â» an allocation to do. In some cases, our techniques enable us to fingerprint HPC codes using runtime MPI data with a high degree of accuracy.Â«Â less\n\nHPC Annual Report 2017\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nDennig, Yasmin\n\nSandia National Laboratories has a long history of significant contributions to the high performance community and industry. Our innovative computer architectures allowed the United States to become the first to break the teraFLOP barrierâpropelling us to the international spotlight. Our advanced simulation and modeling capabilities have been integral in high consequence US operations such as Operation Burnt Frost. Strong partnerships with industry leaders, such as Cray, Inc. and Goodyear, have enabled them to leverage our high performance computing (HPC) capabilities to gain a tremendous competitive edge in the marketplace. As part of our continuing commitment to providing modern computing infrastructuremoreÂ Â» and systems in support of Sandia missions, we made a major investment in expanding Building 725 to serve as the new home of HPC systems at Sandia. Work is expected to be completed in 2018 and will result in a modern facility of approximately 15,000 square feet of computer center space. The facility will be ready to house the newest National Nuclear Security Administration/Advanced Simulation and Computing (NNSA/ASC) Prototype platform being acquired by Sandia, with delivery in late 2019 or early 2020. This new system will enable continuing advances by Sandia science and engineering staff in the areas of operating system R&D, operation cost effectiveness (power and innovative cooling technologies), user environment and application code performance.Â«Â less\n\nThe effect of an antibacterial washing-up liquid in reducing dishwater aerobic plate counts.\n\nPubMed\n\nHolah, J T; Hall, K E\n\n2006-05-01\n\nTo assess any significant differences in the aerobic plate count (APC) of catering dishwaters following the use of a traditional, nonantibacterial or an antibacterial washing-up liquid. A dishwashing trial was undertaken within a commercial restaurant of 6 weeks duration (3 weeks with each washing-up liquid in a randomized, weekly pattern). Five replicate samples were taken from the dishwater at the end of the washing-up operation, on three separate occasions each day corresponding to mid-morning, lunchtime and mid-afternoon meal preparations. The antibacterial product was shown to significantly reduce the APC by an average log10 reduction of 1.81 CFU ml(-1) (98.5%) as compared with the traditional product. APC were lower for each of the three weekly time periods for the antibacterial product. Continued use of the antibacterial product did not decrease the APC of the dishwater, though with the traditional product, dishwater counts increased throughout the trial week. Antibacterial washing-up liquids, with proven activity in controlling levels of microorganisms in dishwaters, could play a significant role in reducing the risk of cross-contamination between washed articles during washing-up operations.\n\nSTAR Data Reconstruction at NERSC/Cori, an adaptable Docker container approach for HPC\n\nNASA Astrophysics Data System (ADS)\n\nMustafa, Mustafa; Balewski, Jan; Lauret, JÃ©rÃ´me; Porter, Jefferson; Canon, Shane; Gerhardt, Lisa; Hajdu, Levente; Lukascsyk, Mark\n\n2017-10-01\n\nAs HPC facilities grow their resources, adaptation of classic HEP/NP workflows becomes a need. Linux containers may very well offer a way to lower the bar to exploiting such resources and at the time, help collaboration to reach vast elastic resources on such facilities and address their massive current and future data processing challenges. In this proceeding, we showcase STAR data reconstruction workflow at Cori HPC system at NERSC. STAR software is packaged in a Docker image and runs at Cori in Shifter containers. We highlight two of the typical end-to-end optimization challenges for such pipelines: 1) data transfer rate which was carried over ESnet after optimizing end points and 2) scalable deployment of conditions database in an HPC environment. Our tests demonstrate equally efficient data processing workflows on Cori/HPC, comparable to standard Linux clusters.\n\nPerformance testing of HPC on Sunshine Bridge.\n\nDOT National Transportation Integrated Search\n\n2009-09-01\n\nThe deck of the Sunshine Bridge overpass, located westbound on Interstate 40 (I-40) near Winslow, Arizona, was : replaced on August 24, 2005. The original deteriorated concrete deck was replaced using high performance : concrete (HPC), reinforced wit...\n\nHPC-Microgels: New Look at Structure and Dynamics\n\nNASA Astrophysics Data System (ADS)\n\nMcKenna, John; Streletzky, Kiril; Mohieddine, Rami\n\n2006-10-01\n\nIssues remain unresolved in targeted chemotherapy including: an inability to effectively target cancerous tissue, the loss of low molecular weight medicines to the RES system, the high cytotoxicity of currently used drug carriers, and the inability to control the release of medicines upon arrival to the target. Hydroxy-propyl cellulose(HPC) microgels may be able to surmount these obstacles. HPC is a high molecular weight polymer with low cytotoxicity and a critical temperature around 41C. We cross-linked HPC polymer chains to produce microgel nanoparticles and studied their structure and dynamics using Dynamic Light Scattering spectroscopy. The complex nature of the fluid and large size distribution of the particles renders typical characterization algorithm CONTIN ineffective and inconsistent. Instead, the particles spectra have been fit to a sum of stretched exponentials. Each term offers three parameters for analysis and represents a single mode. The results of this analysis show that the microgels undergo a multi to uni-modal transition around 41C. The CONTIN size distribution analysis shows similar results, but these come with much less consistency and resolution. During the phase transition it is found that the microgel particles actually shrink. This property might be particularly useful for controlled drug delivery and release.\n\nHydrophilic-treated plastic plates for wide-range analysis of Giemsa-stained red blood cells and automated Plasmodium infection rate counting.\n\nPubMed\n\nHashimoto, Muneaki; Yatsushiro, Shouki; Yamamura, Shohei; Tanaka, Masato; Sakamoto, Hirokazu; Ido, Yusuke; Kajimoto, Kazuaki; Bando, Mika; Kido, Jun-Ichi; Kataoka, Masatoshi\n\n2017-08-08\n\nMalaria is a red blood cell (RBC) infection caused by Plasmodium parasites. To determine RBC infection rate, which is essential for malaria study and diagnosis, microscopic evaluation of Giemsa-stained thin blood smears on glass slides ('Giemsa microscopy') has been performed as the accepted gold standard for over 100Â years. However, only a small area of the blood smear provides a monolayer of RBCs suitable for determination of infection rate, which is one of the major reasons for the low parasite detection rate by Giemsa microscopy. In addition, because Giemsa microscopy is exacting and time-consuming, automated counting of infection rates is highly desirable. A method that allows for microscopic examination of Giemsa-stained cells spread in a monolayer on almost the whole surface of hydrophilic-treated cyclic olefin copolymer (COC) plates was established. Because wide-range Giemsa microscopy can be performed on a hydrophilic-treated plate, the method may enable more reliable diagnosis of malaria in patients with low parasitaemia burden. Furthermore, the number of RBCs and parasites stained with a fluorescent nuclear staining dye could be counted automatically with a software tool, without Giemsa staining. As a result, researchers studying malaria may calculate the infection rate easily, rapidly, and accurately even in low parasitaemia. Because the running cost of these methods is very low and they do not involve complicated techniques, the use of hydrophilic COC plates may contribute to improved and more accurate diagnosis and research of malaria.\n\nWinHPC System Software | High-Performance Computing | NREL\n\nScience.gov Websites\n\nSoftware WinHPC System Software Learn about the software applications, tools, toolchains, and for industrial applications. Intel Compilers Development Tool, Toolchain Suite featuring an industry\n\nInternational Energy Agency's Heat Pump Centre (IEA-HPC) Annual National Team Working Group Meeting\n\nNASA Astrophysics Data System (ADS)\n\nBroders, M. A.\n\n1992-09-01\n\nThe traveler, serving as Delegate from the United States Advanced Heat Pump National Team, participated in the activities of the fourth IEA-HPC National Team Working Group meeting. Highlights of this meeting included review and discussion of 1992 IEA-HPC activities and accomplishments, introduction of the Switzerland National Team, and development of the 1993 IEA-HPC work program. The traveler also gave a formal presentation about the Development and Activities of the IEA Advanced Heat Pump U.S. National Team.\n\nProteomic analysis of cPKCÎ²II-interacting proteins involved in HPC-induced neuroprotection against cerebral ischemia of mice.\n\nPubMed\n\nBu, Xiangning; Zhang, Nan; Yang, Xuan; Liu, Yanyan; Du, Jianli; Liang, Jing; Xu, Qunyuan; Li, Junfa\n\n2011-04-01\n\nHypoxic preconditioning (HPC) initiates intracellular signaling pathway to provide protection against subsequent cerebral ischemic injuries, and its mechanism may provide molecular targets for therapy in stroke. According to our study of conventional protein kinase C Î²II (cPKCÎ²II) activation in HPC, the role of cPKCÎ²II in HPC-induced neuroprotection and its interacting proteins were determined in this study. The autohypoxia-induced HPC and middle cerebral artery occlusion (MCAO)-induced cerebral ischemia mouse models were prepared as reported. We found that HPC reduced 6 h MCAO-induced neurological deficits, infarct volume, edema ratio and cell apoptosis in peri-infarct region (penumbra), but cPKCÎ²II inhibitors Go6983 and LY333531 blocked HPC-induced neuroprotection. Proteomic analysis revealed that the expression of four proteins in cytosol and eight proteins in particulate fraction changed significantly among 49 identified cPKCÎ²II-interacting proteins in cortex of HPC mice. In addition, HPC could inhibit the decrease of phosphorylated collapsin response mediator protein-2 (CRMP-2) level and increase of CRMP-2 breakdown product. TAT-CRMP-2 peptide, which prevents the cleavage of endogenous CRMP-2, could inhibit CRMP-2 dephosphorylation and proteolysis as well as the infarct volume of 6 h MCAO mice. This study is the first to report multiple cPKCÎ²II-interacting proteins in HPC mouse brain and the role of cPKCÎ²II-CRMP-2 in HPC-induced neuroprotection against early stages of ischemic injuries in mice. Â© 2011 The Authors. Journal of Neurochemistry Â© 2011 International Society for Neurochemistry.\n\n75 FR 59067 - Airworthiness Directives; International Aero Engines AG V2500-A1, V2522-A5, V2524-A5, V2525-D5...\n\nFederal Register 2010, 2011, 2012, 2013, 2014\n\n2010-09-27\n\n... plated nuts attaching the HPC stage 3 to 8 drum to the HPC stage 9 to 12 drum, removal of silver residue... plated nuts attaching the HPC stage 3 to 8 drum to the HPC stage 9 to 12 drum, removal of silver residue... AD, removal from service of the fully silver plated nuts attaching the HPC stage 3 to 8 drum to the...\n\nTowards Cloud-based Asynchronous Elasticity for Iterative HPC Applications\n\nNASA Astrophysics Data System (ADS)\n\nda Rosa Righi, Rodrigo; Facco Rodrigues, Vinicius; AndrÃ© da Costa, Cristiano; Kreutz, Diego; Heiss, Hans-Ulrich\n\n2015-10-01\n\nElasticity is one of the key features of cloud computing. It allows applications to dynamically scale computing and storage resources, avoiding over- and under-provisioning. In high performance computing (HPC), initiatives are normally modeled to handle bag-of-tasks or key-value applications through a load balancer and a loosely-coupled set of virtual machine (VM) instances. In the joint-field of Message Passing Interface (MPI) and tightly-coupled HPC applications, we observe the need of rewriting source codes, previous knowledge of the application and/or stop-reconfigure-and-go approaches to address cloud elasticity. Besides, there are problems related to how profit this new feature in the HPC scope, since in MPI 2.0 applications the programmers need to handle communicators by themselves, and a sudden consolidation of a VM, together with a process, can compromise the entire execution. To address these issues, we propose a PaaS-based elasticity model, named AutoElastic. It acts as a middleware that allows iterative HPC applications to take advantage of dynamic resource provisioning of cloud infrastructures without any major modification. AutoElastic provides a new concept denoted here as asynchronous elasticity, i.e., it provides a framework to allow applications to either increase or decrease their computing resources without blocking the current execution. The feasibility of AutoElastic is demonstrated through a prototype that runs a CPU-bound numerical integration application on top of the OpenNebula middleware. The results showed the saving of about 3 min at each scaling out operations, emphasizing the contribution of the new concept on contexts where seconds are precious.\n\nUser-level framework for performance monitoring of HPC applications\n\nNASA Astrophysics Data System (ADS)\n\nHristova, R.; Goranov, G.\n\n2013-10-01\n\nHP-SEE is an infrastructure that links the existing HPC facilities in South East Europe in a common infrastructure. The analysis of the performance monitoring of the High-Performance Computing (HPC) applications in the infrastructure can be useful for the end user as diagnostic for the overall performance of his applications. The existing monitoring tools for HP-SEE provide to the end user only aggregated information for all applications. Usually, the user does not have permissions to select only the relevant information for him and for his applications. In this article we present a framework for performance monitoring of the HPC applications in the HP-SEE infrastructure. The framework provides standardized performance metrics, which every user can use in order to monitor his applications. Furthermore as a part of the framework a program interface is developed. The interface allows the user to publish metrics data from his application and to read and analyze gathered information. Publishing and reading through the framework is possible only with grid certificate valid for the infrastructure. Therefore the user is authorized to access only the data for his applications.\n\nComparative performance of conventional OPC concrete and HPC designed by densified mixture design algorithm\n\nNASA Astrophysics Data System (ADS)\n\nHuynh, Trong-Phuoc; Hwang, Chao-Lung; Yang, Shu-Ti\n\n2017-12-01\n\nThis experimental study evaluated the performance of normal ordinary Portland cement (OPC) concrete and high-performance concrete (HPC) that were designed by the conventional method (ACI) and densified mixture design algorithm (DMDA) method, respectively. Engineering properties and durability performance of both the OPC and HPC samples were studied using the tests of workability, compressive strength, water absorption, ultrasonic pulse velocity, and electrical surface resistivity. Test results show that the HPC performed good fresh property and further showed better performance in terms of strength and durability as compared to the OPC.\n\nDetecting swift fox: Smoked-plate scent stations versus spotlighting\n\nTreesearch\n\nDaniel W. Uresk; Kieth E. Severson; Jody Javersak\n\n2003-01-01\n\nWe compared two methods of detecting presence of swift fox: smoked-plate scent stations and spotlight counts. Tracks were counted on ten 1-mile (1.6-km) transects with bait/tracking plate stations every 0.1 mile (0.16 km). Vehicle spotlight counts were conducted on the same transects. Methods were compared with Spearman's rank order correlation. Repeated measures...\n\nPerm State University HPC-hardware and software services: capabilities for aircraft engine aeroacoustics problems solving\n\nNASA Astrophysics Data System (ADS)\n\nDemenev, A. G.\n\n2018-02-01\n\nThe present work is devoted to analyze high-performance computing (HPC) infrastructure capabilities for aircraft engine aeroacoustics problems solving at Perm State University. We explore here the ability to develop new computational aeroacoustics methods/solvers for computer-aided engineering (CAE) systems to handle complicated industrial problems of engine noise prediction. Leading aircraft engine engineering company, including âUEC-Aviadvigatelâ JSC (our industrial partners in Perm, Russia), require that methods/solvers to optimize geometry of aircraft engine for fan noise reduction. We analysed Perm State University HPC-hardware resources and software services to use efficiently. The performed results demonstrate that Perm State University HPC-infrastructure are mature enough to face out industrial-like problems of development CAE-system with HPC-method and CFD-solvers.\n\nPerformance of high performance concrete (HPC) in low pH and sulfate environment : [technical summary].\n\nDOT National Transportation Integrated Search\n\n2013-01-01\n\nHigh-performance concrete (HPC) refers to any concrete formulation with enhanced characteristics, compared to normal concrete. One might think this refers to strength, but in Florida, the HPC standard emphasizes withstanding aggressive environments, ...\n\nImproved methods for the enumeration of heterotrophic bacteria in bottled mineral waters.\n\nPubMed\n\nRamalho, R; Cunha, J; Teixeira, P; Gibbs, P A\n\n2001-03-01\n\nAt this time the European Union regulations require that the heterotrophic plate counts (HPC) of mineral waters be assessed at two recovery temperatures: 22 degrees C for 72 h and 37 degrees C for 24 h. This procedure is time consuming and expensive. Development of new rapid methods for microbiological assessment of the microbial flora in the bottled water is an industry-driven need. The objectives of this work were to develop a method for the HPC that utilises only one recovery temperature and one incubation period and evaluate the use of, the LIVE/DEAD(R) BacLight Bacterial Viability Kit, 5-cyano-2,3-ditotyl tetrazolium chloride (CTC) and impedance methods to enumerate viable bacteria in bottled mineral water. Results showed that incubation at 30 degrees C could be used instead of incubation at 22 degrees C and 37 degrees C. Good correlation exists between counts at 30 degrees C and counts at 22 degrees C (r>0.90) and all the pathogens important in mineral water analyses grow similarly at 30 degrees C and 37 degrees C during 24 h. It was demonstrated that impedance methods might be useful to the mineral water industry as a rapid indicator of microbiological quality of the water. Results obtained with BacLight and CTC were similar to those obtained with plate counts.\n\nComparison of solid-phase cytometry and the plate count method for the evaluation of the survival of bacteria in pharmaceutical oils.\n\nPubMed\n\nDe Prijck, K; Peeters, E; Nelis, H J\n\n2008-12-01\n\nTo compare the survival of four bacterial strains (Escherichia coli, Proteus mirabilis, Staphylococcus aureus, Pseudomonas aeruginosa) in pharmaceutical oils, including jojoba oil/tea tree oil, carbol oil, jojoba oil and sesame oil. Oils were spiked with the test bacteria in a concentration of 10(4) CFU ml(-1). Bacteria were extracted from oils with phosphate-buffered saline containing 0.5% Tween 20. Aliquots of the pooled water layers were analysed by solid-phase cytometry and plate counting. Plate counts dropped to zero for all test strains exposed for 24 h to three of the four oils. In contrast, significant numbers of viable cells were still detected by SPC, except in the jojoba oil/tea tree oil mixture and partly in sesame oil. Exposure of bacteria for 24 h to the two oils containing an antimicrobial led to a loss of their culturability but not necessarily of their viability. The antibacterial activity of the jojoba oil/tea tree oil mixture supersedes that of carbol oil. These in vitro data suggest that the jojoba oil/tea tree oil mixture more than carbol oil inhibits bacterial proliferation when used for intermittent self-catherization.\n\nA framework for graph-based synthesis, analysis, and visualization of HPC cluster job data.\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nMayo, Jackson R.; Kegelmeyer, W. Philip, Jr.; Wong, Matthew H.\n\nThe monitoring and system analysis of high performance computing (HPC) clusters is of increasing importance to the HPC community. Analysis of HPC job data can be used to characterize system usage and diagnose and examine failure modes and their effects. This analysis is not straightforward, however, due to the complex relationships that exist between jobs. These relationships are based on a number of factors, including shared compute nodes between jobs, proximity of jobs in time, etc. Graph-based techniques represent an approach that is particularly well suited to this problem, and provide an effective technique for discovering important relationships in jobmoreÂ Â» queuing and execution data. The efficacy of these techniques is rooted in the use of a semantic graph as a knowledge representation tool. In a semantic graph job data, represented in a combination of numerical and textual forms, can be flexibly processed into edges, with corresponding weights, expressing relationships between jobs, nodes, users, and other relevant entities. This graph-based representation permits formal manipulation by a number of analysis algorithms. This report presents a methodology and software implementation that leverages semantic graph-based techniques for the system-level monitoring and analysis of HPC clusters based on job queuing and execution data. Ontology development and graph synthesis is discussed with respect to the domain of HPC"
    }
}