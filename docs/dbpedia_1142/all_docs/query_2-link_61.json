{
    "id": "dbpedia_1142_2",
    "rank": 61,
    "data": {
        "url": "https://nips.cc/virtual/2023/events/spotlight-posters-2023",
        "read_more_link": "",
        "language": "en",
        "title": "NeurIPS 2023 Spotlight Posters",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://nips.cc/static/core/img/neurips-navbar-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73425-thumb.png?t=1702202161.2810826",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70403-thumb.png?t=1696914592.3011677",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72540-thumb.png?t=1701252608.5874212",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71022-thumb.png?t=1701849362.8652437",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73453-thumb.png?t=1701416414.071598",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70086-thumb.png?t=1697171314.1079817",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70103-thumb.png?t=1697079884.7467904",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73722-thumb.png?t=1701818679.758732",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71093-thumb.png?t=1702110458.7849197",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70171-thumb.png?t=1702056912.036062",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72994-thumb.png?t=1699898310.031774",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72256-thumb.png?t=1701706872.2776513",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72911-thumb.png?t=1702178536.0742264",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72296-thumb.png?t=1700237454.0344782",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70520-thumb.png?t=1702392065.9398777",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70734-thumb.png?t=1702229402.4785864",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72247-thumb.png?t=1701836650.439229",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72860-thumb.png?t=1701604378.9974945",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73048-thumb.png?t=1702344574.1544566",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71933-thumb.png?t=1702311429.1628969",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70416-thumb.png?t=1701715523.1969802",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71377-thumb.png?t=1702477253.3204775",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71605-thumb.png?t=1702155300.3790953",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71943-thumb.png?t=1701378369.6921606",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70375-thumb.png?t=1701737880.9824455",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71996-thumb.png?t=1700691160.5333278",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70142-thumb.png?t=1702092300.3168235",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71752-thumb.png?t=1702390528.5258029",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71542-thumb.png?t=1702056211.8027954",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73072-thumb.png?t=1697228594.0541027",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70755-thumb.png?t=1698680302.7800863",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72517-thumb.png?t=1701185231.972139",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71215-thumb.png?t=1702335322.4569485",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70908-thumb.png?t=1701831722.72865",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72416-thumb.png?t=1697712116.0855134",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72028-thumb.png?t=1699555424.1707234",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71784-thumb.png?t=1700625254.4424179",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72520-thumb.png?t=1701561495.2937324",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70694-thumb.png?t=1699982397.719647",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71244-thumb.png?t=1699871487.999814",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72587-thumb.png?t=1701768535.6482239",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72118-thumb.png?t=1699131547.4422717",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71081-thumb.png?t=1698305213.973598",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71697-thumb.png?t=1701754095.7610903",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73420-thumb.png?t=1699591655.6488643",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70211-thumb.png?t=1698700287.9187245",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72715-thumb.png?t=1702355767.9237602",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71975-thumb.png?t=1700004530.030351",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73472-thumb.png?t=1702049923.4565887",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70678-thumb.png?t=1701985569.3903756",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73464-thumb.png?t=1701962720.2042656",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71134-thumb.png?t=1701915870.6628902",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72985-thumb.png?t=1702573089.592618",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72422-thumb.png?t=1701808578.2445805",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72427-thumb.png?t=1702165857.277921",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72790-thumb.png?t=1699614606.9435234",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72817-thumb.png?t=1702311955.8104253",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72982-thumb.png?t=1702047637.8976552",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71403-thumb.png?t=1701615526.1498234",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72943-thumb.png?t=1702081556.2949648",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72847-thumb.png?t=1696890443.2233346",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72591-thumb.png?t=1697183191.7925215",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72972-thumb.png?t=1702677733.9514768",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72404-thumb.png?t=1696926284.765641",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72680-thumb.png?t=1701742949.1532917",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72786-thumb.png?t=1702246729.0169897",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72191-thumb.png?t=1700158779.4415946",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73031-thumb.png?t=1701986492.081954",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72654-thumb.png?t=1702107313.492541",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72769-thumb.png?t=1701900736.6050673",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72499-thumb.png?t=1701364468.4957433",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73080-thumb.png?t=1702110456.45673",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72604-thumb.png?t=1701992462.478645",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72490-thumb.png?t=1701803262.7420402",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72868-thumb.png?t=1700764248.3385186",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71840-thumb.png?t=1700367702.170024",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72632-thumb.png?t=1701890674.1824358",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72959-thumb.png?t=1701672468.622343",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72915-thumb.png?t=1702277601.9955478",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72513-thumb.png?t=1701565807.9856153",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72550-thumb.png?t=1701868032.292955",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72666-thumb.png?t=1701482717.337568",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72903-thumb.png?t=1701378944.9233437",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72444-thumb.png?t=1700191711.169092",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72890-thumb.png?t=1701439753.8267303",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72772-thumb.png?t=1701468528.39064",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72878-thumb.png?t=1702269051.6058128",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72968-thumb.png?t=1702251033.417846",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73019-thumb.png?t=1702317102.7925875",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71693-thumb.png?t=1701421390.7740183",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72055-thumb.png?t=1701988567.2879682",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72038-thumb.png?t=1702236260.6982582",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72293-thumb.png?t=1702479904.3053036",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71907-thumb.png?t=1702171704.0718977",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73054-thumb.png?t=1697528205.60491",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72017-thumb.png?t=1701509254.6813083",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72380-thumb.png?t=1702204062.5481846",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72030-thumb.png?t=1701740123.1459298",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71991-thumb.png?t=1701914769.6889563",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72127-thumb.png?t=1701680815.8085413",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72077-thumb.png?t=1701217835.616582",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72058-thumb.png?t=1702074743.2103667",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71831-thumb.png?t=1702078723.6036072",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71688-thumb.png?t=1701702800.4249387",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72015-thumb.png?t=1701268686.0790231",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71812-thumb.png?t=1701687771.2176948",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72046-thumb.png?t=1701747406.1103938",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72272-thumb.png?t=1699840985.8477323",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72356-thumb.png?t=1701272239.7458715",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71967-thumb.png?t=1699740313.5149221",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72814-thumb.png?t=1698446317.0889177",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72349-thumb.png?t=1702220263.2581565",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72060-thumb.png?t=1702227915.8766148",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72158-thumb.png?t=1701746967.7744782",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71710-thumb.png?t=1703185125.076923",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72043-thumb.png?t=1702054400.9628007",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72368-thumb.png?t=1699866495.4993877",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72299-thumb.png?t=1700601942.0007596",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72277-thumb.png?t=1701466693.9847958",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71822-thumb.png?t=1702261735.3226874",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71961-thumb.png?t=1699838715.626634",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72098-thumb.png?t=1702269998.3994284",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71729-thumb.png?t=1701856551.4718661",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72318-thumb.png?t=1700857276.9563384",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72298-thumb.png?t=1699334639.2100453",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71736-thumb.png?t=1702002546.627076",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71995-thumb.png?t=1701895735.568034",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72262-thumb.png?t=1701885730.605845",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72391-thumb.png?t=1700986832.115087",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70059-thumb.png?t=1701900326.387539",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71875-thumb.png?t=1702237614.4734826",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72390-thumb.png?t=1701960274.432292",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72220-thumb.png?t=1699755839.0814335",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71783-thumb.png?t=1701938122.570914",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72258-thumb.png?t=1697447403.2631981",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72294-thumb.png?t=1698753659.1976643",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72136-thumb.png?t=1701403065.9372535",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71887-thumb.png?t=1701438983.54376",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71847-thumb.png?t=1701715591.3065493",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71939-thumb.png?t=1701075206.7784219",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71956-thumb.png?t=1701430811.2080247",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72178-thumb.png?t=1701781851.4598355",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71700-thumb.png?t=1701486785.1136189",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70218-thumb.png?t=1699542887.975714",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71007-thumb.png?t=1701408763.5466018",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71036-thumb.png?t=1698738386.2725105",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71561-thumb.png?t=1699874820.104098",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71302-thumb.png?t=1702420543.469314",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71338-thumb.png?t=1699489298.8282487",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71319-thumb.png?t=1701607020.4607003",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71051-thumb.png?t=1701832251.0118012",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71589-thumb.png?t=1699440381.066554",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71135-thumb.png?t=1701533591.2102373",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71147-thumb.png?t=1701715820.2132661",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71271-thumb.png?t=1699698130.4282463",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71087-thumb.png?t=1699377876.3087428",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71136-thumb.png?t=1701685108.7958677",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71213-thumb.png?t=1702078367.8465376",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71154-thumb.png?t=1701739073.1759608",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71468-thumb.png?t=1702254247.5892696",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71132-thumb.png?t=1698163953.4924502",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71203-thumb.png?t=1701726405.739612",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71188-thumb.png?t=1701853806.627718",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71333-thumb.png?t=1701792694.953788",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71099-thumb.png?t=1698475338.7148008",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71416-thumb.png?t=1698697633.7740283",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70991-thumb.png?t=1702055981.0119371",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71466-thumb.png?t=1701793162.1440268",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71351-thumb.png?t=1697786582.7100928",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71125-thumb.png?t=1699553824.8476462",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71544-thumb.png?t=1699980544.7839813",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71577-thumb.png?t=1702255022.9368236",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72616-thumb.png?t=1699605844.4612687",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71345-thumb.png?t=1697791042.687296",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71497-thumb.png?t=1699525497.953891",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71667-thumb.png?t=1702310998.6674933",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71056-thumb.png?t=1699028372.2105541",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71070-thumb.png?t=1702008195.937084",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71276-thumb.png?t=1700012490.3890536",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71358-thumb.png?t=1701482342.270928",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71582-thumb.png?t=1701377756.5779572",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71523-thumb.png?t=1699860977.5445325",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71397-thumb.png?t=1697096520.5700564",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71200-thumb.png?t=1697336788.999372",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71015-thumb.png?t=1702438959.9449806",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71411-thumb.png?t=1699197332.7173243",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72083-thumb.png?t=1701382372.4644897",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71546-thumb.png?t=1699601862.235215",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71062-thumb.png?t=1699221848.8639617",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71059-thumb.png?t=1701842943.8731823",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71246-thumb.png?t=1699020573.2646656",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70895-thumb.png?t=1702051436.0162678",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70932-thumb.png?t=1702252563.6312394",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70318-thumb.png?t=1702123776.8026476",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70765-thumb.png?t=1699604395.726636",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70588-thumb.png?t=1701377400.5447967",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70535-thumb.png?t=1702333193.8257008",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70954-thumb.png?t=1701377163.581385",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70397-thumb.png?t=1701961044.411222",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70724-thumb.png?t=1697749405.6474113",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70826-thumb.png?t=1702311913.3308926",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70496-thumb.png?t=1701378034.9407523",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70529-thumb.png?t=1701846204.37939",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70357-thumb.png?t=1697534394.2327204",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71858-thumb.png?t=1698071422.6775618",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70829-thumb.png?t=1697799634.0980868",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70507-thumb.png?t=1701444083.224655",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70443-thumb.png?t=1698200747.4926763",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72500-thumb.png?t=1701397677.8972805",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70778-thumb.png?t=1701834127.32113",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70856-thumb.png?t=1701397656.0714998",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70791-thumb.png?t=1702226561.1894503",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70753-thumb.png?t=1697488904.5651321",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70622-thumb.png?t=1702183943.2804384",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70553-thumb.png?t=1701429363.1216366",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70422-thumb.png?t=1701318116.7875025",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70970-thumb.png?t=1701407535.7423246",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70293-thumb.png?t=1702000600.2678251",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70670-thumb.png?t=1701380557.371509",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70802-thumb.png?t=1701810331.4679477",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70740-thumb.png?t=1701999450.0218012",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70736-thumb.png?t=1701184767.7060544",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70656-thumb.png?t=1701593723.1852844",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70435-thumb.png?t=1701658546.2325406",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70518-thumb.png?t=1702139738.3875268",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70274-thumb.png?t=1698980154.3902972",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70433-thumb.png?t=1701988518.3159597",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70349-thumb.png?t=1701393594.0275273",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70841-thumb.png?t=1702074223.7558908",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70813-thumb.png?t=1701887076.6682277",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70303-thumb.png?t=1702168585.028972",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70394-thumb.png?t=1701261039.0895913",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70835-thumb.png?t=1699436032.899601",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70454-thumb.png?t=1697784159.6259408",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70864-thumb.png?t=1701888136.3790941",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70563-thumb.png?t=1696600259.0375066",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69909-thumb.png?t=1701775687.852298",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69887-thumb.png?t=1702052686.374528",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70230-thumb.png?t=1701376311.099529",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73675-thumb.png?t=1702028389.3579435",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73656-thumb.png?t=1701460934.910296",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69981-thumb.png?t=1702012795.7449262",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72908-thumb.png?t=1701851607.6163518",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69958-thumb.png?t=1702313913.813256",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70160-thumb.png?t=1702568924.2258897",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70197-thumb.png?t=1701442758.2643414",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69918-thumb.png?t=1702366332.051574",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73705-thumb.png?t=1702192196.1073394",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70116-thumb.png?t=1701824570.6761992",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70194-thumb.png?t=1699940866.5189335",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69890-thumb.png?t=1699436115.7543657",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70115-thumb.png?t=1699426074.3985507",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73692-thumb.png?t=1699485107.2381167",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69882-thumb.png?t=1701719319.2997134",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72156-thumb.png?t=1701772199.0753672",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70033-thumb.png?t=1698085053.8965786",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73485-thumb.png?t=1701672096.3598895",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70227-thumb.png?t=1696417952.0379667",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70082-thumb.png?t=1702229772.2849195",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70047-thumb.png?t=1697135250.5473504",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70006-thumb.png?t=1699536198.900598",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70044-thumb.png?t=1702008366.3630092",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69893-thumb.png?t=1701888744.1088603",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70087-thumb.png?t=1701706103.1347988",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70268-thumb.png?t=1702912076.3505542",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70092-thumb.png?t=1699576320.2739203",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73529-thumb.png?t=1697392857.546309",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70192-thumb.png?t=1701909927.3173501",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70129-thumb.png?t=1701802735.8829935",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73697-thumb.png?t=1701870348.9940581",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/70168-thumb.png?t=1695891142.0924964",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/69916-thumb.png?t=1701826794.3579745",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72460-thumb.png?t=1699880412.42927",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/72691-thumb.png?t=1698474029.4360125",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/71728-thumb.png?t=1697640604.36304",
            "https://nips.cc/media/PosterPDFs/NeurIPS%202023/73645-thumb.png?t=1700613803.9372616",
            "https://nips.cc/static/core/img/NeurIPS-logo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "In this work we explore recent advances in instruction-tuning language models on a range of open instruction-following datasets. Despite recent claims that open models can be on par with state-of-the-art proprietary models, these claims are often accompanied by limited evaluation, making it difficult to compare models across the board and determine the utility of various resources. We provide a large set of instruction-tuned models from 6.7B to 65B parameters in size, trained on 12 instruction datasets ranging from manually curated (e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and systematically evaluate them on their factual knowledge, reasoning, multilinguality, coding, safety, and open-ended instruction following abilities through a collection of automatic, model-based, and human-based metrics. We further introduce Tülu, our best performing instruction-tuned model suite finetuned on a combination of high-quality open resources.Our experiments show that different instruction-tuning datasets can uncover or enhance specific skills, while no single dataset (or combination) provides the best performance across all evaluations. Interestingly, we find that model and human preference-based evaluations fail to reflect differences in model capabilities exposed by benchmark-based evaluations, suggesting the need for the type of systemic evaluation performed in this work. Our evaluations show that the best model in any given …\n\nIn visual-based Reinforcement Learning (RL), agents often struggle to generalize well to environmental variations in the state space that were not observed during training. The variations can arise in both task-irrelevant features, such as background noise, and task-relevant features, such as robot configurations, that are related to the optimal decisions. To achieve generalization in both situations, agents are required to accurately understand the impact of changed features on the decisions, i.e., establishing the true associations between changed features and decisions in the policy model. However, due to the inherent correlations among features in the state space, the associations between features and decisions become entangled, making it difficult for the policy to distinguish them. To this end, we propose Saliency-Guided Features Decorrelation (SGFD) to eliminate these correlations through sample reweighting. Concretely, SGFD consists of two core techniques: Random Fourier Functions (RFF) and the saliency map. RFF is utilized to estimate the complex non-linear correlations in high-dimensional images, while the saliency map is designed to identify the changed features. Under the guidance of the saliency map, SGFD employs sample reweighting to minimize the estimated correlations related to changed features, thereby achieving decorrelation in visual RL tasks. Our experimental results demonstrate that SGFD …\n\nDespite impressive advances in object-recognition, deep learning systems’ performance degrades significantly across geographies and lower income levels---raising pressing concerns of inequity. Addressing such performance gaps remains a challenge, as little is understood about why performance degrades across incomes or geographies.We take a step in this direction by annotating images from Dollar Street, a popular benchmark of geographically and economically diverse images, labeling each image with factors such as color, shape, and background. These annotations unlock a new granular view into how objects differ across incomes/regions. We then use these object differences to pinpoint model vulnerabilities across incomes and regions.We study a range of modern vision models, finding that performance disparities are most associated with differences in texture, occlusion, and images with darker lighting.We illustrate how insights from our factor labels can surface mitigations to improve models' performance disparities.As an example, we show that mitigating a model's vulnerability to texture can improve performance on the lower income level.We release all the factor annotations along with an interactive dashboardto facilitate research into more equitable vision systems.\n\nWe present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information. Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process. The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training. Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artifacts. The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data. Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling. The biological plausibility of DiffInfinite data is evaluated in a survey by ten experienced pathologists as well as a downstream classification and segmentation task. Samples from the model score strongly on anti-copying metrics which is relevant for the protection of patient data.\n\nAttractor networks require neuronal connections to be highly structured in order to maintain attractor states that represent information, while excitation and inhibition balanced networks (E-INNs) require neuronal connections to be random and sparse to generate irregular neuronal firings. Despite being regarded as canonical models of neural circuits, both types of networks are usually studied in isolation, and it remains unclear how they coexist in the brain, given their very different structural demands. In this study, we investigate the compatibility of continuous attractor neural networks (CANNs) and E-INNs. In line with recent experimental data, we find that a neural circuit can exhibit both the traits of CANNs and E-INNs if the neuronal synapses consist of two sets: one set is strong and fast for irregular firing, and the other set is weak and slow for attractor dynamics. Our results from simulations and theoretical analysis reveal that the network also exhibits enhanced performance compared to the case of using only one set of synapses, with accelerated convergence of attractor states and retained E-I balanced condition for localized input. We also apply the network model to solve a real-world tracking problem and demonstrate that it can track fast-moving objects well. We hope that …\n\nThe stunning qualitative improvement of text-to-image models has led to their widespread attention and adoption. However, we lack a comprehensive quantitative understanding of their capabilities and risks. To fill this gap, we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models (HEIM). Whereas previous evaluations focus mostly on image-text alignment and image quality, we identify 12 aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios encompassing these aspects and evaluate 26 state-of-the-art text-to-image models on this benchmark. Our results reveal that no single model excels in all aspects, with different models demonstrating different strengths. We release the generated images and human evaluation results for full transparency at https://crfm.stanford.edu/heim/latest and the code at https://github.com/stanford-crfm/helm, which is integrated with the HELM codebase\n\nOffline-to-online reinforcement learning (RL) is a training paradigm that combines pre-training on a pre-collected dataset with fine-tuning in an online environment. However, the incorporation of online fine-tuning can intensify the well-known distributional shift problem. Existing solutions tackle this problem by imposing a policy constraint on the policy improvement objective in both offline and online learning. They typically advocate a single balance between policy improvement and constraints across diverse data collections. This one-size-fits-all manner may not optimally leverage each collected sample due to the significant variation in data quality across different states. To this end, we introduce Family Offline-to-Online RL (FamO2O), a simple yet effective framework that empowers existing algorithms to determine state-adaptive improvement-constraint balances. FamO2O utilizes a universal model to train a family of policies with different improvement/constraint intensities, and a balance model to select a suitable policy for each state. Theoretically, we prove that state-adaptive balances are necessary for achieving a higher policy performance upper bound. Empirically, extensive experiments show that FamO2O offers a statistically significant improvement over various existing methods, achieving state-of-the-art performance on the D4RL benchmark. Codes are available at https://github.com/LeapLabTHU/FamO2O.\n\nImitation learning (IL) algorithms excel in acquiring high-quality policies from expert data for sequential decision-making tasks. But, their effectiveness is hampered when faced with limited expert data. To tackle this challenge, a novel framework called (offline) IL with supplementary data has been proposed, which enhances learning by incorporating an additional yet imperfect dataset obtained inexpensively from sub-optimal policies. Nonetheless, learning becomes challenging due to the potential inclusion of out-of-expert-distribution samples. In this work, we propose a mathematical formalization of this framework, uncovering its limitations. Our theoretical analysis reveals that a naive approach—applying the behavioral cloning (BC) algorithm concept to the combined set of expert and supplementary data—may fall short of vanilla BC, which solely relies on expert data. This deficiency arises due to the distribution shift between the two data sources. To address this issue, we propose a new importance-sampling-based technique for selecting data within the expert distribution. We prove that the proposed method eliminates the gap of the naive approach, highlighting its efficacy when handling imperfect data. Empirical studies demonstrate that our method outperforms previous state-of-the-art methods in tasks including robotic locomotion control, Atari video games, and image classification. Overall, our work underscores the potential of improving IL by …\n\nIn the field of phase change phenomena, the lack of accessible and diverse datasets suitable for machine learning (ML) training poses a significant challenge. Existing experimental datasets are often restricted, with limited availability and sparse ground truth, impeding our understanding of this complex multiphysics phenomena. To bridge this gap, we present the BubbleML dataset which leverages physics-driven simulations to provide accurate ground truth information for various boiling scenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled boiling. This extensive dataset covers a wide range of parameters, including varying gravity conditions, flow rates, sub-cooling levels, and wall superheat, comprising 79 simulations. BubbleML is validated against experimental observations and trends, establishing it as an invaluable resource for ML research. Furthermore, we showcase its potential to facilitate the exploration of diverse downstream tasks by introducing two benchmarks: (a) optical flow analysis to capture bubble dynamics, and (b) neural PDE solvers for learning temperature and flow dynamics. The BubbleML dataset and its benchmarks aim to catalyze progress in ML-driven research on multiphysics phase change phenomena, providing robust baselines for the development and comparison of state-of-the-art techniques and models.\n\nWe study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al. (NeurIPS'22), where the number of data points, features, and classes all grow together. We fully resolve the conjecture posed in Subramanian et al. '22, matching the predicted regimes for which the model does and does not generalize. Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically. One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal. The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels. As an application, we show that the same type of analysis can be used to analyze the related multi-label classification problem under the same bi-level ensemble.\n\nModern recording techniques now allow us to record from distinct neuronal populations in different brain networks. However, especially as we consider multiple (more than two) populations, new conceptual and statistical frameworks are needed to characterize the multi-dimensional, concurrent flow of signals among these populations. Here, we develop a dimensionality reduction framework that determines (1) the subset of populations described by each latent dimension, (2) the direction of signal flow among those populations, and (3) how those signals evolve over time within and across experimental trials. We illustrate these features in simulation, and further validate the method by applying it to previously studied recordings from neuronal populations in macaque visual areas V1 and V2. Then we study interactions across select laminar compartments of areas V1, V2, and V3d, recorded simultaneously with multiple Neuropixels probes. Our approach uncovered signatures of selective communication across these three areas that related to their retinotopic alignment. This work advances the study of concurrent signaling across multiple neuronal populations.\n\nExplicit finite-sample statistical guarantees on model performance are an important ingredient in responsible machine learning. Previous work has focused mainly on bounding either the expected loss of a predictor or the probability that an individual prediction will incur a loss value in a specified range. However, for many high-stakes applications it is crucial to understand and control the \\textit{dispersion} of a loss distribution, or the extent to which different members of a population experience unequal effects of algorithmic decisions. We initiate the study of distribution-free control of statistical dispersion measures with societal implications and propose a simple yet flexible framework that allows us to handle a much richer class of statistical functionals beyond previous work. Our methods are verified through experiments in toxic comment detection, medical imaging, and film recommendation.\n\nPrior theoretical and empirical works have established that semi-supervised learning algorithms can leverage the unlabeled data to improve over the labeled sample complexity of supervised learning (SL) algorithms. However, existing theoretical work focuses on regimes where the unlabeled data is sufficient to learn a good decision boundary using unsupervised learning (UL) alone. This begs the question: Can SSL algorithms simultaneously improve upon both UL and SL? To this end, we derive a tight lower bound for 2-Gaussian mixture models that explicitly depends on the labeled and the unlabeled dataset size as well as the signal-to-noise ratio of the mixture distribution. Surprisingly, our result implies that no SSL algorithm improves upon the minimax-optimal statistical error rates of SL or UL algorithms for these distributions. Nevertheless, in our real-world experiments, SSL algorithms can often outperform UL and SL algorithms. In summary, our work suggests that while it is possible to prove the performance gains of SSL algorithms, this would require careful tracking of constants in the theoretical analysis.\n\nIn-context learning––the ability to configure a model's behavior with different prompts––has revolutionized the field of natural language processing, alleviating the need for task-specific models and paving the way for generalist models capable of assisting with any query. Computer vision, in contrast, has largely stayed in the former regime: specialized decoders and finetuning protocols are generally required to perform dense tasks such as semantic segmentation and depth estimation. In this work we explore a simple mechanism for in-context learning of such scene understanding tasks: nearest neighbor retrieval from a prompt of annotated features. We propose a new pretraining protocol––leveraging attention within and across images––which yields representations particularly useful in this regime. The resulting Hummingbird model, suitably prompted, performs various scene understanding tasks without modification while approaching the performance of specialists that have been finetuned for each task. Moreover, Hummingbird can be configured to perform new tasks much more efficiently than finetuned models, raising the possibility of scene understanding in the interactive assistant regime.\n\nAs black-box machine learning models become more complex and are applied in high-stakes settings, the need for providing explanations for their predictions becomes crucial. Although Local Interpretable Model-agnostic Explanations (LIME) \\cite{ribeiro2016should} is a widely adopted method for understanding model behavior, it suffers from instability with respect to random seeds \\cite{zafar2019dlime, shankaranarayana2019alime, bansal2020sam} and exhibits low local fidelity (i.e., how the explanation explains model's local behaviors) \\cite{rahnama2019study, laugel2018defining}. Our study demonstrates that this instability is caused by small sample weights, resulting in the dominance of regularization and slow convergence. Additionally, LIME's sampling approach is non-local and biased towards the reference, leading to diminished local fidelity and instability to references. To address these challenges, we propose \\textsc{Glime}, an enhanced framework that extends LIME and unifies several previous methods. Within the \\textsc{Glime} framework, we derive an equivalent formulation of LIME that achieves significantly faster convergence and improved stability. By employing a local and unbiased sampling distribution, \\textsc{Glime} generates explanations with higher local fidelity compared to LIME, while being independent of the reference choice. Moreover, \\textsc{Glime} offers users the flexibility to choose sampling distribution based on their specific scenarios.\n\nLanguage models learn a great quantity of factual information during pretraining, and recent work localizes this information to specific model weights like mid-layer MLP weights. In this paper, we find that we can change how a fact is stored in a model by editing weights that are in a different location than where existing methods suggest that the fact is stored. This is surprising because we would expect that localizing facts to specific model parameters would tell us where to manipulate knowledge in models, and this assumption has motivated past work on model editing methods. Specifically, we show that localization conclusions from representation denoising (also known as Causal Tracing) do not provide any insight into which model MLP layer would be best to edit in order to override an existing stored fact with a new one. This finding raises questions about how past work relies on Causal Tracing to select which model layers to edit. Next, we consider several variants of the editing problem, including erasing and amplifying facts. For one of our editing problems, editing performance does relate to localization results from representation denoising, but we find that which layer we edit is a far better predictor of performance. …\n\nIn this paper, we examine the long-run behavior of regularized, no-regret learning in finite N-player games. A well-known result in the field states that the empirical frequencies of play under no-regret learning converge to the game’s set of coarse correlated equilibria; however, our understanding of how the players' actual strategies evolve over time is much more limited – and, in many cases, non-existent. This issue is exacerbated further by a series of recent results showing that only strict Nash equilibria are stable and attracting under regularized learning, thus making the relation between learning and pointwise solution concepts particularly elusive. In lieu of this, we take a more general approach and instead seek to characterize the setwise rationality properties of the players' day-to-day trajectory of play. To do so, we focus on one of the most stringent criteria of setwise strategic stability, namely that any unilateral deviation from the set in question incurs a cost to the deviator – a property known as closedness under better replies (club). In so doing, we obtain a remarkable equivalence between strategic and dynamic stability: a product of pure strategies is closed under better replies if and only if its span is stable and attracting …\n\nRecent research has developed several Monte Carlo methods for estimating the normalization constant (partition function) based on the idea of annealing. This means sampling successively from a path of distributions which interpolate between a tractable \"proposal\" distribution and the unnormalized \"target\" distribution. Prominent estimators in this family include annealed importance sampling and annealed noise-contrastive estimation (NCE). Such methods hinge on a number of design choices: which estimator to use, which path of distributions to use and whether to use a path at all; so far, there is no definitive theory on which choices are efficient. Here, we evaluate each design choice by the asymptotic estimation error it produces. First, we show that using NCE is more efficient than the importance sampling estimator, but in the limit of infinitesimal path steps, the difference vanishes. Second, we find that using the geometric path brings down the estimation error from an exponential to a polynomial function of the parameter distance between the target and proposal distributions. Third, we find that the arithmetic path, while rarely used, can offer optimality properties over the universally-used geometric path. In fact, in a particular limit, the optimal path is arithmetic. Based on this theory, we finally propose …\n\nTransformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations?In an attempt to demystify transformer LLMs, we investigate the limits of these models across three representative compositional tasks---multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that transformer LLMs solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how autoregressive generations' performance can rapidly decay with increased task complexity.\n\nRepeated use of a data sample via adaptively chosen queries can rapidly lead to overfitting, wherein the empirical evaluation of queries on the sample significantly deviates from their mean with respect to the underlying data distribution. It turns out that simple noise addition algorithms suffice to prevent this issue, and differential privacy-based analysis of these algorithms shows that they can handle an asymptotically optimal number of queries. However, differential privacy's worst-case nature entails scaling such noise to the range of the queries even for highly-concentrated queries, or introducing more complex algorithms.In this paper, we prove that straightforward noise-addition algorithms already provide variance-dependent guarantees that also extend to unbounded queries. This improvement stems from a novel characterization that illuminates the core problem of adaptive data analysis. We show that the harm of adaptivity results from the covariance between the new query and a Bayes factor-based measure of how much information about the data sample was encoded in the responses given to past queries. We then leverage this characterization to introduce a new data-dependent stability notion that can bound this covariance.\n\nMulti-source domain adaptation (MSDA) methods aim to transfer knowledge from multiple labeled source domains to an unlabeled target domain. Although current methods achieve target joint distribution identifiability by enforcing minimal changes across domains, they often necessitate stringent conditions, such as an adequate number of domains, monotonic transformation of latent variables, and invariant label distributions. These requirements are challenging to satisfy in real-world applications. To mitigate the need for these strict assumptions, we propose a subspace identification theory that guarantees the disentanglement of domain-invariant and domain-specific variables under less restrictive constraints regarding domain numbers and transformation properties and thereby facilitating domain adaptation by minimizing the impact of domain shifts on invariant variables. Based on this theory, we develop a Subspace Identification Guarantee (SIG) model that leverages variational inference. Furthermore, the SIG model incorporates class-aware conditional alignment to accommodate target shifts where label distributions change with the domain. Experimental results demonstrate that our SIG model outperforms existing MSDA techniques on various benchmark datasets, highlighting its effectiveness in real-world applications.\n\nIn response to recent data regulation requirements, machine unlearning (MU) has emerged as a critical process to remove the influence of specific examples from a given model. Although exact unlearning can be achieved through complete model retraining using the remaining dataset, the associated computational costs have driven the development of efficient, approximate unlearning techniques. Moving beyond data-centric MU approaches, our study introduces a novel model-based perspective: model sparsification via weight pruning, which is capable of reducing the gap between exact unlearning and approximate unlearning. We show in both theory and practice that model sparsity can boost the multi-criteria unlearning performance of an approximate unlearner, closing the approximation gap, while continuing to be efficient. This leads to a new MU paradigm, termed prune first, then unlearn, which infuses a sparse prior to the unlearning process. Building on this insight, we also develop a sparsity-aware unlearning method that utilizes sparsity regularization to enhance the training process of approximate unlearning. Extensive experiments show that our proposals consistently benefit MU in various unlearning scenarios. A notable highlight is the 77% unlearning efficacy gain of fine-tuning (one of the simplest approximate unlearning methods) when using our proposed sparsity-aware unlearning method. Furthermore, we showcase the practical …\n\nNon-linear dynamical systems can be handily described by the associated Koopman operator, whose action evolves every observable of the system forward in time. Learning the Koopman operator and its spectral decomposition from data is enabled by a number of algorithms. In this work we present for the first time non-asymptotic learning bounds for the Koopman eigenvalues and eigenfunctions. We focus on time-reversal-invariant stochastic dynamical systems, including the important example of Langevin dynamics. We analyze two popular estimators: Extended Dynamic Mode Decomposition (EDMD) and Reduced Rank Regression (RRR). Our results critically hinge on novel {minimax} estimation bounds for the operator norm error, that may be of independent interest. Our spectral learning bounds are driven by the simultaneous control of the operator norm error and a novel metric distortion functional of the estimated eigenfunctions. The bounds indicates that both EDMD and RRR have similar variance, but EDMD suffers from a larger bias which might be detrimental to its learning rate. Our results shed new light on the emergence of spurious eigenvalues, an issue which is well known empirically. Numerical experiments illustrate the implications of the bounds in practice.\n\nIn-context learning is the ability of a pretrained model to adapt to novel and diverse downstream tasks by conditioning on prompt examples, without optimizing any parameters. While large language models have demonstrated this ability, how in-context learning could be performed over graphs is unexplored. In this paper, we develop \\textbf{Pr}etraining \\textbf{O}ver \\textbf{D}iverse \\textbf{I}n-Context \\textbf{G}raph S\\textbf{y}stems (PRODIGY), the first pretraining framework that enables in-context learning over graphs. The key idea of our framework is to formulate in-context learning over graphs with a novel \\emph{prompt graph} representation, which connects prompt examples and queries. We then propose a graph neural network architecture over the prompt graph and a corresponding family of in-context pretraining objectives. With PRODIGY, the pretrained model can directly perform novel downstream classification tasks on unseen graphs via in-context learning. We provide empirical evidence of the effectiveness of our framework by showcasing its strong in-context learning performance on tasks involving citation networks and knowledge graphs. Our approach outperforms the in-context learning accuracy of contrastive pretraining baselines with hard-coded adaptation by 18\\% on average across all setups. Moreover, it also outperforms standard finetuning with limited data by 33\\% on average with in-context learning.\n\nIntrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating plans autonomously in commonsense planning tasks and (2) the potential of LLMs as a source of heuristic guidance for other agents (AI planners) in their planning tasks. We conduct a systematic study by generating a suite of instances on domains similar to the ones employed in the International Planning Competition and evaluate LLMs in two distinct modes: autonomous and heuristic. Our findings reveal that LLMs’ ability to generate executable plans autonomously is rather limited, with the best model (GPT-4) having an average success rate of ~12% across the domains. However, the results in the heuristic mode show more promise. In the heuristic mode, we demonstrate that LLM-generated plans can improve the search process for underlying sound planners and additionally show that external verifiers can help provide feedback on the generated plans and back-prompt the LLM for better plan generation.\n\nIntracortical brain-computer interfaces (iBCIs) have shown promise for restoring rapid communication to people with neurological disorders such as amyotrophic lateral sclerosis (ALS). However, to maintain high performance over time, iBCIs typically need frequent recalibration to combat changes in the neural recordings that accrue over days. This requires iBCI users to stop using the iBCI and engage in supervised data collection, making the iBCI system hard to use. In this paper, we propose a method that enables self-recalibration of communication iBCIs without interrupting the user. Our method leverages large language models (LMs) to automatically correct errors in iBCI outputs. The self-recalibration process uses these corrected outputs (\"pseudo-labels\") to continually update the iBCI decoder online. Over a period of more than one year (403 days), we evaluated our Continual Online Recalibration with Pseudo-labels (CORP) framework with one clinical trial participant. CORP achieved a stable decoding accuracy of 93.84% in an online handwriting iBCI task, significantly outperforming other baseline methods. Notably, this is the longest-running iBCI stability demonstration involving a human participant. Our results provide the first evidence for long-term stabilization of a plug-and-play, high-performance communication iBCI, addressing a major barrier for the clinical translation of iBCIs.\n\nWe study benign overfitting in two-layer ReLU networks trained using gradient descent and hinge loss on noisy data for binary classification. In particular, we consider linearly separable data for which a relatively small proportion of labels are corrupted or flipped. We identify conditions on the margin of the clean data that give rise to three distinct training outcomes: benign overfitting, in which zero loss is achieved and with high probability test data is classified correctly; overfitting, in which zero loss is achieved but test data is misclassified with probability lower bounded by a constant; and non-overfitting, in which clean points, but not corrupt points, achieve zero loss and again with high probability test data is classified correctly. Our analysis provides a fine-grained description of the dynamics of neurons throughout training and reveals two distinct phases: in the first phase clean points achieve close to zero loss, in the second phase clean points oscillate on the boundary of zero loss while corrupt points either converge towards zero loss or are eventually zeroed by the network. We prove these results using a combinatorial approach that involves bounding the number of clean versus corrupt updates during these phases of training.\n\nLearning from active human involvement enables the human subject to actively intervene and demonstrate to the AI agent during training. The interaction and corrective feedback from human brings safety and AI alignment to the learning process. In this work, we propose a new reward-free active human involvement method called Proxy Value Propagation for policy optimization. Our key insight is that a proxy value function can be designed to express human intents, wherein state- action pairs in the human demonstration are labeled with high values, while those agents’ actions that are intervened receive low values. Through the TD-learning framework, labeled values of demonstrated state-action pairs are further propagated to other unlabeled data generated from agents’ exploration. The proxy value function thus induces a policy that faithfully emulates human behaviors. Human- in-the-loop experiments show the generality and efficiency of our method. With minimal modification to existing reinforcement learning algorithms, our method can learn to solve continuous and discrete control tasks with various human control devices, including the challenging task of driving in Grand Theft Auto V. Demo video and code are available at: https://metadriverse.github.io/pvp.\n\nLarge transformer models trained on diverse datasets have shown a remarkable ability to learn in-context, achieving high few-shot performance on tasks they were not explicitly trained to solve. In this paper, we study the in-context learning capabilities of transformers in decision-making problems, i.e., reinforcement learning (RL) for bandits and Markov decision processes. To do so, we introduce and study the Decision-Pretrained Transformer (DPT), a supervised pretraining method where a transformer predicts an optimal action given a query state and an in-context dataset of interactions from a diverse set of tasks. While simple, this procedure produces a model with several surprising capabilities. We find that the trained transformer can solve a range of RL problems in-context, exhibiting both exploration online and conservatism offline, despite not being explicitly trained to do so. The model also generalizes beyond the pretraining distribution to new tasks and automatically adapts its decision-making strategies to unknown structure. Theoretically, we show DPT can be viewed as an efficient implementation of Bayesian posterior sampling, a provably sample-efficient RL algorithm. We further leverage this connection to provide guarantees on the regret of the in-context algorithm yielded by DPT, and prove that it can learn faster than algorithms used to generate …\n\nOversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models, including random walk GCNs, Graph Attention Networks (GATs) and (graph) transformers. In particular, our analysis accounts for asymmetric, state-dependent and time-varying aggregation operators and a wide range of common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.\n\nLinear-Quadratic-Gaussian (LQG) control is a fundamental control paradigm that is studied in various fields such as engineering, computer science, economics, and neuroscience. It involves controlling a system with linear dynamics and imperfect observations, subject to additive noise, with the goal of minimizing a quadratic cost function for the state and control variables. In this work, we consider a generalization of the discrete-time, finite-horizon LQG problem, where the noise distributions are unknown and belong to Wasserstein ambiguity sets centered at nominal (Gaussian) distributions. The objective is to minimize a worst-case cost across all distributions in the ambiguity set, including non-Gaussian distributions. Despite the added complexity, we prove that a control policy that is linear in the observations is optimal for this problem, as in the classic LQG problem. We propose a numerical solution method that efficiently characterizes this optimal control policy. Our method uses the Frank-Wolfe algorithm to identify the least-favorable distributions within the Wasserstein ambiguity sets and computes the controller's optimal policy using Kalman filter estimation under these distributions.\n\nMachine learning models are often personalized based on information that is protected, sensitive, self-reported, or costly to acquire. These models use information about people, but do not facilitate nor inform their consent. Individuals cannot opt out of reporting information that a model needs to personalize their predictions nor tell if they benefit from personalization in the first place. We introduce a new family of prediction models, called participatory systems, that let individuals opt into personalization at prediction time. We present a model-agnostic algorithm to learn participatory systems for supervised learning tasks where models are personalized with categorical group attributes. We conduct a comprehensive empirical study of participatory systems in clinical prediction tasks, comparing them to common approaches for personalization and imputation. Our results show that participatory systems can facilitate and inform consent in a way that improves performance and privacy across all groups who report personal data.\n\nGenomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context (<0.001% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers or fixed k-mers to aggregate meaningful DNA units, losing single nucleotide resolution (i.e. DNA \"characters\") where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyena’s new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level – an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single …\n\nDesigning reward functions for efficiently guiding reinforcement learning (RL) agents toward specific behaviors is a complex task.This is challenging since it requires the identification of reward structures that are not sparse and that avoid inadvertently inducing undesirable behaviors. Naively modifying the reward structure to offer denser and more frequent feedback can lead to unintended outcomes and promote behaviors that are not aligned with the designer's intended goal. Although potential-based reward shaping is often suggested as a remedy, we systematically investigate settings where deploying it often significantly impairs performance. To address these issues, we introduce a new framework that uses a bi-level objective to learn \\emph{behavior alignment reward functions}. These functions integrate auxiliary rewards reflecting a designer's heuristics and domain knowledge with the environment's primary rewards. Our approach automatically determines the most effective way to blend these types of feedback, thereby enhancing robustness against heuristic reward misspecification. Remarkably, it can also adapt an agent's policy optimization process to mitigate suboptimalities resulting from limitations and biases inherent in the underlying RL algorithms. We evaluate our method's efficacy on a diverse set of tasks, from small-scale experiments to high-dimensional control challenges. We investigate heuristic auxiliary rewards of varying quality---some of which are beneficial …\n\nTwo-photon optogenetics has transformed our ability to probe the structure and function of neural circuits. However, achieving precise optogenetic control of neural ensemble activity has remained fundamentally constrained by the problem of off-target stimulation (OTS): the inadvertent activation of nearby non-target neurons due to imperfect confinement of light onto target neurons. Here we propose a novel computational approach to this problem called Bayesian target optimisation. Our approach uses nonparametric Bayesian inference to model neural responses to optogenetic stimulation, and then optimises the laser powers and optical target locations needed to achieve a desired activity pattern with minimal OTS. We validate our approach in simulations and using data from in vitro experiments, showing that Bayesian target optimisation considerably reduces OTS across all conditions we test. Together, these results establish our ability to overcome OTS, enabling optogenetic stimulation with substantially improved precision.\n\nWe present a novel approach to non-convex optimization with certificates, which handles smooth functions on the hypercube or on the torus. Unlike traditional methods that rely on algebraic properties, our algorithm exploits the regularity of the target function intrinsic in the decay of its Fourier spectrum. By defining a tractable family of models, we allow {\\em at the same time} to obtain precise certificates and to leverage the advanced and powerful computational techniques developed to optimize neural networks. In this way the scalability of our approach is naturally enhanced by parallel computing with GPUs. Our approach, when applied to the case of polynomials of moderate dimensions but with thousands of coefficients, outperforms the state-of-the-art optimization methods with certificates, as the ones based on Lasserre's hierarchy, addressing problems intractable for the competitors.\n\nCounterfactual inference aims to answer retrospective \"what if\" questions and thus belongs to the most fine-grained type of inference in Pearl's causality ladder. Existing methods for counterfactual inference with continuous outcomes aim at point identification and thus make strong and unnatural assumptions about the underlying structural causal model. In this paper, we relax these assumptions and aim at partial counterfactual identification of continuous outcomes, i.e., when the counterfactual query resides in an ignorance interval with informative bounds. We prove that, in general, the ignorance interval of the counterfactual queries has non-informative bounds, already when functions of structural causal models are continuously differentiable. As a remedy, we propose a novel sensitivity model called Curvature Sensitivity Model. This allows us to obtain informative bounds by bounding the curvature of level sets of the functions. We further show that existing point counterfactual identification methods are special cases of our Curvature Sensitivity Model when the bound of the curvature is set to zero. We then propose an implementation of our Curvature Sensitivity Model in the form of a novel deep generative model, which we call Augmented Pseudo-Invertible Decoder. Our implementation employs (i) residual normalizing flows with (ii) variational augmentations. We empirically demonstrate the effectiveness …\n\nAs machine learning-enabled Text-to-Image (TTI) systems are becoming increasingly prevalent and seeing growing adoption as commercial services, characterizing the social biases they exhibit is a necessary first step to lowering their risk of discriminatory outcomes. This evaluation, however, is made more difficult by the synthetic nature of these systems’ outputs: common definitions of diversity are grounded in social categories of people living in the world, whereas the artificial depictions of fictive humans created by these systems have no inherent gender or ethnicity. To address this need, we propose a new method for exploring the social biases in TTI systems. Our approach relies on characterizing the variation in generated images triggered by enumerating gender and ethnicity markers in the prompts, and comparing it to the variation engendered by spanning different professions. This allows us to (1) identify specific bias trends, (2) provide targeted scores to directly compare models in terms of diversity and representation, and (3) jointly model interdependent social variables to support a multidimensional analysis. We leverage this method to analyze images generated by 3 popular TTI systems (Dall·E 2 , Stable Diffusion v 1.4 and 2) and find that while all of their outputs show correlations with US labor …\n\nOne of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic features -- and show that in the latter setting three-layer networks obtain a sample complexity improvement over all existing guarantees for two-layer networks. Crucially, this sample complexity improvement relies on the ability of three-layer networks to efficiently learn nonlinear features. We then establish a concrete optimization-based depth separation by constructing a function which is efficiently learnable via gradient …\n\nReasoning system dynamics is one of the most important analytical approaches for many scientific studies. With the initial state of a system as input, the recent graph neural networks (GNNs)-based methods are capable of predicting the future state distant in time with high accuracy. Although these methods have diverse designs in modeling the coordinates and interacting forces of the system, we show that they actually share a common paradigm that learns the integration of the velocity over the interval between the initial and terminal coordinates. However, their integrand is constant w.r.t. time. Inspired by this observation, we propose a new approach to predict the integration based on several velocity estimations with Newton–Cotes formulas and prove its effectiveness theoretically. Extensive experiments on several benchmarks empirically demonstrate consistent and significant improvement compared with the state-of-the-art methods.\n\nIn the field of behavior-related brain computation, it is necessary to align raw neural signals against the drastic domain shift among them. A foundational framework within neuroscience research posits that trial-based neural population activities rely on low-dimensional latent dynamics, thus focusing on the latter greatly facilitates the alignment procedure. Despite this field's progress, existing methods ignore the intrinsic spatio-temporal structure during the alignment phase. Hence, their solutions usually lead to poor quality in latent dynamics structures and overall performance. To tackle this problem, we propose an alignment method ERDiff, which leverages the expressivity of the diffusion model to preserve the spatio-temporal structure of latent dynamics. Specifically, the latent dynamics structures of the source domain are first extracted by a diffusion model. Then, under the guidance of this diffusion model, such structures are well-recovered through a maximum likelihood alignment procedure in the target domain. We first demonstrate the effectiveness of our proposed method on a synthetic dataset. Then, when applied to neural recordings from the non-human primate motor cortex, under both cross-day and inter-subject settings, our method consistently manifests its capability of preserving the spatio-temporal structure of latent dynamics and outperforms existing approaches in alignment goodness-of-fit and neural decoding performance.\n\nWe consider a number of questions related to tradeoffs between reward and regret in repeated gameplay between two agents. To facilitate this, we introduce a notion of generalized equilibrium which allows for asymmetric regret constraints, and yields polytopes of feasible values for each agent and pair of regret constraints, where we show that any such equilibrium is reachable by a pair of algorithms which maintain their regret guarantees against arbitrary opponents. As a central example, we highlight the case one agent is no-swap and the other's regret is unconstrained. We show that this captures an extension of Stackelberg equilibria with a matching optimal value, and that there exists a wide class of games where a player can significantly increase their utility by deviating from a no-swap-regret algorithm against a no-swap learner (in fact, almost any game without pure Nash equilibria is of this form). Additionally, we make use of generalized equilibria to consider tradeoffs in terms of the opponent's algorithm choice. We give a tight characterization for the maximal reward obtainable against some no-regret learner, yet we also show a class of games in which this is bounded away from the value obtainable against the class of common \"mean-based\" no-regret …\n\nDiffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps. Existing acceleration sampling techniques inevitably sacrifice performance to some extent, leading to over-blurry SR results. To address this issue, we propose a novel and efficient diffusion model for SR that significantly reduces the number of diffusion steps, thereby eliminating the need for post-acceleration during inference and its associated performance deterioration. Our method constructs a Markov chain that transfers between the high-resolution image and the low-resolution image by shifting the residual between them, substantially improving the transition efficiency. Additionally, an elaborate noise schedule is developed to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experiments demonstrate that the proposed method obtains superior or at least comparable performance to current state-of-the-art methods on both synthetic and real-world datasets, \\textit{\\textbf{even only with 20 sampling steps}}. Our code and model will be made publicly.\n\nFeature transformation aims to generate new pattern-discriminative feature space from original features to improve downstream machine learning (ML) task performances. However, the discrete search space for the optimal feature explosively grows on the basis of combinations of features and operations from low-order forms to high-order forms. Existing methods, such as exhaustive search, expansion reduction, evolutionary algorithms, reinforcement learning, and iterative greedy, suffer from large search space. Overly emphasizing efficiency in algorithm design usually sacrifice stability or robustness. To fundamentally fill this gap, we reformulate discrete feature transformation as a continuous space optimization task and develop an embedding-optimization-reconstruction framework. This framework includes four steps: 1) reinforcement-enhanced data preparation, aiming to prepare high-quality transformation-accuracy training data; 2) feature transformation operation sequence embedding, intending to encapsulate the knowledge of prepared training data within a continuous space; 3) gradient-steered optimal embedding search, dedicating to uncover potentially superior embeddings within the learned space; 4) transformation operation sequence reconstruction, striving to reproduce the feature transformation solution to pinpoint the optimal feature space. Finally, extensive experiments and case studies are performed to demonstrate the effectiveness and robustness of the proposed method. The code and data are publicly accessible https://www.dropbox.com/sh/imh8ckui7va3k5u/AACulQegVx0MuywYyoCqSdVPa?dl=0.\n\nWe initiate the study of smoothed analysis for the sequential probability assignment problem with contexts. We study information-theoretically optimal minmax rates as well as a framework for algorithmic reduction involving the maximum likelihood estimator oracle. Our approach establishes a general-purpose reduction from minimax rates for sequential probability assignment for smoothed adversaries to minimax rates for transductive learning. This leads to optimal (logarithmic) fast rates for parametric classes and classes with finite VC dimension. On the algorithmic front, we develop an algorithm that efficiently taps into the MLE oracle, for general classes of functions. We show that under general conditions this algorithmic approach yields sublinear regret.\n\nConditional independence (CI) testing is a fundamental and challenging task in modern statistics and machine learning. Many modern methods for CI testing rely on powerful supervised learning methods to learn regression functions or Bayes predictors as an intermediate step; we refer to this class of tests as regression-based tests. Although these methods are guaranteed to control Type-I error when the supervised learning methods accurately estimate the regression functions or Bayes predictors of interest, their behavior is less understood when they fail due to misspecified inductive biases; in other words, when the employed models are not flexible enough or when the training algorithm does not induce the desired predictors. Then, we study the performance of regression-based CI tests under misspecified inductive biases. Namely, we propose new approximations or upper bounds for the testing errors of three regression-based tests that depend on misspecification errors. Moreover, we introduce the Rao-Blackwellized Predictor Test (RBPT), a regression-based CI test robust against misspecified inductive biases. Finally, we conduct experiments with artificial and real data, showcasing the usefulness of our theory and methods.\n\nRecent research has observed that in machine learning optimization, gradient descent (GD) often operates at the edge of stability (EoS) [Cohen et al., 2021], where the stepsizes are set to be large, resulting in non-monotonic losses induced by the GD iterates. This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime. Despite the presence of local oscillations, we prove that the logistic loss can be minimized by GD with any constant stepsize over a long time scale. Furthermore, we prove that with any constant stepsize, the GD iterates tend to infinity when projected to a max-margin direction (the hard-margin SVM direction) and converge to a fixed vector that minimizes a strongly convex potential when projected to the orthogonal complement of the max-margin direction. In contrast, we also show that in the EoS regime, GD iterates may diverge catastrophically under the exponential loss, highlighting the superiority of the logistic loss. These theoretical findings are in line with numerical simulations and complement existing theories on the convergence and implicit bias of GD for logistic regression, which are only applicable when the stepsizes are sufficiently small.\n\nSemi-Supervised Domain Generalization (SSDG) aims to learn a model that is generalizable to an unseen target domain with only a few labels, and most existing SSDG methods assume that unlabeled training and testing samples are all known classes. However, a more realistic scenario is that known classes may be mixed with some unknown classes in unlabeled training and testing data. To deal with such a scenario, we propose the Class-Wise Adaptive Exploration and Exploitation (CWAEE) method. In particular, we explore unlabeled training data by using one-vs-rest classifiers and class-wise adaptive thresholds to detect known and unknown classes, and exploit them by adopting consistency regularization on augmented samples based on Fourier Transformation to improve the unseen domain generalization. The experiments conducted on real-world datasets verify the effectiveness and superiority of our method.\n\nThe rapid advancement and widespread use of large language models (LLMs) have raised significant concerns regarding the potential leakage of personally identifiable information (PII). These models are often trained on vast quantities of web-collected data, which may inadvertently include sensitive personal data. This paper presents ProPILE, a novel probing tool designed to empower data subjects, or the owners of the PII, with awareness of potential PII leakage in LLM-based services. ProPILE lets data subjects formulate prompts based on their own PII to evaluate the level of privacy intrusion in LLMs. We demonstrate its application on the OPT-1.3B model trained on the publicly available Pile dataset. We show how hypothetical data subjects may assess the likelihood of their PII being included in the Pile dataset being revealed. ProPILE can also be leveraged by LLM service providers to effectively evaluate their own levels of PII leakage with more powerful prompts specifically tuned for their in-house models. This tool represents a pioneering step towards empowering the data subjects for their awareness and control over their own data on the web.\n\nGenerative models capable of precisely capturing nuanced clinical features in medical images hold great promise for facilitating clinical data sharing, enhancing rare disease datasets, and efficiently synthesizing (annotated) medical images at scale. Despite their potential, assessing the quality of synthetic medical images remains a challenge. While modern generative models can synthesize visually-realistic medical images, the clinical plausibility of these images may be called into question. Domain-agnostic scores, such as FID score, precision, and recall, cannot incorporate clinical knowledge and are, therefore, not suitable for assessing clinical sensibility. Additionally, there are numerous unpredictable ways in which generative models may fail to synthesize clinically plausible images, making it challenging to anticipate potential failures and design automated scores for their detection. To address these challenges, this paper introduces a pathologist-in-the-loop framework for generating clinically-plausible synthetic medical images. Our framework comprises three steps: (1) pretraining a conditional diffusion model to generate medical images conditioned on a clinical concept, (2) expert pathologist evaluation of the generated images to assess whether they satisfy clinical desiderata, and (3) training a reward model that predicts human feedback on new samples, which we use to incorporate expert knowledge into the finetuning objective of the diffusion model. Our results show …\n\nSelf-supervised pre-training methods on proteins have recently gained attention, with most approaches focusing on either protein sequences or structures, neglecting the exploration of their joint distribution, which is crucial for a comprehensive understanding of protein functions by integrating co-evolutionary information and structural characteristics. In this work, inspired by the success of denoising diffusion models in generative tasks, we propose the DiffPreT approach to pre-train a protein encoder by sequence-structure joint diffusion modeling. DiffPreT guides the encoder to recover the native protein sequences and structures from the perturbed ones along the joint diffusion trajectory, which acquires the joint distribution of sequences and structures. Considering the essential protein conformational variations, we enhance DiffPreT by a method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the correlation between different conformers of a protein. SiamDiff attains this goal by maximizing the mutual information between representations of diffusion trajectories of structurally-correlated conformers. We study the effectiveness of DiffPreT and SiamDiff on both atom- and residue-level structure-based protein understanding tasks. Experimental results show that the performance of DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new state-of-the-art performance, considering the mean ranks on all tasks. Code will be released upon acceptance.\n\nWe introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude, enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of the selected designs were tight binders.\n\nWe present a novel approach for explaining Gaussian processes (GPs) that can utilize the full analytical covariance structure present in GPs. Our method is based on the popular solution concept of Shapley values extended to stochastic cooperative games, resulting in explanations that are random variables. The GP explanations generated using our approach satisfy similar favorable axioms to standard Shapley values and possess a tractable covariance function across features and data observations. This covariance allows for quantifying explanation uncertainties and studying the statistical dependencies between explanations. We further extend our framework to the problem of predictive explanation, and propose a Shapley prior over the explanation function to predict Shapley values for new data based on previously computed ones. Our extensive illustrations demonstrate the effectiveness of the proposed approach.\n\nBuilding agents based on tree-search planning capabilities with learned models has achieved remarkable success in classic decision-making problems, such as Go and Atari.However, it has been deemed challenging or even infeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse real-world applications, especially when these environments involve complex action spaces and significant simulation costs, or inherent stochasticity.In this work, we introduce LightZero, the first unified benchmark for deploying MCTS/MuZero in general sequential decision scenarios. Specificially, we summarize the most critical challenges in designing a general MCTS-style decision-making solver, then decompose the tightly-coupled algorithm and system design of tree-search RL methods into distinct sub-modules.By incorporating more appropriate exploration and optimization strategies, we can significantly enhance these sub-modules and construct powerful LightZero agents to tackle tasks across a wide range of domains, such as board games, Atari, MuJoCo, MiniGrid and GoBigger.Detailed benchmark results reveal the significant potential of such methods in building scalable and efficient decision intelligence.The code is available as part of OpenDILab at https://github.com/opendilab/LightZero.\n\nSince their inception, Variational Autoencoders (VAEs) have become central in machine learning. Despite their widespread use, numerous questions regarding their theoretical properties remain open. Using PAC-Bayesian theory, this work develops statistical guarantees for VAEs. First, we derive the first PAC-Bayesian bound for posterior distributions conditioned on individual samples from the data-generating distribution. Then, we utilize this result to develop generalization guarantees for the VAE's reconstruction loss, as well as upper bounds on the distance between the input and the regenerated distributions. More importantly, we provide upper bounds on the Wasserstein distance between the input distribution and the distribution defined by the VAE's generative model.\n\nData and code working together is fundamental to machine learning (ML), but the context around datasets and interactions between datasets and code are in general captured only rudimentarily. Context such as how the dataset was prepared and created, what source data were used, what code was used in processing, how the dataset evolved, and where it has been used and reused can provide much insight, but this information is often poorly documented. That is unfortunate since it makes datasets into black-boxes with potentially hidden characteristics that have downstream consequences. We argue that making dataset preparation more accessible and dataset usage easier to record and document would have significant benefits for the ML community: it would allow for greater diversity in datasets by inviting modification to published sources, simplify use of alternative datasets and, in doing so, make results more transparent and robust, while allowing for all contributions to be adequately credited. We present a platform, Renku, designed to support and encourage such sustainable development and use of data, datasets, and code, and we demonstrate its benefits through a few illustrative projects which span the spectrum from dataset creation to dataset consumption and showcasing.\n\nAlthough the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism. Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain. In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion. Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools. Our code will be made publicly available.\n\nExpected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in “classic” analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies. Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature.\n\nIn everyday conversations, humans can take on different roles and adapt their vocabulary to their chosen roles. We explore whether LLMs can take on, that is impersonate, different roles when they generate text in-context. We ask LLMs to assume different personas before solving vision and language tasks. We do this by prefixing the prompt with a persona that is associated either with a social identity or domain expertise. In a multi-armed bandit task, we find that LLMs pretending to be children of different ages recover human-like developmental stages of exploration. In a language-based reasoning task, we find that LLMs impersonating domain experts perform better than LLMs impersonating non-domain experts. Finally, we test whether LLMs' impersonations are complementary to visual information when describing different categories. We find that impersonation can improve performance: an LLM prompted to be a bird expert describes birds better than one prompted to be a car expert. However, impersonation can also uncover LLMs' biases: an LLM prompted to be a man describes cars better than one prompted to be a woman. These findings demonstrate that LLMs are capable of taking on diverse roles and that this in-context impersonation can be used to uncover their strengths and hidden …\n\nIn this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the rich semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks.Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\n\nWe consider the problem of estimating the causal effect of a treatment on an outcome in linear structural causal models (SCM) with latent confounders when we have access to a single proxy variable.Several methods (such as difference-in-difference (DiD) estimator or negative outcome control) have been proposed in this setting in the literature. However, these approaches require either restrictive assumptions on the data generating model or having access to at least two proxy variables.We propose a method to estimate the causal effect using cross moments between the treatment, the outcome, and the proxy variable. In particular, we show that the causal effect can be identified with simple arithmetic operations on the cross moments if the latent confounder in linear SCM is non-Gaussian.In this setting, DiD estimator provides an unbiased estimate only in the special case where the latent confounder has exactly the same direct causal effects on the outcomes in the pre-treatment and post-treatment phases. This translates to the common trend assumption in DiD, which we effectively relax.Additionally, we provide an impossibility result that shows the causal effect cannot be identified if the observational distribution over the treatment, the outcome, and the proxy is jointly Gaussian. Our experiments on both synthetic …\n\nThe representations of neural networks are often compared to those of biological systems by performing regression between the neural network responses and those measured from biological systems. Many different state-of-the-art deep neural networks yield similar neural predictions, but it remains unclear how to differentiate among models that perform equally well at predicting neural responses. To gain insight into this, we use a recent theoretical framework that relates the generalization error from regression to the spectral properties of the model and the target. We apply this theory to the case of regression between model activations and neural responses and decompose the neural prediction error in terms of the model eigenspectra, alignment of model eigenvectors and neural responses, and the training set size. Using this decomposition, we introduce geometrical measures to interpret the neural prediction error. We test a large number of deep neural networks that predict visual cortical activity and show that there are multiple types of geometries that result in low neural prediction error as measured via regression. The work demonstrates that carefully decomposing representational metrics can provide interpretability of how models are capturing neural activity and points the way towards improved models of neural activity.\n\nThe meteoric rise in the adoption of deep neural networks as computational models of vision has inspired efforts to ``align” these models with humans. One dimension of interest for alignment includes behavioral choices, but moving beyond characterizing choice patterns to capturing temporal aspects of visual decision-making has been challenging. Here, we sketch a general-purpose methodology to construct computational accounts of reaction times from a stimulus-computable, task-optimized model. Specifically, we introduce a novel metric leveraging insights from subjective logic theory summarizing evidence accumulation in recurrent vision models. We demonstrate that our metric aligns with patterns of human reaction times for stimulus manipulations across four disparate visual decision-making tasks spanning perceptual grouping, mental simulation, and scene categorization. This work paves the way for exploring the temporal alignment of model and human visual strategies in the context of various other cognitive tasks toward generating testable hypotheses for neuroscience. Links to the code and data can be found on the project page: https://serre-lab.github.io/rnnrtssite/.\n\nThe translation of brain dynamics into natural language is pivotal for brain-computer interfaces (BCIs), a field that has seen substantial growth in recent years. With the swift advancement of large language models, such as ChatGPT, the need to bridge the gap between the brain and languages becomes increasingly pressing. Current methods, however, require eye-tracking fixations or event markers to segment brain dynamics into word-level features, which can restrict the practical application of these systems. These event markers may not be readily available or could be challenging to acquire during real-time inference, and the sequence of eye fixations may not align with the order of spoken words. To tackle these issues, we introduce a novel framework, DeWave, that integrates discrete encoding sequences into open-vocabulary EEG-to-text translation tasks. DeWave uses a quantized variational encoder to derive discrete codex encoding and align it with pre-trained language models. This discrete codex representation brings forth two advantages: 1) it alleviates the order mismatch between eye fixations and spoken words by introducing text-EEG contrastive alignment training, and 2) it minimizes the interference caused by individual differences in EEG waves through an invariant discrete codex. Our model surpasses the previous baseline (40.1 and 31.7) by 3.06% and …\n\nSpiking Neural Networks (SNNs) are considered promising brain-inspired energy-efficient models due to their event-driven computing paradigm.The spatiotemporal spike patterns used to convey information in SNNs consist of both rate coding and temporal coding, where the temporal coding is crucial to biological-plausible learning rules such as spike-timing-dependent-plasticity.The time-based training strategy is proposed to better utilize the temporal information in SNNs and learn in an asynchronous fashion.However, some recent works train SNNs by the time-based scheme with rate-coding-dominated loss functions.In this paper, we first map rate-based loss functions to time-based counterparts and explain why they are also applicable to the time-based training scheme.After that, we infer that loss functions providing adequate positive overall gradients help training by theoretical analysis.Based on this, we propose the enhanced counting loss to replace the commonly used mean square counting loss.In addition, we transfer the training of scale factor in weight standardization into thresholds.Experiments show that our approach outperforms previous time-based training methods in most datasets. Our work provides insights for training SNNs with time-based schemes and offers a fresh perspective on the correlation between rate coding and temporal coding.Our code is available at https://github.com/zhuyaoyu/SNN-temporal-training-losses.\n\nEquivariance has gained strong interest as a desirable network property that inherently ensures robust generalization. However, when dealing with complex systems such as articulated objects or multi-object scenes, effectively capturing inter-part transformations poses a challenge, as it becomes entangled with the overall structure and local transformations. The interdependence of part assignment and per-part group action necessitates a novel equivariance formulation that allows for their co-evolution. In this paper, we present Banana, a Banach fixed-point network for equivariant segmentation with inter-part equivariance by construction. Our key insight is to iteratively solve a fixed-point problem, where point-part assignment labels and per-part SE(3)-equivariance co-evolve simultaneously. We provide theoretical derivations of both per-step equivariance and global convergence, which induces an equivariant final convergent state. Our formulation naturally provides a strict definition of inter-part equivariance that generalizes to unseen inter-part configurations. Through experiments conducted on both articulated objects and multi-object scans, we demonstrate the efficacy of our approach in achieving strong generalization under inter-part transformations, even when confronted with substantial changes in pointcloud geometry and topology.\n\nIn appropriate frameworks, automatic differentiation is transparent to the user, at the cost of being a significant computational burden when the number of operations is large. For iterative algorithms, implicit differentiation alleviates this issue but requires custom implementation of Jacobian evaluation. In this paper, we study one-step differentiation, also known as Jacobian-free backpropagation, a method as easy as automatic differentiation and as performant as implicit differentiation for fast algorithms (e.g. superlinear optimization methods). We provide a complete theoretical approximation analysis with specific examples (Newton's method, gradient descent) along with its consequences in bilevel optimization. Several numerical examples illustrate the well-foundness of the one-step estimator.\n\nThe question of what makes a data distribution suitable for deep learning is a fundamental open problem. Focusing on locally connected neural networks (a prevalent family of architectures that includes convolutional and recurrent neural networks as well as local self-attention models), we address this problem by adopting theoretical tools from quantum physics. Our main theoretical result states that a certain locally connected neural network is capable of accurate prediction over a data distribution if and only if the data distribution admits low quantum entanglement under certain canonical partitions of features. As a practical application of this result, we derive a preprocessing method for enhancing the suitability of a data distribution to locally connected neural networks. Experiments with widespread models over various datasets demonstrate our findings. We hope that our use of quantum entanglement will encourage further adoption of tools from physics for formally reasoning about the relation between deep learning and real-world data.\n\nPrompt-based continual learning is an emerging direction in leveraging pre-trained knowledge for downstream continual learning, and has almost reached the performance pinnacle under supervised pre-training. However, our empirical research reveals that the current strategies fall short of their full potential under the more realistic self-supervised pre-training, which is essential for handling vast quantities of unlabeled data in practice. This is largely due to the difficulty of task-specific knowledge being incorporated into instructed representations via prompt parameters and predicted by uninstructed representations at test time. To overcome the exposed sub-optimality, we conduct a theoretical analysis of the continual learning objective in the context of pre-training, and decompose it into hierarchical components: within-task prediction, task-identity inference, and task-adaptive prediction. Following these empirical and theoretical insights, we propose Hierarchical Decomposition (HiDe-)Prompt, an innovative approach that explicitly optimizes the hierarchical components with an ensemble of task-specific prompts and statistics of both uninstructed and instructed representations, further with the coordination of a contrastive regularization strategy. Our extensive experiments demonstrate the superior performance of HiDe-Prompt and its robustness to pre-training paradigms in continual learning (e.g., up to 15.01% and 9.61% lead on Split CIFAR-100 and Split ImageNet-R, respectively).\n\nIn reinforcement learning (RL), balancing exploration and exploitation is crucial for achieving an optimal policy in a sample-efficient way. To this end, existing sample- efficient algorithms typically consist of three components: estimation, planning, and exploration. However, to cope with general function approximators, most of them involve impractical algorithmic components to incentivize exploration, such as data-dependent level-set constraints or complicated sampling procedures. To address this challenge, we propose an easy-to-implement RL framework called Maximize to Explore (MEX), which only needs to optimize unconstrainedly a single objective that integrates the estimation and planning components while balancing exploration and exploitation automatically. Theoretically, we prove that the MEX achieves a sublinear regret with general function approximators and is extendable to the zero-sum Markov game setting. Meanwhile, we adapt deep RL baselines to design practical versions of MEX in both the model-based and model-free settings, which outperform baselines in various MuJoCo environments with sparse reward by a stable margin. Compared with existing sample-efficient algorithms with general function approximators, MEX achieves similar sample efficiency while also enjoying a lower computational cost and is more compatible with modern deep RL methods.\n\nIn the past few years, there has been an explosive surge in the use of machine learning (ML) techniques to address combinatorial optimization (CO) problems, especially mixed-integer linear programs (MILPs). Despite the achievements, the limited availability of real-world instances often leads to sub-optimal decisions and biased solver assessments, which motivates a suite of synthetic MILP instance generation techniques. However, existing methods either rely heavily on expert-designed formulations or struggle to capture the rich features of real-world instances. To tackle this problem, we propose G2MILP, the first deep generative framework for MILP instances. Specifically, G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs to generate new ones. The appealing feature of G2MILP is that it can learn to generate novel and realistic MILP instances without prior expert-designed formulations, while preserving the structures and computational hardness of real-world datasets, simultaneously. Thus the generated instances can facilitate downstream tasks for enhancing MILP solvers under limited data availability. We design a suite of benchmarks to evaluate the quality of the generated MILP instances. Experiments demonstrate that our method can produce instances that closely resemble real-world datasets in terms of both …\n\nResearch in statistical learning has polarized into two general approaches to perform regression analysis: Transductive methods construct estimates directly based on exemplar data using generic relational principles which might suffer from the curse of dimensionality. Conversely, inductive methods can potentially fit highly complex functions at the cost of compute-intensive solution searches. In this work, we leverage the theory of vector-valued Reproducing Kernel Banach Spaces (RKBS) to propose a hybrid approach: We show that transductive regression systems can be meta-learned with gradient descent to form efficient in-context neural approximators of function defined over both finite and infinite-dimensional spaces (operator regression). Once trained, our Transducer can almost instantaneously capture new functional relationships and produce original image estimates, given a few pairs of input and output examples. We demonstrate the benefit of our meta-learned transductive approach to model physical systems influenced by varying external factors with little data at a fraction of the usual deep learning training costs for partial differential equations and climate modeling applications.\n\nA Top Two sampling rule for bandit identification is a method which selects the next arm to sample from among two candidate arms, a leader and a challenger. Due to their simplicity and good empirical performance, they have received increased attention in recent years. However, for fixed-confidence best arm identification, theoretical guarantees for Top Two methods have only been obtained in the asymptotic regime, when the error level vanishes. In this paper, we derive the first non-asymptotic upper bound on the expected sample complexity of a Top Two algorithm, which holds for any error level. Our analysis highlights sufficient properties for a regret minimization algorithm to be used as leader. These properties are satisfied by the UCB algorithm, and our proposed UCB-based Top Two algorithm simultaneously enjoys non-asymptotic guarantees and competitive empirical performance.\n\nLanguage models pretrained on large collections of tabular data have demonstrated their effectiveness in several downstream tasks.However, many of these models do not take into account the row/column permutation invariances, hierarchical structure, etc. that exist in tabular data. To alleviate these limitations, we propose HyTrel, a tabular language model, that captures the permutation invariances and three more structural properties of tabular data by using hypergraphs--where the table cells make up the nodes and the cells occurring jointly together in each row, column, and the entire table are used to form three different types of hyperedges. We show thatHyTrel is maximally invariant under certain conditions for tabular data, i.e., two tables obtain the same representations via HyTreliff the two tables are identical up to permutation. Our empirical results demonstrate that HyTrel consistently outperforms other competitive baselines on four downstream tasks with minimal pretraining, illustrating the advantages of incorporating inductive biases associated with tabular data into the representations. Finally, our qualitative analyses showcase that HyTrel can assimilate the table structure to generate robust representations for the cells, rows, columns, and the entire table.\n\nContinuous-time score-based generative models consist of a pair of stochastic differential equations (SDEs)—a forward SDE that smoothly transitions data into a noise space and a reverse SDE that incrementally eliminates noise from a Gaussian prior distribution to generate data distribution samples—are intrinsically connected by the time-reversal theory on diffusion processes. In this paper, we investigate the use of stochastic evolution equations in Hilbert spaces, which expand the applicability of SDEs in two aspects: sample space and evolution operator, so they enable encompassing recent variations of diffusion models, such as generating functional data or replacing drift coefficients with image transformation. To this end, we derive a generalized time-reversal formula to build a bridge between probabilistic diffusion models and stochastic evolution equations and propose a score-based generative model called Hilbert Diffusion Model (HDM). Combining with Fourier neural operator, we verify the superiority of HDM for sampling functions from functional datasets with a power of kernel two-sample test of 4.2 on Quadratic, 0.2 on Melbourne, and 3.6 on Gridwatch, which outperforms existing diffusion models formulated in function spaces. Furthermore, the proposed method shows its strength in motion synthesis tasks by utilizing the Wiener process with values in Hilbert space. Finally, our empirical results …\n\nRandomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.\n\nWe present a novel methodology aimed at optimizing the application of frozen large language models (LLMs) for resource-intensive vision-language (VL) pre-training. The current paradigm uses visual features as prompts to guide language models, with a focus on determining the most relevant visual features for corresponding text. Our approach diverges by concentrating on the language component, specifically identifying the optimal prompts to align with visual features. We introduce the Prompt-Transformer (P-Former), a model that predicts these ideal prompts, which is trained exclusively on linguistic data, bypassing the need for image-text pairings. This strategy subtly bifurcates the end-to-end VL training process into an additional, separate stage. Our experiments reveal that our framework significantly enhances the performance of a robust image-to-text baseline (BLIP-2), and effectively narrows the performance gap between models trained with either 4M or 129M image-text pairs. Importantly, our framework is modality-agnostic and flexible in terms of architectural design, as validated by its successful application in a video learning task using varied base modules. The code will be made available at https://github.com/yiren-jian/BLIText.\n\nWe present Prompt Diffusion, a framework for enabling in-context learning in diffusion-based generative models. Given a pair of task-specific example images, such as depth from/to image and scribble from/to image, and a text guidance, our model automatically understands the underlying task and performs the same task on a new query image following the text guidance. To achieve this, we propose a vision-language prompt that can model a wide range of vision-language tasks and a diffusion model that takes it as input. The diffusion model is trained jointly on six different tasks using these prompts. The resulting Prompt Diffusion model becomes the first diffusion-based vision-language foundation model capable of in-context learning. It demonstrates high-quality in-context generation for the trained tasks and effectively generalizes to new, unseen vision tasks using their respective prompts. Our model also shows compelling text-guided image editing results. Our framework aims to facilitate research into in-context learning for computer vision. We share our code and pre-trained models at https://github.com/Zhendong-Wang/Prompt-Diffusion.\n\nDiscovering object-centric representations from images has the potential to greatly improve the robustness, sample efficiency and interpretability of machine learning algorithms. Current works on multi-object images typically follow a generative approach that optimizes for input reconstruction and fail to scale to real-world datasets despite significant increases in model capacity. We address this limitation by proposing a novel method that leverages feature connectivity to cluster neighboring pixels likely to belong to the same object. We further design two object-centric regularization terms to refine object representations in the latent space, enabling our approach to scale to complex real-world images. Experimental results on simulated, real-world, complex texture and common object images demonstrate a substantial improvement in the quality of discovered objects compared to state-of-the-art methods, as well as the sample efficiency and generalizability of our approach. We also show that the discovered object-centric representations can accurately predict key object properties in downstream tasks, highlighting the potential of our method to advance the field of multi-object representation learning.\n\nLarge language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well.Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these bottlenecks with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM based simulator for human feedback that is 45x cheaper than crowdworkers and displays high agreement with humans. Second, we identify an evaluation dataset representative of real-world instructions and propose an automatic evaluation procedure. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, among others) that learn from pairwise feedback. Finally, as an end-to-end validation of AlpacaFarm, we train and evaluate eleven models on 10k pairs of human feedback and show that rankings of models trained in AlpacaFarm match rankings of models trained on human data. As a demonstration of the research possible in AlpacaFarm, we find that methods that use a reward model can substantially improve over supervised fine-tuning and …\n\nIn practice, encoding invariances into models improves sample complexity. In this work, we study this phenomenon from a theoretical perspective. In particular, we provide minimax optimal rates for kernel ridge regression on compact manifolds, with a target function that is invariant to a group action on the manifold. Our results hold for any smooth compact Lie group action, even groups of positive dimension. For a finite group, the gain effectively mu"
    }
}