{
    "id": "dbpedia_1449_2",
    "rank": 32,
    "data": {
        "url": "https://www.bbc.com/news/business-66853057",
        "read_more_link": "",
        "language": "en",
        "title": "Is it possible to regulate artificial intelligence?",
        "top_image": "https://ichef.bbci.co.uk/news/1024/branded_news/C318/production/_131144994_gettyimages-1352002665.jpg",
        "meta_img": "https://ichef.bbci.co.uk/news/1024/branded_news/C318/production/_131144994_gettyimages-1352002665.jpg",
        "images": [
            "https://www.bbc.com/bbcx/grey-placeholder.png",
            "https://ichef.bbci.co.uk/news/240/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/8C2A/production/_131128853_gettyimages-1152559079.jpg.webp 1536w",
            "https://www.bbc.com/bbcx/grey-placeholder.png",
            "https://ichef.bbci.co.uk/news/240/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/2AE6/production/_131128901_pierre.jpg.webp 1536w",
            "https://www.bbc.com/bbcx/grey-placeholder.png",
            "https://ichef.bbci.co.uk/news/240/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/536F/production/_130295312_ai_banner_top_640x2-nc.png.webp 1536w",
            "https://www.bbc.com/bbcx/grey-placeholder.png",
            "https://ichef.bbci.co.uk/news/240/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/7A7F/production/_130295313_ai_banner_bottom_640x2-nc.png.webp 1536w"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Michael Dempsey"
        ],
        "publish_date": "2023-09-20T23:06:31+00:00",
        "summary": "",
        "meta_description": "We are moving towards regulation of AI, but some experts maintain that it will never work.",
        "meta_lang": "en",
        "meta_favicon": "/bbcx/apple-touch-icon.png",
        "meta_site_name": "",
        "canonical_link": "https://www.bbc.com/news/business-66853057",
        "text": "Can artificial intelligence be kept under control? Jimmy Wales, the founder of Wikipedia, says that believing it can be is akin to \"magical thinking\".\n\n\"In many cases politicians and their aides have a weak understanding of how the internet works, and what it is possible to achieve,\" says Mr Wales, who has spent many hours explaining both technology and its role in free speech to politicians around the globe.\n\n\"The question of a body like the United Nations regulating AI is like suggesting the UN regulate [image editing app] Photoshop.\" His point is that he thinks it would be pointless.\n\nThe issue of whether AI should be regulated, and to what extent, heated up this summer when UN Secretary General Ant√≥nio Guterres convened the first ever UN Security Council meeting to specifically discuss its potential dangers.\n\nSpeaking in regard to everything from AI-powered cyber attacks, to the risk of malfunctioning AI, how AI can spread misinformation, and even the interaction between AI and nuclear weapons, Mr Guterres said: \"Without action to address these risks, we are derelict in our responsibilities to present and future generations.\"\n\nMr Guterres has since moved forward with the establishment of a UN panel to investigate what global regulation might be needed. Called the High-Level Advisory Body for Artificial Intelligence, this will comprise \"present and former government experts, as well as experts from industry, civil society, and academia\".\n\nIt is due to publish its initial findings before the end of this year. Meanwhile, last week US tech bosses such as Elon Musk and Meta's Mark Zuckerberg held talks with US lawmakers in Washington to discuss AI and potential future rules.\n\nHowever, some AI insiders are sceptical that global regulation can be successful. One such person is Pierre Haren, who has been researching AI for 45 years.\n\nHis experience includes seven years at computer giant IBM, where he led the team that installed Watson super computer technology for customers. Debuted in 2010, Watson can answer a user's questions, and was one of the pioneers of AI.\n\nDespite Mr Haren's background, he says he was \"flabbergasted\" by the emergence and capability of ChatGPT and other so-called \"generative AI\" programs over the past year.\n\nGenerative AI is, put simply, AI that can quickly create new content, be it words, images, music or videos. And it can take an idea from one example, and apply it to an entirely different situation.\n\nMr Haren says that such an ability is human-like. \"This thing is not like a parrot, repeating what we feed into it,\" he says. \"It's making high-level analogies.\"\n\nSo how can we create a set of rules to stop this AI getting out of control? We can't, says Mr Haren, because he says some countries won't sign up to them.\n\n\"We live in a world with non-cooperative nations like North Korea and Iran,\" he says. \"They won't recognise regulations around AI.\n\n\"The regulation of non-cooperative actors is pie in the sky! Can you imagine Iran looking for a way to destroy Israel and caring about AI regulations?\"\n\nPhysicist Reinhard Scholl is the founder of the UN's \"AI For Good\" programme. This aims to find and implement practical AI solutions to help achieve the UN's sustainable development goals. These include everything from ending poverty, to eradicating hunger and giving everyone access to clean water.\n\nAI for Good began life in 2017 as an annual event, and has blossomed into a regular schedule of online seminars that address every facet of AI.\n\nWith over 20,000 subscribers, AI for Good has hit a nerve, but the appetite for positive AI doesn't mean Mr Scholl is optimistic.\n\n\"Should AI be regulated? It's a no-brainer, yes!\" he declares, comparing the situation to how car or toymakers have to comply with safety regulations.\n\nHis big worry is that AI makes it relatively easy for bad actors to employ the technology as a springboard to acquire dangerous capabilities.\n\n\"A physicist knows how to build a nuclear bomb in theory, but to do it in practice would be very difficult,\" he says. \"But if someone uses AI to design a biological weapon they don't need to know so much.\n\n\"And if it becomes too easy for people to do major damage using AI then someone will do it.\"\n\nBut what form should a future UN regulatory body on AI take? One suggestion is that it mirrors the International Civil Aviation Organisation (ICAO), which regulates global air travel and its safety. This has 193 member nations.\n\nRead additional stories on artificial intelligence\n\nRobert Opp is one AI expert who backs the formation of a body similar to the ICAO. Mr Opp is chief digital officer for the UN Development Programme.\n\nThe agency is tasked with helping countries drive economic growth and end poverty. His job sees him try to find ways to make technology boost the organisation's impact.\n\nThis includes the use of AI to quickly check satellite images of farmland in impoverished areas. Mr Opp says he doesn't want to impede that kind of capability, or restrain the potential of generative AI to assist the poor in building up a business.\n\nBut he also accepts the potential downside of AI. \"There is a sense of urgency in figuring out AI governance.\"\n\nHe believes the international bodies are making a big error in overestimating the role of tech giants like Google in the avalanche of AI products. Mr Wales adds that no amount of good intentions can hold back individual software developers and their use of AI."
    }
}