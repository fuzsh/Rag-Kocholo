{
    "id": "dbpedia_1763_0",
    "rank": 58,
    "data": {
        "url": "https://journals.humankinetics.com/view/journals/jsep/46/S1/article-pS1.xml",
        "read_more_link": "",
        "language": "en",
        "title": "North American Society for the Psychology of Sport and Physical Activity",
        "top_image": "https://journals.humankinetics.com/cover/journals/jsep/jsep_cover.jpg",
        "meta_img": "https://journals.humankinetics.com/cover/journals/jsep/jsep_cover.jpg",
        "images": [
            "https://journals.humankinetics.com/coverimage?doc=%2Fjournals%2Fjsep%2Fjsep-overview.xml&width=200",
            "https://journals.humankinetics.com/fileasset/logo_no_text.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-05-01T00:00:00",
        "summary": "",
        "meta_description": "\"North American Society for the Psychology of Sport and Physical Activity\" published on 01 May 2024 by Human Kinetics.",
        "meta_lang": "en",
        "meta_favicon": "/fileasset/favicon.ico",
        "meta_site_name": "Human Kinetics",
        "canonical_link": "https://journals.humankinetics.com/view/journals/jsep/46/S1/article-pS1.xml",
        "text": "Motor Learning and Control Abstracts\n\nEffect of dual tasking on cognitive performance among college students with concussion history? A pilot study\n\nPrasanna Acharya, Illinois College; Madison Webb, Illinois College; Tsilate Mussie, Illinois College; Marc Dalecki, German University of Health & Sports\n\nOften, dual-tasks (DT) involve a motor and cognitive task such as walking and counting backward and studies showed lower cognitive performance in DT scenarios in healthy individuals and more pronounced performance declines in acutely concussed individuals. Here, we aim to examine whether similar effects exist further time post-injury using computerized cognitive tasks. We hypothesized lower performance during DT and that concussion history participants (CH) perform lower during DT conditions than no-history controls (NoH). Our preliminary data set included ten college students (M = 21.1 yrs., with 4 CH [2 females; > 4 yrs. post-concussion] and 6 NoH [3 females] participants), randomly assigned to start in standing (Single task; ST) or walking (DT) condition. In both conditions, participants completed two cognitive tests on a laptop – a Stroop Color word test (48 congruent, 48 incongruent trials) and a D2 sustained attention test (computerized version of the D2 test, with varying sequences of the letters d and p, and participants had to correctly mark d´s surrounded by two commas) – and the laptop was placed on eye level on top of the treadmill. The participant’s comfortable walking speed (CWS) was determined before testing for the DT condition. ANOVAs were used to analyze response time (RT; ms), error rate (ER; %), and sustained attention score (CS; D2 test only) in the CH and NoH groups during ST and DT conditions. In our pilot data set, no significant cognitive performance differences were detected between ST and DT conditions, groups, or group x condition interactions (all p > .05). NoH and CHs’ Stroop and sustained attention performance was similar in ST and DT walking with CWS in college students >4 yrs. post-injury compared to NoH. Surprisingly, Stroop and sustained attention performance was also similar between DT and ST conditions, independent of groups, suggesting walking with CWS did not draw enough strain on resource capacities to lower performance during these two tasks. However, these results are preliminary, and more data collection is needed.\n\nNeural activity associated with execution of a visuomotor adaptation task performed in different workspace locations\n\nReuben N. Addison, Louisiana State University, DePauw University; Fabian Steinberg, Louisiana State University; Arend W. A. Van Gemmert, Louisiana State University\n\nVisuomotor adaptation studies investigate how humans utilize sensory information to interact within their environment. The sensorimotor system updates crucial information during adaptation, particularly in estimating the target’s location within the workspace. While some studies have proposed workspace-specific adaptation, most evidence from studies indicate potential generalization to other workspace locations. Changes in brain activity occur in response to visually rotated targets, yet understanding neural changes during workspace manipulation remains limited. The current study explored how changes in neural activities are affected by workspace manipulation during a visuomotor adaptation task. Twenty-four right-handed young adults made point-to-point movements with a stylus on a digitizer tablet in three different workspace locations (1) central (CEN); 2) ipsilateral (IPS) to the body, and 3) contralateral (CTL) to the body with the feedback of pen-traces rotated 45° clockwise. Electroencephalography (EEG) was recorded with a 32-electrode system. Within-subject ANOVAs were used to analyze behavioral and neural workspace-related differences. Results indicated that participants improved significantly on the visuomotor adaptation task across all three workspace locations; however, improvements in performance was more pronounced in the ipsilateral workspace compared to the contralateral workspace. The observed workspace related performance differences were associated changes in alpha (C4, CP2, and CP6) and beta waves (C4, CP2, P4, and P8). It can be concluded that neural activity changes were consistent with behavioral patterns, supporting the view that these brain areas are pivotal to process spatial information during the adaption process when novel tasks are performed. We believe that our data suggest that right central and parietal-cortical areas (areas involve in spatial processing) are involved in workspace-related inhibition to allow the left hemisphere work efficiently.\n\nEvaluating the effect of load on visual attention during a live ice hockey practice\n\nNikki Aitcheson-Huehn, University of North Carolina at Chapel Hill; Ryan MacPherson, University of North Carolina at Chapel Hill; Jason P. Mihalik, University of North Carolina at Chapel Hill; Adam W. Kiefer, University of North Carolina at Chapel Hill\n\nHigh-performing athletes must maintain performance across a range of cognitive, perceptual, and physical demands. These demands fluctuate in response to evolving competitive pressures, such as changes in physical workload. Further, informational load changes with the number of participants one is engaged with at any given moment, highlighting the complexity of the perceptual challenges encountered. This study aimed to evaluate the effect of physical and informational loading by monitoring in situ visual attention—indexed via quiet eye (QE)—during team practices, with visual attention hypothesized to decrease with increased physical and informational load. Ten (n = 10; 20.6 ± 2y) Division II club male ice hockey players wore a chest-strap heart rate (HR) monitor (Polar H10) and mobile binocular eye tracking glasses (Tobii Pro Glasses 3) during separate 60-min coach-led practices. Four ice-facing video cameras captured each player’s motor behavior. Physical load was indexed via mean heart rate (HR) during each shot (i.e., puck attainment and release). Average HR during practices was 141bpm (SD = 16) with 25% of each practice spent in 60–70% of HR max. Informational load equated to the number of total players participating in the drill when the shot occurred (i.e., 2–6). Preliminary analysis of the shots of 7 forwards focused on QE, the visual fixation initiated before downswing (i.e., the final movement). The duration of QE was calculated from onset (gaze within 3° of visual angle for at least 3 frames) and offset (gaze moved off location for 3 or more frames) and was relative to shot duration. Predominate QE locations included the goalie’s lower body (30%), the ice in the crease (23%), and the visible portions of the net not occupied by the goalie (16%). During shots with another player and goalie, QE duration was 25.8% (SD = 33.4); whereas, QE duration was 14.6% (SD = 5.8) on shots with 2 other players and goalie. The full analyzed results will be presented to directly test the hypothesized relationship between visual attention and load (i.e., HR and number of players). Funding source: NASPSPA Graduate Student Research Grant.\n\nAdaptation and savings are differentially impacted by the type of virtual partner\n\nNour Al Afif, McMaster University; Daniel Deletsu, McMaster University; Mikayla Lalli, McMaster University; Ola Schwarzenberg, McMaster University; Lidia Barbera, McMaster University; Abby Girouard, McMaster University; Rakshith Lokesh, Northeastern University; Joshua G. A. Cashaback, University of Delaware; Michael J. Carter, McMaster University\n\nCurrent literature suggests that physically collaborating with one or more individuals enhances task completion. However, there are inconsistencies in our understanding of how collaborative experiences impact an individual’s subsequent solo task performance. Some studies suggest that individual performance benefits from these interactions (Takagi et al. 2017), while others do not (Beckers et al. 2020). Additionally, these previous works used non-redundant paradigms where each partner had individual control over their own cursor, which does not accurately reflect collaborative interactions in daily life. To address this, participants (N = 100) in our experiment adapted to a 30-deg visuomotor rotation either alone or sharing the cursor with a virtual partner. The virtual partners were based on the fast and slow states of the two-state model (Smith et al. 2006). The fast state learns quickly but forgets easily, while the slow state learns slower but retains learned behaviour longer. Those who completed the task alone, did so at either the full rotation, or a rotation of 15 degrees. Participants completed 2 sessions, each consisting of a baseline block (50 trials), followed by a visuomotor rotation block (200 trials), a counter-adaptation block (20 trials) and an error clamp block (50 trials). We separated the two sessions with a 5-min break to examine savings, where previous adaptation to a perturbation leads to faster re-adaptation. All participants performed session 2 alone. Reach angle was the primary measure used to examine the extent of adaptation and savings across the blocks of trials. Results indicated that participants who interacted with a fast partner exhibited more spontaneous recovery of the learned adaptation during error clamp in the first session. Yet, those who interacted with the slow partner showed faster re-adaptation in the second session, similar to the group that completed the task alone at a 30 degree rotation. These results suggest that the nature of the partner can influence the extent of savings differently following adaptation. Funding source: Natural Sciences and Engineering Research Council of Canada, Canadian Foundation for Innovation, Ontario Research Fund.\n\nFront leg strategy in older adults’ gait during step-to-step transition\n\nElham Alijanpour, Old Dominion University; Daniel M. Russell, Old Dominion University\n\nWalking requires the coordination of many body components and systems, but aging alters organism constraints, which impacts movement coordination. The step-to-step transition, usually starting before double support and ending afterwards, has been identified as a critical phase where most age-related falls occur. Recently, unbalanced leg forces and a later transition start at double support have been identified in older adults, emphasizing the importance of understanding these dynamics in addressing age-related deficits and fall risk in the elderly. The current study aimed to quantify differences in interlimb coordination and front/back leg force ratio during double support of gait between young and older adults. Two groups of 10 young and 10 older adults walked on an instrumented treadmill at their preferred walking speed while a motion capture system recorded joint kinematics. Based on phase plots of lower extremity joints, interlimb coordination was quantified using continuous relative phase. The results showed older adults (M = 1.4, SE = 0.4) had significantly higher relative force in their front leg during step-to-step transition compared to young adults (M = 1.1, SE = 0.1), t(18) = 1.97, p = .03, with a medium effect size r = .4. Statistical parametric mapping results of knee interlimb coordination revealed larger, faster, and more variable front leg knee flexion during the step-to-step transition in older adults, p < .05. However, there were no significant differences in hip or ankle interlimb coordination patterns. Older adults appear to use a “front leg strategy”, with increased front knee flexion and quicker knee angular phase transition to propel the body forward, compensating for reduced back leg hip extension reported in previous studies. This strategy may serve both shock absorption and step-to-step transition demands in walking but could impact energy efficiency by increasing load on the knee extensor muscle.\n\nMotor vs brain biomarkers for freezing of gait: The most severe motor impairment in Parkinson’s disease\n\nQuincy J. Almeida, Carespace Health & Wellness Clinics; Fatemeh Karimi, University of Waterloo; Nico Castro-Folker, University of Waterloo; Marek Stastna, University of Waterloo; Ning Jiang, Sichuan University\n\nFreezing of gait (FOG) in Parkinson’s disease (PD) is the most debilitating motor symptom impeding independence and quality of life, so it is critical to be able to clinically define, identify and predict when and if it is occurring. Previously, we presented that spatial gait variables are likely more important than temporal variables in predicting FOG. In the current abstract, we pooled gait data from several countries that were followed for up to 3 years, and employed machine learning to make predictions about the likelihood that newly diagnosed PD might experience FOG. Results revealed that 50% of the sample that showed no signs of FOG eventually converted to FOG within 4 years. Utilizing Bayesian classification and principal component analyses, we identified key predictors of FOG, with the most relevant features for training an algorithm with an acceptable false-positive: true-positive as measured using a receiver operating characteristic (ROC) curve. The results of these analyses revealed that mean stride length & velocity, cadence, coefficient of variation of the stride length & velocity (between limbs), and disease duration were key to a portable, robust diagnostic algorithm. Given that some patients are unable to complete full walking assessments, we also had the objective of utilizing EEG-based movement-related cortical potentials (MRCP’s) as a potential biomarker of FOG using a simple, seated ankle dorsi-flexion task in 3 groups (FOG, PD non-FOG, healthy age-matched controls). The FOG group revealed significantly lower MRCP’s than controls (p = .002), which was affected by severity of FOG. Furthermore, beta frequency band (12–35 Hz) desynchronization was absent in FOG, especially over Cz before movement. Interestingly, FOG showed theta band synchronization over the supplementary motor area suggesting involvement of cognitive processes rather than 1° cortex in controlling cue-based voluntary movement (a potential compensatory mechanism in FOG). The pros and cons of utilizing gait vs brain biomarkers as prodromal indicators of FOG in PD will be discussed. Funding source: Michael J. Fox Foundation, NSERC.\n\nPostural control entropy is greater when barefoot compared to when wearing shoes in children aged 4–6 years old\n\nBryon C. Applequist, Texas A&M University – Corpus Christi; Megan E. Perkins, Texas A&M University – Corpus Christi\n\nPostural control gradually evolves during early childhood as children learn how to control the constraints of their environment and growing body. As children grow, their neuromuscular system is maturing with the development of their sensory systems that effect balance and postural control. The constraint of shoes could have a dramatic effect on the development of postural control in children. In many cases, shoes are the connection between the ground and our bodies and are necessary for activities such as sports and physical activity. However, shoes could hinder the child’s ability to fully utilize their proprioceptive system, particularly with the habitual use of footwear in modern children. The purpose of this study was to investigate the effect shoes have on postural control of children, measuring both the conventional standard deviation of the center of pressure (COP) and the sample entropy of COP. 10 healthy young children between the ages of 4–6 (Age: 4.9 ± 1.1years) participated in the study. Subjects were asked to stand in quiet posture for 1-minute while barefoot and while wearing a lab supplied shoe. Standard deviation (SD) and sample entropy (SE) of the COP trajectories in the anteroposterior (AP) and the mediolateral (ML) directions were computed. Dependent t-tests were used to compare the barefoot and shod conditions of each variable. There was a significant difference between the barefoot and shod conditions for COP AP SE (Bare 1.64±.45, Shod 1.16±.40, p = .003), and COP ML SE (Bare 2.83 ± .80, Shod 1.90 ± .87, p = .001). There were no differences for SD for either AP or ML (p > .05). These results indicate that shoes are providing a constraint on the children and driving them towards rigidity in their postural control and lower entropy. Lower entropy values have been related to pathology and neurological deficits. It is possible that shoes can limit the development of healthy postural control and reduce children’s adaptability of their environments and perturbations. Future work should be conducted related to the habitual use of specific types of shoes.\n\nLeveraging eye tracking machine learning system for predicting successful targeting skill performance\n\nAyoub Asadi, Iowa state university/ Alzahra University; Afkham Daneshfar, Alzahra University; Mohammad Reza Saeedpour-Parizi, Indiana University Bloomington; Christopher Aiken, New Mexico State University; Ann Smiley, Iowa state University\n\nEye tracking in sports is an emerging field aimed to uncover the complex interrelationships between visual function and motor performance. While previous studies have identified specific visual behaviors that can differentiate superior sports performance, the application of machine learning systems utilizing eye tracking data in sports remains relatively unexplored. This study aimed to investigate eye movement behaviors to detect successful performance in basketball free throws using machine learning methodologies. Gaze behavior data from 25 student basketball players during successful and unsuccessful free throws were collected and analyzed. The series paired t-tests was used to determine eye movement behaviors differences between hit and miss trials. Furthermore, based on eye movement data, the different machine learning classifiers were developed to detect free-throw performance. Statistical results revealed significant differences in fixation, saccade, and microsaccade durations between hit and miss trials (p ≤ .05), indicating the effectiveness of longer fixation durations and shorter saccade and microsaccade durations for successful performance. Also, the outcomes derived from the machine learning analysis, exhibiting an accuracy rate of 85.9%, highlighted the heightened importance of metrics associated with saccades for successful performance than those related to fixations. The implications of these findings highlight the significance of employing eye tracking coupled with machine learning techniques within the domain of sports. The demonstrated leveraging capability to reliably predict successful performance from athletes’ eye movement data signifies a paradigm shift in understanding the critical elements governing proficient motor skills. Our findings offer valuable initial insights and serve as a source of inspiration for future research concentrating on the advancement of machine learning systems utilizing eye-tracking technology to identify and assess proficiency in motor skills.\n\nDifferences in the prefrontal cortex during the Purdue Peg test performance in young adults with and without ADHD\n\nElham Bakhshipour, University of Delaware; Roxana Burciu, University of Delaware; Roghayeh Barmaki, University of Delaware; Nancy Getchell, University of Delaware\n\nAttention Deficit/Hyperactivity Disorder (ADHD) affects the individual’s quality of life throughout the lifespan. Fine motor function is associated with cognitive function and the quality of life. However, little is known on the impact of ADHD on fine motor function in adulthood. To examine prefrontal cortex (PFC) activation using functional near infrared spectroscopy (fNIRS) during execution of a manual dexterity task in young adults with ADHD aged 20–25 years. Fifteen adults with confirmed ADHD and seventeen without ADHD completed the Purdue Pegboard test (PPT) in a matched sample repeated measures design. Repeated measures two-way ANOVA was performed on average change in deoxygenation (Δ HbR) and change in oxygenation (Δ HbO) in PFC regions (left dorsolateral PFC, left ventro medial PFC, right ventro medial PFC, right dosrsolateral PFC). A Bonferroni correction was used to account for multiple comparisons. The results showed that adults with ADHD may demonstrate no significant difference in PPT performance while their PFC activity has an abnormal pattern compared to the control non-ADHD group. This highlights the importance of utilizing neuroimaging devices to study underlying deficits in this population. The underlying fNIRS substrates show lower baseline at rest, higher activation in the PFC and dorso-lateral PFC (dlPFC) in ADHD group compared to the control group during the task accomplishment time. This can confirm compromised fine motor ability in ADHD group. PFC, and more specifically dlPFC is involved more in confirmed ADHD. This can lead to PFC overuse which in turn can cause more frequent mental fatigue in ADHD. This article demonstrates compromised cortical activation during fine motor task in adults with ADHD.\n\nDifferences in the prefrontal cortex activity during the DASH17+ handwriting performance in young adults with and without ADHD\n\nElham Bakhshipour, University of Delaware; Roxana Burciu, University of Delaware; Curtis Johnson, University of Delaware; Roghayeh Barmaki, University of Delaware; Nancy Getchell, University of Delaware\n\nTo examine differences between adults with and without ADHD on the handwriting performance, we utilized a multimodal assessment strategy: The Detailed Assessment of Speed of Handwriting (DASH17+); and concurrent prefrontal cortex oxygenation measurement using functional near-infrared spectroscopy (fNIRS) as well as kinematic measurement using Wacom digitizer. To address our research question, a total of 32 participants with (n = 17) or without ADHD (n = 15) participated in the study. All participants performed the DASH17+ on the Wacom digitizer while concurrently we collected oxygenation data (indirect measurement of neural activity) from the prefrontal cortex. Performance data were analyzed using MoveAlyzer software to calculate handwriting biomechanics and kinematics. Our results indicated that overall performance scores did not differ between groups between or within the different subtests (copy best, copy fast, free writing). The ADHD group had less frequent short pauses and lower values of oxyhemoglobin than the non-ADHD group. Our research suggests that, despite scoring similarly to our control group on the performance scores of DASH17+, the ADHD participants have a harder time switching the handwriting biomechanics when the demands of the task changes. Further, underlying mechanisms change between tasks, within tasks, and even from one trial block to another that are not reflected in the DASH17+ assessment alone. Funding source: College of Health Science Equipment Grant, Graduate College Summer Doctoral Fellowship Grant, KAAP Dissertation Grant, and KAAP Teaching Assistantship Award and three Professional Development Awards.\n\nAttentional focus does not impact balance in healthy young adults\n\nJohn Henry Ballard, University of Tennessee, Knoxville; Joshua Weinhandl, University of Tennessee, Knoxville; Kevin Becker, University of Tennessee, Knoxville\n\nIn recent years, several researchers have made attempts to add further nuance to our understanding of how attentional focus impacts motor behavior. One line of research has considered the benefit of a holistic focus (i.e., focus on the general feelings associated with completing a task; Becker et al., 2019) relative to the traditionally studied internal and external focus. To date, a holistic focus benefit has been reported in jumping tasks and object projection tasks, but the one study testing a holistic focus in a balancing task found no benefit (Becker & Hung, 2020). These authors suggested the cue used in that study (feeling calm and stable) may have been incongruent with the actual feelings experienced when balancing on a stabilometer, thus rendering it ineffective. The purpose of the present study was to use a different balancing task to determine how an internal, external, and holistic focus impact balance performance in healthy young adults. Participants (N = 18) stood on inflatable balance discs placed on a force plate and attempted to maintain their balance during 10 second trials. They focused on keeping their feet still (internal), keeping the discs still (external), or feeling calm and stable (holistic). Three trials were completed in each condition in a counterbalanced order. Center of pressure data was captured from the force plate at 1000Hz, and a custom MATLAB code was used to calculate root mean square (RMS), median power frequency (MPF), and sample entropy (SEn) in both the medial/lateral (x) and anterior/posterior (y) directions. Repeated measures ANOVAs indicated no effect of focus on RMS or SEn in either direction. MPFx approached a significant difference between conditions (p = .051) with mean values highest in the external condition. The present data do not support the benefit of a holistic or an external focus in the performance of a balancing task by healthy young adults. The latter conclusion is especially surprising but fits a recent trend suggesting the external focus benefit may not be as clear or universal as previously thought.\n\nPerceived workload following a sprinting task using attentional focus instructions\n\nAmanda Barclift, University of North Carolina Greensboro; Aleiza Higgins, University of North Carolina Greensboro; Louisa Raisbeck, University of North Carolina Greensboro\n\nDirecting attention to cues in the environment is an effective strategy to optimize motor learning and performance. Attentional focus (AF) can be external focus (EF) (directs attention to the effects of the movement on the environment) or internal focus (IF) (directs attention to the movement itself). An EF has been shown to be beneficial for performance and learning, due to reduced attentional demands from automatic processing. It is unknown how AF influences perceived workload during sprinting. This study investigated the effects of AF instructions on perceived workload following a sprinting task. Healthy young adults were randomly assigned to one of three groups: EF (N = 4, 22.75 ± 2.06 yrs), IF (N = 4, 21.75 ± 1.71 yrs), or control (N = 4, 21.75 ± .96 yrs) group. Participants completed 3 x 20m baseline sprints and the NASA Task Load Index (NASA-TLX). The acquisition phase consisted of 3 x 20 sprints with EF (focus on driving forward as powerfully as possible while clawing the floor with your shoe as quickly as possible), IF (focus on driving one leg forward as powerfully as possible while moving your other leg and foot down and back as quickly as possible) or no instructions. A 20-minutes retention phase was administered, followed by 3 x 20 sprints and the NASA-TLX. The NASA-TLX has six subscales (Mental, Physical, Temporal, Performance, Effort, and Frustration) which are averaged to calculate a global perceived workload score. A repeated measures ANOVA was performed to assess group differences from baseline to retention. No significant differences were observed F(1,9) = .122, p = .735) for perceived workload between groups at baseline or retention. These results suggest that AF instructions utilized during sprinting acquisition have no effect on mental workload during the retention period. Thus, NASA-TLX should be completed after every trial to determine the influence AF instructions have on mental workload for earlier trials versus later trials. In addition, more trials are needed during acquisition and a larger sample size will provide more statistical power.\n\nThe impact of an internal focus, external focus, and cognitive distraction tasks on the performance of a balancing task\n\nKevin Becker, University of Tennessee, Knoxville; John Henry Ballard, University of Tennessee, Knoxville; Joshua Weinhandl, University of Tennessee, Knoxville\n\nSeveral studies have suggested an external focus can be useful for improving balance (Diekfuss et al., 2019; Wulf et al., 1998), yet other studies have found no benefit (Landers et al., 2016). A recent study compared internal (IF) and external focus (EF) conditions with a continuous cognitive task and found that the cognitive task led to better balance than either an IF or EF (Polskaia et al., 2014). It is possible that distraction may promote automaticity in balance, but the attentional demand of the distraction may influence this relationship. The purpose of the present study was to test the impact of an IF, EF, high demand cognitive task (COG-H), and low demand cognitive task (COG-L) on the performance of a balancing task. Participants (N = 21) balanced on inflatable discs on a force plate for three 10 s trials in each condition. In the IF and EF conditions they focused on keeping their feet or the discs still respectively. In the COG-L and COG-H, they focused on either a short or long number sequence while balancing, and then repeated the sequence back to confirm accuracy. Center of pressure data was captured from the force plate at 1000Hz, and a custom MATLAB code was used to calculate root mean square (RMS), median power frequency (MPF), and sample entropy (SEn) in both the medial/lateral (x) and anterior/posterior (y) directions. RM ANOVAs indicated no effect of focus on RMS or SEn in either direction. A significant focus effect was found for MPFy (p = .019). MPFy in COG-H was higher than COG-L (p = .043), and approached being higher than EF (p = .073). The present data do not demonstrate a clear advantage of any conditions regarding the magnitude (RMS) or structure (SEn) of variability while balancing. However, evidence suggests that a cognitive task higher in demand is effective at eliciting higher frequency postural adjustments which may indicate more automatic processing of balance. Additional work should test the effectiveness of different types of cognitive tasks as an alternative strategy to simply focusing externally at all times to improve balance.\n\nEffect of attentional focus on force curve learning in a dual-task paradigm\n\nMohammed Bila, Wayne State University; Qin Lai, Wayne State University; Kristoph Lopata, Wayne State University\n\nPrior research has extensively shown that an external focus of attention is associated with increased movement effectiveness compared to an internal focus. However, it remains unknown how attention focus affects the learning process during dual-task. This study aims to investigate the effect of attentional focus on motor learning during dual-task settings involving force production and balance maintenance. Participants (N = 17, aged 18–40 years) signed an informed consent, then were randomly assigned to either an internal focus of attention or an external focus of attention group. The dual task involved producing a force curve with a peak of 60% of the maximum grip force and a duration of 1 second. Participants were instructed to direct their focus on the hand dynamometer as external attention and direct their focus on the forearm muscle contraction as internal attention, respectively. During 2-lab visits, participants started with a baseline test, followed by 8 blocks of acquisition with specific focus instructions, each with 6 trials. A retention test was administered 48 hours after the first visit, without a specific attention focus cue or feedback. For the acquisition phase, a 2 (Group) x 8 (Block) ANOVA with repeated measures on Block found a significant group difference in temporal error, (F[1, 15] = 5.01, p = .04). Further, Duncan’s Multiple Range Test (MRT) indicated that external focus produced smaller temporal errors compared to internal focus. For retention and baseline tests, separate 2 (Group) x 2 (Test) ANOVAs with repeated measures on the test demonstrated a significant interaction on force area error (F[1, 15] = 6.28, p =.02), and a tending interaction on temporal error (F[1, 15] = 3.13, p =.09). The study findings suggest that the external focus of attention enhances force curve learning, while the internal focus of attention leads to increased force area and temporal errors under dual-task.\n\nAsymmetrical specificity of learning: Auditory feedback neither helps nor hinders implicit sequence retention and transfer\n\nElena M. Broeckelmann, University of Manitoba; Calvin D. Reimer, University of Manitoba; Cheryl M. Glazebrook, University of Manitoba\n\nAuditory action-effects may enhance sequence learning and retention in the implicit Serial Reaction Time Task (SRTT). Recently we investigated if sound influences how sequences are encoded and found that visuospatial coding was used regardless of the presence of auditory feedback. However, participants performed faster with visual cues only. Thus, it is unclear if the response-stimulus interval (RSI) in the auditory condition moderated these results. The present study replicated this protocol, while also adding a response delay group to determine if processing time along affects sequence learning. Fifty-four neurotypical righthanded adults (M = 23, SD = 3.6) practiced a 10-item implicit SRTT by reaching with their preferred hand to a square array of four targets presented on a touchscreen. The three groups were all guided by visual cues (i.e., targets filled in); Group 1 received an RSI of 0ms, Group 2 received a 300ms RSI with auditory feedback, and a third group had a silent RSI of 300ms. On Day 1, participants repeated the sequence 10 times across blocks 1–6 and 8, while block 7 presented the stimuli in a pseudorandom order. On Day 2 participants completed a retention test with their preferred hand as well as transfer tests with their non-preferred hand in spatially congruent and mirrored motor congruent transfer conditions, with and without auditory feedback. Total sequence time (TST) was analysed using predetermined mixed model ANOVAs. A significant reduction in TST indicated all three groups acquired equal implicit sequence knowledge on Day 1, but those practicing without an RSI performed faster overall. Similarly, all groups performed the sequence more rapidly in the no sound condition on Day 2, including those who had practiced with auditory feedback. A significant main effect of sequence transfer indicates better performance with spatially congruent stimuli. Thus, the RSI constrains response speed, and the presence of auditory feedback does not affect sequence encoding. Notably, participants did not become reliant on the availability of auditory feedback. Funding source: NSERC.\n\nPrior training experience may influence the expression of hand performance abilities.\n\nPamela Bryden, Wilfrid Laurier University; Shreyas Alapatt, Wilfrid Laurier University\n\nThe relationship between handedness and athletic proficiency has long intrigued researchers and the public. A study by Loffing (2017) found a higher prevalence of left-handed athletes in sports requiring shorter response times, such as baseball and table tennis. Studies have shown that training the non-dominant limb can assist the competitor’s ability to perform effectively with either of his or her limbs (Walker & Henneberg, 2017). This provides a significant advantage over other competitors who exclusively focus on performing with only their dominant limb in a sports setting. Therefore, this study examined whether training the non-dominant limb in sports influences hand performance. University-aged participants (N = 21) first completed the Waterloo Handedness Questionnaire (WHQ; Steenhuis et al., 1990), a self-report measure of hand preference, and a background survey to capture the type of sports and training the participant has engaged in. Following this, participants completed the Tapley-Bryden dot marking task, which is a speed-accuracy measure assessing the performance of both the dominant and non-dominant limbs. Given the low number of left-handed participants who completed the experiment, only results from the right-handers will be discussed. Results indicated that all participants completed the task faster with their dominant limb as compared to their non-dominant limb (t(17) = 12.0, p < .001). Participants were then divided into those who had explicit training of their non-dominant limb in a sport (e.g., basketball dribbling) and those who indicated no such training. Here, it was found that the differences between the two hands were smaller and non-significant for those with training (t(4) = 2.2, p = .09) than for those without training (t(12)= 9.85, p < .001). However, no differences were noted between the two groups with respect to hand preference as measured by the Waterloo Handedness Questionnaire. This continues to build on our work indicating that prior training experiences may influence hand preference and performance abilities. Funding source: NSERC.\n\nHandedness in young Canadian baseball players\n\nPamela Bryden, Wilfrid Laurier University; Adam Robertson, Wilfrid Laurier University\n\nIt has been suggested that handedness selection can alter Major League Baseball performance and lead to potential advantages. Brown and colleagues (2019) specified that there was a batting advantage, for left-handed batters who throw right-handed, termed “sinister right-handed players.” These advantages have led to being more likely to have a career batting average of over .299 and more than 7 times more likely to make the major leagues. Cairney et al., (2018) identified that children exposed to hockey early in their development as athletes might be more likely to bat left when they choose to play baseball. The proportion of left-handed batters born in Canada is higher than in other countries leading to higher batting averages. Therefore, the purpose of the current study was to examine young Canadian students and whether playing hockey in their childhood would increase the likelihood of playing at the post-secondary or professional level. Two-hundred and seventy-seven participants (16 to 26 years of age) who had played either baseball or softball were recruited through social media platforms. All participants completed a questionnaire including demographic information, prior sports experiences (specifically hockey and baseball experiences), and questions from the Waterloo Handedness Questionnaire (WHQ). Overall, there was a larger proportion of left-handers than expected in the sample (∼15%). The majority of participants (82.7%) had prior experience playing hockey. Looking more closely, there was a greater than expected number of right-handed players who were sinister right-handers (35.2%). Interestingly, 46% of athletes in the sample with hockey experience achieved the collegiate or junior level of baseball, indicating the positive effects of hockey on baseball output. In conclusion, although still in progress, this study appears to have a clear connection between overall handedness and future successes in baseball due to prior experience playing hockey. Funding source: NSERC.\n\nThe effects of physical activity on bilateral transfer in young and older adults\n\nSean Cochran, Roanoke College; Christopher Aiken, New Mexico State University\n\nBilateral transfer is the change of motor performance in one limb following practice with the other (Parlow & Kinsbourne, 1989). Transfer between limbs in younger adults is typically asymmetrical, meaning a greater amount of change is observed in the nondominant limb (ND) following practice with the dominant limb (D) than vice versa (Pan & van Gemmert, 2013). Asymmetrical transfer is associated with lateralized hemispheric control of movement parameters according to the dynamic dominance model (Sainburg, 2002). Older adults demonstrate more symmetrical transfer caused by additional ipsilateral hemispheric activation as a compensatory mechanism (Cabeza, 2002). Physical activity helps maintain lateralized hemispheric activation in older adults, suggesting asymmetrical transfer could be retained as we age with high levels of physical activity (HPA) (McGregor et al., 2013). Two studies were conducted, one with young adults aged 18–35 (N = 50) and another with older adults aged 65–81 (N = 38). Participants were assessed for hand dominance and reported weekly physical activity levels. Participants were grouped by reported physical activity level and assigned training limb. Individuals performed a 30° visual rotation drawing task. Pre-test of 2 trials established baseline performance of each limb, followed by 40 practice trials on the assigned limb. Post-tests mirrored pre-tests and assessed practice induced changes. For younger adults, HPA resulted in the improved performance of movement time (MT), normalized jerk (NJ), trajectory length (TL), and initial direction error (IDE) in the D limb following ND practice (p < .05). Low levels of physical activity (LPA) showed symmetrical transfer for IDE, meaning either limb improved due to assigned limb training. For older adults, HPA resulted in the improved performance of MT, NJ, TL, and IDE in the D limb following ND limb practice (p < .05). LPA showed no transfer (p > .05). Findings from both studies indicate that HPA elicited asymmetrical transfer, thus suggesting HPA assists in retention of lateralized hemispheric activation.\n\nAnalysis and validation of commercially available immersive virtual reality games\n\nBruna de Souza da Silva, Georgia State University; Eryn Render, Georgia State University; Mansi Patel, Georgia State University; Huy Chiem, Georgia State University; Andre Yousif, Georgia State University; Maggie Abercrombie, Georgia State University; Yuping Chen, Georgia State University\n\nImmersive virtual reality (IVR) gaming has witnessed a surge in popularity, offering experiences that engage players physically and cognitively; however, there is a lack of understanding of the potential health implications. The aim of this study was to examine the effects of five IVR games on heart rate (max, average, max change), number of total arm movements (unilateral and bilateral), and the average number of arm movements per minute. Twenty-seven healthy adults (8 males) played five IVR games (Fruit Ninja [FN], Tennis [T], Baseball [BB], Bowling [B], Beat Saber [BS]) on the Meta Quest 2. The Polar Beat monitor and iphone were used to collect heart rate and to record arm movements. A repeated measures ANOVA and paired t-test were used for analyses. A detailed game analysis table was created first. For heart rate data, FN and T demonstrated a significantly higher max and average heart rate compared to BB, B, and BS (p < .001). FN had a statistically higher max heart rate change than other games (p < .002). For the number of total arm movements, FN and BS produced significantly higher numbers than the other 3 games; BS also had higher numbers than T and B; and T had higher numbers than B (all p < .001). T demonstrated a significantly higher % of unilateral arm movements compared to FN and BS (p < .001). FN demonstrated a significantly higher % of bilateral arm movements than both T and B (p < .001). BS also demonstrated a higher % of bilateral arm movements than T (p < .001). FN and BS each demonstrated a significantly higher average number of arm movements per minute than T, B, and BB (p < .001). Our findings suggested that different games might elicit different responses: FN elicits the greatest heart rate change; FN and BS could elicit greater number of total arm movements, % of bilateral arm movements, and average number of arm movements. Meta Quest 2 games could potentially be used to train arm function. When designing a VR intervention program for clinical populations, it is important to consider the game and the goals as factors in influencing their performance. Funding source: National Institute on Disability, Independent Living, and Rehabilitation Research (award number: 90IFST0009).\n\nThe influence of different virtual partners when performing a redundant visuomotor rotation task\n\nDaniel Deletsu, McMaster University; Nour Al Alif, McMaster University; Mikayla Lalli, McMaster University; Lidia Barbera, McMaster University; Ola Schwarzenberg, McMaster University; Vida Sussman, McMaster University; Rakshith Lokesh, Northeastern University; Joshua G.A. Cashaback, University of Delaware; Michael J. Carter, McMaster University\n\nFrom a parent guiding their toddler when learning to brush their teeth to a physical therapist assisting a client with their range of motion, physically interacting with other people is ubiquitous in our daily life. While some researchers have shown that haptic human-human interaction benefits performance during training as well as later individual performance (Takagi et al. 2017), others have failed to replicate these benefits (Beckers et al. 2018). Participants in these interaction groups were not aware they were haptically linked to a partner and each participant had independent control over their own virtual cursor when tracking the target. Yet, we are typically aware when we are interacting with others and often do so with tasks where we have shared control over the same control point (e.g., a toothbrush). Here, we tested the effectiveness of training alone versus training with a virtual partner when individuals were made aware of their interaction in a redundant reaching task. Participants (N = 100) completed 50 baseline trials followed by 200 trials with a clockwise cursor rotation in one of four randomly assigned groups. Two of the groups performed the adaptation trials with a virtual partner that represented either the fast (Fast Group) or slow (Slow Group) state of the two-state model (Smith et al. 2006) with 30-deg rotation. The two remaining groups performed the task alone with either the 30-deg rotation (Full Alone Group) or a 15-deg rotation (Half Alone Group). Results showed that participants in the Fast Group contributed less to correcting the rotational error early in the adaptation block, but were responsible for most of the correction later in this block, with performance most similar to the Full Alone Group. Conversely, participants in the Slow Group corrected for a greater proportion of the initial errors, but their contribution began to drift during adaptation, with performance resembling that of the Half Alone Group. This pattern of results were consistent with our theory-driven simulations. Funding source: Natural Sciences and Engineering Research Council of Canada, Canadian Foundation for Innovation, Ontario Research Fund.\n\nEffects of treadmill training intervention on kinematic patterns of stepping in infants with Down syndrome\n\nAlexandre dos Santos Kotarski, Georgia State University; Robert Zeid, Georgia State University; Patrick Underwood, Georgia State University; Amy Talboy, Emory University; Seyda Ozcaliskan, Georgia State University; Jianhua Wu, Georgia State University\n\nDown syndrome (DS) is a genetic disorder associated with several brain deficits and delayed psychomotor development, including walking skills, compared to typically developing infants. Previous studies have shown that treadmill intervention is effective in advancing walking onset and quality. However, the mechanism of neuromotor changes is unknown for treadmill intervention. This study aimed to examine the kinematic and spatiotemporal characteristics of stepping over a 5-month span. Eight infants with DS (6M/2F, 11.3 ± 3.3 months) entered the study for treadmill intervention. A pediatric treadmill was provided to the infant and the parents conducted the training for 8 min/day, 5 days/week, starting at a belt speed of 0.1 m/s. At our monthly visit, we used a high-speed camera and reflective markers that were placed on the infant’s right hip, knee, ankle and foot to record a 3-minute stepping trial. Here we report the results from three visits: V1, V3 and V5. Kinematic variables included peak hip and knee joint angle and velocity. Spatiotemporal variables were step length and cadence. A series of one-way (visit) repeated measures ANOVA were conducted using the SPSS software. Results showed that from V1 to V3 to V5, peak knee extension increased from 26.2 to 33.3 to 41.1 deg, peak knee extension velocity increased from 38.4 to 91.1 to 145.3 deg/s, peak hip extension increased from 4.6 to 6.7 to 10.1 deg, and peak hip extension velocity increased from 39.5 to 72.5 to 79.4 deg/s. Step length increased from 105.6 mm at V1 to 148.7 mm at V3 to 147.9 mm at V5. Step cadence increased from 3.9 steps/min at V1 to 4.2 steps/min at V3 to 10.7 steps/min at V5. These results demonstrated improvements in kinematic and spatiotemporal variables in the first five months of treadmill intervention which typically lasts for about 10 months. Future studies will continue to register the kinematic and spatiotemporal progress in infants with DS during treadmill intervention and examine step variability which was seen due in part to lower muscle tone and joint laxity.\n\nRelationship between gait fractal dynamics and fall risk in older adults\n\nScott Ducharme, California State University, Long Beach; Alec Sequeira, California State University, Long Beach; Ayla Donlin, California State University, Long Beach; Jackie Dawson, California State University, Long Beach\n\nWhile walking, the variability of timing between ipsilateral footsteps (i.e., stride time) correlates with fall risk in older adults. Furthermore, the structure of this variability, i.e., fractal dynamics, may also estimate fall risk because it may represent an individual’s ability to adapt their stepping patterns. That is, greater gait adaptability should logically correlate with lower fall risk. However, to date this relationship has not been established. The purpose of this study was to investigate the association between gait fractal dynamics and fall risk. Eight older adults (3M, 5F; age 69.4 ± 3.2 years) performed the Timed Up and Go (TUG) test, which is commonly used to quantify fall risk. Participants then performed three 5-minute treadmill walking trials at; preferred walking speed (PWS), half of their PWS (Half-PWS), and 0.22 m/s (∼0.5 mph; Slow). Heel strike events were obtained via kinematics of heel trajectories, which were then used to obtain stride times. Evenly spaced detrended fluctuation analysis (DFA) was used to quantify stride time fractal dynamics. Results from the TUG tests showed an average of 9.9 ± 2.6 seconds (range [7.79, 16.72]). Fractal dynamic values were 0.72 ± .08, 0.78 ± .19, and 0.81 ± .13 for the PWS, Half-PWS, and Slow conditions, respectively. Fractal dynamics displayed almost no correlations with the TUG scores during PWS (R2 = .01) and Half-PWS (R2 = .06). In contrast, the Slow condition exhibited a moderate negative correlation (R2 = .24), whereby higher fractal dynamic values corresponded with shorter TUG times, indicative of lower fall risk. These findings align with prior studies in which unperturbed walking at typical speeds did not yield differences related to age or physical activity levels, yet when participants were exposed to a challenging task (i.e., slow or asymmetric walking), differences between sub-groups emerged. This study provides preliminary support for the use of fractal dynamics to estimate fall risk. Moreover, extremely slow walking constraints may be a superior setting to adequately test for gait deficiencies.\n\nTandem balance as a predictor for balance asymmetries in women\n\nAtousa Ebrahimi, University of North Carolina at Greensboro; Louisa Raisbeck, University of North Carolina at Greensboro; Stephen Glass, Radford University at Carilion; Scott Ross, University of North Carolina at Greensboro\n\nWomen soccer players sustain more quadriceps, ACL, and ankle ligament injuries than their men counterparts, however, they occur less from contact mechanisms than men. Poor balance and asymmetry between limbs are associated with injury. Assessing balance can identify athletes who may need balance therapy for injury prevention. This study examined tandem stance balance to determine if poor balance or asymmetries exist in women and men soccer players with and without a history of lower extremity injuries. Participants with and without a history of injury included 27 women and 33 men collegiate soccer players. Balance was assessed in tandem stance requiring participants to stand heel to toe on a force plate for 3 10-sec trials on each limb. Participants were instructed to remain as motionless as possible with their eyes closed. Center-of-pressure resultant velocity assessed balance of both limbs and lower values were indicative of better balance. A limb X sex X injury history interaction was assessed with a repeated measures ANOVA (α = .05) and LSD post-hoc examination of mean differences. The left-side balance of women with injury (.89 ± .51 cm/s) was better than 5 comparisons (injury: women right-side = 1.22 ± .53, men left-side=1.28 ± .74; no injury: women left-side = 1.31 ± .47, men right-side = 1.19 ± .24, left side = 1.44 ± .84) but not two others (injury: men right-side = 1.11 ± .49; no injury: women right-side = .91 ± .38). Women without injury had better right-side balance than women with injury. However, men with injury had better right-side balance than the left-side for men without injury. Interestingly, women showed asymmetry between sides regardless of injury status and men did not. Our results do not support the notion that poor balance would identify candidates for therapy to prevent injury since better or equivalent balance was found on most comparisons between men and women in both groups. However, women clearly had balance asymmetries regardless of injury history and may need balance therapy to equate sides to reduce injuries associated with women soccer players.\n\nThe Impact of aging and Parkinson’s disease on interlimb coordination: An investigation of gait adaptability\n\nMorteza Farivar, Texas Christian University; Adam C. King, Texas Christian University\n\nInterlimb coordination, which refers to synchronizing movements between different limbs, is an essential part of human movement. A lack of coordination can cause gait dysfunction and instability, which are commonly experienced by older adults and individuals with Parkinson’s Disease (PD). Our scoping review aimed to explore the impact of older adults/aging and (PD) on interlimb coordination as it relates to gait adaptability. This study focuses on older adults and individual with PD (>52 years old), with assessment of interlimb coordination during gait, in an open context, according to the Population, Concept, Context framework. A literature search was performed in PubMed, Web of Science™, Scopus, SPORTDiscus, and gray literature in Google Scholar™, according to the PRISMA-ScR recommendations. Studies written in English language and published between 2006 and 2023 were included. Qualitative studies, conference proceedings, letters, and editorials were excluded. The pivotal research domains identified were “Parkinson’s Disease”, “Interlimb Coordination”, “Gait Adaptability”, “Older Adults”, “Kinematic”, “Electromyography”. The search identified 710 potentially relevant studies, with a total of 17 fulfilling the established criteria. Interlimb coordination was assessed during walking in treadmill (n = 2), overground (n = 14) and both (n = 1). The comprehensive assessment comprised a clinical evaluation, a detailed gait kinematic analysis focusing on spatiotemporal variables and the range of motion in joint angles, and a thorough analysis of interlimb coordination. Interlimb coordination impairments, particularly in older adults and individuals with PD, can lead to falls and injuries due to their impact on gait adaptability. Identifying fall risk through the assessment of gait coordination allows for targeted interventions that enhance gait adaptability. Therefore, prioritizing gait assessments in these populations is crucial for developing effective fall prevention strategies.\n\nAnticipatory ability scales with spatial exaggeration of an opponent’s action\n\nKazunobu Fukuhara, Tokyo Metropolitan University; Hiroki Nakamoto, National Institute of Fitness and Sports in Kanoya; Takahiro Higuchi, Tokyo Metropolitan University; David L Mann, Vrije Universiteit Amsterdam\n\nResearch in sports anticipation has investigated the mechanisms underpinning skilled anticipation and the usefulness of perceptual training, often utilizing video stimuli depicting the movements of opposing players. However, a common limitation is the absence of opponent models tailored to the individual observer’s anticipatory abilities. This limits the degree to which rigorous experiments can be designed (e.g., in testing at an individual’s performance threshold) and prevents adaptable training paradigms tailored to an individual’s ability. To this end, we created tennis avatars performing forehand groundstrokes using kinematic data and spatially exaggerated the kinematic features specifying the shot direction. While previous studies have demonstrated that kinematic exaggeration enhances the accuracy of identifying movement types such as the tennis serving style, it remains uncertain whether it also enhances accuracy in anticipating the outcome of opponent’s action. The aim of this study was to examine whether increases in kinematic exaggeration result in a commensurate increase in accuracy when anticipating the outcome of those actions. Twelve skilled and 19 novice tennis players were asked to anticipate the direction of forehand shots performed by the avatar within an immersive virtual environment. We established nine exaggeration conditions (5% to 400%), evaluating anticipation accuracy and sensitivity (d’) in each condition. The results showed a significant enhancement in anticipatory performance as the degree of exaggeration increased, a relationship observed in both skilled and novice players. In the 150% to 400% exaggeration conditions, skilled players consistently outperformed novices significantly. These findings underscore the influence of participants’ anticipatory abilities on the quantity/quality of information extracted from the opponent’s kinematic cues. The exaggerated avatars have properties to manipulate the difficulty of the anticipation task, suggesting promising prospects for tailored testing/training to the participant’s skill level. Funding source: SPS KAKENHI Grant Number JP23K10589.\n\nStretch times of acute opposing ankle muscles: Stretch less to sway less\n\nTaylor Gauss, Louisiana State University; Rhys Lormand, Louisiana State University; Matthew Yeomans, University of South Carolina Upstate; Jan Hondzinski, Louisiana State University\n\nBenefits of static stretching include improved flexibility and range of motion; however, the impact of static stretching on postural sway and proprioception remain unclear. We previously showed that acute stretching of opposing ankle muscles in 2–4 30 s bouts decreased sample entropy, thus automated control of sway, and increased center of pressure (COP) variability in the mediolateral (ML) direction compared to no stretch (NS) and/or non-opposing ankle muscle stretches. Interestingly, standing sway remained the same after stretching the non-opposing ankle muscles, despite different stretch times. Here we determined if postural sway would differ for various times of acute opposing ankle muscle stretches. Twelve young adults (4 F/8 M; Age 25 +/- 4.9 years) received NS or passive plantar- and dorsi-flexion stretching to discomfort for 2–4 bouts of 15, 30, or 45 s before performing 3 trials of static stance (barefoot participants stood as still as possible with eyes closed for 45 s on an ATMI force plate) and proprioception tasks (participants actively matched remembered ankle angles, measured by a handheld goniometer). Repeated measures ANOVAs revealed increased M-L standard deviation (SD) and M-L displacement (D) in the 45 s condition compared to NS (p < .05). As with our previous outcomes, results revealed that lower M-L sample entropy after stretching compared to NS (p < .001), stretching did not influence proprioception or anteroposterior sway, and proprioception error negatively correlated with M-L SD and M-L D, especially in more flexible participants. Thus, a better ability to actively reproduce ankle positioning likely encourages an internal focus of attention on movement, known to increase postural sway. Moreover, while less automation of M-L sway occurs after stretching bouts as short as 15 s, it takes only 2–4 bouts of opposing muscle stretching for 45 s to increase postural sway displacement and its variability. We recommend use of less than 45 s bouts of stretching when prioritizing reduced postural sway.\n\nComparing executive function in adults with and without ADHD\n\nNancy Getchell, University of Delaware; Elham Bakhshipour, University of Delaware; Roxana Burciu, University of Delaware; Roghayeh Barmaki, University of Delaware\n\nPrevious research has demonstrated that the N-back test, a visuospatial task that requires storage and continual updating of information in working memory, can reveal significant differences between individuals with attention deficit hyperactivity disorder (ADHD) and without ADHD. The current study utilized functional near infrared spectroscopy (fNIRS) to compare prefrontal cortex (PFC) oxygenation in these populations. To address this, a two-way ANOVA was conducted, assuming group as one factor and task level as another factor. Thirty-two participants s (15 with ADHD, 17 without ADHD) completed a N-back test, with three different levels of the test (N = 1, 2, 3) while fNIRs simultaneously recorded PFC oxygenation change. Overall, fNIRS revealed a greater PFC activity during 2-back vs 1-back in both groups. Funding source: College of Health Science equipment grant, Graduate college summer doctoral fellowship grant, KAAP dissertation grant, professional development awards (University of Delaware).\n\nExploring the relationship between physical activity levels and implicit learning proficiency in young adults\n\nRichard Guerra, Eastern New Mexico University; Prabha Shrestha, Eastern New Mexico University\n\nExploring the intricate relationship between physical activity (PA) and implicit learning (IL) in young adults, this study aims to unravel the correlations between various PA levels and IL proficiency. A cross-sectional design was employed, with thirty-five college-aged participants (F = 18, M = 17) completing the International Physical Activity Questionnaire-Form (IPAQ) for PA levels before the Triplets Learning Task (TLT), a computer button-pressing task for IL proficiency. Categorized by IPAQ, PA levels ranged from vigorous to moderate activities or a combination totaling ≥ 600 MET minutes per week. Statistical analyses were employed to identify significant differences and associations, including ANOVA and t-tests for group comparisons and regression and correlation analysis to examine relationships between PA levels and IL proficiency. This study identified four distinct PA choices and assessed IL through reaction time and accuracy. A two-sample t-test revealed a significant gender difference in reaction time (Males: M = .37s, Females: M = 1.06s; t(31) = −2.81, p = .008), indicating faster responses in males. Our findings show no influence of PA level on IL, contradicting Guerra et al. (2021), which showed enhanced IL capabilities in cardiovascular and resistance training participants. Highlighting the complexity of PA’s impact on IL, this research underscores the need for further nuanced investigation into PA strategies and regimens. Integrating moderate to vigorous PA could play a critical role in cognitive development programs, enhancing IL in diverse educational contexts. Future studies are encouraged to delve deeper into the mechanisms linking PA with IL, potentially guiding more tailored and effective cognitive enhancement strategies. These insights pave the way for innovative educational initiatives incorporating physical fitness and activity as components of learning enhancement methodologies. Such integration could significantly affect pedagogical practices and learner outcomes.\n\nThe development of a novel, non-binary measure of motor planning flexibility\n\nJesse Hansen, Utah State University; Rachel Larson, Utah State University; Breanna E. Studenka, Utah State University\n\nThe ability to properly change from one movement to another is important for individuals to adapt to their environment and interact with others (Cox & Smitsman, 2006, Rosenbaum, 1992). Studies have shown (Lebkuecher et al., 2022, Schutz & Schack, 2019, Weigelt et al., 2009, Cohen & Rosenbaum, 2011) that, for binary tasks, individuals show a hysteresis effect, (the reuse of previous motor plans), which decreases end-state comfort when a task is changed. To date there is no agreed-upon method for measuring planning flexibility. This study’s purpose was to develop a non-binary measure of motor planning flexibility. The study used 24 participants (18 to 27 years), who performed the task twice on two different days. Each participant performed the task of grasping the top of the cylinder on the object (8 pointers 45° apart connected to a central cylinder) and rotating it clockwise either 0°, 45° or 90°. After grasping the object, they rotated the colored pointer on one side of the object to the corresponding-colored target located at either −90°, −45°, 0°, 45° or 90° with respect to the center of the object only using their wrist, elbow or shoulder and without using their fingers or adjusting their grasp. Task sequence lengths of 1, 3 and 6 were used before a task switch (e.g.: 0°, 0°, 0°, −90° – sequence length 3). Ninety tasks were performed within a session for each day. All participants performed sequence length 1 first. Odd participants then performed sequence length 3, then 6 and even participants performed sequence length 6 then 3. Results showed no significance sequence length effect on beginning or end-state hand position. There was also, on average, a positive lag autocorrelation from 1 to 3 indicating a declining effect of prior grasps (up to about 3) on the current grasp choice, which helps to explain why sequence lengths longer than 1 had no increasing hysteresis effect. Interestingly, the lag effect varied among participants demonstrating the need to examine individual differences as we further develop this task.\n\nWhen might an internal focus prove beneficial? An exploration of attentional focus instructions across skill levels\n\nEdward Hebert, Southeastern Louisiana University; Christopher Aiken, New Mexico State University; Kevin Becker, University of Tennessee; Cameron Diez, Southeastern Louisiana University\n\nRecent work has challenged the conclusion that an external focus should be used universally to support motor learning. Some authors have suggested an internal focus could be beneficial in the earliest stage of learning when learners are conceptualizing how their body needs to move, with an external focus being more useful in later stages. The purpose of this study was to examine the effects of internal (INT), external (EXT), or internal-then-external (INT-EXT) attentional focus instructions on learning a bowling task. Participants were 63 college students separated into Beginner (n = 30) and Intermediate (n = 33) groups based on self-described experience and a pretest. They were assigned to 3 conditions using a stratified approach to balance experience and gender. Over 4 days, participants completed a pretest, 50 acquisition trials, and retention/transfer tests of a bowling task. They rolled a rubber bowling ball toward 7 bowling pins arranged horizontally from a distance of 14.63m (48ft) during acquisition and retention, and 16.46m (54ft) during transfer. Pins were separated by 30.48cm (12in), and marked with points for scoring (1–4). The goal of the task was to strike the center pin (worth 4 points). For acquisition, participants were given the following instructions: (1) INT: focus on moving your hand back and forward in a straight line; (2) EXT: focus on the middle pin; roll the ball directly at it; or (3) INT-EXT: INT instructions for the first 25 trials, EXT instructions for the last 25 trials. Points were recorded for each trial and averaged across blocks of 10 trials. Separate 2 (Experience Level) x 3 (Condition) ANOVAs showed significant Experience Level differences across the study, and a significant Experience x Condition interaction for retention and transfer. In Beginners, INT resulted in higher retention and transfer scores than EXT or INT-EXT. No significant group differences were observed for intermediate learners. These results provide evidence that internal focus instructions may be more effective for early-stage, lower skilled learners.\n\nInstructional adherence during a sprinting task using attentional focus cues\n\nAlice Hibbard, University of North Carolina Greensboro; Amanda Barclift, University of North Carolina Greensboro; Louisa Raisbeck, University of North Carolina Greensboro\n\nAttentional focus (AF) directs attention internally or externally. Using an external focus (EF: directing attention to the effects of the movement on the environment) leads to better motor learning and performance relative to an internal focus (IF: directing attention to the movement itself). Compliance checks in research are used to confirm adherence to instructional cues. Research on AF has not consistently shown how to measure adherence to the focus cues. This study examined adherence between AF groups during a sprinting task. Participants were randomly assigned to one of three groups: EF (n = 4, 22.75 ± 2.06 yrs), IF (n = 4, 21.75 ± 1.71 yrs), or control (n= 4, 21.75 ± 0.96 yrs). Participants completed 3 x 20-m baseline sprints. During acquisition, participants completed 3 x 20-m sprints using AF cues. EF instructions were “focus on driving forward as powerfully as possible while clawing the floor with your shoe as quickly as possible”. IF instructions were “focus on driving one leg forward as powerfully as possible while moving your other leg and foot down and back as quickly as possible”, and the control group received no instructions. Following each sprinting trial participants completed a self-reported compliance check asking, “how much were you able to follow the given instruction while performing the task”. A repeated measures ANOVA for adherence revealed no significant differences between the attentional focus conditions F(2,8) = 1.459, p = .288. Overall, those in the EF condition reported greater adherence than the IF condition in later trials: EF (Trial 1 M = 5.25 ± .50, Trial 2 M = 5.25 ± .50, Trial 3 M = 5.50 ± .58) and IF (Trial 1 M = 4.00 ± 1.16, Trial 2 M = 4.25 ± .50, Trial 3 M = 4.50 ± .58). These results suggest that a larger sample size is needed to increase overall statistical power, and during the acquisition phase more sprinting trials are needed as participants may not be able to follow assigned instructions until they reach a certain level.\n\nExamining attentional focus, anxiety, and mental workload in a CPR augmented reality simulation\n\nAleiza Higgins, University of North Carolina Greensboro; Scott Ross, University of North Carolina Greensboro; Aaron Terranova, University of North Carolina Greensboro; Louisa Raisbeck, University of North Carolina Greensboro\n\nCardiopulmonary resuscitation (CPR) is a crucial clinical psychomotor skill performed by athletic trainers (ATs) under stressful, distracting conditions; thus, it is imperative to practice CPR under conditions simulating real scenarios. A common strategy for improving motor skill performance is attentional focus (AF). Research has demonstrated that an external attentional focus (EF; effect of the movement) is more beneficial than an internal attentional focus (IF; movement characteristics) and our preliminary results demonstrate that compression rate accuracy can be maintained with EF despite an overall rate increase under distracting simulated conditions. Furthermore, redirecting attention using AF cues has been effective for reducing anxiety and mental workload. This study examined the effects of AF cues on CPR performance in a distraction-free environment and distracting augmented reality simulation. We hypothesized that the simulation would produce greater anxiety and worse performance with a non-directional hypothesis regarding the effect of AF on anxiety and workload. Fourteen ATs and 24 AT students certified in CPR (N = 38; 24 women, 12 men; Mage 38 ± 9.5 years) received EF cues (focus on compressing the chest down to the beat of Stayin’ Alive) or IF cues (focus on pressing your hands down) before performing 3-minutes of CPR in 2 Trials: (1) quiet lab, (2) gymnasium with bystander video. State anxiety and mental workload were measured for each trial with the Spielberger State-Trait Anxiety Inventory (STAI-Y1) and NASA-TLX, respectively. The EF group had lower levels of state anxiety than the IF group (X2 = 6.486, p = .039) in the simulation. RTLX scores (t(37) = −5.040, p < .001), mental demand (t(37) = −5.439, p < .001), temporal demand (t(37) = −5.119, p < .001), and frustration (t(37) = −4.919, p < .001) subscales were higher with the simulation, but not affected by AF. These results suggest that EF cues, such as a song, may buffer against state anxiety during distracting simulations which increase the mental demands of a stressful task such as CPR.\n\nEffects of neural motivational system, impulsivity, and working memory on performance of a shoot/don’t shoot task with and without high cognitive load\n\nRobert Horn, Montclair State University; Skylar Paletta, Montclair State University; Gustavo Heidner, Montclair State University; Daniel Gwon, Montclair State University; Nicholas Murray, East Carolina University; Luis Torres, Montclair State University; William Lewinski, Force Science Institute\n\nThe shoot/don’t shoot (SDS) task requires people to rapidly distinguish between the threat of gunfire and similar non-threatening movements. These situations attract intense media scrutiny and research is urgently needed to establish reasonableness and identify cognitive- and personality-based risk factors. To date, limited effects of impulsivity and working memory have been examined with this task. Here, we tested the effects of impulsivity and working memory (WM) with and without a cognitive secondary task in which participants had to rapidly assess the accuracy of the dispatch message describing the suspect before they appeared. We also examined the effects of behavioral activation (BAS), behavioral inhibition (BIS), and fight/flight/freeze measures (rRST-Q; Reuters et al., 2015). Participants (18 male; 12 female) completed the rRST-Q, Barratt BIS-11 impulsivity test, and a complex span WM test. The SDS task used a training gun in response to the video presentation of six scenarios, for which there was a shoot and don’t shoot version. Each was shown twice with and without the dispatch message (DM; no-DM), in a randomized order. Dependent measures were shoot errors, fail-to-shoot errors, response time, and response accuracy. Using independent t-tests (p < .05), in the DM condition, participants with higher BAS, BIS, and motor impulsivity scores showed more shoot errors than those with lower scores. Also, participants with higher flight scores showed faster response times, and participants with lower WM scores made more fail-to-shoot errors than those with lower scores. In the no-DM condition, higher motor impulsivity and lower WM were associated with higher fail-to-shoot errors. Compared to the no-DM condition, in the DM condition, participants increased their accuracy, maintained their response time, and made fewer fail-to-shoot errors. However, they made more shoot errors. This implies adopting a strategy under high cognitive load that increases the risk of erroneous shootings.\n\nNeuromotor performance is influenced by blast magnitude in military personnel\n\nCharlend Howard, Old Dominion University; Marcia Dovel, Uniformed Services University, Henry M. Jackson Foundation for the Advancement of Military Medicine; Justin Toxey, Uniformed Services University, Henry M. Jackson Foundation for the Advancement of Military Medicine; Rie Leverett, Uniformed Services University, Henry M. Jackson Foundation for the Advancement of Military Medicine; Alexander Hill, Uniformed Services University, Henry M. Jackson Foundation for the Advancement of Military Medicine; David Keyser, Uniformed Services University; Walter Carr, Walter Reed Army Institute of Research; Rene Hernandez, Uniformed Services University, Henry M. Jackson Foundation for the Advancement of Military Medicine; Sheilah Rowe, Uniformed Services University, Henry M. Jackson Foundation for the Advancement of Military Medicine; Andrea Gonzales, Applied Research Associates; Suthee Wiri, Applied Research Associates; Michael Roy, Uniformed Services University; Christopher Rhea, Old Dominion University\n\nVariability in a neuromotor task can be an indicator of neurological functioning. Our previous work showed recurrent low-level blast (LLB) exposure from heavy weapons training contributes to a decline in neuromotor variability six hours after LLB exposure. This study examined the relation between blast exposure magnitude—measured via maximum overpressure and impulse—and neuromotor variability six hours after LLB exposure. The coefficient of variation of the maximum flexion angle of the thigh during a stepping in place task was assessed with a custom smartphone app and used as the neuromotor variability metric. We hypothesized that a negative correlation would be observed; higher blast exposure magnitude would be associated with lower neuromotor variability (i.e., more robotic movement). A total of 110 active-duty military personnel (n = 65 Special Operators [SOs], n = 32 Range Safety Officers [RSOs], and n = 13 SOs Trainees [Trainees]) performed the stepping-in-place task before repetitive LLB exposure from heavy weapons training and again six hours after the training. Correlation analysis revealed a significant negative correlation between the Trainee’s maximum blast overpressure and neuromotor variability (r = −.62, p = .02). Additionally, a weaker, yet significant negative correlation was observed for SOs between blast impulse and neuromotor variability (r = −.288, p = .02). No relationship between blast magnitude and neuromotor variability was observed for RSOs. Trainees may have exhibited the strongest dose response to blast magnitude due to their relatively novel exposure to repetitive LLB. SOs have been previously exposed to LLB as part of their duty, which may have decreased their sensitivity to the blasts. RSOs stand further away or have at least 3 feet between them and the blast which may dampen blast magnitude, leading to no relation with neuromotor variability. Future research will examine this dose response effect in a larger sample size across the three groups, as well as its relation to other indicators of neurological functioning (i.e., cognition). Funding source: The INVICTA Study is supported by Award HU00012220065 and a subcontract to Christopher K. Rhea (HJF subcontract 5975). The Uniformed Services University of the Health Sciences (USU), 4301 Jones Bridge Rd., A1040C, Bethesda, MD 20814-4799 is the awarding and administering office.\n\nSimilarities in brain activity during motor imagery and motor execution: A systematic literature review\n\nJudith Jiménez-Díaz, Universidad de Costa Rica; María Gabriela Morales-Scholz, Universidad de Costa Rica\n\nThis study aimed to summarize and analyze the scientific evidence on brain activity while performing motor imagery (MI) and execution (ME). A comprehensive search across eight databases identified eighteen relevant studies published up to 2023. Inclusion criteria involved studies with healthy participants of all ages, incorporating neural activity assessments during MI and ME of a motor skill. The aggregated sample size across these studies comprised 313 participants. Predominantly, fMRI and fNIRS were employed to assess brain activity. The mean number of activated brain areas reported across the 18 studies was 6.44 for ME and 5.56 for MI. Notably, five areas exhibited more frequent activation: BA1, BA4, BA6, BA40, and the cerebellum. For BA1, 94.4% of studies reported brain activity during ME, compared to 72.22% during MI. 77.78% and 72.22% of the studies reported brain activity for BA6 during ME and MI, respectively. For BA4, 72.22% reported activity during ME, while 55.56% during MI. Concerning the cerebellum, 55.56% reported activity during ME, whereas 33.33% during MI. Eight of the 18 studies specified which condition was associated with greater intensity of brain activity. Seven of the eight studies indicated more intense activity in BA4 during ME than MI, while one reported the opposite. Four studies noted greater intensity in BA1 and BA6 during ME, with two reporting higher intensity during MI, for BA6. No studies reported a higher intensity of BA1 during MI. Additionally, three studies observed more intense activity in BA40 during ME, while two reported higher intensity during MI for the same area. In conclusion, similarities were observed in terms of the reported number of activated areas, with at least five regions displaying similar frequencies for both conditions. Furthermore, four out of five regions exhibited comparable intensity levels. These results support the proposal that ME and MI rely on similar neural mechanisms; explaining the benefits of using mental practice to improve motor performance.\n\nThe effect of variability practice on baseball hitting\n\nMin-Jae Ju, Yonsei University; Soo-Jung Yang, Yonsei University; Seon-Young Ahn, Yonsei University; Ye-Ji Choi, Yonsei University; Jong-Hyun Lee, Yonsei University; Yong-Jin Yoon, Yonsei University; Seong-Kwan Cho, Texas A&M International University\n\nBaseball is one of those open-skill sports in which performance improves with various practice. As batters have to judge and predict the unpredictable ball thrown by pitchers within a short period of time, they need to perform various practice to improve their hitting accuracy, but there is a lack of prior research on this topic. Taking all the above into account, this study aims to investigate the variability types of hitting practice were divided to confirm how each practice affects hitting accuracy. To accomplish the purpose of the study, four subjects were randomly assigned to each contextual interference (CI) and differential learning (DL) practice (N = 8). In this study, the experiment was limited to the inside and outside of the baseball strike zone. A random hitting operation was performed 15 times for each course (in and out) and each group (DL and CI), and hitting scores were evaluated on a 3-point Likert scale (1. Missed, 2. Bad Hit, 3. Perfect Hit). The pre- and post-training hitting scores were calculated through descriptive statistics analysis using the mean and standard deviation values. In addition, the Cohen’s D formula was used to compare the improvement of the hitting score for each training. The results of the study showed that DL practice significantly improved hitting scores compared to CI practice in the In course, but the effect size was small as .165 (95% CI = .073 – .257). These results indicate that DL practice is effective in improving contact ability for the In course. On the other hand, CI practice does not seem to improve rotation and rotation-related skills in the In-course. In the Out course, CI practice had a significant effect on improving the batting score compared to DL training, but it showed a medium effect size of −.531 (95% CI = −.756–.307). This seems to have been more effective in the Out course because the short and long moment of bat inertia was repeated during CI practice, which increased the subjects’ wrist hinge technique. On the other hand, DL practice seems to be insufficient to improve coordination for the out course.\n\nPhysical activity may not protect against proprioceptive decline in Parkinson’s disease\n\nJason Kang, University of Minnesota; Jacquelyn Sertic, University of Minnesota; Jürgen Konczak, University of Minnesota\n\nParkinson’s disease (PD) is a neurodegenerative disease associated with progressive motor and somatosensory decline. A physically active lifestyle can preserve proprioception – the awareness of body position and movement – from age-related decline in healthy aging adults. However, it is unclear whether it also preserves proprioception in PD. We hypothesized that physically active people with PD (n = 11) would also show preserved proprioceptive function. We applied a psychophysical method to measure ankle position sense just-noticeable-difference (JND) threshold. For 35 trials, the ankle was rotated to a 15° reference and a comparison (<15°) position. Participants verbally indicated which position was perceived to move further. Based on the verbal response and perceived movement, a psi-marginal algorithm selected the next comparison position. Physical activity (PA) levels were measured using the Godin-Shephard Leisure-Time PA Questionnaire. Participants responded to the question, “How many times on average do you do. . . [strenuous, moderate, or mild] exercise in a typical week?”. Responses were used to calculate total PA level, in which >23 is Active, 14–23 is Moderately Active, and <14 is Insufficiently Active. PD motor severity was measured using the Movement Disorder Society-Unified Parkinson’s Disease Rating Scale (MDS-UPDRS)-III, in which <33 is mild and >59 is severe. The main findings: (1) PA levels (range 25–129) did not correlate to the JND threshold (range 1.2–4.4°, mean 2.4°, p > .05). (2) motor severity ranged from 16–48 (mean 30) indicating mild-to-moderate severity. A significant inverse correlation of PA levels to motor severity was found (r = −0.66, p = .04; after controlling for 1 outlier). That is, higher MDS-UPDRS III scores were correlated with lower PA levels, and vice versa Our preliminary findings indicate that PA may not protect people with PD from proprioceptive decline. These data also indicate that people with less severe motor symptoms are more likely to be physically active than people with higher severity of motor symptoms. Funding source: NASPSPA Graduate Student Research Grant.\n\nThe effect of unilateral ankle loading on spatiotemporal gait parameters in adults and children during treadmill walking\n\nYeon-Joo Kang, Georgia State University; Haneol Kim, University of Wisconsin-La Crosse; Jianhua Wu, Georgia State University\n\nHealthy populations display a relatively symmetrical gait pattern. However, gait symmetry can be compromised due to pathology or injury. One way to introduce gait asymmetry is by adding weights on one leg only (i.e., unilateral loading). We found that with unilateral ankle loading, young adults increase step length on both sides and increase step time on the loaded side but decrease it on the unloaded side. The purpose of this study was to examine the effect of unilateral ankle loading on spatiotemporal gait parameters between adults and children during treadmill walking. Twenty adults (aged 18–35 years, 10M/10F) and 11 children (aged 6–12 years, 5M/6F) completed 5-minute treadmill walking trials under four load conditions in a random order: no load and ankle loads which increased the moment of inertia of the lower leg by 25%, 50%, and 75%, respectively. The Vicon lower-body model with 16 markers was used to collect the gait data. Spatiotemporal variables included normalized step length and step width, step time, stance percentage, and swing percentage. Three-way (2 group x 2 side x 4 load) mixed ANOVA were conducted on each variable. Results showed that while adults displayed similar step length between the two sides, children produced longer step length on the loaded side than on the unloaded side. In contrast, children displayed similar step width between the two sides, adults produced greater step width on the loaded side than on the unloaded side. Both groups increased step time on the loaded side and decreased it on the unloaded side with increasing ankle load; children had longer step time than adults across the conditions. In addition, children showed higher stance percentage and lower swing percentage than adults across the conditions. These results suggest that children use different motor strategies compared to adults while adapting to the perturbation of unilateral ankle loading during treadmill walking. The development of gait adaptation to external constraints such as mechanical loading may continue beyond preadolescence.\n\nInvestigating Lost Move Syndrome in the rolling of recreational white-water kayakers\n\nPhilip Kearney, University of Limerick; Aidan Doran, University of Limerick; Edward Christian, University of Chichester\n\nAthletes presenting with Lost Move Syndrome (LMS) find themselves unable to perform a skill that was previously automatic. To date, this phenomenon has been investigated in a limited range of sports. An explanatory sequential design was used to further understand LMS in the context of Irish paddlesport. A cross-sectional online survey explored kayakers’ initial learning and subsequent performance of the kayak roll, including the prevalence of LMS; 108 experienced kayakers completed this survey (M = 14.3 years white water kayaking; minimum level 3 white water kayaking qualification from Canoeing Ireland). Subsequently, interviews were conducted with six respondents who identified as having experience of LMS. Problems with rolling were common: 41.3% of survey respondents indicated they experienced problems shortly after learning, 27.5% indicated that problems occurred a long time after learning and 12.8% indicated they were currently having problems rolling. Of the 85 participants who reported experiencing problems with the kayak roll, 49 reported previously or currently experiencing LMS. There was no association between the likelihood of reporting LMS and either performance characteristics (e.g., self-rated ability to execute the roll prior to problems) or practice history variables (e.g., frequency of practice; initially learning to roll on one or both sides). The interviews supported the presence of some form of performance block, and provided detailed accounts of ‘learning to roll’, ‘losing the roll’, and ‘recovering the roll’. In particular, interview participants’ accounts suggest that their experiences of learning to roll were not conducive to developing a skill that could be performed in a high-pressure dynamic environment. As well as contributing to the understanding of LMS, these findings have practical implications for the white water paddling community as a whole; specifically, for the coaches and instructors who operate in the white water community, and the National Governing Body and its role in the provision of coach/instructor education.\n\nSynchronization in space: Exploring bimanual skills on the vomit comet\n\nDeanna Kennedy, Texas A&M University; Madison Weinrich, Texas A&M University; Renee Abbott, Texas A&M University; Osmar Neto, Anhembi Morumbi University; Nathan Keller, Texas A&M University; Traver Wright, University of Texas Medical Branch; Bonnie Dunbar, Texas A&M University; Ana Diaz-Artiles, Texas A&M University\n\nThe upcoming Artemis program represents a pivotal milestone in space exploration, with its primary goal of returning humans to the Moon and laying the groundwork for crewed missions to Mars. Therefore, understanding human performance in microgravity and partial gravity environments is of critical importance. The current experiment was designed to determine if the bimanual control of force changes as a function of gravity. Parabolic flight (i.e., the vomit comet) was used to deliver G-levels of 0, 0.25, 0.5, and 0.75G. Right limb-dominant participants (N = 12) were required to synchronize patterns of isometric forces in a 1:2 multi-frequency pattern by exerting force with their right and left triceps brachii muscles. Lissajous plots and force templates were provided to guide performance. Muscle activity from the triceps brachii muscles were recorded. EMG-EMG coherence between the two EMG signals was calculated using wavelet coherence. Results indicated effective synchronization across all gravity levels, but differences in force control and muscle activation were observed. Notably, microgravity (0G) showed higher mean force production for the right limb compared to partial gravity conditions. Additionally, force harmonicity was lower, and EMG-EMG coherence was significantly reduced in microgravity. These findings suggest gravity influences bimanual control, emphasizing the need for further research to fully grasp how exposure to different gravity levels impacts motor control. Funding source: NASA 80NSSC20K1499.\n\nThe impact of attentional focus on motor learning and competitive state anxiety\n\nYoung-Joon Kim, The University of Tennessee; Jared Marak Porter, The University of Tennessee\n\nPrior studies have revealed the impact of attention on motor learning and anxiety. There is a need to explore whether attentional focus effective in motor learning can be utilized as a strategy to cope with competitive state anxiety. The purpose of this study is to ascertain the impact of attentional focus on motor learning and competitive state anxiety. We predicted that an external and holistic focus of attention would be more effective in motor learning compared to an internal focus of attention, and would also induce more effective motor performance in a competitive situation. Participants (N = 48) were randomly assigned to one of four experimental conditions (i.e. control, external, holistic, internal). Participants in the External, Internal, and Holistic conditions were instructed to focus their attention on the target, arm movement, and swing rhythm, respectively, while performing the task. The participants performed 9 trials for the pre-test, followed by a total of 54 practice trials. During the practice phase of the experiment, participants were asked to repeat the prescribed instructions after every 9 trials. 24 hours later, the participants performed 9 trials each in non-competitive and competitive situations for the post-test and completed the CSAI-2 to measure competitive state anxiety. According to the analysis of results, all groups exhibited higher levels of competitive state anxiety in the competitive situation compared to the non-competitive situation. Furthermore, learning effects were observed in terms of the accuracy in the External and Holistic conditions. Only the External condition maintained this learning effect even in the competitive situation. Regarding consistency, learning effects were found in the External, Internal, and Holistic conditions, with only the Holistic condition maintaining this learning effect in the competitive situation. The results of this experiment provide evidence that specific attentional focuses can serve as effective strategies in competitive situations.\n\nPersistent coordination impairments following anterior-cruciate ligament reconstruction\n\nAdam King, Texas Christian University; Kuanting Chen, Texas Christian University; Morteza Farivar, Texas Christian University; Caleb Voskuil, Texas Christian University; Channing Burning, Texas Christian University; Joshua Carr, Texas Christian University\n\nImpairments of movement patterns and lower-limb coordination following anterior-cruciate ligament reconstruction (ACLR) appear to persist beyond recovery and rehabilitation. Re-injury risk exists due to these abnormal movements, which have been strongly linked to increased potential of early onset knee osteoarthritis. Range of motion and strength indices typically denoted recovery progression, yet subtle movement impairments restrict functional performance tend to be more readily detectable using coordination analyses. The aim of the current study was to examine whether ACLR individuals (with full return to participation) exhibited different coordination patterns during a bimanual lower limb task as compared to healthy individuals. Twenty-four individuals (n =12 ACLR, n =12 Healthy, Age: M = 24, SD = 3.8 years, IKDC score: M = 80.1, SD = 16.5, Time since return: 3 – 120 months) performed an anti-phase coordination pattern with the lower limbs through flexion and extension motion of the knee joints. Self- and metronome-paced conditions were executed at slow and fast tempos. Kinematic markers placed at the hip, knee, and ankle were used to determine knee joint angle trajectories. A phase coordination index (PCI) between the bimanual joint angles was computed. Results revealed higher PCI (poorer coordination) values for ACLR as compared to healthy individuals (p = .01). Self-paced coordination was worse than with the use of a metronome-paced (p = .01). Both self- and metronome-paced conditions exhibited significant differences in PCI between the slow and fast conditions (p < .001). In the fast conditions, self-paced coordination showed higher PCI than the metronome-paced (p < .001) but lower PCI during the slow conditions (p = .01). The findings of persistent coordination impairments for the ACLR individuals have important implications on rehabilitation protocols and established criteria used to determine return-to-play status. Investigating the observed impaired coordination throughout recovery is warranted as well as understanding the association with additional injury risks.\n\nPreference, familiarity, and usefulness of attentional focus instructions on golf putting performance\n\nHaley Kivett, Whittier College; Mehdi Babak, Urmia University; Hassan Mohammadzade, Urmia University; Jalal Dehghanizade, Urmia University; Masahiro Yamada, Whittier College\n\nAlthough the relationship between external focus (EF) and internal focus (IF) has long been studied, some studies showed that preference (likeness—Like, perceived usefulness—Use) for or familiarity (Fam) with EF/IF can moderate the attentional focus effect. The central predictions of our preliminary study were that these concepts would be influenced by previous experience (i.e. , ball- or body-oriented sports; participation duration) and immediate experience (before and after exposure to EF/IF cues). Specifically, we hypothesized that (A) Fam would be explained by previous experience; (B) Fam, Use, and Like would be different concepts; and (C) the proportion of Like and Use for EF/IF would shift after experiencing EF/IF. After familiarization and baseline trials of golf putting, high-school students (N = 60, M = 15.36 +/- 0.63 yrs) received a list of two IF and four EF (two EF-Near and two EF-Far) cues and responded to questions about Fam (“Which cue is most familiar?”), Like (“Which cue do you like the most?”) and Use (“Which cue is most helpful?”). Then, participants completed 3 trials of golf putting with each cue. After experiencing golf putting with EF/IF cues, the same questions were asked (e.g., “Which cue did you. . .?”). The responses were categorized into EF-Near, EF-Far, or IF. For Hypothesis A, the results of a multinomial logistic regression (Fam = Sport type + duration + error, reference = IF) showed that individuals who played ball sports tended to feel more familiar with EF-Far (b = −1.412, SE = 0.749, p = .0596), which was not evident for Use or Like. For Hypothesis B, the responses between Fam and Like, Fam and Use, and Like and Use showed low agreements: 63.33%, 45%, and 46.67%, respectively. For Hypothesis C, we found an increase in the proportion of IF pre"
    }
}