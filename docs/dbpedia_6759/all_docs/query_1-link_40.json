{
    "id": "dbpedia_6759_1",
    "rank": 40,
    "data": {
        "url": "https://amt.copernicus.org/articles/17/899/2024/",
        "read_more_link": "",
        "language": "en",
        "title": "Introducing the Video In Situ Snowfall Sensor (VISSS)",
        "top_image": "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-avatar-web.png",
        "meta_img": "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-avatar-web.png",
        "images": [
            "https://contentmanager.copernicus.org/800952/400/ssl",
            "https://contentmanager.copernicus.org/800952/400/ssl",
            "https://www.atmospheric-measurement-techniques.net/licenceSVG_16.svg",
            "https://www.atmospheric-measurement-techniques.net/licenceSVG_16.svg",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-avatar-thumb150.png",
            "https://www.atmospheric-measurement-techniques.net/mendeley.png",
            "https://www.atmospheric-measurement-techniques.net/reddit.png",
            "https://www.atmospheric-measurement-techniques.net/twitter.png",
            "https://www.atmospheric-measurement-techniques.net/facebook.png",
            "https://www.atmospheric-measurement-techniques.net/linkedin.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f01-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-t01-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f02-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f03-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f04-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f05-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f06-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f07-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f08-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f09-thumb.png",
            "https://amt.copernicus.org/articles/17/899/2024/amt-17-899-2024-f10-thumb.png",
            "https://www.atmospheric-measurement-techniques.net/mendeley.png",
            "https://www.atmospheric-measurement-techniques.net/reddit.png",
            "https://www.atmospheric-measurement-techniques.net/twitter.png",
            "https://www.atmospheric-measurement-techniques.net/facebook.png",
            "https://www.atmospheric-measurement-techniques.net/linkedin.png",
            "https://contentmanager.copernicus.org/319373/400/ssl",
            "https://contentmanager.copernicus.org/319376/400/ssl"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Matthew D"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Abstract. The open-source Video In Situ Snowfall Sensor (VISSS) is introduced as a novel instrument for the characterization of particle shape and size in snowfall. The VISSS consists of two cameras with LED backlights and telecentric lenses that allow accurate sizing and combine a large observation volume with relatively high pixel resolution and a design that limits wind disturbance. VISSS data products include various particle properties such as maximum extent, cross-sectional area, perimeter, complexity, and sedimentation velocity. Initial analysis shows that the VISSS provides robust statistics based on up to 10â000 unique particle observations per minute. Comparison of the VISSS with the collocated PIP (Precipitation Imaging Package) and Parsivel instruments at HyytiÃ¤lÃ¤, Finland, shows excellent agreement with the Parsivel but reveals some differences for the PIP that are likely related to PIP data processing and limitations of the PIP with respect to observing smaller particles. The open-source nature of the VISSS hardware plans, data acquisition software, and data processing libraries invites the community to contribute to the development of the instrument, which has many potential applications in atmospheric science and beyond.",
        "meta_lang": "en",
        "meta_favicon": "https://www.atmospheric-measurement-techniques.net/favicon_copernicus_16x16_.ico",
        "meta_site_name": "",
        "canonical_link": "https://amt.copernicus.org/articles/17/899/2024/",
        "text": "It is well known that âevery snowflake is uniqueâ. The shape of a snow crystal is very sensitive to the processes that were active during its formation and growth. Vapor depositional growth leads to a myriad of crystal shapes depending on temperature, humidity, and their turbulent fluctuations. Aggregation combines individual crystals into complex snowflakes. Riming describes the freezing of small droplets onto ice crystals, causing them to rapidly gain mass and form a more rounded shape. In other words, the shape of snow particles is a fingerprint of the dominant processes during the life cycle of snowfall.\n\nBetter observations of the fingerprints of snowfall formation processes are needed to advance our understanding of ice and mixed-phase clouds and precipitation formation processes (Morrison etÂ al.,Â 2020). Given the importance of snowfall formation processes for global precipitation (MÃ¼lmenstÃ¤dt etÂ al.,Â 2015; Field and Heymsfield,Â 2015), the lack of process understanding leads to gaps in the representation of these processes in numerical models. In a warming climate, precipitation amounts and extreme events, including heavy snowfall, are expected to increase (Quante etÂ al.,Â 2021), but the exact magnitudes are associated with large uncertainties (Lopez-Cantu etÂ al.,Â 2020).\n\nRemote sensing observations of snowfall are indirect, which limits their ability to identify snow particle shape by design. Ground-based in situ observations of ice and snow particles can identify the fingerprints of the snowfall formation processes and provide detailed information on particle size, shape, and sedimentation velocity. Using assumptions about sedimentation velocity or an aggregation and riming model as a reference, the particle massâsize and/or massâdensity relationship can also be inferred from in situ observations (Tiira etÂ al.,Â 2016; von Lerber etÂ al.,Â 2017; Pettersen etÂ al.,Â 2020; Tokay etÂ al.,Â 2021; Leinonen etÂ al.,Â 2021; VÃ¡zquez-MartÃ­n etÂ al.,Â 2021a). Various attempts have been made to classify particle types and identify active snowfall formation processes using various machine learning techniques (NurzyÅska etÂ al.,Â 2013; Grazioli etÂ al.,Â 2014; Praz etÂ al.,Â 2017; Hicks and NotaroÅ¡,Â 2019; Leinonen and Berne,Â 2020; DelÂ Guasta,Â 2022; Maherndl etÂ al.,Â 2023b); these classifications are needed to support quantification of snowfall formation processes (Grazioli etÂ al.,Â 2017; Moisseev etÂ al.,Â 2017; Dunnavan etÂ al.,Â 2019; Pasquier etÂ al.,Â 2023). In situ observations have also been used to characterize particle size distributions (Kulie etÂ al.,Â 2021; Fitch and Garrett,Â 2022), to investigate sedimentation velocity and turbulence of hydrometeors (Garrett etÂ al.,Â 2012; Garrett and Yuter,Â 2014; Li etÂ al.,Â 2021; VÃ¡zquez-MartÃ­n etÂ al.,Â 2021b; Takami etÂ al.,Â 2022), and for model evaluation (Vignon etÂ al.,Â 2019). In combination with ground-based remote sensing, in situ snowfall data have been used to validate or better understand remote sensing observations (Gergely and Garrett,Â 2016; Li etÂ al.,Â 2018; Matrosov etÂ al.,Â 2020; Luke etÂ al.,Â 2021), to develop joint radar in situ retrievals (Cooper etÂ al.,Â 2017, 2022), and to train remote sensing retrievals (Huang etÂ al.,Â 2015; Vogl etÂ al.,Â 2022).\n\nDifferent design concepts have been used for in situ snowfall instruments. Line scan cameras are commonly used by optical disdrometers such as the OTT Parsivel (LÃ¶ffler-Mang and Joss,Â 2000), and their relatively large observation volume reduces the statistical uncertainty for estimating the particle size distribution (PSD). However, additional assumptions are required to size irregularly shaped particles such as snow particles correctly due to the one-dimensional measurement concept (Battaglia etÂ al.,Â 2010). This limitation can be overcome when adding a second line camera as for the Two-Dimensional Video Disdrometer (2DVD;Â SchÃ¶nhuber etÂ al.,Â 2007), but particle shape estimates can still be biased by horizontal winds (Huang etÂ al.,Â 2015; Helms etÂ al.,Â 2022). The 2DVD's pixel resolution of approx. 190âÂµm per pixel (px) and the lack of gray-scale information prohibit resolving fine-scale details of snow particles.\n\nTo get high-resolution images, a group of instruments uses various approaches to obtain particle images with microscopic resolution at the expense of the measurement volume size. For example, the MASC (Multi-Angle Snowfall Camera;Â Garrett etÂ al.,Â 2012) takes three images with 30âÂµmâpxâ1 pixel resolution of the same particle from different angles. This allows for resolving very fine particle structures, but during a snowfall event Gergely and Garrett (2016) observed only 102â104Â particles, which is not sufficient to reliably estimate a PSD on the minute temporal scales needed to capture changes in precipitation properties. DelÂ Guasta (2022) have developed a flatbed scanner (ICE-CAMERA) that has a pixel resolution of 7âÂµmâpxâ1 and can provide mass estimates by melting the particles, but this approach only works at low snowfall rates. The images of the D-ICI (Dual Ice Crystal Imager;Â Kuhn and VÃ¡zquez-MartÃ­n,Â 2020) even have a pixel resolution of 4âÂµmâpxâ1 and show particles from two perspectives, but similarly to the MASC, the small sampling volume does not allow for the measurement of PSDs with a sufficiently high accuracy.\n\nThe SVI (Snowfall Video Imager;Â Newman etÂ al.,Â 2009) and its successor the PIP (Precipitation Imaging Package;Â Pettersen etÂ al.,Â 2020) use a camera pointed to a light source to image snow particles in free fall. The open design limits wind field perturbations, and the large measurement volume (4.8âcmâÃâ6.4âcmâÃâ5.5âcm for a 1âmm snow particle) minimizes statistical errors in deriving the PSD. However, the pixel resolution of 100âÂµmâpxâ1 is not sufficient to study fine details. Further, the open design requires that the depth of the observation volume is not constrained by the instrument itself. As a consequence, particle blur needs to be used to determine whether a particle is in the observation volume or not, which is potentially more error-prone than a closed instrument design. A similar design was used by Testik and Rahman (2016) to study the sphericity oscillations of raindrops. Kennedy etÂ al. (2022) developed the low-cost OSCRE (Open Snowflake Camera for Research and Education) system that uses a strobe light to illuminate particles from the side, allowing for the observation of particle type of blowing and precipitating snow, but the observation volume is not fully constrained.\n\nThis study presents the Video In Situ Snowfall Sensor (VISSS). The goal was to develop a sensor with an open instrument design without sacrificing the quality of measurement volume definition or resolution. It uses the same general principle as the PIP (Fig.Â 1): gray-scale images of particles in free fall illuminated by a background light. Unlike the PIP, this setup is duplicated with overlapping measurement volumes so that particles are observed simultaneously from two perspectives at a 90â angle. This robustly constrains the observation volume without the need for further assumptions. In addition, having two perspectives of the same particle increases the likelihood that the observed maximum dimension (Dmax) and aspect ratio are representative of the particle. While the VISSS does not reach the microscopic resolution of the D-ICI or ICE-CAMERA, its pixel resolution of 43 to 59âÂµmâpxâ1 is significantly better than the PIP, and the use of telecentric lenses eliminates sizing errors caused by the variable distance of snow particles to the cameras.\n\nThe VISSS was originally developed for the MOSAiC (Multidisciplinary drifting Observatory for the Study of Arctic Climate) experiment (Shupe etÂ al.,Â 2022) and deployed at MetCity and, after the sea ice became too unstable in April 2020, on the PÂ deck of the research vessel Polarstern. After MOSAiC, the original VISSS was deployed at HyytiÃ¤lÃ¤, Finland (PetÃ¤jÃ¤ etÂ al.,Â 2016), in 2021/22; at Gothic, Colorado, as part of the SAIL campaign in 2022/23 (Surface Atmosphere Integrated Field Laboratory;Â Feldman etÂ al.,Â 2023); and at Eriswil, Switzerland, for the PolarCAP (Polarimetric Radar Signatures of Ice Formation Pathways from Controlled Aerosol Perturbations) campaign in 2023/24. During a test set up in Leipzig, Germany, the VISSS was used to evaluate a radar-based riming retrieval (Vogl etÂ al.,Â 2022). An improved second generation of the VISSS was installed at the FrenchâGerman Arctic research base AWIPEV (the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine ResearchÂ â AWIÂ â and the French Polar Institute Paul-Ãmile VictorÂ â PEV) in Ny-Ã lesund, Svalbard (Nomokonova etÂ al.,Â 2019), in 2021. A further improved third-generation VISSS with 1300âmm working distance was deployed in HyytiÃ¤lÃ¤ at the end of 2023. The VISSS hardware plans and software libraries have been released under an open-source license (Maahn etÂ al.,Â 2023b; Maahn,Â 2023a, b; Maahn and Wolter,Â 2024) so that the community can replicate and further develop the VISSS. The VISSS hardware design and data processing are described in Sects.Â 2 andÂ 3, respectively. Example cases including a comparison with the PIP are given in Sect.Â 4, and concluding remarks are given in Sect.Â 5.\n\nThe VISSS consists of two camera systems oriented at a 90â angle to the same measurement volume (Fig.Â 1). Both cameras work using the complementary metal oxide semiconductor (CMOS) global-shutter principle and use a resolution of 1280âÃâ1024 gray-scale pixels and a frame rate of 140âHz (220 to 250âHz since the second generation). One camera acts as the leader, sending trigger signals to both the follower camera and the two LED backlights that illuminate the scenes from behind with a 350â000âlux flash. Green backlights (530ânm) were chosen because the camera and lenses are optimized for visual light. The leaderâfollower setup results in a slight delay in the start of exposure between the two cameras. To compensate for this, the background LEDs are turned on for a duration of 60âÂµs only when the exposure of both cameras is active. Thus, the 60âÂµs flash of the backlights determines the effective exposure time of the camera as long as there is no bright sunlight, which is a rare condition during precipitation.\n\nThe two cameraâlensâbacklight combinations are at a 90â angle so that particles are observed from two perspectives, reducing sizing errors. Leinonen etÂ al. (2021) found that using only a single perspective for sizing snow particles can lead to a normalized root mean square error of 6â% for Dmax, and Wood etÂ al. (2013) estimated the resulting bias in simulated radar reflectivity to be 3.2âdB. For the VISSS, the accuracy of the measurements can be further improved by taking advantage of the fact that the VISSS typically observes 8Â to 11Â frames of each particle (assuming a sedimentation velocity of 1âmâsâ1 and a frame rate of 140 to 250âHz), and additional perspectives can be obtained from the natural tumbling of the particle.\n\nTelecentric lenses have a constant magnification within the usable depth of field, eliminating sizing errors. Consequently, the lens aperture must be as large as the observation area, making the lens bulky, heavy, and expensive. For the first VISSS (VISSS1), a lens with a magnification of 0.08 was chosen, resulting in a pixel resolution of 58.832âÂµmâpxâ1 (TableÂ 1). The working distance, i.e.,Â the distance from the edge of the lens to the center of the observation volume, is 227âmm. This partly undermines the goal of having an instrument with an observation volume that is not obstructed by turbulence induced by nearby structures but was caused by budget limitations. It also does not allow for sufficiently large roofs over the camera windows to protect against snow accumulation in all weather conditions. This problem was partially solved by the increased budget (EURâ22â000) for the second-generation VISSS2, which used a 600âmm working distance lens as well as a camera with an increased frame rate of 250âHz and a pixel resolution of 43.266âÂµmâpxâ1. However, the optical quality of the lens proved to be borderline for the applications, resulting in an estimated optical resolution of approximately 50âÂµm and slightly blurred particle images. Consequently, the lens was changed again for the third-generation VISSS3, which has a working distance of 1300âmm. This was motivated by the result of Newman etÂ al. (2009) showing that the airflow is undisturbed at a distance of 1âm from the instrument. Image quality is potentially also impacted by motion blur, and the exposure time of 60âÂµs was selected to limit motion blur of particles falling at 1âmâsâ1 to 1.02 and 1.44âpx for VISSS1 and VISSS2, respectively. Particle blur can also occur when particles are not exactly in the focus of the lenses. The maximum circle of confusion is 1.3âpx at the edges of the observation volume.\n\nThe lensâcamera combinations and backlights are housed in waterproof enclosures that are heated to â5Â and 10ââC, respectively. The low temperature in the camera housing is to prevent melting and refreezing of particles on the camera window.\n\nThe cameras of VISSS1 and VISSS2/VISSS3 are connected to the data acquisition systems via separate 1Â and 5âGbit Ethernet connections, respectively. Due to the increased frame rate, two separate systems are required to record data in real time for VISSS2/VISSS3.\n\nThe cameras transmit every captured image to the data acquisition systems, which are standard desktop computers running Linux. Based on simple brightness changes, the computers save only moving images and discard all other data (this was not implemented for MOSAiC). The raw data of the VISSS consist of the video files (.mov or .mkv video files with H.264 compression), the first recorded frame as an image (.jpg format) for quick evaluation of camera blocking, and a .csv file with the timestamps of the camera (capture_time) as well as the computer (record_time) and other meta-information for each frame. The cameras run continuously, and new files are created every 10âmin (5âmin for MOSAiC). In addition, a daily status .csv file is maintained that contains information about software start and stop times and when new files were created. Both cameras record completely separately, which requires an accurate synchronization of the camera and computer clocks for matching the observations of a single particle.\n\nObtaining particle properties from the individual VISSS video images requires (1)Â detecting the particles, (2)Â matching the observations of the two cameras, and (3)Â tracking the particles over multiple frames to estimate the fall velocities. The Level-1 products contain per-particle properties in pixel units using (1) a single camera, (2) matched particles from both cameras, and (3) exploiting particles tracked in time. For the Level-2 products, the Level-1 observations are calibrated (i.e., converted from pixels into metric units) and distributions of the particle size, aspect ratio, and other properties are estimated based on the per-particle properties. In addition to the Level-1 and Level-2 products, there are metadata products: metaEvents is a netCDF version of the status files along with a camera blocking estimate based on the .jpg images. metaFrames is a netCDF version of the .csv file. metaRotation keeps track of the camera misalignment as detailed below. The imagesL1detect product contains images of the detected particles, which is required for creating quicklooks like Fig.Â 1c.\n\nIn the following, the processing of the Level-1 and Level-2 products is described in detail (Fig.Â 2).\n\n3.1âParticle detection\n\nHydrometeors need to be detected and sized based on individual frames. First, video frames containing motion are identified by a simple threshold-based filter. Except for the MOSAiC data set, this is done in real time, which significantly reduces the data volume. Because snow may stick to the camera window, individual particles within a video frame cannot be identified by image brightness. Instead, the moving mask of pixels is identified by OpenCV's BackgroundSubtractorKNN class (Zivkovic and van der Heijden,Â 2006) in the image coordinate system (horizontal dimension X, vertical dimension Y pointing to the ground). In the moving mask identified by the background subtraction method, the individual particles are systematically too large so that the moving mask cannot be used directly for particle sizing. For each particle, i.e.,Â connected group of moving pixels, we select a 10âpx padded box around the region of interest (ROI) which is the smallest non-rotated rectangular box around the particle's moving mask (Fig.Â 3). This extended ROI is the input for OpenCV's Canny edge detection (after applying a Gaussian blur with a standard deviation of 1.5âpx) to identify the edges of the particle. To estimate the particle mask by filling in the retrieved particle edges, gaps (typically 1âpx in size) between the particle edges must be closed. For this, we dilate the retrieved edges by 1âpx to form a closed contour, fill in the created contour, and erode the filled shape by 1âpx to obtain the particle mask. To detect potential particle holes, which should be retained to avoid overestimating the particle area, the Canny filter particle mask and the moving mask are combined for the final particle mask. As a result, the VISSS can detect even relatively small particle structures, as shown in Fig.Â 3. The use of only 1âpx (i.e., 43 to 59âÂµm) for dilation was found to be sufficient and allows us to potentially resolve more details of the particles than MASC and the PIP, which dilate by 200âÂµm (Garrett etÂ al.,Â 2012) and 300âÂµm (Helms etÂ al.,Â 2022), respectively. The final particle mask and corresponding contour are used to estimate the particle's maximum dimension (using OpenCV's minEnclosingCircle function), perimeter p (arcLength), area A (contourArea), and aspect ratio AR (defined as the ratio between the major and minor axis), as well as the canting angle Î± (defined between the vertical axis and major axis). AR and Î± are estimated in three different ways, from the smallest rectangle fitted around the contour (minAreaRect) or from an ellipse fitted to the contour (fitEllipse and the more stable fitEllipseDirect). The particle area equivalent diameter (Deq) is obtained from A. Particle complexity c (Garrett etÂ al.,Â 2012; Gergely etÂ al.,Â 2017) is derived from the ratio of the particle perimeter p to the perimeter of a circle with the same area A:\n\n(1) c = p 2 Ï A .\n\nIn addition to these geometric variables, the level1detect product contains variables describing the pixel brightness (min, max, standard deviation, mean, skewness), the position of the centroid, and the blur of the particle estimated from the variance of the Laplacian of the ROI. All particles are processed for which Dmaxâ¥â2âpx and Aâ¥â2âpx hold. To avoid detection of particles completely out of focus, the brightness of the darkest pixel must be at least 20 steps darker than the median of the entire image, and the variance of the Laplacian of the ROI brightness must be at leastÂ 10. Particle detection is the most computationally intensive processing step and is typically performed on a small cluster. Processing 10âmin of heavy snowfall for a single VISSS camera can take several hours on a single AMD EPYC 7302 core.\n\n3.2âParticle matching\n\nThe particle detection of each camera is completely separate, so the particles observed by each camera must be combined. This particle combination allows for the particle position to be determined in a three-dimensional reference coordinate system. As a side effect, this constrains the observation volume by discarding particles outside of the intersection of their observation volumes, i.e.,Â observed by only one camera. We use a right-handed reference coordinate system (x,y,z) with z pointing to the ground to define the position of particles in the observation volume (Fig.Â 1). In the absence of an absolute reference, we attach the coordinate system to the leader camera (i.e., (xL,yL,zL)â=â(x,y,z)) such that x=XL and z=YL, where XL and YL are the particle positions in the two-dimensional leader images. Note that small letters describe the three-dimensional coordinate system and capital letters describe the two-dimensional position on the images of the individual camera images. The missing dimension y is obtained from the follower camera with y=-XF , where XF is the horizontal position in the follower image.\n\nThe matching of the particles from both cameras is based on the comparison of two variables: the vertical position of the particles and their vertical extent. Due to measurement uncertainties, the agreement of these variables cannot be perfect and they are treated probabilistically. That is, it is assumed that the difference in vertical extent Îh (vertical position Îz) between the two cameras follows a normally distributed probability density function (PDF) with mean zero and a standard deviation of 1.7âpx (1.2âpx), based on an analysis of manually matched particle pairs. To determine the probability (of, e.g., measuring a certain vertical extent), the PDF is integrated over an interval of Â±â0.5âpx representing the discrete 1âpx steps.\n\nThis process requires matching the observations of both cameras in time. The internal clocks of the cameras (âcapture timeâ) can deviate by more than 1Â frame per 10âmin. The time assigned by the computers (ârecord timeâ) is sometimes, but not always, distorted by computer load. Therefore, the continuous frame index (âcapture idâ) is used for matching, but this requires determining the index offset between both cameras at the start of each measurement (typically 10âmin). For this, the algorithm uses pairs of frames with observed particles that are less than 1âms (i.e.,Â less than 1/4 of the measurement resolution) apart in record time assuming that the lag due to computer load is only sporadically increased. This allows the algorithm to identify the most common capture id offset of the frame pairs. We found that this method gives stable results for a subset of 500Â frames. Similarly to h and z, the capture id offset Îi is used as the mean of a normal distribution with a standard deviation value of 0.01, which ensures that only particles observed at the same time are matched. During MOSAiC, the data acquisition computer CPUs turned out to be too slow to keep up with processing during heavy snowfall. With the additional impact of a bug in the data acquisition code and drifting computer clocks when the network connection to the ship's reference clock was interrupted, the particle matching for the MOSAiC data set often requires manual adjustment. These problems have been resolved for later campaigns so that matching now works fully automatically.\n\nThe joint product of the probabilities from Îh, Îz, and Îi is considered a match score, which describes the quality of the particle match. Manual inspection revealed that the number of false matches increases strongly for match scores of less than 0.001, which is used as a cutoff criterion. Assuming that the probabilities are correctly determined, this implies that 0.1â% of particle matches are falsely rejected, resulting in a negligible bias.\n\nFor each particle, its three-dimensional position is provided and all per-particle variables from the detection are carried forward to the matched-particle product level1match. The ratio of matched to observed particles from a single camera varies with the average particle size, since larger particles can be identified even when they are out of focus, and varies between approximately 10â% and 90â%.\n\n3.3âCorrection for camera alignment\n\nAlthough alignment of both observation volumes is a priority during installation, the cameras can be rotated or displaced, i.e., misaligned. As a result, the same particle may be observed at different heights and z=YL=YF does not hold. The observed offsets are not constant and can change due to unstable surfaces or pressure of accumulated snow on the VISSS frame. We could simply ignore the misalignment and continue to take z from the leader, but this would not allow us to generally use the vertical position to match particles from both cameras (see above). Also, offsets in z reduce the common observation volume of both cameras, which could lead to biases when calibrating the PSDs if not accounted for.\n\nBesides a constant offset in the vertical z dimension Ofz, one of the cameras can also be rotated around the optical axis (expressed analogously to aircraft coordinate systems with roll Ï), around the horizontal axis perpendicular to the optical axis (pitch Î¸), or around the vertical axis (yaw Ï). As a consequence, Îz=YL-YF depends on the position of the particle in the observation volume.\n\nTo account for the misalignment, we attach the coordinate system to the leader (i.e., we assume that the leader is perfectly aligned, (xL,yL,zL)â=â(x,y,z)) and retrieve the misalignment of the follower with respect to the leader in terms of Ï, Î¸, and Ofz. We cannot derive Ï from the observation, and we have no choice but to neglect it by assuming Ï=0 to reduce the number of unknowns. Mathematically, we need to transform the follower coordinate system (xF,yF,zF) to our leader reference coordinate system (xL,yL,zL) using rotation and shear matrices. In the AppendixÂ A, we show how the transformation matrices can be arranged so that the follower's vertical measure zF can be converted to zL depending on Ï and Î¸ with\n\n(2) z L = - sin Î¸ cos Î¸ x L + sin Ï cos Î¸ y F + cos Ï cos Î¸ ( z F + O f z ) .\n\nThis equation can be considered a forward operator that calculates the expected leader observation zL based on a misalignment state (Ofz, Ï, and Î¸) and additional parameters (xL, yF, zF). While we assume that the misalignment state is constant for each 10âmin observation period, the other variables (xL, yF, zF) are available on a per-particle basis, combining observations from both cameras. Therefore, we can use a Bayesian inverse optimal estimation retrieval (Rodgers,Â 2000) implemented by the pyOptimalEstimation library (Maahn etÂ al.,Â 2020) to retrieve the misalignment state from the actual observed zL.\n\nThe retrieved misalignment parameters are required for matching, but retrieving the misalignment parameters requires matched particles. To solve this dilemma, we use an iterative method assuming that misalignment does not change suddenly. The method starts by using the misalignment estimates and uncertainties (inflated by a factor ofÂ 10) from the previous time period (10âmin) to match particles of the current time period. These particles are used to retrieve values for Ï, Î¸, and Ofz which are used as a priori input for the next iteration of misalignment retrieval. The iteration is stopped when the changes in Ï, Î¸, and Ofz are less than the estimated uncertainties. For efficiency, the iterative method is applied only to the first 300 observed particles and the resulting coefficients are stored in the metaRotation product. A drawback of the method is that this processing step requires processing the 10âmin measurement chunks in chronological order, creating a serial bottleneck in the otherwise parallel VISSS processing chain. Obviously, this method does not work when no information is available from the previous time step, e.g., after the instrument was set up or adjusted. To get the starting point for the iteration, the matching algorithm is applied for frames where only a single, relatively large (>â10âpx) particle is detected so that the matching can be done based on particle height difference (Îh) alone, ignoring vertical offsetÂ (Îz).\n\n3.4âParticle tracking\n\nTracking a matched particle over time provides its three-dimensional trajectory, from which sedimentation velocity and interaction with turbulence can be determined. Since the natural tumbling of the particles provides new particle perspectives, the estimates of particle properties such as Dmax, A, p, and AR can be further improved. This can be seen in a composite of a particle (Fig.Â 4aâb) observed during MOSAiC, which also shows how the multiple perspectives of the particle help to identify its true shape. The example also shows that during MOSAiC the alignment of the cameras was not perfect, resulting in some of the measurements being slightly out of focus; this has been resolved for later campaigns. The tracking algorithm uses a probabilistic approach similar to particle matching, taking into account that the particles' velocities only change to a certain extent from one frame to the next. That change can be quantified as a cost derived from the particles' distances and area differences between two time steps. This allows us to use the Hungarian method (Kuhn,Â 1955) to assign the individual matched particles to particle tracks for each time step in a way that minimizes the costs, i.e.,Â to solve the assignment problem. To account for the fact that the particle's position is expected to change between observations, we use a Kalman filter (Kalman,Â 1960) to predict a particle's position based on the past trajectory and use the distance Î´l between predicted and actual position for the cost estimate. Without a past trajectory, the Kalman filter uses a first guess which we derive from the velocities of 200 previously tracked particles. If no previous particles are available, the tracking algorithm is applied twice to the first 400 particles to avoid a potential bias caused by using a non-case-specific fixed value as a first guess. We found that tracking based only on position is unstable and added the difference in particle area (Î´A, mean of both cameras) to the cost estimate to promote continuity of particle shape. The combined cost is estimated from the product of Î´l and Î´A weighted by their expected variance. The performance of the algorithm can be seen for an observation obtained in HyytiÃ¤lÃ¤ on 23Â January 2022 at 04:10âUTC where multiple particles are tracked at the same time (Fig.Â 4câd). The results of the tracking algorithm are stored in the level1track product which contains the track id and the same per-particle variables as the other Level-1 products.\n\n3.5âCalibration\n\nCalibration is required to convert Dmax, Deq, and p from pixels to micrometers. It depends not only on the optical properties of the lens but also on the computer vision routines used. Calibration is obtained using reference steel or ceramic spheres with 1Â to 3âmm diameter that are dropped into the VISSS observation volume. After processing using the standard VISSS routines, the estimated sizes are compared to the expected ones. A linear least-squares fit is applied to the 604 reference sphere observations obtained at HyytiÃ¤lÃ¤ and SAIL, resulting in\n\n(3) D max [ px ] = ( 0.01700 Â± 0.00001 ) â D max [ Âµ m ] + ( 0.49301 Â± 0.02101 ) ,\n\nfor VISSS1 (Fig.Â 5a), and\n\n(4) D max [ px ] = ( 0.02311 Â± 0.00003 ) â D max [ Âµ m ] + ( 0.81569 Â± 0.06997 ) ,\n\nfor VISSS2 based on 372 samples from Ny-Ã lesund (Fig.Â 5b). The inverse of the slope is 58.832âÂµmâpxâ1 (43.266âÂµmâpxâ1) and is close to the manufacturer's specification of 58.75âÂµmâpxâ1 (43.125âÂµmâpxâ1) for VISSS1 (VISSS2). The random error estimated from the normalized root mean square error obtained from the difference between observed and expected size is less than 0.8â%, indicating that random errors are negligible. To investigate the source of the non-zero intercept, we also tested the VISSS computer vision routines with artificially created VISSS images with drawn spheres and compared the expected to measured Dmax by a least-squares fit (Fig.Â 5c). Gaussian blur with a standard deviation between 0Â and 3âpx was applied to account for a realistic range of blurring due to, e.g., motion blur or particles that are slightly out of focus. Note that in addition to that, a Gaussian blur filter with a standard deviation of 1.5âpx needs to be applied during image processing for the Canny edge detection as discussed above. For the artificial spheres, the obtained slope deviates less than 2â% from the expected slope of 1.0, but the offset ranges from 0.6 to 1.5âpx, caused by the seeming enlargement of the particle due to the applied blur. To investigate the shape dependency of the results, we repeated the experiment with squares (Fig.Â 5d). Again, the slope deviates less than 2â% from 1.0, but the offset is negative with values ranging between â1.4Â and â2.9âpx depending on blur. This is because the corners of the square are rounded when applying Gaussian blur so that the true Dmax can no longer be obtained. In summary, the VISSS routines overestimate the Dmax of spheres but underestimate the Dmax of squares. In reality, the VISSS observes a wide range of different shapes that can be either rather spherical or rather complex with âpointyâ corners. Therefore, we decided to set the intercept toÂ 0 when calibrating Dmax, which can cause a particle-shape-dependent bias of Â±â4â% to Â±â6â%. For particles smaller than 10âpx, this bias can be slightly larger due to discretization errors, as can be seen from the larger impact of blur for small squares (Fig.Â 5d).\n\nFor better comparison with Dmax, Deq is used instead of A for testing the computer vision method for estimating A (Fig.Â 5eâh). The results are almost identical to Dmax, so the slopes derived from Dmax are applied to Deq (and consequently A) as well.\n\nFor the perimeter p (Fig.Â 5iâl), the slopes derived from the reference spheres are about 5â% steeper than for Dmax, indicating that VISSS p values are biased high. This bias is also found for artificial spheres independent of the applied additional blur. Therefore, this bias is related to the image processing and most likely caused by the Gaussian blur required for the Canny edge detection. For squares, however, the slope is close toÂ 1, likely due to compensating effects caused by âcutting cornersâ of the algorithm. In reality, the VISSS observes more complex particles for which the perimeter increases with decreasing scale (compare to the coastline paradox;Â Mandelbrot,Â 1967). Therefore, we conclude that it is extremely unlikely that the perimeter of real particles is biased high like for artificial spheres but rather biased low depending on complexity. As a pragmatic approach, we also apply the Dmax slope to p but stress that p has a considerably higher uncertainty than Dmax or Deq.\n\nThe calibration is also checked by holding a millimeter pattern in the camera and measuring the pixel distance in the images; the difference found from the reference spheres is less than 2â%. The millimeter pattern calibration did not reveal any dependence on the position in the observation volume, so errors related to imperfect telecentricity of the lenses can likely be neglected.\n\n3.6âTime-resolved particle properties\n\nWhile Level-1 products contain per-particle properties, Level-2 products provide time-resolved properties. This includes the particle size distribution (PSD), which is the concentration of particles as a function of size normalized to the bin width. To estimate the PSD, the individual particle data are binned by particle size (1âpx spacing, i.e.,Â 43.266 to 58.832âÂµm), averaged over all frames during 1âmin periods, and divided by the observation volume. For perfectly aligned cameras, the observation volume would simply be the volume of a cuboid with a base of 1280âpxâÃâ1280âpx and a height of 1024âpx. However, due to misalignment of the cameras, the actual joint observation volume is slightly smaller than a cuboid and can have an irregular shape. Therefore, the observation volumes are first calculated separately for leader and follower. To calculate the intersection of the two individual observation volumes, the eight vertices of the follower observation volume are rotated to the leader coordinate system, and the OpenSCAD library is used to calculate the intersection of the two separate observation volumes in pixel units. To account for the removal of partially observed particles detected at the edge of the image, the effective observation volume is reduced by Dmax/2px on all sides. Consequently, each size bin of the PSD is calibrated independently with a different, Dmax-dependent effective observation volume. Finally, the volume is converted from pixel units to cubic meters using the calibration factor estimated above.\n\nThe Level-2 products are available based on the level1match and level1track products. For level2match, binned particle properties are available either from one of the cameras or using the minimum, average, or maximum from both cameras for each observed particle property. This means that the multiple observations of the same particle all contribute to the PSD. This does not bias the PSD because the number of observed particles is divided by the number of frames, and the PSD describes how many particles are on average in the observation volume. For level2track, the distributions are based on the observed tracks instead of individual particles and are calculated using the minimum, maximum, mean, or standard deviation along the observed track using both cameras. The use of the maximum (minimum) value along a track is motivated by the assumption that the estimated properties of a particle such as Dmax (AR) of a particle will be closer to the true value than when ignoring the different perspectives of a particle along the track obtained by the two cameras.\n\nFor both level2 variants, the binned PSD and A, perimeter p, and particle complexity c are available binned with Dmax and Deq to allow comparison with instruments using either size definition. In addition to the distributions, PSD-weighted mean values with 1âmin resolution are available for A, AR, and c in addition to the first to fourth and sixth moments of the PSD that can be used to describe normalized size distributions (DelanoÃ« etÂ al.,Â 2005; Maahn etÂ al.,Â 2015).\n\nFor VISSS observations where only a single camera is available, it would also be possible to develop a product based on particles detected by a single camera, using a threshold based on particle blur to define the observation volume, which is similar to the PIP (Newman etÂ al.,Â 2009).\n\nHere, we analyze first-generation VISSS (VISSS1) data collected in winter 2021/22 at the HyytiÃ¤lÃ¤ Forestry Field Station (61.845ââN, 24.287ââE; 150âma.m.s.l. ) operated by the University of Helsinki, Finland, to show the potential of the instrument. For comparison, we use a collocated PIP (von Lerber etÂ al.,Â 2017; Pettersen etÂ al.,Â 2020) and OTT Parsivel2 laser disdrometer (LÃ¶ffler-Mang and Joss,Â 2000; Tokay etÂ al.,Â 2014). The distance between the VISSS and PIP was 20âm. The Parsivel was located inside of the double fence intercomparison reference, which was located 35âm from the VISSS.\n\n4.1âCase study comparing the VISSS, PIP, and Parsivel\n\nVISSS level2match data are compared with PIP and Parsivel observations for a snowfall case on 26Â January 2022. For a fair comparison with the PIP and Parsivel, which observe particles from a single perspective, only data of a single VISSS camera are used in this section. Because the Parsivel uses something similar to Deq (see discussion inÂ Battaglia etÂ al.,Â 2010,Â for the predecessor instrument), Deq is also used as a PIP and VISSS size descriptor in the following. Also, Deq is not affected by the problems of the PIP particle sizing algorithm identified by Helms etÂ al. (2022). The PSD is characterized by the two variables, N0â and D32, used to describe the normalized size distributions N(D)=N0âF(D/D32) (Testud etÂ al.,Â 2001; DelanoÃ« etÂ al.,Â 2005) where N0â is a scaling parameter and D32 normalizes the size distribution by size. Assuming a typical value of 2 for the exponent b of the massâsize relation (e.g.,Â Mitchell,Â 1996), D32 is the proxy for the mean mass-weighted diameter defined as the ratio of the third to the second measured PSD moments M3/M2 . Assuming the same value for b, N0â can be calculated with\n\n(5) N 0 â = M 2 4 M 3 3 27 2\n\nas shown in Maahn etÂ al. (2015). The variability in N0â and D32 as well as the particle complexity c and the number of particles observed throughout the day is depicted in Fig.Â 6. The spectral variable c is available for each size bin. Because using a PSD-weighted average over all sizes for c would be heavily weighted towards smaller particles which are less complex due to the finite resolution, we use the 95th percentile for c in the following. The main precipitation event lasted from 10:00 to 17:30âUTC and shows an anticorrelation between N0â and D32: the former increases up to 105âm-3mm-1 until 13:00âUTC before decreasing to 103âm-3mm-1 at the end of the event. The particle complexity c divides the core period of the event into two parts with cââ2 before 13:00âUTC and cââ2.8 after 13:00âUTC. This transition can also be seen in the random selection of matched particles observed by the VISSS (Fig.Â 7) retrieved from the imagesL1detect product. For each particle, a pair of images is available from the two VISSS cameras. Before 13:00âUTC, a wide variety of different particle types were observed, including plates, small aggregates, and small rimed particles. Since particle shape and mean brightness are not used to match particles, the observed image pairs also confirm the ability of the VISSS to correctly match data from the two cameras. After 13:00âUTC, needles and needle aggregates dominate the observations, explaining the increase in observed complexity. Towards the end of the event, particles become smaller and more irregularly shaped. Around 18:30âUTC, even some ice-lolly-shaped particles (Keppas etÂ al.,Â 2017) are observed by the VISSS.\n\nN0â and D32 are also calculated from the PSDs observed by the PIP and Parsivel. For the core event, N0â measured by the PIP is about an order of magnitude smaller than that measured by the VISSS and Parsivel. The agreement of the VISSS and Parsivel is better, but some peaks in N0â are not resolved by the Parsivel when D32 is large. This discrepancy may be related to problems of the Parsivel with larger particles reported before (Battaglia etÂ al.,Â 2010). The reason for the observed differences between the PIP and the VISSS is likely more complex. Overall the measured D32 agrees better than N0â . Because D32 is a proxy for the mass-weighted mean diameter, larger, more massive snowflakes have a larger impact on D32 than more numerous smaller particles. This implies that the PIP is not capturing as many small ice particles as the VISSS, while measurements of larger particles seem to be less affected. Tiira etÂ al. (2016) have studied the effect of the left-side PSD truncation on PIP observations (see Fig.Â 6 inÂ Tiira etÂ al.,Â 2016), but the observed VISSSâPIP difference seems to be somewhat larger than expected; namely the difference extends to larger D32 values.\n\nThe number of particle observations ranges between 10â000 and 100â000âperâminute, showing that estimates of N0â , D32, and c are based on a sufficient number of observations to limit the impact of random errors. This is about 1.5Â orders of magnitude more particles than observed by the Parsivel and PIP (Fig.Â 6d), but this is not a fair comparison because the Parsivel and PIP report the number of unique particles, and the number of particle observations is used here for the VISSS. When applying the tracking algorithm to the VISSS andÂ â consistently with the other sensorsÂ â considering only unique particle observations, the advantage of the VISSS is reduced to 50â% more particles than observed by the Parsivel and PIP. The average track length of the VISSS varies throughout the day between 5Â and 20Â frames with an overall average of 8.5Â frames.\n\nTo further investigate the differences between the instruments, we compare VISSS, PIP, and Parsivel PSDs (Fig.Â 8) for the three discussed times during the snowfall case. While the Parsivel and VISSS mostly agree for Dâ>â1âmm for all three cases, the Parsivel observes more particles for 0.6âmmâ<âDâ<â1âmm (as previously reported byÂ Battaglia etÂ al.,Â 2010) before dropping for Dâ<â0.6âmm, which is likely related to limitations associated with the Parsivel pixel resolution of 125âÂµm. The comparison of the VISSS and PIP shows larger discrepancies as explained above. The PSDs tend to agree for Deqâ>â1âmm for cases where larger ice particles are more spherical (11:24âUTC). For the needle case (13:00âUTC), the PIP reports lower number concentrations than the VISSS and Parsivel for almost all sizes. At 10:10âUTC, the VISSS and PIP approximately agree for sizes between 0.4 and 0.8âmm, but the PIP reports lower values for other sizes. Although no needles are observed at 10:10âUTC, Fig.Â 7 shows that there were also small columns that could be affected by the dilation of structures less than 0.4âmm wide by the PIP software, or some parts of radiating assemblage of plates were removed by the image processing.\n\nAll three instruments have different sensitivities to small particles. This can be seen for the drop in D32 around 17:45âUTC (Fig.Â 6) where the Parsivel does not report any values, and the PIP N0â estimates differ strongly from the VISSS when D32â<â1âmm. The VISSS reports D32 values as low as 0.16âmm around 19:00âUTC. Although the sample sizes are sufficient (>â10â000 particles per minute), the errors are likely large due to the VISSS pixel resolution of â¼â0.06âmm. In the absence of an instrument designed to observe small particles, it is not possible to determine how reliably the VISSS detects and sizes small particles.\n\nAdditional insight is provided by comparing the drop size distributions (DSDs) observed by the three instruments during a drizzle event on 16Â October 2021 (Fig.Â 8d). The use of drizzle allows the Parsivel to be used as a reference instrument as it has been shown to provide accurate DSDs for sizes between 0.5 and 5âmm (Tokay etÂ al.,Â 2014). In fact, Parsivel and VISSS DSDs differ no more than 10â% for 0.55âmmâ>âDâ>â0.9âmm, with both showing a dip in the distribution around 0.55âmm. For larger droplets, differences are likely related to their low frequency of occurrence increasing statistical errors. For smaller droplets, the VISSS (as well as the PIP) reports concentrations about an order of magnitude higher than the Parsivel. Similarly, Thurai etÂ al. (2019) found that a 50âÂµm optical array probe observed more small drizzle droplets than a Parsivel. For these small particle sizes close to the VISSS camera pixel resolution, discretization errors likely play a role, which we investigate by comparing Dmax and Deq for the VISSS. As drizzle droplets can be considered sufficiently spherical (i.e.,Â ARâ>â0.9) for Dâ<â1âmm (Beard etÂ al.,Â 2010), we can evaluate whether Dmax=Deq holds as expected (Fig.Â 8d). As expected, VISSS Dmax and Deq are in almost perfect agreement for Dâ>â0.5âmm, but larger differences occur for Dâ<â0.3âmm, indicating that discretization errors can become substantial for Dâ<â0.3âmm.\n\nIn the absence of a reference instrument for smaller particles in HyytiÃ¤lÃ¤ or reference spheres with diameters smaller than 0.5âmm, the performance of the VISSS for observing small particles with Dâ<â0.5âmm is difficult to assess. Particles close to the thresholds for size, area, and blur might be rejected for parts of the observed trajectory, which could explain the decrease in VISSS number concentration for small particle sizes.\n\n4.2âStatistical comparison of the VISSS, PIP, and Parsivel\n\nThe results of the case study comparison of the VISSS, PIP, and Parsivel also hold when comparing 6661âmin of joint snowfall observations during the winter of 2021/22 (Fig.Â 9). The ratio of N0â observed by the VISSS and PIP (Parsivel) is compared to D32, N0â , and complexity c. For D32â<â1âmm, the VISSS-to-PIP (VISSS-to-Parsivel) N0â ratio increases strongly and can reach a value of 10â000 (10). Therefore, the comparison of the N0â ratio with N0â itself and c is limited to data with D32â>â1âmm. For the PIP, the difference in N0â does not depend on N0â butÂ â as suggested by the needle case aboveÂ â on complexity c, with higher c values indicating larger N0â differences, probably as a result of limitations in the PIP image processing implementation. For the VISSS-to-Parsivel comparison, the N0â difference depends on N0â instead of c. Because D32 and N0â are often anticorrelated, this could be related to size-dependent errors of the Parsivel as identified by Battaglia etÂ al. (2010).\n\n4.3âAdvantage of the second VISSS camera\n\nHere, we quantify the advantage of observing multiple orientations of a particle with the VISSS. For this, we compare 1âmin values of mean Dmax, Deq, and p obtained from a single camera, using the maximum value obtained from both cameras and the maximum value obtained during the observed particle track (Fig.Â 10aâc). For AR, the minimum of the two cameras and along the track is used instead of the maximum (Fig.Â 10d). To evaluate the effect of particle type, three cases with mostly dendritic aggregates (6Â December 2021, 07:19â12:30âUTC), needles (5Â January 2022, 00:00â14:30âUTC), and graupel (6Â December 2021, 00:00â04:50, 13:30â14:20, and 21:15â24:00, and 5Â January 2022, 15:00â16:40 and 19:40â20:50âUTC) are used. The change in observed values is strongest for needles, which are the most complex particles, where when using two cameras Dmax, Deq, p, and AR change by 16â%, 10â%, 14â%, and â12â%, respectively, and when additionally considering tracking the values change by 24â%, 19â%, 24â%, and â27â%, respectively. Changes for dendritic aggregates and graupel are smaller and surprisingly similar: Dmax increases by 8â% and 7â% (13â% and 16â%), Deq increases by 6â% and 6â% (14â% and 14â%), and p increases by 7â% and 7â% (19â% and 16â%), respectively, when using two cameras (two cameras with tracking). The dependency of particle properties on orientation can also be seen from the fact that mean AR decreases from 0.62 to 0.54 and 0.42 for aggregates and from 0.73 to 0.67 and 0.54 for graupel, highlighting that orientating matters even for graupel.\n\nUnderestimating Dmax can lead to biases when using commonly used Dmax-based power laws for particle mass (Mitchell,Â 1996) or when using in situ observations to forward-model radar observations. This is because scattering properties of non-spherical particles are typically parameterized as a function of Dmax (Mishchenko etÂ al.,Â 1996; Hogan etÂ al.,Â 2012). Further, particle scattering properties are also impacted by the distribution of particle mass along the path of propagation (Hogan and Westbrook,Â 2014), which is impacted by AR. To analyze how the different Dmax and AR estimates affect the simulated radar reflectivity for vertically pointing cloud radar observations at 94âGHz, we use the PAMTRA radar simulator (Passive and Active Microwave radiative TRAnsfer tool;Â Mech etÂ al.,Â 2020) with the riming-dependent parameterization of the particle scattering properties (Maherndl etÂ al.,Â 2023a) assuming horizontal particle orientation (Sassen,Â 1977; Hogan etÂ al.,Â 2002). Using two cameras (i.e., max(Dmax,min(AR)) increases mean Ze values by 2.1, 2.5, and 1.8âdB for aggregates, needles, and graupel, respectively. When the varying orientations are taken into account during tracking, the offsets increase to 4.5, 4.6, and 3.7âdB, respectively, which are considerably larger than the commonly used measurement uncertainty of 1âdB for cloud radars. The change in Ze is similar to the 3.2âdB found by Wood etÂ al. (2013) using idealized particles.\n\nThe hardware and data processing of the open-source Video In Situ Snowfall Sensor (VISSS) have been introduced. The VISSS consists of two cameras with telecentric lenses oriented at a 90â angle to each other and that observe a common observation volume. Both cameras are illuminated by LED backlights (see TableÂ 1 for specifications). The goal of the VISSS design was to combine a large, well-defined observation volume and relatively high pixel resolution with a design that limits wind disturbance and allows accurate sizing. The VISSS was initially developed for MOSAiC, but additional deployments at HyytiÃ¤lÃ¤, Finland; Gothic, Colorado, USA; and Eriswil, Switzerland, followed. Advanced versions of the instrument have been installed at Ny-Ã lesund, Svalbard, and again at HyytiÃ¤lÃ¤, Finland. The VISSS Level-1 processing steps for obtaining per-particle properties include particle detection and sizing, particle matching between the two cameras considering the exact alignment of the cameras to each other, and tracking of individual particles to estimate sedimentation velocity and improve particle property estimates. For Level-2 products, the temporally averaged particle properties and size distributions are available in calibrated metric units.\n\nThe initial analysis shows the potential of the instrument. The relatively large observation volume of the VISSS leads to robust statistics based on up to 10â000 individual particle observations per minute. The data set from HyytiÃ¤lÃ¤ obtained in the winter of 2021/22 is used to compare the VISSS with collocated PIP and Parsivel instruments. While the comparison with the Parsivel showsÂ â given the known limitations of the instrument for snowfall (Battaglia etÂ al.,Â 2010)Â â excellent agreement, the comparison with the PIP is more complicated. The differences in the observed PSDs increase with increasing particle complexity c (e.g., needles), but differences remain even for non-needle cases, and for a case with a relatively high concentration of large, relatively spherical particles, agreement was only found for sizes larger than 1âmm. Because the Parsivel is well characterized for liquid precipitation (Tokay etÂ al.,Â 2014), a drizzle case is also used for comparison. The case shows an excellent agreement between the Parsivel and VISSS for droplets larger than 0.5âmm, confirming the general accuracy of the VISSS. Compared to both the PIP and the Parsivel, the VISSS observes a larger number of small particles that can drastically change the retrieved PSD coefficients in some cases. However, the first-generation VISSS pixel resolution of 0.06âmm is likely to introduce discretization errors for particles smaller than 0.3âmm (i.e.,Â 5âpx), potentially leading to errors in the sizing of very small particles. Furthermore, we analyzed the advantage of the VISSS due to the availability of a second camera. Depending on the particle type, mean Dmax increases up to 16â% and mean aspect ratio AR decreases by 12â%. For the analyzed case, the VISSS observes each particle on average 8.5Â times, which can further improve estimates of particle properties due to the natural rotation of the particle during sedimentation. In comparison to using only a single camera, this can increase the mean Dmax by up to 24â% and reduce AR by up to 31â%.\n\nVISSS product development will continue, e.g., by implementing machine-learning-based particle classifications (Praz etÂ al.,Â 2017; Leinonen and Berne,Â 2020; Leinonen etÂ al.,Â 2021). Also, we will work on making VISSS data acquisition and processing more efficient by handling some processing steps in the data acquisition system in real time. We also invite the community to contribute to the development of the open-source instrument. This not only applies to the software products, but also allows for other groups to build and improve the instrument. It could even mean advancing the VISSS hardware concept further, by, e.g.,Â adding a third camera to observe snow particles from below orÂ â given the extended 1300âmm working distance of VISSS3Â â from above. The VISSS hardware plans (second-generation VISSS;Â Maahn etÂ al.,Â 2023b; third-generation VISSS; Maahn and Wolter,Â 2024), data acquisition software (Maahn,Â 2023a), and data processing libraries (Maahn,Â 2023b) have been released under an open-source license so that reverse engineering as done by Helms etÂ al. (2022) is not required to analyze the VISSS data processing. The only limitation of the licenses used is that modification of the VISSS needs to be made publicly available under the same license.\n\nThere are many potential applications for VISSS observations. They can be used for model evaluation with advanced microphysics (e.g.,Â Hashino and Tripoli,Â 2011; Milbrandt and Morrison,Â 2015), characterization of PSDs as a function of snowfall formation processes, or retrievals combining in situ and remote sensing observations. Tracking of a particle in three dimensions can be used to understand the impact of turbulence on particle trajectories. Beyond atmospheric science, the VISSS shows potential for quantifying the occurrence of flying insects, as standard insect counting techniques such as suction traps are typically destructive and labor-intensive.\n\nBattaglia, A., Rustemeier, E., Tokay, A., Blahak, U., and Simmer, C.: PARSIVEL Snow Observations: A Critical Assessment, J.Â Atmos. Ocean. Tech., 27, 333â344, https://doi.org/10.1175/2009JTECHA1332.1, 2010.âa, b, c, d, e, f\n\nBeard, K.Â V., Bringi, V.Â N., and Thurai, M.: A New Understanding of Raindrop Shape, Atmos. Res., 97, 396â415, https://doi.org/10.1016/j.atmosres.2010.02.001, 2010.âa\n\nCooper, S. J., Wood, N. B., and L'Ecuyer, T. S.: A variational technique to estimate snowfall rate from coincident radar, snowflake, and fall-speed observations, Atmos. Meas. Tech., 10, 2557â2571, https://doi.org/10.5194/amt-10-2557-2017, 2017.âa\n\nCooper, S.Â J., L'Ecuyer, T.Â S., Wolff, M.Â A., Kuhn, T., Pettersen, C., Wood, N.Â B., Eliasson, S., Schirle, C.Â E., Shates, J., Hellmuth, F., Engdahl, B. J.Â K., VÃ¡squez-MartÃ­n, S., Ilmo, T., and NygÃ¥rd, K.: Exploring Snowfall Variability through the High-Latitude Measurement of Snowfall (HiLaMS) Field Campaign, B.Â Am. Meteorol. Soc., 103, E1762âE1780, https://doi.org/10.1175/BAMS-D-21-0007.1, 2022.âa\n\nDel Guasta, M.: ICE-CAMERA: a flatbed scanner to study inland Antarctic polar precipitation, Atmos. Meas. Tech., 15, 6521â6544, https://doi.org/10.5194/amt-15-6521-2022, 2022.âa, b\n\nDelanoÃ«, J., Protat, A., Testud, J., Bouniol, D., Heymsfield, A.Â J., Bansemer, A., Brown, P. R.Â A., and Forbes, R.Â M.: Statistical Properties of the Normalized Ice Particle Size Distribution, J.Â Geophys. Res., 110, D10201, https://doi.org/10.1029/2004JD005405, 2005.âa, b\n\nDunnavan, E.Â L., Jiang, Z., Harrington, J.Â Y., Verlinde, J., Fitch, K., and Garrett, T.Â J.: The Shape and Density Evolution of Snow Aggregates, J.Â Atmos. Sci., 76, 3919â3940, https://doi.org/10.1175/JAS-D-19-0066.1, 2019.âa\n\nFeldman, D.Â R., Aiken, A.Â C., Boos, W.Â R., Carroll, R. W.Â H., Chandrasekar, V., Collis, S., Creamean, J.Â M., deÂ Boer, G., Deems, J., DeMott, P.Â J., Fan, J., Flores, A.Â N., Gochis, D., Grover, M., Hill, T. C.Â J., Hodshire, A., Hulm, E., Hume, C.Â C., Jackson, R., Junyent, F., Kennedy, A., Kumjian, M., Levin, E. J.Â T., Lundquist, J.Â D., O'Brien, J., Raleigh, M.Â S., Reithel, J., Rhoades, A., Rittger, K., Rudisill, W., Sherman, Z., Siirila-Woodburn, E., Skiles, S.Â M., Smith, J.Â N., Sullivan, R.Â C., Theisen, A., Tuftedal, M., Varble, A.Â C., Wiedlea, A., Wielandt, S., Williams, K., and Xu, Z.: The Surface Atmosphere Integrated Field Laboratory (SAIL) Campaign, B.Â Am. Meteorol. Soc., 104, 2192â2222, https://doi.org/10.1175/BAMS-D-22-0049.1, 2023.âa\n\nField, P.Â R. and Heymsfield, A.Â J.: Importance of Snow to Global Precipitation, Geophys. Res. Lett., 42, 2015GL065497, https://doi.org/10.1002/2015GL065497, 2015.âa\n\nFitch, K.Â E. and Garrett, T.Â J.: Graupel Precipitating From Thin Arctic Clouds With Liquid Water Paths Less Than 50âg M-2, Geophys. Res. Lett., 49, e2021GL094075, https://doi.org/10.1029/2021GL094075, 2022.âa\n\nGarrett, T.Â J. and Yuter, S.Â E.: Observed Influence of Riming, Temperature, and Turbulence on the Fallspeed of Solid Precipitation, Geophys. Res. Lett., 41, 6515â6522, https://doi.org/10.1002/2014GL061016, 2014.âa\n\nGarrett, T. J., Fallgatter, C., Shkurko, K., and Howlett, D.: Fall speed measurement and high-resolution multi-angle photography of hydrometeors in free fall, Atmos. Meas. Tech., 5, 2625â2633, https://doi.org/10.5194/amt-5-2625-2012, 2012.âa, b, c, d\n\nGergely, M. and Garrett, T.Â J.: Impact of the Natural Variability in Snowflake Diameter, Aspect Ratio, and Orientation on Modeled Snowfall Radar Reflectivity, J.Â Geophys. Res.-Atmos., 121, 2016JD025192, https://doi.org/10.1002/2016JD025192, 2016.âa, b\n\nGergely, M., Cooper, S. J., and Garrett, T. J.: Using snowflake surface-area-to-volume ratio to model and interpret snowfall triple-frequency radar signatures, Atmos. Chem. Phys., 17, 12011â12030, https://doi.org/10.5194/acp-17-12011-2017, 2017.âa\n\nGrazioli, J., Tuia, D., Monhart, S., Schneebeli, M., Raupach, T., and Berne, A.: Hydrometeor classification from two-dimensional video disdrometer data, Atmos. Meas. Tech., 7, 2869â2882, https://doi.org/10.5194/amt-7-2869-2014, 2014.âa\n\nGrazioli, J., Genthon, C., Boudevillain, B., Duran-Alarcon, C., Del Guasta, M., Madeleine, J.-B., and Berne, A.: Measurements of precipitation in Dumont d'Urville, AdÃ©lie Land,Â EastÂ Antarctica, The Cryosphere, 11, 1797â1811, https://doi.org/10.5194/tc-11-1797-2017, 2017.âa\n\nHashino, T. and Tripoli, G.Â J.: The Spectral Ice Habit Prediction System (SHIPS). PartÂ III: Description of the Ice Particle Model and the Habit-Dependent Aggregation Model, J.Â Atmos. Sci., 68, 1125â1141, https://doi.org/10.1175/2011JAS3666.1, 2011.âa\n\nHelms, C. N., Munchak, S. J., Tokay, A., and Pettersen, C.: A comparative evaluation of snowflake particle shape estimation techniques used by the Precipitation Imaging Package (PIP), Multi-Angle Snowflake Camera (MASC), and Two-Dimensional Video Disdrometer (2DVD), Atmos. Meas. Tech., 15, 6545â6561, https://doi.org/10.5194/amt-15-6545-2022, 2022.âa, b, c, d\n\nHicks, A. and NotaroÅ¡, B.Â M.: Method for Classification of Snowflakes Based on Images by a Multi-Angle Snowflake Camera Using Convolutional Neural Networks, J.Â Atmos. Ocean. Tech., 36, 2267â2282, https://doi.org/10.1175/JTECH-D-19-0055.1, 2019.âa\n\nHogan, R.Â J. and Westbrook, C.Â D.: Equation for the Microwave Backscatter Cross Section of Aggregate Snowflakes Using the Self-Similar Rayleigh-Gans Approximation, J.Â Atmos. Sci., 71, 3292â3301, https://doi.org/10.1175/JAS-D-13-0347.1, 2014.âa\n\nHogan, R.Â J., Field, P.Â R., Illingworth, A.Â J., Cotton, R.Â J., and Choularton, T.Â W.: Properties of Embedded Convection in Warm-Frontal Mixed-Phase Cloud from Aircraft and Polarimetric Radar, Q.Â J. Roy. Meteor. Soc., 128, 451â476, https://doi.org/10.1256/003590002321042054, 2002.âa\n\nHogan, R.Â J., Tian, L., Brown, P. R.Â A., Westbrook, C.Â D., Heymsfield, A.Â J., and Eastment, J.Â D.: Radar Scattering from Ice Aggregates Using the Horizontally Aligned Oblate Spheroid Approximation, J.Â Appl. Meteorol. Clim., 51, 655â671, https://doi.org/10.1175/JAMC-D-11-074.1, 2012.âa\n\nHuang, G.-J., Bringi, V.Â N., Moisseev, D., Petersen, W.Â A., Bliven, L., and Hudak, D.: Use of 2D-video Disdrometer to Derive Mean DensityâSize and ZeâR Relations: Four Snow Cases from the Light Precipitation Validation Experiment, Atmos. Res., 153, 34â48, https://doi.org/10.1016/j.atmosres.2014.07.013, 2015.âa, b\n\nKalman, R.Â E.: A New Approach to Linear Filtering and Prediction Problems, J.Â Basic Eng., 82, 35â45, https://doi.org/10.1115/1.3662552, 1960.âa\n\nKennedy, A., Scott, A., Loeb, N., Sczepanski, A., Lucke, K., Marquis, J., and Waugh, S.: Bringing Microphysics to the Masses: The Blowing Snow Observations at the University of North Dakota: Education through Research (BLOWN-UNDER) Campaign, B.Â Am. Meteorol. Soc., 103, E83âE100, https://doi.org/10.1175/BAMS-D-20-0199.1, 2022.âa\n\nKeppas, S.Â Ch., Crosier, J., Choularton, T.Â W., and Bower, K.Â N.: Ice Lollies: An Ice Particle Generated in Supercooled Conveyor Belts, Geophys. Res. Lett., 44, 5222â5230, https://doi.org/10.1002/2017GL073441, 2017.âa\n\nKuhn, H.Â W.: The Hungarian Method for the Assignment Problem, Nav. Res. Logist.Â Q., 2, 83â97, https://doi.org/10.1002/nav.3800020109, 1955.âa\n\nKuhn, T. and VÃ¡zquez-MartÃ­n, S.: Microphysical properties and fall speed measurements of snow ice crystals using the Dual Ice Crystal Imager (D-ICI), Atmos. Meas. Tech., 13, 1273â1285, https://doi.org/10.5194/amt-13-1273-2020, 2020.âa\n\nKulie, M.Â S., Pettersen, C., Merrelli, A.Â J., Wagner, T.Â J., Wood, N.Â B., Dutter, M., Beachler, D., Kluber, T., Turner, R., Mateling, M., Lenters, J., Blanken, P., Maahn, M., Spence, C., Kneifel, S., Kucera, P.Â A., Tokay, A., Bliven, L.Â F., Wolff, D.Â B., and Petersen, W.Â A.: Snowfall in the Northern Great Lakes: Lessons Learned from a Multi-Sensor Observatory, B.Â Am. Meteorol. Soc., 102, 1â61, https://doi.org/10.1175/BAMS-D-19-0128.1, 2021.âa\n\nLeinonen, J. and Berne, A.: Unsupervised classification of snowflake images using a generative adversarial network and K-medoids classification, Atmos. Meas. Tech., 13, 2949â2964, https://doi.org/10.5194/amt-13-2949-2020, 2020.âa, b\n\nLeinonen, J., Grazioli, J., and Berne, A.: Reconstruction of the mass and geometry of snowfall particles from multi-angle snowflake cameraÂ (MASC) images, Atmos. Meas. Tech., 14, 6851â6866, https://doi.org/10.5194/amt-14-6851-2021, 2021.âa, b, c\n\nLi, H., Moisseev, D., and von Lerber, A.: How Does Riming Affect Dual-Polarization Radar Observations and Snowflake Shape?, J.Â Geophys. Res.-Atmos., 123, 6070â6081, https://doi.org/10.1029/2017JD028186, 2018.âa\n\nLi, J., Abraham, A., Guala, M., and Hong, J.: Evidence of preferential sweeping during snow settling in atmospheric turbulence, J. Fluid Mech., 928, A8, doi:10.1017/jfm.2021.816, 2021âa\n\nLÃ¶ffler-Mang, M. and Joss, J.: An Optical Disdrometer for Measuring Size and Velocity of Hydrometeors, J.Â Atmos. Ocean. Tech., 17, 130â139, https://doi.org/10.1175/1520-0426(2000)017<0130:AODFMS>2.0.CO;2, 2000.âa, b\n\nLopez-Cantu, T., Prein, A.Â F., and Samaras, C.: Uncertainties in Future U. S. Extreme Precipitation From Downscaled Climate Projections, Geophys. Res. Lett., 47, e2019GL086797, https://doi.org/10.1029/2019GL086797, 2020.âa\n\nLuke, E.Â P., Yang, F., Kollias, P., Vogelmann, A.Â M., and Maahn, M.: New Insights into Ice Multiplication Using Remote-Sensing Observations of Slightly Supercooled Mixed-Phase Clouds in the Arctic, P.Â Natl. Acad. Sci. USA, 118, e2021387118, https://doi.org/10.1073/pnas.2021387118, 2021.âa\n\nMaahn, M.: Video In Situ Snowfall Sensor (VISSS) Data Acquisition Software V0.3.1, Zenodo [code], https://doi.org/10.5281/zenodo.7640801, 2023a.âa, b, c\n\nMaahn, M.: Video In Situ Snowfall Sensor (VISSS) Data Processing Library V2023.1.6, Zenodo [code], https://doi.org/10.5281/zenodo.7650394, 2023b.âa, b, c\n\nMaahn, M. and Maherndl, N.: Video In Situ Snowfall Sensor (VISSS) Data for Ny-Ã lesund (2021â2022), Pangaea [data set], https://doi.org/10.1594/PANGAEA.958537, 2023.âa\n\nMaahn, M. and Moisseev, D.: Video In Situ Snowfall Sensor (VISSS) Data for HyytiÃ¤lÃ¤ (2021â2022), Pangaea [data set], https://doi.org/10.1594/PANGAEA.959046, 2023a.âa\n\nMaahn, M. and Moisseev, D.: VISSS, PIP, and Parsivel Snowfall Observations from Winter 2021/22 in HyytiÃ¤lÃ¤, Finland, Zenodo [data set], https://doi.org/10.5281/zenodo.8383794, 2023b.âa\n\nMaahn, M. and Wolter, S.: Hardware design of the Video In Situ Snowfall Sensor v3 (VISSS3), https://doi.org/10.5281/zenodo.10526898 (last access: 19Â FebruaryÂ 2024), 2024.âa, b, c\n\nMaahn, M., LÃ¶hnert, U., Kollias, P., Jackson, R.Â C., and McFarquhar, G.Â M.: Developing and Evaluating Ice Cloud Parameterizations for Forward Modeling of Radar Moments Using in Situ Aircraft Observations, J.Â Atmos. Ocean. Tech., 32, 880â903, https://doi.org/10.1175/JTECH-D-14-00112.1, 2015.âa, b\n\nMaahn, M., Turner, D.Â D., LÃ¶hnert, U., Posselt, D.Â J., Ebell, K., Mace, G.Â G., and Comstock, J.Â M.: Optimal Estimation Retrievals and Their Uncertainties: What Every Atmospheric Scientist Should Know, B.Â Am. Meteorol. Soc., 101, E1512âE1523, https://doi.org/10.1175/BAMS-D-19-0027.1, 2020.âa\n\nMaahn, M., Cox, C.Â J., Gallagher, M.Â R., Hutchings, J.Â K., Shupe, M.Â D., and Taneil, U.: Video In Situ Snowfall Sensor (VISSS) Data from MOSAiC Expedition with POLARSTERN (2019â2020), Pangaea [data set], https://doi.org/10.1594/PANGAEA.960391, 2023a.âa\n\nMaahn, M., Haseneder-Lind, R., and Krobot, P.: Hardware Design of the Video In Situ Snowfall Sensor v2 (VISSS2), Zenodo [data set], https://doi.org/10.5281/zenodo.7640821, 2023b.âa, b, c\n\nMaherndl, N., Maahn, M., Tridon, F., Leinonen, J., Ori, D., and Kneifel, S.: A Riming-Dependent Parameterization of Scattering by Snowflakes Using the Self-Similar RayleighâGans Approximation, Q.Â J. Roy. Meteor. Soc., 149, 3562â3581, https://doi.org/10.1002/qj.4573, 2023a.âa\n\nMaherndl, N., Moser, M., Lucke, J., Mech, M., Risse, N., Schirmacher, I., and Maahn, M.: Quantifying riming from airborne data during HALO-(AC)3, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2023-1118, 2023b.âa\n\nMandelbrot, B.: How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension, Science, 156, 636â638, https://doi.org/10.1126/science.156.3775.636, 1967.âa\n\nMatrosov, S.Â Y., Ryzhkov, A.Â V., Maahn, M., and de Boer, G.: Hydrometeor Shape Variability in Snowfall as Retrieved from Polarimetric Radar Measurements, J.Â Appl. Meteorol. Clim., 59, 1503â1517, https://doi.org/10.1175/JAMC-D-20-0052.1, 2020.âa\n\nMech, M., Maahn, M., Kneifel, S., Ori, D., Orlandi, E., Kollias, P., Schemann, V., and Crewell, S.: PAMTRA 1.0: the Passive and Active Microwave radiative TRAnsfer tool for simulating radiometer and radar measurements of the cloudy atmosphere, Geosci. Model Dev., 13, 4229â4251, https://doi.org/10.5194/gmd-13-4229-2020, 2020.âa\n\nMilbrandt, J.Â A. and Morrison, H.: Parameterization of Cloud Microphysics Based on the Prediction of Bulk Ice Particle Properties. PartÂ III: Introduction of Multiple Free Categories, J.Â Atmos. Sci., 73, 975â995, https://doi.org/10.1175/JAS-D-15-0204.1, 2015.âa\n\nMishchenko, M.Â I., Travis, L.Â D., and Mackowski, D.Â W.: T-Matrix Computations of Light Scattering by Nonspherical Particles: A Review, J.Â Quant. Spectrosc. Ra., 55, 535â575, https://doi.org/10.1016/0022-4073(96)00002-7, 1996.âa\n\nMitchell, D.Â L.: Use of Mass- and Area-Dimensional Power Laws for Determining Precipitation Particle Terminal Velocities, J.Â Atmos. Sci., 53, 1710â1723, https://doi.org/10.1175/1520-0469(1996)053<1710:UOMAAD>2.0.CO;2, 1996.âa, b\n\nMoisseev, D., von Lerber, A., and Tiira, J.: Quantifying the Effect of Riming on Snowfall Using Ground-Based Observations, J.Â Geophys. Res.-Atmos., 122, 2016JD026272, https://doi.org/10.1002/2016JD026272, 2017. âa\n\nMorrison, H., van Lier-Walqui, M., Fridlind, A.Â M., Grabowski, W.Â W., Harrington, J.Â Y., Hoose, C., Korolev, A., Kumjian, M.Â R., Milbrandt, J.Â A., Pawlowska, H., Posselt, D.Â J., Prat, O.Â P., Reimel, K.Â J., Shima, S.-I., van Diedenhoven, B., and Xue, L.: Confronting the Challenge of Modeling Cloud and Precipitation Microphysics, J.Â Adv. Model. Earth Sy., 12, e2019MS001689, https://doi.org/10.1029/2019MS001689, 2020.âa\n\nMÃ¼lmenstÃ¤dt, J., Sourdeval, O., DelanoÃ«, J., and Quaas, J.: Frequency of Occurrence of Rain from Liquid-, Mixed-, and Ice-Phase Clouds Derived from A-Train Satellite Retrievals, Geophys. Res. Lett., 42, 6502â6509, https://doi.org/10.1002/2015GL064604, 2015.âa\n\nNewman, A.Â J., Kucera, P.Â A., and Bliven, L.Â F.: Presenting the Snowflake Video Imager (SVI), J.Â Atmos. Ocean. Tech., 26, 167â179, https://doi.org/10.1175/2008JTECHA1148.1, 2009.âa, b, c\n\nNixdorf, U., Dethloff, K., Rex, M., Shupe, M., Sommerfeld, A., Perovich, D.Â K., Nicolaus, M., HeuzÃ©, C., Rabe, B., Loose, B., Damm, E., Gradinger, R., Fong, A., Maslowski, W., Rinke, A., Kwok, R., Spreen, G., Wendisch, M., Herber, A., Hirsekorn, M., Mohaupt, V., Frickenhaus, S., Immerz, A., Weiss-Tuider, K., KÃ¶nig, B., Mengedoht, D., Regnery, J., Gerchow, P., Ransby, D., Krumpen, T., Morgenstern, A., Haas, C., Kanzow, T., Rack, F.Â R., Saitzev, V., Sokolov, V., Makarov, A., Schwarze, S., Wunderlich, T., Wurr, K., and Boetius, A.: MOSAiC Extended Acknowledgement, Zenodo, https://doi.org/10.5281/zenodo.5541624, 2021.âa\n\nNomokonova, T., Ebell, K., LÃ¶hnert, U., Maturilli, M., Ritter, C., and O'Connor, E.: Statistics on clouds and their relation to thermodynamic conditions at Ny-Ã lesund using ground-based sensor synergy, Atmos. Chem. Phys., 19, 4105â4126, https://doi.org/10.5194/acp-19-4105-2019, 2019.âa\n\nNurzyÅska, K., Kubo, M., and Muramoto, K.-i.: Shape Parameters for Automatic Classification of Snow Particles into Snowflake and Graupel, Meteorol. Appl., 20, 257â265, https://doi.org/10.1002/met.299, 2013.âa\n\nPasquier, J.Â T., Henneberger, J., Korolev, A., Ramelli, F., Wieder, J., Lauber, A., Li, G., David, R.Â O., Carlsen, T., Gierens, R., Maturilli, M., and Lohmann, U.: Understanding the History of Two Complex Ice Crystal Habits Deduced From a Holographic Imager, Geophys. Res. Lett., 50, e2022GL100247, https://doi.org/10.1029/2022GL100247, 2023.âa\n\nPetÃ¤jÃ¤, T., O'Connor, E.Â J., Moisseev, D., Sinclair, V.Â A., Manninen, A.Â J., VÃ¤Ã¤nÃ¤nen, R., von Lerber, A., Thornton, J.Â A., Nicoll, K., Petersen, W., Chandrasekar, V., Smith, J.Â N., Winkler, P.Â M., KrÃ¼ger, O., Hakola, H., Timonen, H., Brus, D., Laurila, T., Asmi, E., Riekkola, M.-L., Mona, L., Massoli, P., Engelmann, R., Komppula, M., Wang, J., Kuang, C., BÃ¤ck, J., Virtanen, A., Levula, J., Ritsche, M., and Hickmon, N.: BAECC: A Field Campaign to Elucidate the Impact of Biogenic Aerosols on Clouds and Climate, B.Â Am. Meteorol. Soc., 97, 1909â1928, https://doi.org/10.1175/BAMS-D-14-00199.1, 2016.âa\n\nPettersen, C., Bliven, L.Â F., von Lerber, A., Wood, N.Â B., Kulie, M.Â S., Mateling, M.Â E., Moisseev, D.Â N., Munchak, S.Â J., Petersen, W.Â A., and Wolff, D.Â B.: The Precipitation Imaging Package: Assessment of Microphysical and Bulk Characteristics of Snow, Atmosphere, 11, 785, https://doi.org/10.3390/atmos11080785, 2020.âa, b, c\n\nPraz, C., Roulet, Y.-A., and Berne, A.: Solid hydrometeor classification and riming degree estimation from pictures collected with a Multi-Angle Snowflake Camera, Atmos. Meas. Tech., 10, 1335â1357, https://doi.org/10.5194/amt-10-1335-2017, 2017.âa, b\n\nQuante, L., Willner, S.Â N., Middelanis, R., and Levermann, A.: Regions of Intensification of Extreme Snowfall under Future Warming, Sci. Rep.-UK, 11, 16621, https://doi.org/10.1038/s41598-021-95979-4, 2021.âa\n\nRodgers, C.Â D.: Inverse Methods for Atmospheric Sounding:Theory and Practice, World Scientific Publishing Company, World Scientific Publishing Company, Singapore, 2000.âa\n\nSassen, K.: Ice Crystal Habit Discrimination with the Optical Backscatter Depolarization Technique, J.Â Appl. Meteorol. Clim., 16, 425â431, https://doi.org/10.1175/1520-0450(1977)016<0425:ICHDWT>2.0.CO;2, 1977.âa\n\nSchÃ¶nhuber, M., Lammer, G., and Randeu, W. L.: One decade of imaging precipitation measurement by 2D-video-distrometer, Adv. Geosci., 10, 85â90, https://doi.org/10.5194/adgeo-10-85-2007, 2007.âa\n\nShupe, M.Â D., Rex, M., Blomquist, B., Persson, P. O.Â G., Schmale, J., Uttal, T., Althausen, D., Angot, H., Archer, S., Bariteau, L., Beck, I., Bilberry, J., Bucci, S., Buck, C., Boyer, M., Brasseur, Z., Brooks, I.Â M., Calmer, R., Cassano, J., Castro, V., Chu, D., Costa, D., Cox, C.Â J., Creamean, J., Crewell, S., Dahlke, S., Damm, E., de Boer, G., Deckelmann, H., Dethloff, K., DÃ¼tsch, M., Ebell, K., Ehrlich, A., Ellis, J., Engelmann, R., Fong, A.Â A., Frey, M.Â M., Gallagher, M.Â R., Ganzeveld, L., Gradinger, R., Graeser, J., Greenamyer, V., Griesche, H., Griffiths, S., Hamilton, J., Heinemann, G., Helmig, D., Herber, A., HeuzÃ©, C., Hofer, J., Houchens, T., Howard, D., Inoue, J., Jacobi, H.-W., Jaiser, R., Jokinen, T., Jourdan, O., Jozef, G., King, W., Kirchgaessner, A., Klingebiel, M., Krassovski, M., Krumpen, T., Lampert, A., Landing, W., Laurila, T., Lawrence, D., Lonardi, M., Loose, B., LÃ¼pkes, C., Maahn, M., Macke, A., Maslowski, W., Marsay, C., Maturilli, M., Mech, M., Morris, S., Moser, M., Nicolaus, M., Ortega, P., Osborn, J., PÃ¤tzold, F., Perovich, D.Â K., PetÃ¤jÃ¤, T., Pilz, C., Pirazzini, R., Posman, K., Powers, H., Pratt, K.Â A., PreuÃer, A., QuÃ©lÃ©ver, L., Radenz, M., Rabe, B., Rinke, A., Sachs, T., Schulz, A., Siebert, H., Silva, T., Solomon, A., Sommerfeld, A., Spreen, G., Stephens, M., Stohl, A., Svensson, G., Uin, J., Viegas, J., Voigt, C., von der Gathen, P., Wehner, B., Welker, J.Â M., Wendisch, M., Werner, M., Xie, Z., and Yue, F.: Overview of the MOSAiC ExpeditionâAtmosphere, Elementa Sci. Anth., 10, 00060, https://doi.org/10.1525/elementa.2021.00060, 2022.âa\n\nTakami, K., Kamamoto, R., Suzuki, K., Yamaguchi, K., and Nakakita, E.: Relationship between Newly Fallen Snow Density and Degree of Riming Estimated by Particles' Fall Speed in Niigata Prefecture, Japan, Hydrological Research Letters, 16, 87â92, https://doi.org/10.3178/hrl.16.87, 2022.âa\n\nTestik, F.Â Y. and Rahman, M.Â K.: High-Speed Optical Disdrometer for Rainfall Microphysical Observations, J.Â Atmos. Ocean. Tech., 33, 231â243, https://doi.org/10.1175/JTECH-D-15-0098.1, 2016. âa\n\nTestud, J., Oury, S., Black, R.Â A., Amayenc, P., and Dou, X.: The Concept of Normalized Distribution to Describe Raindrop Spectra: A Tool for Cloud Physics and Cloud Remote Sensing, J.Â Appl. Meteorol., 40, 1118â1140, https://doi.org/10.1175/1520-0450(2001)040<1118:TCONDT>2.0.CO;2, 2001.âa\n\nThurai, M., Bringi, V., Gatlin, P.Â N., Petersen, W.Â A., and Wingo, M.Â T.: Measurements and Modeling of the Full Rain Drop Size Distribution, Atmosphere, 10, 39, https://doi.org/10.3390/atmos10010039, 2019.âa\n\nTiira, J., Moisseev, D. N., von Lerber, A., Ori, D., Tokay, A., Bliven, L. F., and Petersen, W.: Ensemble mean density and its connection to other microphysical properties of falling snow as observed in Southern Finland, Atmos. Meas. Tech., 9, 4825â4841, https://doi.org/10.5194/amt-9-4825-2016, 2016.âa, b, c\n\nTokay, A., Wolff, D.Â B., and Petersen, W.Â A.: Evaluation of the New Version of the Laser-Optical Disdrometer, OTT Parsivel2, J.Â Atmos. Ocean. Tech., 31, 1276â1288, https://doi.org/10.1175/JTECH-D-13-00174.1, 2014.âa, b, c\n\nTokay, A., von Lerber, A., Pettersen, C., Kulie, M.Â S., Moisseev, D.Â N., and Wolff, D.Â B.: Retrieval of Snow Water Equivalent by the Precipitation Imaging Package (PIP) in the Northern Great Lakes, J.Â Atmos. Ocean. Tech., 39, 37â54, https://doi.org/10.1175/JTECH-D-20-0216.1, 2021.âa\n\nVÃ¡zquez-MartÃ­n, S., Kuhn, T., and Eliasson, S.: Mass of different snow crystal shapes derived from fall speed measurements, Atmos. Chem. Phys., 21, 18669â18688, https://doi.org/10.5194/acp-21-18669-2021, 2021a.âa\n\nVÃ¡zquez-MartÃ­n, S., Kuhn, T., and Eliasson, S.: Shape dependence of snow crystal fall speed, Atmos. Chem. Phys., 21, 7545â7565, https://doi.org/10.5194/acp-21-7545-2021, 2021b.âa\n\nVignon, E., Besic, N., Jullien, N., Gehring, J., and Berne, A.: Microphysics of Snowfall Over Coastal East Antarctica Simulated by Polar WRF and Observed by Radar, J.Â Geophys. Res.-Atmos., 124, 11452â11476, https://doi.org/10.1029/2019JD031028, 2019.âa\n\nVogl, T., Maahn, M., Kneifel, S., Schimmel, W., Moisseev, D., and Kalesse-Los, H.: Using artificial neural networks to predict riming from Doppler cloud radar observations, Atmos. Meas. Tech., 15, 365â381, https://doi.org/10.5194/amt-15-365-2022, 2022.âa, b\n\nvon Lerber, A., Moisseev, D., Bliven, L.Â F., Petersen, W., Harri, A.-M., and Chandrasekar, V.: Microphysical Properties of Snow and Their Link to ZeâS Relations during BAECC 2014, J.Â Appl. Meteorol. Clim., 56, 1561â1582, https://doi.org/10.1175/JAMC-D-16-0379.1, 2017.âa, b\n\nWood, N. B., L'Ecuyer, T. S., Bliven, F. L., and Stephens, G. L.: Characterization of video disdrometer uncertainties and impacts on estimates of snowfall rate and radar reflectivity, Atmos. Meas. Tech., 6, 3635â3648, https://doi.org/10.5194/amt-6-3635-2013, 2013.âa, b\n\nZivkovic, Z. and van der Heijden, F.: Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction, Pattern Recogn. Lett., 27, 773â780, https://doi.org/10.1016/j.patrec.2005.11.005, 2006.âa"
    }
}