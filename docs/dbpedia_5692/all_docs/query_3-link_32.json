{
    "id": "dbpedia_5692_3",
    "rank": 32,
    "data": {
        "url": "https://dl.acm.org/doi/fullHtml/10.1145/3623809.3623820",
        "read_more_link": "",
        "language": "en",
        "title": "Co-Designing with a Social Robot Facilitator: Effects of Robot Mood Expression on Human Group Dynamics",
        "top_image": "https://dl.acm.org/cms/attachment/html/10.1145/3623809.3623820/assets/html/images/image3.png",
        "meta_img": "",
        "images": [
            "https://dl.acm.org/cms/attachment/html/10.1145/3623809.3623820/assets/html/images/image1.jpeg",
            "https://dl.acm.org/cms/attachment/html/10.1145/3623809.3623820/assets/html/images/image2.png",
            "https://dl.acm.org/cms/attachment/html/10.1145/3623809.3623820/assets/html/images/image3.png",
            "https://www.acm.org/binaries/content/gallery/acm/publications/cc-by/cc-by-nc.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Alwin de Rooij",
            "Department of Communication",
            "Tilburg University",
            "alwinderooij@tilburguniversity.edu",
            "Simone van den Broek",
            "sjce.vandenbroek@avans.nl",
            "Michelle Bouw",
            "Jan de Wit",
            "KEYWORDS: Affective Computing",
            "Co-Design"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "1 INTRODUCTION\n\nCo-design, the active involvement of stakeholders in the design process [1], has become a critical part of the research and development cycle of many organizations [2, 3]. Involving stakeholders in the design process supports designers in developing products and services that balance the needs of clients, prospective users, and other invested parties [4]. Co-design is often organized in dedicated sessions where stakeholders collaborate to develop a problem statement, generate ideas, prototype, or test design solutions [5]. These sessions are led by a facilitator, who instructs, motivates, and regulates group dynamics to support effective collaboration, reduce conflict, and create a climate where all voices are heard. Emerging technologies enable the development of digital tools and materials that support co-design in unique ways [6]. Generative artificial intelligence, for example, can be useful for generating and exploring scenarios [7] and prototypes [8]. Less explored is how emerging technologies can facilitate desirable group dynamics during co-design [9, 10]. Social robotics might offer a particularly relevant platform for innovating how co-design is facilitated.\n\nSocial robots are embodied machines designed to interact with humans in a social manner [11]. This is typically achieved by programming social behaviors expressed through generated speech, facial expressions, and body language [12, 13]. Given that human facilitators inevitably rely on these same modalities to instruct, motivate, and regulate group dynamics in a co-design session, social robots could be programmed to do the same [14]. Robot mood expressions might offer a practical way in which robots can regulate desirable human group dynamics. Moods are long-lasting free-floating affective states that vary in valence and arousal [15] and are expressed through relatively distinct paralinguistic speech features [16], facial expressions [17], and body language [18]. A person might smile more when positive, display closed body language when negative, and speak faster when aroused. In human groups, negative mood expressions signal there is a problem, promoting conflict, whereas positive expressions signal safety, promoting cooperation [19, 20]. The latter might also promote a group dynamic that ensures all stakeholders’ voices are heard and represented in a co-design session's output, cf. [21, 22]. Co-design could therefore benefit from positive mood expressions by a robot facilitator.\n\nWhether similar effects on human group dynamics can be elicited by the mood expressions of a social robot facilitator, however, is an open scientific and practical question. Robot mood expressions, for example, are often perceived less accurately than human mood expressions, and the effects of mood expressions on group dynamics depend on a range of psychological factors, such as agency, which are likely limited in social robots. Such critical differences between human and robot facilitators might affect the efficacy of robot mood expressions for eliciting beneficial dynamics in human groups during co-design. Therefore, the following research question will be explored: Do mood expressions by a social robot facilitator influence human group dynamics during a co-design session? In what follows, related work is reviewed in more detail, after which the details of an experiment (N = 98) and its results are presented. The paper closes with a discussion of the results, study limitations, and new directions for future work intended to advance the development of robot facilitation of co-design.\n\n2 RELATED WORK\n\nEmerging evidence suggests that social robots can be designed to facilitate co-design sessions. Fucinato et al. [14] used the EZ-Robot to facilitate a product design activity with small groups of 3-4 adults, who generated associations with a picture of a beach and collaboratively developed a new chocolate product based on their previous associations. When the robot instructed groups with a charismatic voice, compared to a non-charismatic voice, participants generated more original and elaborate ideas, but at the cost of group resilience. Relatedly, [23] explored how groups perceived facilitation by the Nao robot during a range of collaborative interface design tasks. Participants perceived robot facilitation as advantageous in terms of time management, objectivity, and efficiency when compared to a human facilitator, but also mentioned a range of drawbacks such as limited communication. Similarly, facilitation by the Nao robot of a collaborative planning task resulted in generally favorable views of the robot facilitator and its utility [24].\n\nExperimental studies on robot facilitation of idea generation in 1-on-1 settings lend further credence to the utility of social robots for facilitating co-design. Facilitation of a Zen garden design task by the Wizard-of-Oz controlled robot Robovie helped users to generate more creative expressions than when the task was facilitated with a PowerPoint presentation [25]. Brainstorming facilitation by the Nao robot, teleoperated by a professional facilitator, led to similar productivity compared to when participants brainstormed with the human facilitator face-to-face [9]. Studies from the child-robot interaction domain suggest that children's productivity and creativity in play and games can benefit from social robots providing creative suggestions [26, 27], but see [28, 29], posing challenges and asking questions [27], uttering motivational and positive statements [27, 30], and facilitating creativity techniques [31].\n\nThe regulation of desirable group dynamics by social robots, however, appears to be less straightforward [32]. Jung et al. [33] showed how intervention by a ‘talking’ OWI robot into negative human behavior during a bomb-defusing task unexpectedly increased perceived conflict among the human collaborators. Counter to expectations based on the psychology literature, a furry gargoyle robot decreased, rather than increased, group cohesion when it made performance-equalizing statements during a training phase before a collaborative problem-solving game [34]. Whereas statements to foster collaboration by the MyKeepon robot did not affect children's interpersonal dynamics during a rocket-building task [35]. Suggestions by the Nao robot to engage in discussion, however, did increase dialogue and engagement during a learning task between human dyads, which can be indicative of cooperation [36]. Known effects of human social interactions on group dynamics and related factors are therefore often not replicated with social robots.\n\nMood expressions might provide an alternative and currently understudied way in which social robots can elicit human group dynamics. In a now classical study, Barsade [19] showed how positive expressions, compared to negative expressions, by a confederate group member increased group cooperation and decreased group conflict during a managerial exercise. Similar effects have been replicated with team members, leaders, and facilitators across a range of tasks [20, 22]. Positive expressions signal that the environment can be safely and freely explored and emphasize (other) positive aspects of one's surroundings, whereas negative expressions signal there is a problem and emphasize negative aspects of one's surroundings, and influence human behavior accordingly [37]. During group work, moods signal information about group functioning [38]. Positive expressions, compared to neutral or negative expressions, therefore tend to emphasize and subsequently promote cooperation, with an opposite effect on conflict [19, 20]. During co-design, positive expressions might also promote a climate where all stakeholders’ voices are heard and represented in a co-design session's outcome [21, 22].\n\nRegarding social robots, a large body of work confirms how mood expressions can be designed for social robots and are perceived with relative accuracy by human beings [39, 40]. Human recognition rates of robot expressions are approximately 58% [40], which is well below typical recognition rates of human expressions, e.g., 82% in [41]. Still, Stock-Homburg [40] argues these recognition rates are sufficient for most human-robot interaction applications. Crucially, human perception of robot mood expressions remains sufficiently accurate during a range of activities, such as when the Nao robot ‘gives’ a lecture [42] or ‘reads’ a story [43]. To replicate the latter findings within the context of co-design facilitation, the following hypothesis will be tested: Positive robot mood expressions, compared to neutral and negative mood expressions, increase the perceived valence of the robot's mood during a co-design session (H1).\n\nPreviously observed effects of human facilitator mood on human group dynamics might therefore also be elicited by the mood expressions of a social robot facilitator. Critically, perceived relevance determines how much attention people allocate to mood expressions [44], and attention determines whether the information signaled by mood expressions becomes available to inform a group's behavior. [45]. Furthermore, the effects of human mood expressions on group dynamics can also depend on, for example, psychological distance [46], power [47], and agency [48]. Social robots are likely limited in all those regards because these machines are perceived as something in between inanimate toys and animate social beings [49]. This raises questions about whether a social robot facilitator's mood expressions during a co-design session will influence human group dynamics. Therefore, the following working hypothesis will be tested: The effects of robot mood expressions on perceived robot mood mediate a decrease in conflict and an increase in cooperation and the degree to which participants’ ideas are represented in the final outcome (H2).\n\n3 METHOD\n\nTo explore the research question and test the hypotheses an experiment was conducted with a between-subjects design.\n\n3.1 Participants\n\nHundred-ten participants (29 groups) initially participated. Data from 12 participants (4 groups) were removed because of technical problems during the experiment. Data from the remaining 98 participants (25 groups) were included in the analyses. The average group size was 4.00 (SD = .83). Participants (Age = 16-28, Female = 67%, Male = 32%, Non-Binary = 1%, Other = 0%) were recruited using volunteer sampling from the human-subjects pool of the Tilburg School of Humanities and Digital Sciences (TSHD). The participants felt positive (M = 3.68, SD = .82) and neither calm nor excited (M = 2.86, SD = 1.00) at the start of the experiment. They had little experience facilitating (M = 1.68, SD = .92) and participating in (M = 1.96, SD = .97) co-design sessions. The study was approved by the TSHD Research Ethics and Data Management Committee. Participants received course credit for their participation.\n\n3.2 Co-design session\n\nParticipants engaged in small groups (3-5 people) in a co-design session facilitated by the social robot Nao. The students (stakeholders) collaboratively developed problem statements and possible solutions for student-health-related challenges. The session consisted of five tasks (Figure 1). Participants discussed and wrote down their associations with “health” on white A7 cards and placed these on a table (Task 1). They then collaboratively categorized the cards under six different dimensions of health (physical, emotional, intellectual, social, spiritual, environmental [50]) and added further associations (Task 2), categorized which associations were (not) important in their daily life (Task 3) [51], and discussed why certain aspects of health were important to them (Task 4). Finally, they collaboratively selected the five aspects of health they believed could and should be improved, and generated potential solutions for how these could be improved (Task 5). The tasks were developed by a co-design professional. See the supplementary materials for further details.\n\n3.3 Robot facilitator\n\nThe Nao V6 robot was used with the Choregraphe software to set up a Wizard-of-Oz paradigm [52, 53]. The researcher triggered various stages of the session based on a predefined facilitation protocol (see supplementary materials). Live video from the experiment room was streamed to the laptop of the researcher to time the robot's actions. The researcher could deviate from the protocol or repeat certain steps, but this was minimized to maintain consistency between sessions. The robot introduced tasks, managed time, and gave brief reminders of instructions. When switching to the next task, the robot turned to face the new task's materials. A timer automatically triggered the robot's next utterance for tasks with a time limit. If the robot had to wait for a task to be completed the Wizard controlled the timing. The content of the robot's utterances and its hand gestures were identical across conditions. Only its mood expressions differed. To enhance anthropomorphism the robot's breathing, eye-blinking, and eye-contact modes were enabled. The participants somewhat agreed that the robot was functioning autonomously (M = 4.76, SD = 1.75; 7-point scale), with no significant differences between the experimental conditions, F(2, 95) = 1.81, p = .170. Throughout the co-design session, the robot displayed positive, neutral, or negative expressions. Paralinguistic speech patterns, facial expressions, and body language of the robot were manipulated to create the different robot mood expressions (Table 1). The Nao robot has limited capabilities to show facial expressions. The color LEDs in the robot's eyes were used instead [54]. The gestures and posture were based on a robot expression validation study by [55]. Five different gestures were displayed by the robot throughout each session: wave (greeting/goodbye), head nod, single hand extended, both hands extended as an invitation, and a celebratory gesture as positive feedback. Figure 2 shows a selection of gestures and mood expressions.\n\nRobot behavior Negative robot expressions Neutral robot expressions Positive robot expressions Speech Speaking rate = 60%, pitch = 80%, style = ‘neutral’ Speaking rate = 85%, pitch = 100%, style = ‘neutral’ Speaking rate = 65%, pitch = 90%, style = ‘joyful’ Eye LEDs while gesturing Turned off Default eye color Alternating colors Gesture speed and size Slow (7 fps), small Medium (15 fps), medium Fast (25 fps), large Robot pose while gesturing Closed hand, head down Semi-open hand, head straight Open hand, head up\n\n3.4 Measuring robot mood expression perception, human group dynamics, and sample characteristics\n\nTo assess the perception of the robot's mood expressions participants rated its perceived valence (1 = very negative, 5 = very positive) and arousal (1 = very calm, 5 = very excited) using 5-point bipolar scales. The use of bipolar scales follows previous research suggesting that mood dimensions are bipolar rather than monopolar [56]. While valence is central to the hypotheses, arousal is also measured because it is a common confound of valence effects [57], which therefore needs to be accounted for in the statistical model. The mean valence and arousal measured after the five tasks were calculated. The means were used in further analysis.\n\nTo assess human group dynamics the participants rated after each task whether they “… experienced cooperation with other group members”, “experienced conflict with other group members”, cf. [19], and whether their “… contributions to the task were represented in the final outcome of the task” using 5-point Likert scales (1 = strongly disagree, 5 = strongly agree). Counter to research on mood, it is unlikely that group dynamics should be formalized as bipolar, rather than monopolar, constructs [19]. Therefore, a Likert scale was used for measuring group dynamics. The means were calculated for the five tasks for each of the three measurements and used in further analysis.\n\nParticipants self-reported their age and gender. They also reported the valence (1 = very negative, 5 = very positive) and arousal (1 = very calm, 5 = very excited) of their current mood using 5-point bipolar scales, and rated two 4-point scales about how often they facilitated and participated in a co-design session (1 = never, 4 = often). This provides insight into what population any results might generalize to. Several other measurements were administered after each task as part of a larger study. The rationale, data, and analyses in the present paper have not previously been published.\n\n3.5 Procedure\n\nThe study was advertised on the TSHD SONA page, where students volunteered to participate. If less than three participants signed up for a time slot, they were asked to find a new time slot. Groups of 3-5 participants were needed for a session to proceed. Upon arrival, information about the study was provided by the researcher and participants signed informed consent. Each group was randomly assigned to one of the experimental conditions. That is, working with a robot facilitator that expressed either negative, neutral, or positive moods while facilitating the co-design session. The group then entered a space set up for the co-design session. From there on, the co-design session was completely led by the social robot (sections 3.2 and 3.3). The robot also administered the questionnaires after each task (section 3.4). After completing all tasks the participants were debriefed by the researcher.\n\n3.6 Data analysis\n\nThe data were analyzed using R 4.2.0 [58]. Descriptive statistics were calculated to provide insight into the general characteristics of the dataset. Manipulation checks were conducted using ANOVA and Pearson correlations. To test the hypotheses a path analysis was conducted (maximum likelihood estimation) using Lavaan 0.6-12 [59]. The robot mood expressions were dummy coded into two independent variables. Neutral expressions and negative expressions were coded such that they were compared to the positive expressions condition. Perceived robot valence and arousal were included as mediators and the three measured group dynamics as dependent variables. Following [60], 240-480 cases are recommended. With 98 cases resulting from 5 aggregated measurements (490 cases), we assume this requirement is met. No problematic outliers were detected (Tukey's fences, k = 3.0). No signs of multicollinearity were detected, i.e. all r < .700 [61]. The distribution of the group dynamics data deviated from normality. Therefore, robust standard errors and a Satterthwaite correction were used [59]. Arousal and valence were not co-varied in the model, but the three group dynamics variables were. This produced a good model fit with the smallest number of model parameters (robust comparative fit index = .97) [62].\n\n4 RESULTS\n\nTo provide insight into the general characteristics of the data the descriptive statistics are presented in Table 2. The participants’ mood valence, F(2, 60.5) = .26, p = .772, and arousal, F(2, 61.9) = .03, p = .972, did not differ significantly between the experimental conditions. Similarly, there were no significant differences between the experimental conditions for the participants’ experience with participating in co-design, F(2, 63.0) = 2.44, p = .095. There was a significant difference in the participants’ experience with facilitating co-design, F(2, 63.2) = 3.77, p = .028. A post-hoc test showed that the participants exposed to neutral robot expressions were also slightly more experienced with facilitating co-design (M = 1.97, SD = 1.06) than participants exposed to positive robot expressions (M = 1.38, SD = .68), p = .022. We assume, however, that this finding does not confound the hypothesis tests because the participants’ experience with facilitating co-design sessions did not significantly correlate with any of the variables included in the path analysis, i.e. all p > .050. These findings provide further insight into the validity of the study.\n\nIndependent variable Perceived robot valence Perceived robot arousal Cooperation in group Conflict in group Representation in the final outcome Negative robot expressions 3.45 (.70) 2.51 (.85) 4.55 (.43) 1.21 (.36) 4.38 (.53) Neutral robot expressions 3.71 (.55) 2.43 (.98) 4.32 (.56) 1.23 (.40) 4.29 (.46) Positive robot expressions 4.14 (.58) 3.78 (.93) 4.41 (.44) 1.34 (.48) 4.37 (.45)\n\nThe results of the path analysis are presented in Figure 3. Relevant indirect effects are presented in-text. The results suggested that positive robot facilitator expressions, compared to negative, b = .690, p < .001, or neutral, b = .434, p = .002, expressions, significantly and positively influenced perceived robot valence. Positive robot facilitator expressions, compared to negative, b = 1.346, p < .001, or neutral, b = 1.270, p < .001, expressions, also significantly and positively influenced perceived robot arousal. This confirms hypothesis H1. The results showed furthermore that perceived robot valence significantly and positively influenced cooperation, b = .157, p = .028, and significantly and negatively influenced conflict in the group, b = -.127, p = .050. Perceived robot valence did not significantly influence the degree to which participants felt their ideas were represented in the final outcomes of the tasks, b = .114, p = .174. No significant effects were found of perceived robot arousal on cooperation, b = .072, p = .251, conflict, b = .031, p = .424, nor on the representation of ideas in the final outcomes of the task, b = -.021, p = .675. Tests of indirect effects suggested that positive robot facilitator expressions, compared to negative, b = .108, p = .085, and neural, b = .068, p = .094, robot expressions might positively influence cooperation, in a manner that depends on its effects on the perceived valence of the robot's behaviors. Polar opposite indirect effects were found for positive robot expressions, compared to negative, b = -.088, p = .103, and neutral, b = -.055, p = .134, expressions, on conflict. Note that these indirect effects were not significant. (Partially) Countering these indirect effects, is a significant negative direct effect of positive robot expressions, compared to negative robot expressions, on cooperation, b = -.331, p = .030. Other direct effects were not significant but suggested similar opposing effects. These findings partly confirm hypothesis H2.\n\n5 DISCUSSION AND CONCLUSION\n\nDo mood expressions by a social robot facilitator influence human group dynamics during a co-design session? The results of the present study suggested that positive robot mood expressions, compared to neutral and negative mood expressions, increased the valence of the robot's perceived mood (H1). These findings replicate previous work done with robot lecturing [42] and storytelling [43]. The present study adds that robot mood expressions are also perceived as such when a social robot facilitator leads a co-design session [9, 14, 23]. The results also showed a positive effect of perceived robot valence on cooperation and a negative effect on conflict experienced in the group (H2). While the mediation analyses alluded to an indirect effect of robot mood expression on cooperation via perceived robot valence, this was not significant (p < .100). No effects were found on the degree to which participants felt their ideas were represented in the final outcomes of the co-design session. The manipulations also influenced perceived robot arousal, but arousal did not influence human group dynamics and therefore did not confound the results. While known effects of human social interactions on group dynamics are often not replicated with social robots [32, 33, 34, 35], the results of the present study suggest that robot mood expressions can be used to regulate cooperation and conflict in a way that is consistent with the psychology literature [19, 20, 22]. Mood expressions by a social robot facilitator can be designed to predictably influence desirable human group dynamics during a co-design session.\n\nThe study also has limitations. The opposite mediating and direct effects meant that no net effects were observed. Something we did not measure negatively influenced human group dynamics. The higher speech rate in the positive expression condition might have reduced the clarity of the robot's instructions (Table 1). Moreover, the negative robot expressions were perceived as less positive than the positive expressions but were not clearly perceived as negative. The found effects on group dynamics are therefore best explained by reduced positive mood expression perception, rather than by negative robot mood perception. Also, the single-item measurements, while convenient, do not provide a rich or objective account of the measured constructs, which threatens the construct validity of these measures [63]. Finally, the use of the Wizard-of-Oz paradigm comes with a range of well-documented limitations [64].\n\nWe propose two directions for future work. Firstly, the effectiveness of mood expressions for regulating group dynamics depends on timing and context [65, 66]. Appropriate expressions displayed contingent upon changes during co-design, rather than displayed continuously, might therefore improve the effectiveness of social robot facilitators. This can require, for example, the development of a closed-loop system that monitors performance within a group, to time, select, and evaluate what robot responses are most effective at a given moment [67, 68]. Secondly, and in parallel, we propose to develop situated design methods to better align the functionality and embodiment of social robot facilitators with the needs of designers [69, 70]. This requires co-design in itself, with designers as the stakeholders, to support the ethical development of social robots that effectively and desirably support co-design in professional practice [70, 71].\n\nIn conclusion, the present study contributes new evidence suggesting that the mood expressions of a social robot facilitator can influence the perceived valence of the robot. Perceived robot valence, in turn, influences human group dynamics during co-creation sessions. These findings contribute novel insight into how social robots can be used to innovate how co-design is facilitated."
    }
}