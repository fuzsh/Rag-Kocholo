{
    "id": "dbpedia_5692_3",
    "rank": 25,
    "data": {
        "url": "https://arxiv.org/html/2310.07127v2",
        "read_more_link": "",
        "language": "en",
        "title": "An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/extracted/5343096/figures/example.png",
            "https://arxiv.org/html/extracted/5343096/figures/flowchart.png",
            "https://arxiv.org/html/x2.png",
            "https://arxiv.org/html/x3.png",
            "https://arxiv.org/html/x4.png",
            "https://arxiv.org/html/x5.png",
            "https://arxiv.org/html/x6.png",
            "https://arxiv.org/html/x7.png",
            "https://arxiv.org/html/x8.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "generative AI",
            "human-AI interaction",
            "interactive machine learning"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "License: CC BY-NC-ND 4.0\n\narXiv:2310.07127v2 [cs.HC] 12 Jan 2024\n\nAn HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions\n\nJingyu Shi , Rahul Jain , Hyungjun Doh , Ryo Suzuki and Karthik Ramani\n\nAbstract.\n\nGenerative AI (GenAI) has shown remarkable capabilities in generating diverse and realistic content across different formats. HCI literature has investigated how to effectively create collaborations between humans and GenAI systems. However, the current literature lacks a comprehensive framework to better understand human-GenAI interactions, as the holistic aspects of human-centered GenAI systems are rarely analyzed systematically. We present a survey of 291 papers, providing a novel taxonomy and analysis of Human-GenAI Interactions from both human and GenAI perspectives. We highlight challenges and opportunities to guide the design of GenAI systems and interactions toward the future design of human-centered GenAI applications.\n\ngenerative AI, human-AI interaction, interactive machine learning\n\nThis work is partially supported by the NSF under the Future of Work at the Human-Technology Frontier (FW-HTF) 1839971. We also acknowledge the Feddersen Distinguished Professorship Funds and a gift from Thomas J. Malott. Any opinions, findings, and conclusions expressed in this material are those of the authors and do not necessarily reflect the views of the funding agency.\n\n††copyright: none††articleseq: 0††ccs: Human-centered computing Interaction design theory, concepts and paradigms\n\n1. Introduction\n\nRecently, Generative Artificial Intelligence (GenAI) models have gained immense popularity and are being applied in diverse applications such as art (Li et al., 2023b; Alayrac et al., 2022), design (Karras et al., 2019; Sbai et al., 2018), and entertainment (Li and Sung, 2021; Tseng et al., 2023). Current popular GenAI models including Large Language Models (LLM) and Large Vision Models (LVM) are widely deployed on platforms or in software for their capabilities to create imagery content (Dalle-2 (Ramesh et al., 2022), Stable Diffusion (Rombach et al., 2022a)), writing literature (Yuan et al., 2022), and Question Answering (ChatGPT (OpenAI, 2021)). The adoption of GenAI models has demonstrated significant advantages, e.g. fostering creativity (Qiao et al., 2022), driving innovation (Chang et al., 2023), enabling personalized content generation (Wu et al., 2023c), and providing valuable assistance in creation endeavors (Ma et al., 2022). As a result, these models have become ubiquitous, emphasizing the need for well-crafted and compelling interactions between humans and GenAI.\n\nTo take advantage of the generative power of GenAI models, Human-GenAI interaction techniques such as prompt engineering (Liu and Chilton, 2022; Qiao et al., 2022), visualization (Wan and Lu, 2023), and interactive interfaces (Dang et al., 2022b; Evirgen and Chen, 2023), have become popular and effective mediums for humans to interact with GenAI systems. These allow users to collaborate (Yuan et al., 2022), be assisted(Aksan et al., 2018), take suggestions (Chu et al., 2023) or revise recommendations (Valencia et al., 2023) from GenAI systems.\n\nHowever, existing research on Human-GenAI interactions focuses on each individual aspect and domain. The key design considerations, common practices, and future research opportunities are still hidden and scattered across many broad topics embedded in GenAI and its applications. To keep pace with the development of GenAI models and their new out-of-the-box capabilities, we identify a need to systematically analyze the research in this field, particularly from an interaction design perspective, to assist the HCI community to innovate and explore new interaction design techniques for the best utilization of GenAI capabilities. Furthermore, this view of GenAI will also foster new emerging applications to consider key vantage points where our framework will point.\n\nInspired by the above, we aimed to lay the groundwork for further developments in the field of human-GenAI interactions by systematically synthesizing all the current research and consolidating the existing knowledge and approaches in this domain.\n\nIn this paper, we review a corpus of 291 papers for synthesizing the taxonomy of human-GenAI interactions. Specifically, we synthesize the research fields from both the user and GenAI perspectives (briefly shown in Figure 1) into the following dimensions of the design space: 1) Purposes of Using GenAI, 2) Feedback from Models to Users, 3) Control from Users to Models, 4) Levels of Engagement, 5) Application Domains, and 6) Evaluation Strategies.\n\nOur main goal is to present a comprehensive overview of recent developments in and research on AI-model analysis, interaction designs, visualization techniques, and application domains of GenAI-based systems. By compiling the state-of-the-art advancements in these areas, we aim to provide a valuable resource for researchers to understand the current landscape and situate their own work within a broader design space. To achieve the goals above, we summarize a taxonomy from the literature, offering a holistic view that encompasses perspectives from both the GenAI model side (e.g. I/O design, capabilities, and volumes) and the human side (e.g. evaluation strategies and application domains), as well as the interactions between them (e.g. interfaces to control, visualization technique, and feedback design). This taxonomy will enable readers to gain a deeper understanding of the intricacies involved in creating effective and meaningful human-GenAI interaction systems, fostering future evolution and innovation in the design of GenAI technologies. Additionally, we identify open research questions, challenges, and opportunities in the future design of GenAI systems and interactions. By highlighting these areas of exploration, we aim to guide researchers in their pursuit of addressing crucial issues and uncovering new possibilities, so that the HCI community paces and also identifies vantage points for creating new GenAI, with the rapidly evolving technology of GenAI.\n\n2. Background, Scopes, and Contributions\n\nIn this section, we cover the developments in GenAI models in prior research as well as open-source platforms and software.\n\nA widely accepted definition (Xu et al., 2015) of GenAI goes by the probabilistic models that model the joint distribution in contrast to discriminate AI models that model the conditional distribution. From a high-level understanding, GenAI is defined as ”an AI that uses existing media to create new, plausible media” (Muller et al., 2022). As a sub-topic in the domain of AI, GenAI has a rich history of development.\n\nIn the early stage of its development, the metaphor of GenAI advanced independently in two major domains, namely Natural Language Processing (NLP) and Computer Vision (CV). In NLP, the generation of nature languages by AI was handled by early implementations of Recurrent Neural Networks(RNN) (Elman, 1990) and Long Short-Term Memory (LSTM) networks (Graves and Graves, 2012). Likewise in CV, the concepts of Artificial/Convolutional Neural Networks (ANN (Fukushima, 1988) and CNN (LeCun et al., 1998)) were applied to models that generate images. Nevertheless, in both fields, the NN-based methods were greatly limited by the hardware conditions back then.\n\nIt was not until the early 2010s that the breakthrough in hardware technology enabled the explosion in GenAI research with increased computational power in both NLP and CV fields. Long sentence generation and sequence-to-sequence generation were then achieved by RNNs with much larger sizes and computational power (Sutskever et al., 2014; Mikolov et al., 2013). Similarly in the CV area, models like Generative Adversarial Networks (GAN) (Goodfellow et al., 2014), Variational Autoencoders (VAE) (Kingma and Welling, 2013), and their successors (Karras et al., 2019, 2017, 2020; Brock et al., 2018) enabled diverse applications such as style transferring between images (Gatys et al., 2016; Zhu et al., 2017), generating images based on texts (Zhu et al., 2019), etc.\n\nRecent research has highlighted and merged the two fields, enabling the multi-modal generative power of GenAI. Works like Transformer (Vaswani et al., 2017) and Diffusion Model (Ho et al., 2020; Rombach et al., 2022b; Saharia et al., 2022; Nichol et al., 2022) have built the theoretical foundation for the current stage of GenAI, where large models such as Generative Pretrained Transformer (GPT) and its successors (Radford et al., 2018, 2019; Keskar et al., 2019; Brown et al., 2020), T5 (Raffel et al., 2020), BERT (Devlin et al., 2018), and CLIP (Radford et al., 2021) enable diverse applications with content of higher quality and multiple modalities.\n\nEmpowered by the models, an increasing number of software and interactive platforms are being developed to cater to various fields, such as art, design, education, and algorithm development, democratizing access to the creative potential of GenAI. In this paper, we provide a comprehensive summary of diverse GenAI applications and highlight some notable open-source platforms in Table 15 . These platforms are designed and contributed by researchers, developers, and experts, aiming to make GenAI technology accessible to a broader audience. Table 15 serves as a valuable resource for readers to gain insights into the versatility of GenAI applications and discover open-source platforms that can facilitate their creative pursuits.\n\n2.1. Scope\n\n2.1.1. GenAI vs AI\n\nGenAI, as its name suggests, represents a category of AI that goes beyond traditional models by focusing on generating new data rather than solely analyzing or making predictions. In our research, we place a particular emphasis on GenAI models that excel at generating fresh content. While traditional AI models are designed to perform specific tasks or offer predefined responses based on data patterns and algorithms (i.e. discriminative), GenAI systems possess the unique ability to create novel content (i.e. generative). By enabling users to influence the generated content through inputs like prompts, these interactions become more dynamic and creative.\n\n2.1.2. GenAI Systems\n\nAmong extensive existing research and work on the applications of GenAI systems, we have chosen to narrow the scope of our research to focus exclusively on GenAI systems that are developed using deep generative models and specifically designed for user interactions, because of their overwhelming generative power (Dhariwal and Nichol, 2021) and rapid improvement in recent years.\n\nNotably, our paper does not encompass the usage of GenAI models where no user interaction exists, i.e. research that focuses on only the model performance and architectures rather than interactions or applications. We have also deliberately chosen not to delve into the detailed formulations of GenAI models and their creation process. Similarly, we do not discuss the specific methodologies for creating GenAI models, improving their performance, or training and collecting datasets. While the technical details of creating and deploying GenAI models are undoubtedly essential and relevant in other contexts, our research emphasizes the human perspective such as the utilization and interaction of these systems by users and the impact of GenAI systems on user experiences, creativity, and decision-making.\n\n2.2. Contributions\n\nThe GenAI has been explored in various other papers from both sides human and GenAI model (Zhou and Shimada, 2023). Some work has conducted study (Hu et al., 2023) and discussion (Chen et al., 2023) to gain human perspective in using GenAI models. Chen et al. (Chen et al., 2023) conducted a discussion with researchers and presented a roadmap for future directions from the technical (GenAI models) side aligning with human values and accommodating human intent (Cao et al., 2023). Prior work has contributed in survey and review papers in the field of GenAI such as GenAI recent developments (Zhao et al., 2023), their technical perspective (Harshvardhan et al., 2020; Zhang et al., 2023b), content generated (Cao et al., 2023) and application (Zhou and Shimada, 2023; Gozalo-Brizuela and Garrido-Merchán, 2023). Some recent work has also proposed design space (Weisz et al., 2023; Hu et al., 2023; Morris et al., 2023) and design guidelines (Liu and Chilton, 2022). Recently, GenAI and human interactions have been a topic in HCI workshops (Muller et al., 2023, 2022; Bernstein et al., 2018).\n\nBuilding upon prior work, this paper offers the following significant contributions.\n\nFirstly, it presents a comprehensive taxonomy of the design space, considering both the human perspective and the GenAI perspective. This taxonomy provides a detailed and in-depth view of various dimensions and categories, with a specific focus on human interactions with GenAI systems. By examining the design aspects from these two perspectives, the paper sheds light on the dynamic and creative interactions between users and GenAI systems, providing valuable insights into the user-centric nature of these systems.\n\nSecondly, the paper represents a pioneering effort as the first comprehensive literature survey on human-GenAI interaction systems. The literature survey serves as a valuable resource for HCI researchers, offering a well-organized and insightful compilation of the current state of human-GenAI interaction systems. Researchers can draw from this survey to gain a deeper understanding of the design space and the nuances of interactions between users and GenAI systems. Moreover, the survey provides a solid foundation for further research and exploration of novel design possibilities in this rapidly evolving area.\n\nThirdly, we end our paper with discussions over directions for future investigations, helping researchers identify unexplored opportunities and challenges in human-GenAI interactions. The discussions and insights are derived from the collections of the papers and the high-level summarization we identified.\n\n3. Methodology\n\nWe aim to identify and collect a large representative set of state-of-the-art GenAI models and GenAI systems using systematic search techniques (Hosseini et al., 2023). We systematically created a relevant corpus using PRISMA (Page et al., 2021) guideline: (1) Search strategy to explore; (2) Identification of the publication outlets; (3) Evidence Screening; (4) Eligibility; (5) Inclusion.\n\n3.1. Search Strategy\n\nWe performed two search waves to select the relevant keywords for our survey. First search waves identify keywords for advancements in GenAI models in the Machine Learning/Deep Learning conferences. This also includes open-source software built on GenAI models such as ChatGPT. This first spectrum of keywords provides models that were further used in developing a methodology to find GenAI systems corpus in the HCI domain. The two search strategies are discussed in detail below:\n\n3.1.1. Methodology to Define GenAI-related Model Keywords\n\n: The GenAI field is broad and continuous works are being published in general machine learning areas and domain-specific areas such as CV and NLP. Therefore, we performed a broad search to identify keywords related to GenAI in order to maximize the inclusion of relevant papers. Focusing on GenAI models, we used different expressions and abbreviations of ”Generative Artificial intelligence”. The list of keywords used is shown in Table 3. We searched the title, abstract, and keywords to get relevant papers related to GenAI. The search was conducted in the proceedings of prominent machine learning conferences (ICML, ICLR, and NeurIPS), computer vision conferences (CVPR, ICCV, and ECCV), and NLP conferences (ACL, EMNLP, and HLT-NAACL). To ensure the relevance of the research specifically to Deep GenAI models, we limited our search to papers published 10 years prior to our work. During the search process, we carefully examined author keywords, abstracts, and titles to extract additional relevant keywords related to GenAI models. We also added more keywords based on the three authors’ knowledge about the recent advancements in GenAI algorithms and software.\n\n3.1.2. Methodology to Define GenAI-Related Systems Keywords\n\n: Then, we focus on finding relevant keywords related to GenAI systems that are interacted with by the users. As the focus of the papers should involve Human-GenAI interactions, we used combinations of keywords: ”Generative AI models” AND ”Humans” OR ”Human” OR ”Users” OR ”User” for our search. The complete list of keywords is shown in Table 4.\n\n3.2. Identification\n\nWe meticulously executed a systematic search strategy using relevant keywords from renowned publication platforms, including ACM Digital Library, IEEE Xplore, MDPI, Springer, and Elsevier. Employing the OR operator between keywords ensured a comprehensive exploration of the literature on GenAI models and systems. Additionally, we proactively searched for variations and synonyms of the keywords, encompassing terms such as ”GAN,” ”StyleGAN,” ”CycleGAN,” ”Transfer learning,” and ”ChatBots,” and many more to capture diverse facets of GenAI research. To focus on the most pertinent content, we applied filters to restrict the search to the title, abstract, and authors’ keywords of the articles. Considering the rapid advancements in GenAI models, we narrowed our search to papers published in the last 10 years because of the advancements in Deep GenAI models. Moreover, we prioritized open-access papers and those accessible via institutional subscriptions, broadening the availability of our research findings. We also included relevant citations in our corpus from the papers we found from our key strategy.\n\n3.3. Screening\n\nThree authors screened the initial corpus of 12076 papers individually based on the title and abstract. The entire corpus was divided into 3 equal parts and each part was screened by one author. The authors read the title and abstract of the papers assigned to them and screened the paper based on the following exclusion and inclusion criteria: 1) We focus on including papers that were only written in English. 2) We included peer-reviewed conference papers such as journals, conferences, and workshop papers. We excluded opinion papers, idea papers, workshop proposals, patents, non-peer-reviewed papers (e.g. arXiv papers), posters, surveys, and literature review papers. 3) We removed false and change-of-context papers that were not focused on Human-GenAI interaction but were present because of keywords. 4) we excluded the papers with no Deep GenAI model papers used. 5) papers were included that focused on human GenAI interactions rather than on GenAI model performance improvement. If the authors were unsure about the paper, a discussion among all the authors was considered for the final assessment. After the screening process, we kept 797 papers.\n\n3.4. Eligibility\n\nTo determine the eligibility of papers each author individually read the entire papers. As the primary interest is in human GenAI interactions, we included additional inclusion and exclusion criteria (as shown in Table 1) that were also used when reading the entire paper: 1) we removed papers that were focusing on only technical improvements of the GenAI model. 2) we excluded works without human interactions with the GenAI model or system. 3) we included papers where humans were interacting with the AI system, even if the papers were not focusing on the GenAI system or humans. 4) We included study-based papers that involved interaction with GenAI systems. These criteria along with screening criteria, three authors reviewed the entire corpus individually by going through the entire paper independently and following the selection criteria to exclude out-of-scope papers. We determined inter-rater agreement among the three authors using Fleiss’ Kappa Measure during the eligibility of the final corpus. The agreement score of κ𝜅\\kappaitalic_κ = 0.79 indicates substantial agreement. A final discussion was performed to solve any discrepancies. The overall focus for selection criteria involves papers with only human GenAI system interactions. Then all three authors discussed each paper in the corpus to finalize a total of 291 papers.\n\n3.5. Inclusion\n\nOur final paper has a total of 291 papers. The collected corpus varies from 2013 to 2024. A larger majority of the papers have been published in ACM (55%)and IEEE (29%). Table 2 shows the filtering of manuscripts at various stages for the final corpus.\n\nDespite our systematic methodology for collecting representative papers of the existing work, we acknowledge that the resulting corpus might not contain every piece of the development of GenAI, due to the mass popularity of GenAI in every other domain such as medicine, manufacturing, and others. Further, there might be some papers that are on the borderline of Exclusion/Inclusion criteria that were not included in the corpus.\n\nNevertheless, we argue that this corpus is large and comprehensive enough to provide representative subsets of each dimension for the most relevant papers for our taxonomy. To collectively address our limitations, we will make our coding, dataset, and tagging system open-source and available for researchers to iterate, suggest new categories, expand our current taxonomy, and advance.\n\n3.6. Analysis\n\nAs discussed in the former sections, we aim to present a comprehensive taxonomy of human-GenAI interaction in order to help future research and development in designing interactive GenAI systems. Over the collected corpus of literature, we conduct a collaborative analysis to identify the key dimensions of the taxonomy.\n\nThe analysis involves multiple stages of review and collaboration among the authors. Initially, each of the authors reads and summarizes a small subset (N=25𝑁25N=25italic_N = 25) of the papers to establish an approximate taxonomy of components and dimensions. These preliminary taxonomies are then discussed among all authors to iteratively refine and enhance, by highlighting the overlapping dimensions, adding or subtracting components and categories as necessary, and eventually agreeing upon one revised taxonomy. Upon revision, three authors individually read the entire list of papers thoroughly to assign them to their respective categories and dimensions. During this phase, workshop proposals, surveys, and literature reviews are not included in the final categorization but are used as supplementary references to guide our analysis and concretize the design components and categories. To ensure consistency and resolve any conflicts, the three authors subsequently engaged in discussions to finalize the tagging of the papers, by iteratively opening up new discussions upon any author identifying a paper that does not properly fit into the existing taxonomy. At the end of each iteration, authors decide if a new dimension is needed for the taxonomy or agree on the position of the paper in the existing taxonomy. This collaborative approach helps ensure the accuracy and reliability of the categorization process.\n\nEventually, our analysis results in a comprehensive taxonomy of dimensions from an HCI design perspective. The HCI design logic behind this taxonomy suggests that developers and researchers in this field practice User-Centered Design (Abras et al., 2004) by\n\n(1)\n\norienting the system through the needs of the end-users (section 4)\n\n(2)\n\nconsidering the capabilities and functions of the GenAI models (section 5)\n\n(3)\n\nexploring the possible actions of the users, the corresponding results of the actions, and the mapping between the actions and the results(section 6)\n\n(4)\n\nenabling different levels of engagement in the interaction for different tasks (section 7)\n\n(5)\n\ndeciding the application domain the system can be generalized into (section 8),\n\n(6)\n\nand evaluating the system via designated metrics (section 9).\n\nIn the following sections, we discuss various components in the dimensions and the motivations for considering them when designing a system. Later on, we present the future opportunities and challenges in this domain summarized from our literature review. In the appendix, we included tables containing all the papers’ citations and counts that fall into respective categories and dimensions.\n\n4. Purposes of Using GenAI\n\nThe initial step of designing an interactive GenAI system is to determine the end goals of (i.e. purposes of using) the system from the user’s perspective. Characterizing such purposes sets the fundamental notes on the design of the systems and answers the essential questions on what types of tasks the system is to fulfill and what the users of the system expect from it. To this end, in the very first section, we categorize the purposes of users of GenAI applications. On a high level, we identify the purposes falling into the following categories: 1) Refine the Outcome, 2) Explore Alternatives, 3) Get Answers for Inquiries, 4) Understand a Subject, 5) Automate Processes, 6) Enhance Experiences, and 7) Augment Sample Data.\n\nPurpose-1 Refine the Outcome\n\nUsers possess certain expectations of an instance or outcome to be created. With a specific objective, users utilize GenAI applications to generate instances to meet their qualitative or quantitative expectations. Qualitative expectations of the users encompass subjective properties of the instances, such as style of a fashion design (Wu et al., 2023c), melody in a piece of music (Louie et al., 2020; Suh et al., 2021), plots in a story (Chung et al., 2022), layout in a web application (Jing et al., 2023; Mozaffari et al., 2022), content (Evirgen and Chen, 2022; Qiao et al., 2022) or subjects (de la Torre-Ortiz et al., 2020; Chang et al., 2023) in an image, etc. Quantitative expectations depict the objective metrics that the generated instances are to satisfy, such as parametric designs of a 3D model (Koyama and Goto, 2022), efficiency of codes (Liu et al., 2023c), precise layout of cameras in a VR space (Yoo et al., 2021), etc.\n\nPurpose-2 Explore Alternatives\n\nUsers can actively utilize GenAI to generate multiple instances of an idea, building from the abstraction of knowledge learned by the GenAI models. Users then explore the generated alternatives for ideation, choosing among, or learning the patterns. For example, GAN-based applications like GANravel (Evirgen and Chen, 2023) and GANCollage (Wan and Lu, 2023) enable the users to generate multiple images similar to the input and explore the gallery of images to decide the best design of the images. GenAI can also passively assist users in their ideation process. For example, CatAlyst (Arakawa et al., 2023) motivates the users to continue their unfinished presentations by completing part of their work to provide new ideas.\n\nPurpose-3 Get Answers for Inquiries\n\nWhen faced with a specific challenge or question, users can leverage GenAI to brainstorm potential solutions or avenues of inquiry. The inquiries put forward can be of single or multiple modalities and from diverse domains. To design GenAI applications fulfilling this purpose requires considerations over both the delivery of the answers and the capability of providing correct or rational answers. For instance, users can ask GenAI systems a specific question and have it generate programming codes to solve this question and iterate with the system to optimize the codes (Kazemitabaar et al., 2023). Moreover, GenAI can directly generate the answers in natural language to the problem input by users (Kim et al., 2020).\n\nPurpose-4 Understand Subjects\n\nDifferent from getting answers to specific inquiries, users can utilize the generative powers of models to obtain their understanding of various subjects in a comprehensive manner, without users explicitly deciding the form or content generated to contribute to the understanding. The understanding is enhanced by GenAI through diverse methodologies such as providing insights, generating examples, or offering new perspectives. Such understanding can be of the process of the model itself (e.g., GANslider (Dang et al., 2022b) utilizes filmstrips of screenshots to illustrate the process of GAN-based transferring of images.), the knowledge of a concept in specific domains (e.g., Liu et al. (Liu and Chilton, 2022) demonstrates how users of text-to-image GenAI can effectively prompt by observing vast amount of text-image-pairs.), the nature or phenomena conveyed by data (e.g., Vis Ex Machina (Zehrung et al., 2021) generates graphs and charts based on input data from the users in order to help understand the data.).\n\nPurpose-5 Automate Processes\n\nUsers can utilize GenAI as an automation tool in a broad spectrum of applications. GenAI is specifically strong in automating tasks that involve the generation of content. GenAI can be applied to generating control sequences of robots (Lin et al., 2020; Brohan et al., 2023; Ren et al., 2023; Huang et al., 2022) in various scenarios based on users’ textual or voice commands. While traditional automation focuses on executing repetitive tasks based on specific instructions, GenAI can also introduce creativity, adaptability, and decision-making into automation processes. For example, Liventsev et al. (Liventsev et al., 2023) propose fully autonomous programming with LLMs, where the models are able to rationalize and determine the best practice of coding.\n\nPurpose-6 Enhance Experiences\n\nGenAI, given its ability to generate content and adapt to user input, can significantly enhance user experiences across various platforms and applications. In general, GenAI is capable of enhancing the experience by improving the quality of the generated content based on diverse metrics. For instance, GenAI can extend the visual experience of the users (Kimura and Rekimoto, 2018), make language in articles user-friendly (Strengers et al., 2020), or modify the user input for more efficient communication (Wu et al., 2022b; Valencia et al., 2023) A particular key aspect in GenAI’s enhancement of experience is personalization, where GenAI adapts its output based on users’ profiles, preferences, or states. For example, VocabEncounter (Arakawa et al., 2022) adapts to the contexts of the users to provide personalized experiences of learning foreign vocabulary. AdaptiFont (Kadner et al., 2021) generates adaptive fonts according to users’ reading speed to maximize the reading experience.\n\nPurpose-7 Augment Sample Data\n\nGenAI has become a powerful tool for data augmentation, a process used to increase the amount and diversity of data. AI-generated data can be used as training data to build a new AI model. For example, Word-Gesture-GAN (Chu et al., 2023) utilizes GAN to generate synthetic gesture data for training keyboard gesture recognition models. Deepwriting (Aksan et al., 2018) uses GAN to generate handwriting data to train style-transfer models. Enabled by the large corpus of knowledge learned by LLMs and LVMs, research has also investigated the possibility of deploying AI-generated data of various modalities into other research domains. For instance, Park et al. (Park et al., 2022) and Hamalainein et al. (Hämäläinen et al., 2023) experimented with AI-generated for research in social computing and HCI respectively.\n\n5. Feedback from Models to Users\n\nTo better understand the essence of human-GenAI interaction, we investigate the field from two major aspects. The first aspect is the feedback from Models to Users. In this aspect, we majorly consider the capabilities of the models, the range of modalities of the models, and the methodologies of delivering the output of the models. These considerations over the models are essential to designing a GenAI system in order to fulfill the purposes aforementioned in section 4. Prior work (Yang et al., 2020) in general human-AI interaction has also addressed that the key design challenge stems from understanding AI’s capabilities, especially from a user-centered perspective. To this end, we identified three dimensions to depict the current landscape of feedback techniques of GenAI systems, namely, 1) Output Modalities, 2) Functions of the Models, and 3) Output Synchronization.\n\nDimension-1 Output Modalities\n\nThe output modality of a GenAI model refers to the type or form of data that the model produces. Generative models can produce a variety of outputs, and the modality is determined by the type of data they are trained on and designed to generate. In our research, output modality determines the modality of the feedback presented to the users (i.e. they are identical), because we have not identified a case where the output of the system is not presented to the users.\n\n—Textual Textual output encompasses natural language in texts, programming code (Liu et al., 2023c; Jiang et al., 2022b; Liventsev et al., 2023), the handwriting of texts (Aksan et al., 2018), and fonts (Kadner et al., 2021). Specifically, natural language in texts can be chats (Zamfirescu-Pereira et al., 2023a; Huber et al., 2018; Han et al., 2021), descriptions of a problem (Kazemitabaar et al., 2023), or pieces of literature (Strengers et al., 2020; Oh et al., 2020; Chung et al., 2022).\n\n2D Visual GenAI models that produce 2D visual outputs are typically trained on large datasets of images to learn the underlying patterns and can create novel images based on their training. 2D visual outputs consist of images (Liu et al., 2020; Chang et al., 2023; Sanchez, 2023; Liu and Chilton, 2022; Ross et al., 2021), sketches (Zhao et al., 2020; Cheng et al., 2020), videos (Truong et al., 2021; Liu et al., 2023b), 2D visualization of data (Zehrung et al., 2021; Lee et al., 2022a), and spatial AR (Kimura and Rekimoto, 2018; Kimura et al., 2019).\n\n3D Graphic 3D graphic outputs consist of 3D models, 3D motion of various objects, and XR scenes. For example, Koyama et al. (Koyama and Goto, 2022) utilize generated 3D models to provide suggestions during 3D design. Yoo et al. (Yoo et al., 2021) generate VR camera layouts by referring to a clip of a film.\n\nAudio Audio output consists of music (Louie et al., 2020; Suh et al., 2021; Frid et al., 2020), sound effects (Oh et al., 2020), or natural language voice synthesis (Janssens et al., 2022).\n\nLayout GenAI is capable of generating layout information, widely deployed in designing game layouts (Mozaffari et al., 2022), web layouts (Wang et al., 2023a), graphic layouts (Jing et al., 2023; Guo et al., 2021), and more domain-specific layout designs (e.g. game layout (Capps and Schrum, 2021; Schrum et al., 2020; Volz et al., 2018)).\n\nNumerical Data All modalities of input can be fundamentally regarded as numerical data in the computer science and engineering realm. In addition to the aforementioned modalities that contain high-level information that can be directly perceived by humans, we identify the numerical data otherwise conveying information and being used as inputs to GenAI e.g., gestural data (Chu et al., 2023), control sequence to a robot (Brohan et al., 2023; Ren et al., 2023), and hierarchical representations of concepts (Lee et al., 2022a).\n\nDimension-2 Functions of the Models\n\nAs was previously elucidated, the core capability of GenAI is to generate new data samples that are similar in distribution and characteristics to the training data. Based on this capability, a range of functions of GenAI models are developed. We categorized the most common six functions in the literature, namely: 1) Generation from Scratch, 2) Completion, 3) Intra-Modal Transformation, 4) Inter-Modal Conversion, 5) Diversification, and 6) Aggregation. The categorization of the functions of GenAI models aims to bring a clear vision of designing a GenAI system to fulfill the users’ needs, utilizing a specific or a combination of functions.\n\nGeneration from Scratch GenAI applications are capable of producing entirely new content without specific input. This could be through utilizing pre-trained patterns, internal algorithms, or some combination of initial states or conditions within the model itself. The initial generated content is not directly guided by a user’s input, and the model operates more autonomously. With this autonomy, this method of input initialization can benefit (1) GenAI systems with non-expert (Louie et al., 2020; Kadner et al., 2021; Suh et al., 2021) users who do not possess knowledge of proper input, (2) systems that passively assist the users (Arakawa et al., 2022; Kadner et al., 2021), or (3) systems that help the users with ideation within a specific domain through vast collections of examples (Ko et al., 2022; Volz et al., 2018; Evirgen and Chen, 2023; Padiyath and Magerko, 2021)\n\nCompletion In some scenarios, GenAI is required to finish an incomplete product from the user. For example, GenAI can generate auto-completion or suggestions for an ongoing writing task to compose a piece of literature or a story (Jakesch et al., 2023; de la Torre-Ortiz et al., 2020) with designated plots or opinions to inspire or lead the writers. Moreover, based on what users have input, generated content can be as good as the user input in terms of quality in some cases, (Fan et al., 2019) or provide a different perspective on the subject (Arakawa et al., 2023).\n\nIntra-Modal Transformation Intra-modal transformation refers to the function of GenAI to change within the same input modality to generate a different output in the same modality. Systems that leverage intra-modal transformation typically include modifying the details in the content to meet the users’ preferences or experiences (e.g. Strengers et al. (Strengers et al., 2020) propose an LLM-based method to modify the article for friendliness to people for minority and De et al. (de la Torre-Ortiz et al., 2020) enable human portraits editing with brain signals.). Such transformation usually results in changes in styles (Guo et al., 2021; Qiao et al., 2022), content (Yuan et al., 2022; Qiao et al., 2022), or quality (Koyama and Goto, 2022; Kimura and Rekimoto, 2018; Wu et al., 2022b) of the output.\n\nInter-Modal Conversion Inter-modal conversion refers to the function of GenAI models to convert between different input and output modalities. This function to convert abstract knowledge or representations among diverse modalities has fostered a promising quantity of possibilities for GenAI applications. This is because human knowledge and information can now be instantiated to the best modality to either 1) be conveyed efficiently or 2) fit the platforms of the applications. For example, Cheng et al. (Cheng et al., 2020) enable image editing via texts to convert textual descriptions of a design into a visual representation of the design. Similarly, Yoo et al. (Yoo et al., 2021) utilize GenAI to generate VR camera layouts given a reference video, obtaining a unique output for VR applications. Moreover, this function of inter-modal conversion has lessened the barriers of expertise requirements in many domains for novices, particularly thanks to its capability to convert ideas and information from intuitive modality, e.g. natural language and sketches, to exclusive modalities, such as programming language, artistic work, or domain-specific designs. For example, text-to-code applications allow conversion from simple descriptions of tasks in natural language to codes to handle the tasks (Liu et al., 2023c; Liventsev et al., 2023; Jiang et al., 2022b; Kazemitabaar et al., 2023). This benefit is also manifested in text-to-image and sketch-to-image applications, where users with no artistic skills can instantiate their intuition or idea, and eventually compose an artistic painting (Chang et al., 2023).\n\nDiversification GenAI possesses the function of diversification, by generating multiple diverse outputs from a single input. The outputs can be of the same modality (1 to n intra-modal transformation). In this case, GenAI is capable of generating instances with variations in details. For example, generating images of the same content but with different viewpoints or features (Zhang and Banovic, 2021; Evirgen and Chen, 2023; Wan and Lu, 2023), generating longer music given a short clip of melody (Louie et al., 2020; Suh et al., 2021), generating textual content such as NPC quests in games (Ashby et al., 2023) or (fake) news (Zhou et al., 2023), or designs for different game layouts (Capps and Schrum, 2021; Schrum et al., 2020; Volz et al., 2018). Moreover, the outputs can be of different modalities (1 to n inter-modal conversion). In this case, GenAI is converting the input inter-modally to multiple outputs. For example, Jing et al. (Jing et al., 2023) enable the generation of diverse layout designs from a scenario constraint for mobile shopping applications.\n\nAggregation Finally, GenAI is capable of taking multiple inputs and synthesizing them into a single concise output, which we refer to as aggregation. GenAI can aggregate inputs of different modalities of inputs to an output of specific modalities. For instance, PopBlends (Wang et al., 2023b) blends the concepts from texts and images into a new image, to generate the best representations of an idea. Huber et al. (Huber et al., 2018) make possible the aggregation from texts and images to emotional dialogues. GenAI can also aggregate inputs to outputs of uniform modalities, focusing on refining the information within. For example, StyleMe (Wu et al., 2023c) enables users to merge the outlines and styles from two fashion designs into a new one. AngleKindling allows journalists to take different angles in writing a journal by summarizing the ideas from the text (Petridis et al., 2023).\n\nDimension-3 Output Synchronization\n\nGenAI systems also utilize different output synchronization strategies. The synchronization strategies of the GenAI systems investigated follow certain objectives. Understanding the logic of selecting the synchronization strategy is therefore critical to the system design. We identify three strategies based on the output timing with respect to the user interaction timing.\n\nPreliminary This category describes a GenAI system with output prior to the user interaction. The preliminary output strategy is usually utilized in the GenAI systems where users absorb the AI-generated content (Arakawa et al., 2022) passively or as is (Jo et al., 2023; Wang et al., 2021b). Another scenario with preliminary output is the human-GenAI collaboration tasks where GenAI takes the first move to inspire (Lee et al., 2022a) or motivate (Arakawa et al., 2023) the human.\n\nReal-time Real-time output is generated concurrently with human interaction with the GenAI systems. This strategy benefits the systems with the requirement of immediate responses such as in writing suggestions (Jakesch et al., 2023; Valencia et al., 2023; Bhat et al., 2023) and auto completion (Lehmann et al., 2022). Moreover, real-time output is preferred when the systems consist of interaction modalities that tweak the direction, attributes, or details of the generated content. In these systems, users expect real-time feedback generated when they are interacting. For example, in GAN-based image generation applications (Dang et al., 2022b; Xu and Karamouzas, 2021; Evirgen and Chen, 2023), when a user is dragging a slider controlling the direction of the GAN models, the visualization of the generated images is expected to be dynamic and aligned with the slider movement. This advantage of real-time feedback can be identified through other collaborative applications such as webtoon sketch creation (Ko et al., 2022), co-writing (Bhat et al., 2023), and programming assistance (Prather et al., 2023; Finnie-Ansley et al., 2023).\n\nDelayed A delayed output is generated after an explicit mark of the end of the users’ interaction, e.g., hitting enter when chatting with a chatbot (Najafian et al., 2023; Janssens et al., 2022) or clicking on a button to input a set of parameters (Guérin et al., 2017). Delay can be intentionally designed for users to either modify their input or confirm the parameters. This strategy is common in most human-GenAI interactive applications that require descriptions of human expectations of the output, such as fashion design containing multiple layers (Cheng et al., 2020), artistic image generation considering multiple attributes (Ko et al., 2022), style merging requiring multiple inputs (Wu et al., 2023c), etc. When there are multiple elements to be considered by the humans in the loop, the delayed output prioritizes users’ decision-making on the final output. Some interaction techniques require delayed output by nature. For example, interaction with a chatbot requires input and output on a conversational basis which goes one by one. Nevertheless, the computation cost is a major reason for some applications resorting to delayed output. Although from a design perspective, real-time output is preferred for the reasons aforementioned, subject to the model size and constraints on the computational power, most image-based GenAI systems resort to delayed output for consistent user interactions.\n\n6. Control from Users to Models\n\nThe second aspect of the interaction comes from the human side. We seek the answers to the questions of what and how users can control so that the models arrive at an expected output. These answers serve as critical human factors in designing the interactions in a GenAI system. To this end, this section delves into the common ways by which humans can provide feedback to the GenAI system, as well as the categorization of feedback to be provided. Broadly, we categorize into three categories: How users take actions to navigate or adjust GenAI, what the objects in GenAI systems are controlled, and the mediums to provide feedback.\n\nDimension-1 Methods to Improve the Output\n\nIn this subsection, we aim to reveal the answers to the essential question – how do users get the expected generated content from GenAI? Looking at the question from an HCI perspective, we summarize the high-level interaction design of the GenAI systems in the literature, to identify the methodologies of user interaction to prompt or improve the output towards their expectations. The design of the interactions follows specific design goals, which are crucial considerations for the HCI design of a GenAI system.\n\nOptions Selection Users can select their preferred output from a range of options generated by the AI, allowing them to choose the result that best aligns with their needs (Louie et al., 2020; Wan and Lu, 2023; O’Donovan et al., 2015). Output selection can also serve as a feedback mechanism to train or fine-tune GenAI to get better results in the future. Additionally, users can also select one of the outputs from GenAI model intermediate layers guiding the direction to the final desired output (Evirgen and Chen, 2022). This allows the user to iterate or build on the intermediate output refining them further to achieve the final result.\n\nHighlighting and Inpainting It allows users to point out specific areas that need modification or replacement in the input such as image (Evirgen and Chen, 2023), text (Dang et al., 2022a; Fu et al., 2023), or document (Ma et al., 2022). Users can highlight or color paint emphasizing particular details, areas, or objects to either add (Bau et al., 2020),erase (Fu et al., 2023; Bau et al., 2020), modify (Evirgen and Chen, 2022; Ko et al., 2022) or keep (Lee et al., 2022b) specific regions of the input in generating the final output.\n\nParameter based Tuning GenAI system provides users with a unique ability to access and manipulate the intermediate layers to indirectly modify (compared to composing the content artificially) the output (Schrum et al., 2020; Suh et al., 2021; Ueno and Satoh, 2021; Dang et al., 2022b; Koyama and Goto, 2022). It provides users with a granular level of control over the output using slider (Suh et al., 2021) or numerical input (Ueno and Satoh, 2021) to semantically change a generation of output. Parameter tuning is helpful in image input-output target matching (Dang et al., 2022b; Ross et al., 2021), controlling the randomness of the generated output such as LLMs (Leinonen et al., 2023b), changing the style of output (Rafner et al., 2021) e.g. graphic design (Ueno and Satoh, 2021), and editing the content but preserving style (Rafner et al., 2021; Aksan et al., 2018).\n\nNatural language Commands Natural language guidance from humans either text or voice allows them to guide the output from the GenAI system using commands or instructions (Huang et al., 2022; Ren et al., 2023; Cheng et al., 2020). Users can provide commands sequentially to steer the output generation (Liu et al., 2020). These commands are commonly used in Large Language models (Hämäläinen et al., 2022), Chatbots (Han et al., 2021), and visual design assistant (Cheng et al., 2020).\n\nAdditional Demonstration Users can further provide additional information to the GenAI system by drawing sketches (Zheng et al., 2019; Guérin et al., 2017), outline (Shen et al., 2020), copy & paste (Chong et al., 2021), handwriting (Aksan and Hilliges, 2021), images (Qiao et al., 2022) and keywords (Liu et al., 2022b) to narrow the scope of the generated output. Users can provide specific preferences (Zheng et al., 2019), additional context (Wu et al., 2023c; Zhao and Ma, 2018), and set constraints (Chung et al., 2022) to generate a more relevant and accurate output.\n\nRe-intiliazation Users can re-initialize the generation process, with new or some adjustments (Fan et al., 2019; Lin et al., 2020; Twomey, 2022) in the input. This iterative and adaptable approach allows users to fine-tune content generation effectively (Oh et al., 2018). Reinitializing also allows for experimentation to see how different approaches or inputs affect the output (Linzbach et al., 2023).\n\nDimension-2 Objects to Control\n\nIn this subsection, we elaborate on the objects inside the GenAI models that are actually controlled by the users during interaction. We broadly identify four categories, namely, the latent space, the hyper-parameters, the weights/parameters, and the input, which are commonly but not systematically identified objects controlled by the users of an AI system by prior works on general human-AI interaction (Schrum et al., 2020; Higuchi et al., 2021; Dudley and Kristensson, 2018; Amershi et al., 2019). As a sub-set of general AI systems, GenAI inherits these identical properties in terms of interactive components. To provide concrete and novel insights based on prior work by Morris et al. (Morris et al., 2023) that touches upon how GenAI models reach evolution of themselves (i.e. how GenAI models improve the output through interactions), we further investigate the distinctions between controlling GenAI and controlling general AI in the following discussion.\n\nLatent Space Latent spaces are high-dimension representations of the input given by the users. Modifying these high-dimension states allows users a semantically meaningful way to control the style of the output. For example, GANravel (Evirgen and Chen, 2023) allows users to edit face features such as adding glasses to their eyes or making the person smile keeping the rest of the face the same. Such controls of latent space representation in GenAI systems give users the freedom to visualize the direction of output (Kahng et al., 2018), explore for diverse generated outputs (Davis et al., 2023; Zhang and Banovic, 2021), and transform (Mozaffari et al., 2022) the latent space to get the desired output. In most cases, users may not directly manipulate the latent space so they are mapped to UI elements such as clicking a button (Evirgen and Chen, 2023) or moving sliders (Ko et al., 2022; Dang et al., 2022b). In addition, latent space allows users to potentially influence the types (Jing et al., 2023; Yuan et al., 2022), quantities (Zhang and Banovic, 2021), and levels of variability (Evirgen and Chen, 2023) present in the system’s outputs.\n\nParameters/Weights Parameters/Weights refer to the weights and coefficients that the algorithm extracts (learns) from the data during the training process. The approach to changing the parameters of a model is addressed as fine-tuning. Fine-tuning the GenAI system involves re-training the GenAI model either with few or zero-shot learning (Brown et al., 2020; Swanson et al., 2021). It allows the system to become adaptive and personalized for each individual user (Spape et al., 2021). Fine-tuning GenAI systems makes them personalized to the user by improving task-specific capabilities and domain-specific knowledge of the GenAI system, consequently enabling guided generation of content, in terms of a range of elements in the content, e.g. the subjects or the style of the generated content.\n\nHyper-Parameters Hyper-parameters refer to the type of parameters that are second-level tuning parameters that decide the training and inferencing process other than the first-level parameters or model weights (Feurer and Hutter, 2019; Probst et al., 2019). Specific designs to interact with these GenAI model hyper-parameters allow users to control the creativity(randomness) in the outputs generated from the GenAI systems (Leinonen et al., 2023b). Some GenAI system includes Temperature parameter (Valencia et al., 2023; Louie et al., 2020), frequency penalty (Lee et al., 2022b) and random seed during the development of GenAI system (Leinonen et al., 2023b) to control the variability in the generated output. For example, Louie et al. (Suh et al., 2021) use a temperature parameter to generate conventional or surprising music. Hyper-parameters can be changed by the end-user using tools that allow changing values using sliders (Louie et al., 2020) or text editor (Leinonen et al., 2023b).\n\nInput Input control provides the unique ability for the user to interact with GenAI without changing the parameters or the hyper-parameters (Zamfirescu-Pereira et al., 2023a). The quality (Liu and Chilton, 2022) and relevance (Lee et al., 2022a) of the input prompt influence the output generated from GenAI systems. Users can provide input prompts to the model to get the desired generated output (Wu et al., 2023c). Directly giving input prompts from the user to the model often generates out-of-context output. To eliminate this users can additionally provide a few examples of the input-output to guide the model in generating output in a way the user wants (Jiang et al., 2022a; Yang et al., 2023). For example, Jiang et al. (Jiang et al., 2022b) used LLMs to support software development. Users can also develop an automatic method of designing such input prompts instead of manually specifying (Kim et al., 2023) to get more relevant output. Some of the examples are by suggesting prompts (Lee et al., 2022a), constructing prompt templates (Linzbach et al., 2023), combining multiple prompts primitive (Jiang et al., 2022a), reformulating prompts suiting GenAI system (Ma et al., 2022), and transforming prompt to different input modality (Chung et al., 2022).\n\nDimension-3 Mediums of Control\n\nThe interfaces through which users interact with the GenAI models are essential in the HCI design of GenAI systems. Under a framework of a generic taxonomy of human-computer input mediums, we characterize the interface design considerations for GenAI systems.\n\nGUI and Widget UI and widgets are the most common design elements in the GenAI system which allow users to understand the displayed information and interact with them, because of the coverage over the most common modalities of data of GenAI systems. GUIs provide straightforward visualization and mediums of input for textual and imagery data. Similarly, widgets provide also straightforward adjustments to objects being controlled. Buttons (Dang et al., 2023), sliders (Dang et al., 2022b), mouse clicks and drags (Endo, 2022), and tool pallets (Zhang and Banovic, 2021) are often used to provide input or any modifications to GenAI system. Image editors (Evirgen and Chen, 2022) and text editors (Wu et al., 2022a) are also used to display outputs and provide or edit the inputs. Interfaces are also used in displaying the 3D content (Liu et al., 2023d) Information panels and menus are used to display information that guides users to use the GenAI system (Suh et al., 2021). Canvas is also used to provide multiple (Evirgen and Chen, 2022; Wan and Lu, 2023; Evirgen and Chen, 2023) or different modalities (Qiao et al., 2022) to the user for viewing and selection of the input-output.\n\nController The controller is a user interface example that allows the user to provide input and can be used to control the GenAI system. This medium is specialized for the generation of control sequences for robots, game control, or human motion. For instance, Xu et al. (Xu and Karamouzas, 2021) used a game controller to control human motion generation.\n\nTangible Object The user can control GenAI systems by moving objects in the real world (Noyman and Larson, 2020). The tangible object includes interactions with physical objects such as static objects(Shirazi et al., 2021), dynamic objects(Nakano et al., 2019b), and remote objects (Duan et al., 2019). Users’ interactions with the tangible objects in the 3D space, virtual or real, are usually mapped as the input to the generation of 3D content, with consistency in I/O spatiality.\n\nPen For imagery or visual-text-based GenAI systems, having the users draw their ideation or instance is a popular way of controlling the models. Users can use a physical pen or pencil to draw (Twomey, 2022; Lin et al., 2020), write text (Aksan and Hilliges, 2021; Aksan et al., 2018), or make sketches (Ko et al., 2022; Zhao and Ma, 2018) on screens (He et al., 2022) and paper (Twomey, 2022).\n\nBrian Control Signal Brian signals are another medium that helps the user control the GenAI system using brain signals. Some works record these signals using electroencephalography(EEG) (Kangassalo et al., 2020; Spape et al., 2021; Davis et al., 2022). Brain responses are directly connected to the internal parameters of GenAI models such as latent space (de la Torre-Ortiz et al., 2020) for providing implicit feedback. For example, Spape et al. (Spape et al., 2021) used a brain interface for generating personalized attractive images.\n\nBody Motion and Gesture Gesture interaction involves the utilization of physical gestures and movements as a means of engaging with the GenAI system, commonly carrying spatial-temporal information that guides the generation of content. Gesture movement can be captured by interactive surfaces such as mobiles and tablets (Chu et al., 2023; Chung et al., 2021). Also, body movements are useful in interacting with GenAI in immersive environments (Chang et al., 2018). Face tracking, facial emotion, and expressions are also used in designing natural interactions with GenAI (Jordan et al., 2021), which usually carries sentimental or semantical information that guides the generation of content.\n\nAudio Audio includes both human voice(Ahn et al., 2022; Janssens et al., 2022) and music (Frid et al., 2020). Human voice commands offer a dynamic approach to manipulating and directing the outcomes of GenAI models. Through vocal prompts, users can effectively steer the generated output (Liu et al., 2023c), leveraging their spoken instructions to guide the GenAI output. This innovative interaction method harnesses the potential of natural language and empowers users to shape the GenAI output in a more personalized (Jo et al., 2023) and intuitive manner (Liu et al., 2023c). On the other hand, music or sound effects as the medium of control usually serve as the reference of styles for generated content.\n\n7. Levels of Engagement\n\nWith the design human-GenAI interaction investigated from both the human side and the GenAI model side, we then examine the high-level characterization of the design of the interaction as an entity. In this section, we follow the most commonly used definition of engagement as ”the process by which interactors start, maintain, and end their perceived connections to each other during an interaction.” (Sidner et al., 2003; Oertel et al., 2020). We identify four levels of engagement in human-GenAI interaction, namely, Passive Engagement, Deterministic Engagement, Collaborative Engagement, and Assistive Engagement, with an increasing connection between the generated output and the user interaction within the engagement. Put simply, with a design of passive engagement, users do not substantially contribute to the generation of the content but the models generate the actual output. On the other hand, in assistive engagement, the models do not substantially contribute but only help in ideation for users to create the content. A comprehensive metaphor could be writing a story, where the ideation is to come up with the flow and plot of the story and substantial contribution means writing down the story in full-text in any form.\n\nThe design of engaging patterns of a GenAI system critically determines the user groups for the particular part of the output users can contribute and the expense of mental load they can afford (Dudley and Kristensson, 2018). It also determines the application scenarios because the level of engagement limits the choices of interaction mediums. Finally, the originality or creativity of the content created is also determined by the level of engagement, as pointed out by many prior works (Sarkar, 2023; Mikalonytė and Kneer, 2022; Todorov, 2019) that the process of the work assigns the credit for generated work by a human-AI team.\n\nLevel-1 Passive Engagement:\n\nPassive engagement depicts the systems with which users receive information or content generated by the AI without direct interaction. In this case, users do not create or contribute to the generated content directly but their profiles or preferences are passively taken by the models to direct the output. Example system designs with passive engaging interactions fulfill the tasks of immersive news writing (Oh et al., 2020) and immersive vision system (Kimura et al., 2019; Kimura and Rekimoto, 2018), where the users are passively engaged with GenAI and its product without explicit interactions to guide the output.\n\nWith only passive input from the users, passively engaging GenAI systems are expected to generate satisfactory products through an end-to-end pipeline. The design for possible passive input from the users is also tricky and thus challenging due to its implicity and constraints.\n\nLevel-2 Deterministic Engagement:\n\nAs its name conveys, in a GenAI system where the engagement is deterministic, the outcome is determined by the AI’s inherent logic, instructions, or a predetermined set of rules, rather than being shaped by the users’ interactions. Similar to passively engaging systems, deterministic GenAI systems usually consider users’ profiles and preferences as part of the input and directly generate content to meet the users’ requirements, resulting in limited contribution from the users to the final result. Yet Deterministic Engagement differs from Passive Engagement with active interactions from the users. User interactions in this type of engagement are usually just instructions to stop and start the generation. Examples can be a foreign language dictionary for the users to learn but in AI-decided contexts (Arakawa et al., 2022), AI-generated hierarchical tutorials for the users to follow (Truong et al., 2021), or an adaptive font generator that evaluates the users’ performance and autonomously generates the best font for reading (Kadner et al., 2021).\n\nAn end-to-end pipeline for generation is also expected for deterministic GenAI systems. In this setup, users do not need to possess knowledge of the domain to contribute to the generation but are supposed to simply notify the systems when the content is needed by them.\n\nLevel-3 Assistive Engagement:\n\nAssistive engagement allows the GenAI system to generate content to assist the users in the creation process in the form of suggestions, summarization, or ideation that do not substantially contribute to the final product of the interactions but rather conceptually or abstractly contribute to the creation process. An example of an assistive system can be an auto-completion assistant in writing (Jakesch et al., 2023), a contextual provider of suggestions (Valencia et al., 2023), or an online debugger for an ongoing programming (Prather et al., 2023).\n\nAssistive engagement requires the systems to possess the capabilities to abstractly understand users’ needs and produce high-level assistance with the tasks. In the possible application scenarios, users of such systems are expected to complete the generation of the final output with the generated high-level assistance from GenAI models.\n\nLevel-4 Collaborative Engagement:\n\nCollaborative engagement is the most common design in the current deployment of GenAI systems. In these systems, GenAI and users work collaboratively on a task, with both sides contributing to the final product. One major method of these systems is to collaborate through interactive two-way conversation, exchanging information, and user iterating based on the responses. This method is widely deployed among the systems based on large language models (Mirowski et al., 2023; Buschek et al., 2021; Yuan et al., 2022; Jiang et al., 2022a; Yang et al., 2022b), where conversation in natural language dialogue is possible, and some GAN-based applications, where GenAI provides hints or visualizations on the generation direction in response to user queries (Wang et al., 2021c; Liu et al., 2020; Mozaffari et al., 2022; Evirgen and Chen, 2023; Dang et al., 2022b; Endo, 2022). Another method is cooperation, in which the users and the GenAI share the same goal and substantially contribute to the final results in the same format or modality. Examples of this method can be jointly creating slides for a presentation (Arakawa et al., 2023), finishing a sketch by GenAI adding details (Fan et al., 2019), and composing a piece of melody by both users and generated music (Louie et al., 2020; Suh et al., 2021).\n\nCollaboratively engaging GenAI systems require the users to possess the skills and abilities to create the entity or part of content themselves, with GenAI models sharing the same tasks with them. It also requires the GenAI models to possess a similar set of capabilities as users in the designated application scenarios.\n\n8. Application Domains\n\nThrough our exploration, we identified a range of diverse application domains of human-GenAI systems. Figure 9 summarizes the categories of domains and lists the related papers correspondingly. We classified existing works into the following high-level application domains: (1) Art and Creativity, (2) Science and Research, (3) Writing, (4) Programming, (5) Robotics/IoT, (6) Education and Training, (7) Game Development (8) 3D Modeling, (9) Design, and (10) Quality of Life. A detailed list of references in each of the domains above can be found in Table 13.\n\nArt and Creativity is the domain where most applications emerge. The generative power of GenAI has changed the game in the art industry, covering lots of aspects of artistic creation across the disciplines of visual arts, music, literature, and filming. In general, GenAI can contribute to the processes of ideation, variation, and polishing the artwork. Such contribution will be further refined by the improvement of the interaction design of human-GenAI. GenAI also manifests promising potential in the realm of design. In Art and Design, where the visual components are generated by GenAI and then evaluated by human designers, we anticipate further research on the interaction designs in this context from both micro (e.g. efficiency of certain methods for visualizing designs) and macro perspective (e.g. conceptual processes in designs that can be enhanced by GenAI and how). In our discovery, there are more domains that are less investigated or not investigated best to our knowledge, e.g. Education and Learning. We foresee further exploration and exploitation in these domains based on the insights into specific patterns and methodologies depicted by our taxonomy.\n\n9. Evaluation Methodologies\n\nIn this section, we report our categorization of evaluation strategies for GenAI systems. The main categories we identified following the classification by Suzuki et al (Suzuki et al., 2022): (1) technical evaluations, (2) evaluation through demonstration, and (3) user evaluations. Through this section, we aim to provide references for future research on GenAI systems, specifically for deciding the evaluation techniques for future systems.\n\nEvaluation-1 Technical Evaluation\n\nTechnical Evaluation focuses on the performance of the backend, the algorithm, and the model of a system. Typical technical evaluation methods on system performance are qualitative assessment of the output (Zhou et al., 2023; Leinonen et al., 2023a; Fu et al., 2017), and quantitative measurement of the output via computing distance (e.g. BLEU for text and FID for images) between the generated and the expected in public datasets (He et al., 2022; Davis et al., 2022; Wang et al., 2023c; Janssens et al., 2022). The evaluations can be conducted on annotated datasets by the researchers themselves and the technical statistics of the datasets are also reported (Aksan et al., 2018; Wang et al., 2021b).\n\nEvaluation-2 Demonstration\n\nEvaluations through demonstrations assess the system performance under specific conditions. Common methods consist of generalizability demonstration (Koyama and Goto, 2022), proof of concept demonstration (Strengers et al., 2020; Lehmann, 2023; Zamfirescu-Pereira et al., 2023a), demonstration through an example use case (Yurman and Reddy, 2022; Chang et al., 2023; Kimura and Rekimoto, 2018).\n\nEvaluation-3 User Evaluation\n\nUser evaluation refers to measuring the performance of a system through user studies, focusing mostly on the effectiveness of the interaction designs in the system, which is hard to technically evaluate through uniform metrics. Common methods for user evaluation are questionnaires carefully designed to assess how well the design goals of the systems are satisfied (Dang et al., 2022b; Liu and Chilton, 2022), qualitative lab studies (Janssens et al., 2022) for rich insights into design and contextual understanding, quantitative lab studies (Evirgen and Chen, 2022) for objective measurement and generalizability, and interviews with both experts (Sun et al., 2022; Padiyath and Magerko, 2021) and novices (Zamfirescu-Pereira et al., 2023b; Wu et al., 2022a) in the subject matter.\n\n10. Findings\n\nBased on the analysis of our taxonomy, Figure 10 shows a summary of the number of papers for each dimension In this section, we discuss the standard strategies and gaps that we identify through our analysis of the literature.\n\nFinding-1 Mediums of Control: Direct but not Intuitive\n\nThrough our literature review, we notice that direct control modalities are more applied (e.g. widgets, controllers, drawings and highlighting, and text, N=234𝑁234N=234italic_N = 234) than the intuitive ones (e.g. gestures, brain signals, and voice, N=49𝑁49N=49italic_N = 49) to control the output of the GenAI system. Direct control modalities allow users to modify the attributes of the models or data straightforwardly, while intuitive control modalities require mappings from the users’ intuition to the functions of the models.\n\nThis inclination highlights that GenAI systems align more with the need to tweak the GenAI models for specific functions directly while overlooking the users’ need for intuitive interactions. For example, using sliders to adjust the weights of the attributes of a GAN model (Evirgen and Chen, 2022; Wan and Lu, 2023; Evirgen and Chen, 2023) is direct yet not intuitive, because novice users (who do not know AI) do not possess the technical knowledge to understand the correspondences between the attributes and the outputs. When users interact with systems with straightforward interactions, they need to build the mapping between their interaction input and the output (Abras et al., 2004), while with intuitive interactions, researchers have preset this mapping for the users. Put simply, considering the Gen-AI systems as black boxes with unknown I/O correspondence, intuitive interactions foster smoother learning curves of this I/O correspondence than straightforward interactions. This observation suggests that intuitive human interactions are not yet the mainstream mediums for controlling the GenAI models.\n\nFinding-2 Visualizing the Results rather than the Process\n\nWe notice that most GenAI systems do not reveal the intermediate layers or output to the users (N=231𝑁231N=231italic_N = 231). This is hard to accomplish from the AI-developing side, given the fact that it is hard for end-users to comprehend the mathematical functions that lie within the intermediate layers of the users. However, from an HCI perspective, we highlight the necessity of investigating the design space of interacting with the intermediate layers of the GenAI systems, which is a significant missing piece in the current research. It is important that users understand the intention-action mapping (Abras et al., 2004; Norman, 1988) of using a system, i.e. what consequences result from each of their interactions. From the designer’s perspective, it is required to understand the complexity of the models so that designers can ”conceptualize the system’s behaviors in order to choreograph its interactions” (Yang et al., 2020). From the user’s perspective, users need to interpret outputs and express feedback to the models (Dudley and Kristensson, 2018), which can benefit from a multi-layer design of the system compared to an end-to-end one. Starting from this consideration, we further discuss the future directions to address this concern in section 11\n\nFinding-3 the Use of Foundation Models\n\nWe observed that a major GenAI utilized in the research is Large Language Models (LLMs, a significant subset of Foundation Models, which are defined as models (e.g., BERT, DALL-E, GPT-3) trained on broad data (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks (Morris et al., 2023; Bommasani et al., 2021; Kirillov et al., 2023) in 82 papers). Large language models have gained significant popularity due to their unparalleled ability to understand and produce human-like text. We also observed that most LLM-based applications utilize textual conversation as their interaction modality, implying that the users of these LLM-based systems interact by text input. This interaction follows the most instinctive patterns for LLMs, which are, after all, models of language. However, considering LLMs’ overwhelming generative power and multi-modal potential, we suggest taking one step back and reconsidering the possible interaction modalities applicable to LLMs. For example, a voice command can be converted to text to converse (Kim et al., 2022a), and vice versa (Janssens et al., 2022). Similarly, images can be summarized by models and translated into text for conversation as well (Wang et al., 2021a). Enlightened by this finding, we discuss the future opportunities of research in interaction design in section 11\n\nFinding-4 Missing Discussion over Ethics\n\nThrough our discovery in the papers, we identify the missing piece of discussion over the ethical problems induced by the widespread application of GenAI. Out of the corpus of 291 research papers, only 21 papers discuss the potential ethical problems induced or tackled by their systems or studies. From our previous analysis of the papers, we identified similar patterns in the topics, methodologies, or application domains. We conclude that the applications of GenAI share similar ethical concerns that are yet to be addressed through further research. Examples of GenAI ethical problems we have located include GenAI plagiarism (Francke and Bennett, 2019; Dien, 2023; Noci, 2023), opinionated bias in GenAI system (Jakesch et al., 2023), and gender bias in Natural Language generation (Strengers et al., 2020). We will be detailing the future opportunity of investigating how to tack GenAI ethical problems in section 11.\n\n11. Future Opportunities\n\nOpportunity-1 Designing and Exploring Interactions with Foundation Models\n\n—Various I/O Modalities through Foundation Models In our survey, we identified promising usage of Foundation Models, as mentioned in section 10. While the Foundation Models have enabled diverse applications in domains associated with texts and images, we argue that further research can aim toward more intuitive modalities, considering the cross-modality potential shown from both applications we’ve investigated (Sanchez, 2023; Liu et al., 2023d; Wang et al., 2023c). Human conveys information through diverse means in addition to text and image. For example, the audio of natural language speaking can be converted into text as an approach to converse, a gesture or sign language may contain the information needed for instructing a robot, or a human gaze can guide the foundation models to generate descriptions of an object or an event in sight for educational purpose. AI and ML community have been widely discussed over the capabilities of Foundation Models learning the abstraction of human knowledge and generating representations of the knowledge in diverse modalities (Morris et al., 2023; Bommasani et al., 2021). With our proposed taxonomy identifying the design considerations of interaction mediums and modalities of the GenAI models, questions are to be addressed such as (1)What are the possible modalities of Foundation Models that can be applied in interactive systems? For example, there is a limited amount of research that tackles the 3D content generation for AR/VR applications through Foundation Models. (2)What are the effects of the conversion of modalities by Foundation Models on the users? The abstraction of knowledge can be instantiated by Foundation Models across modalities, but what are the effects of the conversion on the users? How much of the information or knowledge is preserved through the generated modalities? How much of it is actually perceived by the users? Answering those questions will significantly guide the direction of future GenAI application development. (3) The former questions lead to the investigation of another questionWhat are the metrics to evaluate the interactions? Since the popularity and continuing growth of Foundation Models are still novel, there is not yet a set of dedicated metrics to evaluate the quality of the interaction (not just of the model performance or the generated content as proposed in (Muller et al., 2023)) design for them. Finally, (4) What are the general patterns we can conclude from the designs addressing the aforementioned questions? A general framework for designing interactions with Foundation Models is called for the future development of this promising direction.\n\n—Diverse Applications through Foundation Models Further from above, we argue that more diverse applications of Foundation Models can be introduced by future endeavors. First of all, through the capability of Foundation Models to handle diverse modalities I/O, we anticipate consideration of the formats of data that were unable to be generated by the predecessors of current GenAI models, which can be specifically used in a certain task. For example, there can be an application to generate a blueprint of a novel refrigerator (sketch, numerical data, and text as output) given users’ routines of menus (text and image as input). Secondly, we suggest that the interaction with Foundation Models (or GenAI in general) should not be constrained to merely collaborative tasks, but can also be applied to tasks with passive or deterministic engagement. To be specific, with the strong generative power and capability to consume data in diverse forms, Foundation Models are able to actively understand the environment or context of the users and generate content that is to be passively consumed by the users. For example, a GenAI-based instructional AR system can scan the vision or environment of the users and detect the elements in the context (e.g. tools, furniture, and appliances), based on which it will predict the intended tasks of the users and generate corresponding AR instructions. To embrace the promising possibility of diverse applications through Foundation Models, questions remain unanswered What are the types of information that can be passively perceived by the users and meanwhile be generated by the Foundation Models (or GenAI in general)? What are the types of contextual, semantic, or environmental information that can be used as the input to the models?\n\nOpportunity-2 Designing Interactions for Understanding GenAI\n\nPointed out by many prior works on human-AI interaction, a key consideration in designing an interface for AI-based applications is to enable the users to understand AI, in terms of the capabilities or potential mistakes to make (Amershi et al., 2019). Some (Dudley and Kristensson, 2018) also argue that the users require the ”ability to retrace steps in the event that recent actions have resulted in an undesired outcome” and that it is necessary to consider how to reduce the effort of the users to interpret the outputs and express the feedback. Based on these general discussions over human-AI interaction design, we investigate what open research questions are yet to be addressed specifically about GenAI.\n\n—Users Understanding the model capabilities Different from predictive or discriminative AI models that perform a discrimination behavior, solving classification or regression problems (Gozalo-Brizuela and Garrido-Merchan, 2023), GenAI models generate new media. This difference creates a divergence between the interactions with predictive AI and those with GenAI. The capabilities of GenAI to be understood are vaguer and more subjective than those of predictive AI since the latter mostly focuses on or works towards a specific or explicit goal while the former focuses on creativity or implicit tries to meet the users’ expectations (Muller et al., 2022). The questions remain unanswered: (1) What are the metrics to evaluate how close the generated content is to users? With the designated sets of metrics, we can investigate (2) How can users themselves learn to interact with the systems to bring the generated content closer to their expectations? To address this question, the interfaces or designers need to make clear to the users why the system did what it did (Amershi et al., 2019). For example, there are already a massive amount of empirical tutorials, blogs, posts, and even academic papers (White et al., 2023; Robinson, 2023; Magalhães, 2023) on how to prompt with ChatGPT to direct the output of it. What are the essential HCI problems behind the empirical studies that can be applied to other GenAI systems? Answering this question leads to a clearer vision of how interactions should be designed so that the users understand the capabilities of the GenAI models they are interacting with. (3) What are the correspondences between the model parameters and the model capabilities? And which capabilities (and their corresponding parameters) are to be made optional for users to control, considering the particular application domains the systems serve? Interacting with internal parameters of the GenAI system allows users to explore GenAI model capabilities(Dang et al., 2022b). Only 18 papers out of 291 allow users to control the model parameters. One of the principles of User-centered Design is that the systems should allow users to guide the behavior of output to align with their preferences (Abras et al., 2004). This involves adjusting certain GenAI model parameters and exploring the full capabilities of GenAI models. The correspondence between the GenAI model parameters and the actual generated content is different from that between predictive AI parameters and the if-else-rule-based prediction. A promising direction we see is in the domain of Explainable GenAI, where the correspondence can be studied and applied to the interaction design of actual systems. It is also crucial for system designers to understand the trade-off between the controllability and the complexity of the GenAI system (Yang et al., 2020). Reducing the choices of parameters for the end-users, on the one hand, enhances user experience and increases efficiency, but on the other hand, lessens customization or adaptability of the system. A balance between the degree of freedom and efficiency of the system has yet to be revealed by future research.\n\n—Exploring Novel Interactions We found limited numbers of dedicated mediums of interaction between the users and the GenAI systems. With natural interaction such as gesture-based and brain-controlled interfaces, users interact with devices and systems through modalities as intuitive as moving the hands or thinking about a picture, to obtain a desired output. We foresee the potential novel interactions with such modalities that reduce the cognitive offset between user-expected output (resulting from the interactions) and the actual output. For example, enabling the usage of brain signals to control the modifications to a generated image waives the cognitive cost of learning the correspondence between traditional GUI and output.\n\nFurthermore, this allows the deployment of GenAI systems in more natural and immersive platforms, particularly in virtual reality (VR) and augmented reality (AR) applications. Also, BCIs have the potential to enable interactions without any physical movement, opening up possibilities for users with disabilities and new modes of interaction. Finally, natural interactions often come with technological difficulties such as user adaptation and personalization, subject to variability in user input and interaction. For example, people tend to express their feelings in different ways. Some prefer informal language, while others make ambiguous gestures. These differences pose challenges for designing an adaptive system that relies on users’ expressions as input, say, to generate an image that describes their mood. The research questions to be addressed in these scenarios are: 1) How do we integrate natural interactions with current GenAI models? What can be the connections between the natural interactions and the generation of the content? 2) How do we accurately contextualize and adapt the generated content to users’ natural interactions as input?\n\nOpportunity-3 Investigating the Uncertainty of GenAI\n\nThe uncertainty of an AI system lies in two major aspects. First, as mentioned in (Yang et al., 2020) the capabilities of the AI system are uncertain to both the HCI designers and the end-users. Second, the systems are prone to be more uncertain when the users come into the picture as the human factors (Amershi et al., 2019). To tackle both aspects of uncertainty, the AI systems are called to be adaptive (as discussed in the last subsection) and explainable respectively.\n\nIn the scope of GenAI, the domain of explainability in GenAI is still underexplored, although Explainable AI (XAI) has been discussed for general AI over the years. The explainability of AI is domain-specific and user-oriented. Few works like (Sun et al., 2022) investigated the need for explainability for a specific application scenario as well as its impact on the HCI considerations of the systems.\n\nOpportunity-4 Multi-party Interaction Design\n\nA less general yet interesting direction in future discussions of human-GenAI interaction is the multi-party interaction design. We anticipate a less constrained workflow with multiple users or multiple GenAI models engaging towards the same generative task. In this workflow, the users and the models can function in the same roles or not. For example, there can be multiple users brainstorming over a topic while a LLM-based system functions as a summarizer of the discussions from the users. In addition to the parties, there can be another diffusion-model-based system generating visualization based on the summarization from the LLM-based system. We propose to investigate the following research question in the potential scenario (1) What is the difference in user experience when interacting with multiple GenAI models, when they are of the same and different roles? (2) What are the characterizations of the interactions between the multiple models in the workflow? More interestingly, (3) Can the roles setup be agnostic of whether they are filled by models or humans? And finally, (4) How much can models and humans each contribute to the final content generation?\n\nOpportunity-5 Human-GenAI Ethics Discussion\n\nAs stated in the Discussion and Findings, we identified the missing pieces of discussion over ethical problems induced by GenAI. The impact of the problems varies across different applications, such as shrinking the job market (Ghosh and Fossas, 2022), intrusion into copyrights and intellectual property (Noci, 2023), and generation of illegal content (Al-Rubaie and Chang, 2019; Danezis et al., 2015). We will describe two common problems as examples to open the floor for further discussion for researchers to take into consideration when addressing more foreseen ethical concerns.\n\n—Credit Assignment between GenAI and Human In the GenAI applications where the final output is of market values or artistic attributes, it is still vague and undefined how the credit between GenAI and Human creators should be rigorously distributed, despite the heated discussion over this topic. The credit assignment dynamic between GenAI systems and human users exemplifies a modern collaboration where innovation is nurtured through a symbiotic relationship. For example, if an artist creates a painting using a GAN-based system, does he or the GenAI system deserve credit for this artwork? It would be unrealistic to claim that GenAI should take full credit, for the fact that there would not be art without humans as long as human interactions are the external force fostering this artistic creation. Yet, one can easily see the flaws and unfairness in giving the human artist the full credit, because, in the creation process, GenAI contributes to the final result, whether in ideation, styling, or any fundamental stroke. It is also a weak argument that GenAI (or AI in general) is not human and deserves no credit in human work, considering the human efforts in implementing the model and creating the artwork sample training this model. With all these being said, we propose to take the middle ground that both sides share the credit. The credit lies in the harmonious exchange: AI offers a canvas, while humans contribute a vivid palette of experiences, cultural nuances, and depth of understanding. However, a rigorous pattern for credit assignment will not emerge until the following questions are addressed: (1) What is the definition of creativity in the context of human-GenAI collaboration? (2) Should the data being used to train GenAI be considered contributing to the generated content? (3) What is the taxonomy of human-GenAI interactions that can help define the contribution of a work?\n\n—Inappropriate Use of GenAI Generated content can be harmful in many possibilities, such as generating biased or opinionated data for educational content, overlooking the needs of minority groups, generating illegal content that poses threats to society (e.g. rumors), or breaching basic human rights (e.g. identity theft in fake content). We call for rigorous and clarified rules, regulations, and laws in the domain, which are also considered significant parts of human-GenAI interactions. Only with clear-defined appropriate applications and usages of GenAI, shall we foster a positive impact of GenAI on the existing human industries and communities.\n\n12. Conclusion\n\nIn this paper, we present a survey on existing GenAI applications and research, deriving a taxonomy of human-GenAI interactions. We synthesize the existing research in this scope and discuss their (1) Purposes of Interacting with GenAI, (2) Feedback from Models to Users, (3) Control from Users to Models, (4) Levels of Engagement, (5) Application Domains, and (6) Evaluation Strategies. Our research aims to provide an overview of the landscape of the topic of human-GenAI interaction and the common ground of application design. Further, we discuss future opportunities in this topic, namely, (1) designing interactions for Foundation Models, (2) designing interactions for understanding GenAI, (3) investigating the Uncertainty of GenAI, (4) multi-party interaction design, and (5) ethical discussion on GenAI. We hope our research will guide and inspire future work on human-GenAI interaction.\n\nReferences\n\n(1)\n\nA et al. (2023) Rajagopal A, Nirmala V, Immanuel Johnraja Jebadurai, Arun Muthuraj Vedamanickam, and Prajakta Uthaya Kumar. 2023. Design of Generative Multimodal AI Agents to Enable Persons with Learning Disability. In Companion Publication of the 25th International Conference on Multimodal Interaction (Paris, France) (ICMI ’23 Companion). Association for Computing Machinery, New York, NY, USA, 259–271. https://doi.org/10.1145/3610661.3617514\n\nAbdal et al. (2022) Rameen Abdal, Peihao Zhu, John Femiani, Niloy Mitra, and Peter Wonka. 2022. Clip2stylegan: Unsupervised extraction of stylegan edit directions. In ACM SIGGRAPH 2022 conference proceedings. 1–9.\n\nAbras et al. (2004) Chadia Abras, Diane Maloney-Krichmar, Jenny Preece, et al. 2004. User-centered design. Bainbridge, W. Encyclopedia of Human-Computer Interaction. Thousand Oaks: Sage Publications 37, 4 (2004), 445–456.\n\nAdão et al. (2023) Telmo Adão, João Oliveira, Somayeh Shahrabadi, Hugo Jesus, Marco Fernandes, Ângelo Costa, Vânia Ferreira, Martinho Fradeira Gonçalves, Miguel A Guevara Lopéz, Emanuel Peres, et al. 2023. Empowering Deaf-Hearing Communication: Exploring Synergies between Predictive and Generative AI-Based Strategies towards (Portuguese) Sign Language Interpretation. Journal of Imaging 9, 11 (2023), 235.\n\nAgbodike et al. (2020) Obinna Agbodike, Chiao-Hua Huang, and Jenhui Chen. 2020. Cognitive Attention Network (CAN) for Text and Image Multimodal Visual Dialog Systems. In 2020 6th International Conference on Applied System Innovation (ICASI). IEEE, 37–41.\n\nAhn et al. (2022) Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al. 2022. Do as i can, not as i say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 (2022).\n\nAksan and Hilliges (2021) Emre Aksan and Otmar Hilliges. 2021. Generative Ink: Data-Driven Computational Models for Digital Ink. Artificial Intelligence for Human Computer Interaction: A Modern Approach (2021), 417–461.\n\nAksan et al. (2018) Emre Aksan, Fabrizio Pece, and Otmar Hilliges. 2018. Deepwriting: Making digital ink editable via deep generative modeling. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1–14.\n\nAl-Rubaie and Chang (2019) Mohammad Al-Rubaie and J Morris Chang. 2019. Privacy-preserving machine learning: Threats and solutions. IEEE Security & Privacy 17, 2 (2019), 49–58.\n\nAlayrac et al. (2022) Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. 2022. Flamingo: a visual language model for few-shot learning. Advances in Neural Information Processing Systems 35 (2022), 23716–23736.\n\nAmershi et al. (2019) Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen, et al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi conference on human factors in computing systems. 1–13.\n\nAneja et al. (2023) Shivangi Aneja, Justus Thies, Angela Dai, and Matthias Nießner. 2023. Clipface: Text-guided editing of textured 3d morphable models. In ACM SIGGRAPH 2023 Conference Proceedings. 1–11.\n\nArai et al. (2023) Kota Arai, Yutaro Hirao, Takuji Narumi, Tomohiko Nakamura, Shinnosuke Takamichi, and Shigeo Yoshida. 2023. TimToShape: Supporting Practice of Musical Instruments by Visualizing Timbre with 2D Shapes based on Crossmodal Correspondences. In Proceedings of the 28th International Conference on Intelligent User Interfaces. 850–865.\n\nArakawa et al. (2023) Riku Arakawa, Hiromu Yakura, and Masataka Goto. 2023. CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1–19.\n\nArakawa et al. (2022) Riku Arakawa, Hiromu Yakura, and Sosuke Kobayashi. 2022. VocabEncounter: NMT-powered vocabulary learning by presenting computer-generated usages of foreign words into users’ daily lives. In Proceedings of the 2022 CHI conference on human factors in computing systems. 1–21.\n\nAshby et al. (2023) Trevor Ashby, Braden K Webb, Gregory Knapp, Jackson Searle, and Nancy Fulda. 2023. Personalized Quest and Dialogue Generation in Role-Playing Games: A Knowledge Graph-and Language Model-based Approach. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1–20.\n\nBamani et al. (2021) Eran Bamani, Nadav D Kahanowich, Inbar Ben-David, and Avishai Sintov. 2021. Robust multi-user in-hand object recognition in human-robot collaboration using a wearable force-myography device. IEEE Robotics and Automation Letters 7, 1 (2021), 104–111.\n\nBang et al. (2023) Junseong Bang, Byung-Tak Lee, and Pangun Park. 2023. Examination of Ethical Principles for LLM-Based Recommendations in Conversational AI. In 2023 International Conference on Platform Technology and Service (PlatCon). IEEE, 109–113.\n\nBau et al. (2020) David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, and Antonio Torralba. 2020. Semantic photo manipulation with a generative image prior. arXiv preprint arXiv:2005.07727 (2020).\n\nBenjamin et al. (2023) Jesse Josua Benjamin, Heidi Biggs, Arne Berger, Julija Rukanskaitė, Michael B Heidt, Nick Merrill, James Pierce, and Joseph Lindley. 2023. The Entoptic Field Camera as Metaphor-Driven Research-through-Design with AI Technologies. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1–19.\n\nBernstein et al. (2018) Michael S Bernstein, Joon Sung Park, Meredith Ringel Morris, Saleema Amershi, Lydia Chilton, and Mitchell L Gordon. 2018. Architecting Novel Interactions With Generative AI Models. (2018).\n\nBhargava et al. (2022) Rishabh Bhargava, Russel Lobo, Rushabh Shah, Nishank Shah, and Sindhu Nair. 2022. Easier Web Navigation Using Intent Classification, Web Scraping and NLP Approaches. In 2022 5th International Conference on Advances in Science and Technology (ICAST). 286–290. https://doi.org/10.1109/ICAST55766.2022.10039559\n\nBhat et al. (2023) Advait Bhat, Saaket Agashe, Parth Oberoi, Niharika Mohile, Ravi Jangir, and Anirudha Joshi. 2023. Interacting with Next-Phrase Suggestions: How Suggestion Systems Aid and Influence the Cognitive Processes of Writing. In Proceedings of the 28th International Conference on Intelligent User Interfaces. 436–452.\n\nBhavya et al. (2023) Bhavya Bhavya, Jinjun Xiong, and Chengxiang Zhai. 2023. Cam: A large language model-based creative analogy mining framework. In Proceedings of the ACM Web Conference 2023. 3903–3914.\n\nBian et al. (2021) Yali Bian, Chris North, Eric Krokos, and Sarah Joseph. 2021."
    }
}