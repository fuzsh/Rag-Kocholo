{
    "id": "correct_subsidiary_00048_3",
    "rank": 19,
    "data": {
        "url": "https://dl.acm.org/doi/10.1145/3638246",
        "read_more_link": "",
        "language": "en",
        "title": "Test Generation Strategies for Building Failure Models and Explaining Spurious Failures",
        "top_image": "https://dl.acm.org/cms/asset/810d1627-25f6-4f0c-a42f-1e9a69963162/3613665.cover.jpg",
        "meta_img": "https://dl.acm.org/cms/asset/810d1627-25f6-4f0c-a42f-1e9a69963162/3613665.cover.jpg",
        "images": [
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-dl-logo-white-1ecfb82271e5612e8ca12aa1b1737479.png",
            "https://dl.acm.org/doi/10.1145/specs/products/acm/releasedAssets/images/acm-logo-1-ad466e729c8e2a97780337b76715e5cf.png",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/footer-logo1-45ae33115db81394d8bd25be65853b77.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/Default_image_lazy-0687af31f0f1c8d4b7a22b686995ab9b.svg",
            "https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81100370608&format=rel-imgonly&assetId=mauro.pezze.jpg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-dl-8437178134fce530bc785276fc316cbf.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-3-10aed79f3a6c95ddb67053b599f029af.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Search-based testing",
            "machine learning",
            "surrogate models",
            "failure models",
            "test-input validity",
            "and spurious failures"
        ],
        "tags": null,
        "authors": [
            "Canada https:",
            "orcid.org",
            "Baharin A. Jodat",
            "Abhishek Chandar",
            "Shiva Nejati",
            "Mehrdad Sabetzadeh",
            "JodatBaharin A"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Test inputs fail not only when the system under test is faulty but also when the inputs\nare invalid or unrealistic. Failures resulting from invalid or unrealistic test inputs\nare spurious. Avoiding spurious failures improves the effectiveness of testing ...",
        "meta_lang": "en",
        "meta_favicon": "/pb-assets/head-metadata/apple-touch-icon-1574252172393.png",
        "meta_site_name": "ACM Transactions on Software Engineering and Methodology",
        "canonical_link": "https://dl.acm.org/doi/10.1145/3638246",
        "text": "Abstract\n\nTest inputs fail not only when the system under test is faulty but also when the inputs are invalid or unrealistic. Failures resulting from invalid or unrealistic test inputs are spurious. Avoiding spurious failures improves the effectiveness of testing in exercising the main functions of a system, particularly for compute-intensive (CI) systems where a single test execution takes significant time. In this article, we propose to build failure models for inferring interpretable rules on test inputs that cause spurious failures. We examine two alternative strategies for building failure models: (1) machine learning (ML)-guided test generation and (2) surrogate-assisted test generation. ML-guided test generation infers boundary regions that separate passing and failing test inputs and samples test inputs from those regions. Surrogate-assisted test generation relies on surrogate models to predict labels for test inputs instead of exercising all the inputs. We propose a novel surrogate-assisted algorithm that uses multiple surrogate models simultaneously, and dynamically selects the prediction from the most accurate model. We empirically evaluate the accuracy of failure models inferred based on surrogate-assisted and ML-guided test generation algorithms. Using case studies from the domains of cyber-physical systems and networks, we show that our proposed surrogate-assisted approach generates failure models with an average accuracy of 83%, significantly outperforming ML-guided test generation and two baselines. Further, our approach learns failure-inducing rules that identify genuine spurious failures as validated against domain knowledge.\n\nReferences\n\n[1]\n\n(Accessed: June 2023). Autopilot Online Benchmark. Retrieved from https://www.mathworks.com/matlabcentral/fileexchange/41490-autopilot-demo-for-arp4754a-do-178c-and-do-331?focused=6796756&tab=model\n\n[2]\n\n(Accessed: June 2023). Benchmark for Simulink Models. Retrieved from https://github.com/anonpaper23/testGenStrat/tree/main/Benchmark/Simulink%20Models\n\n[3]\n\n(Accessed: June 2023). Code to Generate Results of each Research Questions. Retrieved from https://github.com/anonpaper23/testGenStrat/tree/main/Evaluation\n\n[4]\n\n(Accessed: June 2023). Code to SoTA Implementation for NTSS Case Study. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Code/NTSS/SoTA.py\n\n[5]\n\n(Accessed: June 2023). Code to SoTA Implementation for Simulink Model Case Study. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Code/Simulink/Algorithms/decisiontreeSoTA.m\n\n[6]\n\n(Accessed: June 2023). CPS and NTSS Requirements. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Benchmark/Formalization/CPS_and_NTSS_Formalization.pdf\n\n[7]\n\n(Accessed: June 2023). ENRICH – Non-robustnEss aNalysis for tRaffIC sHaping. Retrieved from https://github.com/baharin/ENRICH\n\n[8]\n\n(Accessed: June 2023). Figure 16 to Figure 21 – Precision and Recall Results Obtained by Varying Time Budget in RQ2. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[9]\n\n(Accessed: June 2023). Figure 9 – Comparing Dataset Sizes for Dynamic SA Algorithm and Seven Individual SA Algorithms in RQ1. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[10]\n\n(Accessed: June 2023). Lockheed Martin. Retrieved from https://www.lockheedmartin.com\n\n[11]\n\n(Accessed: June 2023). Logistic Regression. Retrieved from http://faculty.cas.usf.edu/mbrannick/regression/Logistic.html\n\n[12]\n\n(Accessed: June 2023). OpenWrt. Retrieved from www.openwrt.org\n\n[13]\n\n(Accessed: June 2023). Raw Datasets Obtained from each Algorithm for CPS and NTSS. Retrieved from https://github.com/anonpaper23/testGenStrat/tree/main/Data/Dataset\n\n[14]\n\n(Accessed: June 2023). Replication Package of Alhazen Framework. Retrieved from https://zenodo.org/records/3902142\n\n[15]\n\n(Accessed: June 2023). Results of each Research Question. Retrieved from https://github.com/anonpaper23/testGenStrat/tree/main/Evaluation%20Results\n\n[16]\n\n(Accessed: June 2023). Results of Statistical Analysis. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Evaluation%20Results/RQ2/RQ2StatisticalResults.xlsx\n\n[17]\n\n(Accessed: June 2023). Rules Obtained for each CI Subject. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Evaluation%20Results/RQ4/APandNTSS_Rules.xlsx\n\n[18]\n\n(Accessed: June 2023). Source Codes of Algorithms for CPS and NTSS. Retrieved from https://github.com/anonpaper23/testGenStrat/tree/main/Code\n\n[19]\n\n(Accessed: June 2023). Table 15 to Table 20 – Average Accuracy, Recall and Precision Over all Runs of Algorithms by Varying Execution Time Budget in RQ2. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[20]\n\n(Accessed: June 2023). Table 21 to Table 24 – Full Set of Rules Obtained for NTSS, AP1, AP2 and AP3 in RQ4. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[21]\n\n(Accessed: June 2023). Table 3 – Parameter Names, Descriptions and Values used by SoTA. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[22]\n\n(Accessed: June 2023). Table 5 – Time Budgets Given to Non-CI Subjects in RQ1. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[23]\n\n(Accessed: June 2023). Table 6 – Statistical Tests for Dataset Size and Percentage of Incorrect Labels Over Dataset Size in RQ1. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[24]\n\n(Accessed: June 2023). Table 7 – Time Budget Considered for CI Subjects in RQ2. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[25]\n\n(Accessed: June 2023). Table 8 – Maximum Number of Test Executions for Non-CI Subjects in RQ2. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[26]\n\n(Accessed: June 2023). Table 9 to Table 14 – Statistical Tests for Accuracy, Recall and Precision by Varying Execution Time Budget in RQ2. Retrieved from https://github.com/anonpaper23/testGenStrat/blob/main/Supplementary_Material.pdf\n\n[27]\n\n(Accessed: June 2023). tc-cake. Retrieved from https://man7.org/linux/man-pages/man8/tc-cake.8.html\n\n[28]\n\nYashwanth Annpureddy, Che Liu, Georgios Fainekos, and Sriram Sankaranarayanan. 2011. S-TaLiRo: A tool for temporal logic falsification for hybrid systems. In Proceedings of the Tools and Algorithms for the Construction and Analysis of Systems.Parosh Aziz Abdulla and K. Rustan M. Leino (Eds.), Springer, 254–257.\n\n[29]\n\nAitor Arrieta, Shuai Wang, Urtzi Markiegi, Ainhoa Arruabarrena, Leire Etxeberria, and Goiuria Sagardui. 2019. Pareto efficient multi-objective black-box test case selection for simulation-based testing. Information and Software Technology 114 (2019), 137–154.\n\n[30]\n\nAitor Arrieta, Shuai Wang, Urtzi Markiegi, Goiuria Sagardui, and Leire Etxeberria. 2017. Search-based test case generation for cyber-physical systems. In Proceedings of the 2017 IEEE Congress on Evolutionary Computation. IEEE, 688–697.\n\n[31]\n\nFederal Aviation Administration (FAA)/Aviation Supplies & Academics (ASA). 2009. Advanced Avionics Handbook. Aviation Supplies & Academics, Incorporated. Retrieved from https://books.google.lu/books?id=2xGuPwAACAAJ\n\n[32]\n\nCornelius Aschermann, Tommaso Frassetto, Thorsten Holz, Patrick Jauernig, Ahmad-Reza Sadeghi, and Daniel Teuchert. 2019. NAUTILUS: Fishing for deep bugs with grammars. In Proceedings of the NDSS.\n\n[33]\n\nOsbert Bastani, Rahul Sharma, Alex Aiken, and Percy Liang. 2017. Synthesizing program input grammars. ACM SIGPLAN Notices 52, 6 (2017), 95–110.\n\n[34]\n\nHalil Beglerovic, Michael Stolz, and Martin Horn. 2017. Testing of autonomous vehicles using surrogate models and stochastic optimization. In Proceedings of the 2017 IEEE 20th International Conference on Intelligent Transportation Systems. IEEE, 1–6.\n\n[35]\n\nRaja Ben Abdessalem, Shiva Nejati, Lionel C. Briand, and Thomas Stifter. 2016. Testing advanced driver assistance systems using multi-objective search and neural networks. In Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering. 63–74.\n\n[36]\n\nMarcel Böhme, Charaka Geethal, and Van-Thuan Pham. 2020. Human-in-the-loop automatic program repair. In Proceedings of the 2020 IEEE 13th International Conference on Software Testing, Validation and Verification. IEEE, 274–285.\n\n[37]\n\nCaius Brindescu, Iftekhar Ahmed, Rafael Leano, and Anita Sarma. 2020. Planning for untangling: Predicting the difficulty of merge conflicts. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering. 801–811.\n\n[38]\n\nDevendra K. Chaturvedi. 2017. Modeling and Simulation of Systems using MATLAB® and Simulink®. CRC press.\n\n[39]\n\nNitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. 2002. SMOTE: synthetic minority over-sampling technique. Journal of Artificial Intelligence Research 16 (2002), 321–357.\n\n[40]\n\nWilliam W. Cohen. 1995. Fast effective rule induction. In Proceedings of the Machine Learning Proceedings 1995. Elsevier, 115–123.\n\n[41]\n\nLeonardo De Moura and Nikolaj Bjørner. 2008. Z3: An efficient SMT solver. In Proceedings of the International Conference on Tools and Algorithms for the Construction and Analysis of Systems. Springer, 337–340.\n\n[42]\n\nPatricia Derler, Edward A. Lee, Stavros Tripakis, and Martin Törngren. 2013. Cyber-physical system design contracts. In Proceedings of the ACM/IEEE 4th International Conference on Cyber-Physical Systems. 109–118.\n\n[43]\n\nAlan Díaz-Manríquez, Gregorio Toscano, Jose Hugo Barron-Zambrano, and Edgar Tello-Leal. 2016. A review of surrogate assisted multiobjective evolutionary algorithms. Computational Intelligence and Neuroscience 2016 (2016), 14 Pages.\n\n[44]\n\nArkadiy Dushatskiy, Tanja Alderliesten, and Peter A. N. Bosman. 2021. A novel surrogate-assisted evolutionary algorithm applied to partition-based ensemble learning. In Proceedings of the Genetic and Evolutionary Computation Conference. 583–591.\n\n[45]\n\nRobert Feldt and Shin Yoo. 2020. Flexible probabilistic modeling for search based test data generation. In Proceedings of the 13th International Workshop on Search-Based Software Testing. 537–540.\n\n[46]\n\nMartina Friese, Thomas Bartz-Beielstein, and Michael Emmerich. 2016. Building ensembles of surrogates by optimal convex combination. Bioinspired Optimization Methods and their Applications (2016), 131–143.\n\n[47]\n\nKhouloud Gaaloul, Claudio Menghi, Shiva Nejati, Lionel C. Briand, and David Wolfe. 2020. Mining assumptions for software components using machine learning. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 159–171.\n\n[48]\n\nBaljinder Ghotra, Shane McIntosh, and Ahmed E. Hassan. 2015. Revisiting the impact of classification techniques on the performance of defect prediction models. In Proceedings of the 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering. IEEE, 789–800.\n\n[49]\n\nDimitra Giannakopoulou, Corina S. Pasareanu, and Howard Barringer. 2002. Assumption generation for software component verification. In Proceedings of the International Conference on Automated Software Engineering. IEEE, 3–12.\n\n[50]\n\nDimitra Giannakopoulou, Thomas Pressburger, Anastasia Mavridou, and Johann Schumann. 2021. Automated formalization of structured natural language requirements. Information and Software Technology 137 (2021), 106590. DOI:\n\n[51]\n\nRahul Gopinath, Alexander Kampmann, Nikolas Havrikov, Ezekiel O. Soremekun, and Andreas Zeller. 2020. Abstracting failure-inducing inputs. In Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis. 237–248.\n\n[52]\n\nKenneth V. Hanford. 1970. Automatic generation of test cases. IBM Systems Journal 9, 4 (1970), 242–257.\n\n[53]\n\nFitash Ul Haq, Donghwan Shin, Shiva Nejati, and Lionel Briand. 2021. Can offline testing of deep neural networks replace their online testing? A case study of automated driving systems. Empirical Software Engineering 26, 5 (2021), 90.\n\n[54]\n\nMark Harman, Sung Gon Kim, Kiran Lakhotia, Phil McMinn, and Shin Yoo. 2010. Optimizing for the number of tests generated in search based test data generation with an application to the oracle cost problem. In Proceedings of the 2010 3rd International Conference on Software Testing, Verification, and Validation Workshops. IEEE, 182–191.\n\n[55]\n\nMark Harman and Phil McMinn. 2009. A theoretical and empirical study of search-based testing: Local, global, and hybrid search. IEEE Transactions on Software Engineering 36, 2 (2009), 226–247.\n\n[56]\n\nThomas A. Henzinger, Shaz Qadeer, and Sriram K. Rajamani. 1998. You assume, we guarantee: Methodology and case studies. In Proceedings of the Computer Aided Verification: 10th International Conference, CAV’98 Vancouver, BC, Canada, June 28–July 2, 1998 Proceedings 10. Springer, 440–451.\n\n[57]\n\nToke Høiland-Jørgensen, Dave Täht, and Jonathan Morton. 2018. Piece of CAKE: A comprehensive queue management solution for home gateways. In Proceedings of the 2018 IEEE International Symposium on Local and Metropolitan Area Networks.IEEE, 37–42.\n\n[58]\n\nLinxiong Hong, Huacong Li, and Jiangfeng Fu. 2022. A novel surrogate-model based active learning method for structural reliability analysis. Computer Methods in Applied Mechanics and Engineering 394 (2022), 114835. DOI:\n\n[59]\n\nBoyue Caroline Hu, Lina Marsso, Krzysztof Czarnecki, Rick Salay, Huakun Shen, and Marsha Chechik. 2022. If a human can see it, so should your system: Reliability requirements for machine vision components. In Proceedings of the 44th International Conference on Software Engineering.Association for Computing Machinery, New York, NY, 1145–1156. DOI:\n\n[60]\n\nDmytro Humeniuk, Giuliano Antoniol, and Foutse Khomh. 2021. Data driven testing of cyber physical systems. In Proceedings of the 2021 IEEE/ACM 14th International Workshop on Search-Based Software Testing. IEEE, 16–19.\n\n[61]\n\nDmytro Humeniuk, Foutse Khomh, and Giuliano Antoniol. 2022. A search-based framework for automatic generation of testing environments for cyber-physical systems. Information and Software Technology 149 (2022), 106936.\n\n[62]\n\nYaochu Jin. 2005. A comprehensive survey of fitness approximation in evolutionary computation. Soft Computing 9, 1 (2005), 3–12.\n\n[63]\n\nYaochu Jin and Bernhard Sendhoff. 2002. Fitness approximation in evolutionary computation-a survey. In Proceedings of the GECCO. 1105–12.\n\n[64]\n\nBaharin A. Jodat, Shiva Nejati, Mehrdad Sabetzadeh, and Patricio Saavedra. 2023. Learning non-robustness using simulation-based testing: A network traffic-shaping case study. In Proceedings of the 2023 IEEE Conference on Software Testing, Verification and Validation. IEEE, 386–397.\n\n[65]\n\nAlexander Kampmann, Nikolas Havrikov, Ezekiel O. Soremekun, and Andreas Zeller. 2020. When does my program do this? learning circumstances of software behavior. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1228–1239.\n\n[66]\n\nCharaka Geethal Kapugama, Van-Thuan Pham, Aldeida Aleti, and Marcel Böhme. 2022. Human-in-the-loop oracle learning for semantic bugs in string processing programs. In Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis. 215–226.\n\n[67]\n\nFitsum Meshesha Kifetew, Roberto Tiella, and Paolo Tonella. 2017. Generating valid grammar-based test inputs by means of genetic programming and annotated grammars. Empirical Software Engineering 22, 2 (2017), 928–961.\n\n[68]\n\nNeil Kulkarni, Caroline Lemieux, and Koushik Sen. 2021. Learning highly recursive input grammars. In Proceedings of the 2021 36th IEEE/ACM International Conference on Automated Software Engineering. IEEE, 456–467.\n\n[69]\n\nJaekwon Lee, Seung Yeob Shin, Shiva Nejati, Lionel C. Bsriand, and Yago Isasi Parache. 2022. Estimating probabilistic safe WCET ranges of real-time systems at design stages. ACM Transactions on Software Engineering and Methodology 32, 2 (2022), 1–33.\n\n[70]\n\nSean Luke. 2013. Essentials of Metaheuristics (2nd. ed.). Lulu. Retrieved from http://cs.gmu.edu/sean/book/metaheuristics/\n\n[71]\n\nReza Matinnejad, Shiva Nejati, and Lionel C. Briand. 2017. Automated testing of hybrid Simulink/Stateflow controllers: Industrial case studies. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2017, Paderborn, Germany, September 4-8, 2017. ACM, 938–943.\n\n[72]\n\nPatrick E. McKnight and Julius Najab. 2010. Mann-Whitney U test. The Corsini Encyclopedia of Psychology (2010), 1–1.\n\n[73]\n\nClaudio Menghi, Shiva Nejati, Lionel Briand, and Yago Isasi Parache. 2020. Approximation-refinement testing of compute-intensive cyber-physical models: An approach based on system identification. In Proceedings of the 2020 IEEE/ACM 42nd International Conference on Software Engineering. IEEE, 372–384.\n\n[74]\n\nClaudio Menghi, Shiva Nejati, Khouloud Gaaloul, and Lionel C. Briand. 2019. Generating automated and online test oracles for simulink models with continuous and uncertain behaviors. In Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 27–38.\n\n[75]\n\nBarton P. Miller, Lars Fredriksen, and Bryan So. 1990. An empirical study of the reliability of UNIX utilities. Communication of the ACM 33, 12 (1990), 32–44.\n\n[76]\n\nChristoph Molnar. 2020. Interpretable Machine Learning. Lulu. com.\n\n[77]\n\nShiva Nejati, Khouloud Gaaloul, Claudio Menghi, Lionel C. Briand, Stephen Foster, and David Wolfe. 2019. Evaluating model testing and model checking for finding requirements violations in Simulink models. In Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1015–1025.\n\n[78]\n\nShiva Nejati, Lev Sorokin, Damir Safin, Federico Formica, Mohammad Mahdi Mahboob, and Claudio Menghi. 2023. Reflections on surrogate-assisted search-based testing: A taxonomy and two replication studies based on industrial ADAS and simulink models. Information and Software Technology 163 (2023), 107286.\n\n[79]\n\nAndrew Ng. 2018. Machine learning yearning. Retrieved from http://www.mlyearning.org/. Accessed June 2023.\n\n[80]\n\nRipon Patgiri, Hemanth Katari, Ronit Kumar, and Dheeraj Sharma. 2019. Empirical study on malicious URL detection using machine learning. In Proceedings of theInternational Conference on Distributed Computing and Internet Technology. Springer, 380–388.\n\n[81]\n\nVincenzo Riccio and Paolo Tonella. 2023. When and why test generators for deep learning produce invalid inputs: an empirical study. In IEEE/ACM 45th International Conference on Software Engineering (ICSE’23), IEEE, 1161–1173.\n\n[82]\n\nAlberto Sangiovanni-Vincentelli, Werner Damm, and Roberto Passerone. 2012. Taming Dr. Frankenstein: Contract-based design for cyber-physical systems. European Journal of Control 18, 3 (2012), 217–238.\n\n[83]\n\nAlexander Schaap, Gordon Marks, Vera Pantelic, Mark Lawford, Gehan Selim, Alan Wassyng, and Lucian Patcas. 2018. Documenting simulink designs of embedded systems. In Proceedings of the International Conference on Model Driven Engineering Languages and Systems Companion Proceedings. ACM, 47–51.\n\n[84]\n\nJasper Snoek, Hugo Larochelle, and Ryan P. Adams. 2012. Practical bayesian optimization of machine learning algorithms. Advances in Neural Information Processing Systems 25 (2012), 2960–2968.\n\n[85]\n\nRobert C. Streijl, Stefan Winkler, and David S. Hands. 2016. Mean opinion score (MOS) revisited: Methods and applications, limitations and alternatives. Multimedia Systems 22, 2 (2016), 213–227.\n\n[86]\n\nHao Tong, Changwu Huang, Leandro L. Minku, and Xin Yao. 2021. Surrogate models in evolutionary single-objective optimization: A new taxonomy and experimental study. Information Sciences 562 (2021), 414–437.\n\n[87]\n\nCumhur Erkan Tuncali, Georgios Fainekos, Danil Prokhorov, Hisahiro Ito, and James Kapinski. 2019. Requirements-driven test generation for autonomous vehicles with machine learning components. IEEE Transactions on Intelligent Vehicles 5, 2 (2019), 265–280.\n\n[88]\n\nAndrás Vargha and Harold D. Delaney. 2000. A critique and improvement of the CL common language effect size statistics of McGraw and Wong. Journal of Educational and Behavioral Statistics 25, 2 (2000), 101–132.\n\n[89]\n\nJunjie Wang, Bihuan Chen, Lei Wei, and Yang Liu. 2019. Superion: Grammar-aware greybox fuzzing. In Proceedings of the 2019 IEEE/ACM 41st International Conference on Software Engineering. IEEE, 724–735.\n\n[90]\n\nYan Wang, Peng Jia, Luping Liu, Cheng Huang, and Zhonglin Liu. 2020. A systematic review of fuzzing based on machine learning techniques. PloS One 15, 8 (2020), e0237749.\n\n[91]\n\nIan H. Witten, Eibe Frank, and Mark A. Hall. 2011. Data Mining: Practical Machine Learning Tools and Techniques (3rd. ed.). Morgan Kaufmann, Amsterdam. Retrieved from http://www.sciencedirect.com/science/book/9780123748560\n\n[92]\n\nHuanwei Xu, Xin Zhang, Hao Li, and Ge Xiang. 2021. An ensemble of adaptive surrogate models based on local error expectations. Mathematical Problems in Engineering 2021, Article ID 8857417 (2021), 14 pages.\n\nIndex Terms\n\nTest Generation Strategies for Building Failure Models and Explaining Spurious Failures\n\nComputing methodologies\n\nMachine learning\n\nMachine learning algorithms\n\nMachine learning approaches\n\nRule learning\n\nSoftware and its engineering\n\nSoftware creation and management\n\nSearch-based software engineering\n\nSoftware verification and validation\n\nEmpirical software validation\n\nRecommendations\n\nAchieving scalable mutation-based generation of whole test suites\n\nWithout complete formal specification, automatically generated software tests need to be manually checked in order to detect faults. This makes it desirable to produce the strongest possible test set while keeping the number of tests as small as ...\n\nA detailed investigation of the effectiveness of whole test suite generation\n\nA common application of search-based software testing is to generate test cases for all goals defined by a coverage criterion (e.g., lines, branches, mutants). Rather than generating one test case at a time for each of these goals individually, whole ...\n\nAn industrial evaluation of unit test generation: finding real faults in a financial application\n\nICSE-SEIP '17: Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track\n\nAutomated unit test generation has been extensively studied in the literature in recent years. Previous studies on open source systems have shown that test generation tools are quite effective at detecting faults, but how effective and applicable are ...\n\nInformation & Contributors\n\nInformation\n\nPublished In\n\n940 pages\n\nISSN:1049-331X\n\nEISSN:1557-7392\n\nDOI:10.1145/3613665\n\nEditor:\n\nMauro Pezzè\n\nUSI Università della Svizzera italiana and SIT Schaffhausen Institute of Technology, Switzerland\n\nIssue’s Table of Contents\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from [email protected].\n\nPublisher\n\nAssociation for Computing Machinery\n\nNew York, NY, United States\n\nPublication History\n\nPublished: 17 April 2024\n\nOnline AM: 21 December 2023\n\nAccepted: 08 December 2023\n\nRevised: 01 November 2023\n\nReceived: 15 June 2023\n\nPublished in TOSEM Volume 33, Issue 4\n\nCheck for updates\n\nAuthor Tags\n\nSearch-based testing\n\nmachine learning\n\nsurrogate models\n\nfailure models\n\ntest-input validity\n\nand spurious failures\n\nQualifiers\n\nResearch-article\n\nFunding Sources\n\nNSERC of Canada\n\nContributors\n\nOther Metrics\n\nBibliometrics & Citations\n\nBibliometrics\n\nArticle Metrics\n\n0\n\nTotal Citations\n\n208\n\nTotal Downloads\n\nDownloads (Last 12 months)208\n\nDownloads (Last 6 weeks)45\n\nOther Metrics\n\nCitations\n\nView Options\n\nGet Access\n\nLogin options\n\nCheck if you have access through your login credentials or your institution to get full access on this article.\n\nSign in\n\nFull Access\n\nView options\n\nPDF\n\nView or Download as a PDF file.\n\nPDF\n\neReader\n\nView online with eReader.\n\neReader\n\nFull Text\n\nView this article in Full Text.\n\nFull Text\n\nMedia\n\nFigures\n\nOther\n\nTables\n\nShare\n\nShare\n\nShare this Publication link\n\nCopied!\n\nCopying failed.\n\nShare on social media\n\nAffiliations\n\nBaharin A. Jodat\n\nUniversity of Ottawa, Ottawa, Canada\n\nAbhishek Chandar\n\nUniversity of Ottawa, Ottawa, Canada\n\nShiva Nejati\n\nUniversity of Ottawa, Ottawa, Canada\n\nMehrdad Sabetzadeh\n\nUniversity of Ottawa, Ottawa, Canada\n\nRequest permissions Authors Info & Affiliations"
    }
}