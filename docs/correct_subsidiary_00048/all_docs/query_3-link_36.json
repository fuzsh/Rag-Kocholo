{
    "id": "correct_subsidiary_00048_3",
    "rank": 36,
    "data": {
        "url": "https://www.sigmetrics.org/sigmetrics2024/tutorials.html",
        "read_more_link": "",
        "language": "en",
        "title": "SIGMETRICS 2024",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.sigmetrics.org/sigmetrics2024/images/banner.jpeg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/MaximilienDreveton.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/DanielFigueiredo.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/JiamingXu.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/SophieYu.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/PrakirtJhunjhunwala.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/SushilVarma.png",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/SivaThejaMaguluri.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/AlainJean-Marie.png",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/EmmanuelHyon.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/IsaacGrosof.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/MichelDeLara.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/GeorgeIosifidis.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/NaramMhaisen.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/QiaominXie.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/YudongChen.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/AngelMerino.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/FranciscoCaravaca.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/AngelCuevas.png",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/RubenCuevas.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/TingHe.jpg",
            "https://www.sigmetrics.org/sigmetrics2024/images/tutorials_images/ChristinaLeeYu.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Annual Conference of the ACM Special Interest Group on Performance Evaluation",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Track 1\n\n↑\n\nTutorial T1.A: Network clustering: 50 years and still going!\n\nSpeakers: Maximilien Dreveton (EPFL, Switzerland), Daniel R. Figueiredo (UFRJ, Brazil)\n\nDuration: 3 hours\n\nSlides available here.\n\nAbstract: Networks are arguably the most fundamental model to represent relationships between objects and have been adopted by different disciplines to represent various systems and phenomena. From social networks that encode different interactions among people, to the power grid and the Internet that represents how electrons and bits are transferred, to the connectome and protein interaction networks that encode neural and protein activity in the brain and the cell, respectively. Finding sets of similar nodes in a network, known as network clustering or community detection, is one of the most fundamental problems in network analysis. In particular, node clusters often reveal different latent information such as node function or node type with applications in various domains. Not surprisingly, network clustering has been studied for over 50 years in various scenarios and approaches.\n\nMost advances within network clustering can be broadly categorized into either information-theoretic or algorithmic. The former is concerned with establishing conditions under which cluster detection is possible. This often requires a clean mathematical model for generating networks with clusters and provides thresholds (as a function of model parameters) for partial and exact recovery of the network clusters as the network grows large. Algorithmic advances are concerned with the design of algorithms that recover network clusters from data. To be useful, such algorithms must be efficient (in terms of computational complexity) and accurate (in terms of identifying network clusters).\n\nMotivated by the increasing amounts of data, nodes, and edges of modern networks often have various attributes that significantly enhance the information encoded by the network (much beyond just the network structure). This relatively recent observation has led to novel advances in information-theoretic and algorithmic results further broadening the problem of network clustering.\n\nThis tutorial provides a comprehensive overview of network clustering over the past 50 years, covering fundamental information-theoretic and algorithmic results. Theoretical thresholds for partial and exact recovery of clusters in the classic Stochastic Block Model and in the more recent Contextual Stochastic Block Model (that handles attributes) will be presented. Classic algorithms based on spectral methods, statistical inference, modularity-maximization, and more recent algorithms that leverage Graph Neural Networks, will also be presented. The tutorial will also provide an outlook for topics not covered, such as overlapping communities and evolving communities\n\nSpeakers biographies:\n\n↑\n\nTutorial T1.B: Fundamental Limits and Efficient Algorithms for Random Graph Matching\n\nSpeakers: Jiaming Xu (Duke University, USA) and Sophie H. Yu (Stanford University, USA)\n\nJiaming Xu will conduct the tutorial as Sophia H. Yu is not able to travel to Italy, the duration of the tutorial has been reduced. Sorry for the inconvenience.\n\nDuration: 3 hours 1.5 hours\n\nSlides available here.\n\nAbstract: Random graph matching aims to recover the hidden vertex correspondence between two random graphs whose edges are correlated. This is a ubiquitous problem arising in various applications across diverse fields such as network privacy, computational biology, computer vision, and natural language processing. The problem is also deep and rich in theory, involving the delicate interplay of information-theoretic limits, algorithms, and computational complexity. Recently, exciting progress has been achieved in matching two correlated Erdös–Rényi graphs, thanks to collective efforts from multiple research communities including information theory, probability, and optimization. This tutorial will present an overview of the information-theoretic recovery thresholds for matching correlated Erdös–Rényi graphs and efficient algorithms with near optimality both statistically and computationally. Various open problems and important future directions will be discussed along the way.\n\nSpeakers biographies:\n\nTrack 2\n\n↑\n\nTutorial T2.A: Transform Method for Stochastic Processing and Matching Networks\n\nPrakirt Jhunjhunwala (Columbia Business School, USA), Sushil Mahavir Varma (Georgia Tech, USA), Siva Theja Maguluri (Georgia Tech, USA)\n\nPrakirt Jhunjhunwala and Sushil Mahavir Varma will conduct the tutorial as Siva Theja Maguluri is not able to travel to Italy.\n\nDuration: 3 hours\n\nSlides available here (zip archive).\n\nAbstract: Motivated by real-world applications in data centers and online marketplaces, this tutorial delves into the design and performance of stochastic processing and matching networks. Our focus centers on congestion or queue length behavior, e.g., jobs waiting for processing at a data center or customers waiting for a taxi in ride-hailing systems. In this tutorial, we present the recently developed Transform method, a methodology to systematically characterize the steady-state queue length distribution across various asymptotic and non-asymptotic regimes.\n\nThe idea of the transform method is to analyze the drift of a carefully constructed exponential test function in the steady state. The resultant equation can then be solved to obtain an approximate closed-form expression of the transform of the queue lengths. Such a result allows us to obtain queue length distribution in various asymptotic regimes as well as tight bounds on queue length statistics like the mean and tail in non-asymptotic regimes. While the framework of the transform method remains invariant to the application, a careful adaptation is warranted. For example, the test function needs to be tailored to capture the underlying system dynamics, and solving the resultant equation requires novel ideas. To this end, we demonstrate the versatility of the method by analyzing a wide variety of stochastic processing and matching networks like load balancing systems, input-queued switches, and matching queues, endowed with features like customer abandonment, multiple bottlenecks, and surge pricing respectively. In doing so, the transform method opens new frontiers in the analysis of stochastic networks and we hope this tutorial will enable us to inspire fellow researchers to consider adopting and further developing this methodology.\n\nSpeakers biographies:\n\n↑\n\nTutorial T2.B: An introduction to pyMarmote and pyMarmoteMDP for Markovian modeling\n\nSpeakers: Alain Jean-Marie (Inria, France) and Emmanuel Hyon (Paris Nanterre University, France)\n\nDuration: 1.5 hours\n\nSlides available here\n\nMarmote tool is available here.\n\nAbstract: Markov Chain modeling and optimization with Markov Decision Processes are classical activities in the SIGMETRICS and PERFORMANCE communities and in several fields of science: Stochastic Operations Research, Performance Evaluation, Performability, Machine Learning, but also Statistical Physics, BioInformatics etc. Many packages for solving Markov chains (or higher-level descriptions involving them, like Queueing Networks, Petri Nets, Stochastic Algebras) have been proposed in the past. Yet, modelers still resort mostly to direct programming in their favorite language. Programming the solution of Markov models from scratch is typically a time-consuming and error-prone activity.\n\nThe intention of Marmote is to ease up the work of Markov modelers by providing an easy-to-use yet numerically efficient modeling environment. For this reason, it has been programmed in C++ but has been endowed with a Python user interface. The tutorial will provide an introduction to the capabilities of software environment Marmote via its Python interface: pyMarmote/pyMarmoteMDP.\n\nMarmote is a programming library for modeling with Markov chains, analyzing and \"solving\" these chains. It provides the objects for building continuous-time and discrete-time Markov chains on discrete but possibly complicated state spaces. Once defined, Markov chains can be analyzed with a variety of methods, including structural analysis, Monte-Carlo simulation and numerical solution for criteria such as transient and stationary distributions, or average hitting times. The extension MarmoteMDP provides a library for modeling with Markov Decision Processes. It provides algorithms for numerically determining optimal policies for all classical optimization criteria. It also features capabilities for the structural analysis of the resulting policies and value functions.\n\nThe presentation will consist of showing how to use Marmote in a series of thematic Python notebooks. These notebooks will be shared so as to allow motivated attendants to practice themselves.\n\nSpeakers biographies:\n\n↑\n\nTutorial T2.C: Analyzing Queues with Markovian Arrivals and Markovian Service\n\nSpeaker: Isaac Grosof (University of Illinois, Urbana-Champaign, USA)\n\nDuration: 1.5 hours\n\nSlides available here\n\nVideo recording available here.\n\nAbstract: Queueing analysis focuses on settings with i.i.d. interarrival times and service durations. Many real systems are not captured by these models. Real systems have varying rates. More generally, real systems have correlated arrival and service patterns. Components fail, demand surges, and networks experience congestion.\n\nThis tutorial will teach about a highly general model for fluctuating arrival and service rates known as the MAMS queue, a single-server queue where arrival rate and service rate each fluctuate according to a general finite-state Markov chain. This model is flexible enough to capture a wide range of applications that may be of interest to attendees.\n\nThe tutorial will teach about the Relative Arrivals for Drift (RAD) method for analyzing the MAMS system. Attendees will learn how to use RAD analysis to prove closed-form, explicit bounds on performance measures such as mean queue length in MAMS models which arise from practical applications. These bounds also provide tight characterizations of the heavy-traffic behavior of the system. RAD overcomes limitations from prior approaches to analyzing the MAMS system, where results were too complicated or too computational to provide analytic insight. RAD captures the effects of fluctuations of arrival and service rate in a concise, analytically-tractable fashion, providing a new way to think about the MAMS system.\n\nThe tutorial will be highly interactive, helping attendees to engage with the material and internalize RAD analysis.\n\nSpeakers biography:\n\nTrack 3\n\n↑\n\nTutorial T3.A: Games in Product Form\n\nSpeaker: Michel De Lara (École des Ponts ParisTech, France)\n\nDuration: 3 hours\n\nSlides available here.\n\nAbstract: Game theory offers a mathematical formalism to study strategic interactions. In such models of competition, information (who knows what and before whom) plays a crucial role. In the fifties, H. W. Kuhn used trees to define a game in extensive form (GEF); in a GEF, the information of a player is represented by a partition of the player node moves. In the seventies, H. S. Witsenhausen used agents, a product set and a product sigma-field to define the so-called intrinsic model (IM) in multi-agent stochastic control problems; in an IM, the information of an agent is represented by a subfield of the product sigma-field. In this tutorial, we introduce games in product form (GPF) as an alternative (based on IM) to GEF. In the first hour, we present the Witsenhausen intrinsic model, with many illustrations. We also discuss classification of information structures and the potential for decomposition, be it hierarchical or parallel, with respect to subgroups of agents. In the second hour, we advocate the relevance of GPF for game theory by providing a case of game form that is playable, but that cannot be written on a tree, illustrating with examples the easiness and flexibility of GPF to model games (Alice and Bob, principal-agent models), and discussing how to represent stochastic and Bayesian games inside the GPF formalism. In the third hour, we provide a definition of perfect recall, of behavioral strategies \"à la Aumann\" and we prove a Kuhns Equivalence Theorem for GPF.\n\nSpeakers biography:\n\n↑\n\nTutorial T3.B: Optimistic Learning for Resource Management in Communication Systems\n\nSpeakers: George Iosifidis (TU Delft, The Netherlands; Amazon), Naram Mhaisen (TU Delft, The Netherlands)\n\nDuration: 1.5 hours\n\nSlides available here.\n\nAbstract: The ever-growing complexity of communication systems, coupled with the increasingly-stringent KPIs of the offered services, call for a new generation of resource management (RM) tools that are both principled and practical. Today, a vast range of such tools are built using Deep Learning (DL) and are proved to be extremely effective if there are sufficient representative training data. At the same time, a parallel research thrust relies on online learning algorithms that turn runtime observations into resource control decisions and promise robust, alas conservative, performance guarantees. These two orthogonal approaches come with their own advantages and disadvantages, and as such fail to serve as an effective and versatile resource management toolbox.\n\nIn this tutorial we will present a best-of-both-worlds solution based on optimistic learning. The premise of OL is simple and intuitive: leverage any available predictions about the future system\n\nstate, environment conditions or user demands, to improve the performance of online learning algorithms. The ultimate goal of OL is to expedite the learning convergence when the predictions are accurate, while maintaining the worst-case bounds of the legacy learning algorithms, when the predictions fail. OL is particularly promising for communication systems where typically one has access to past observations without, however, knowing in advance their relevance to the yet-to-be-seen conditions/scenarios. Therefore, OL has the potential to mitigate the lack of guarantees and the (often) detrimental performance of DL-based tools while overcoming the unnecessary slow convergence of legacy online learning algorithms, enabling eventually the robust and interpretable performance of communication systems.\n\nThe tutorial will start by tracing the origins of OL in machine learning optimization and introducing the basic principles and main results of OL for convex optimization problems. Next, it will focus on commonly-encountered non-convex problems and explain how OL can be extended to these more intricate scenarios. The last part will present how OL can be used to optimize stateful systems and systems/KPIs with memory effects. The theoretical results will be tied to representative, classical and new, resource management (RM) problems in caching, edge computing, slicing and load-balancing.\n\nSpeakers biographies:\n\n↑\n\nTutorial T3.C: Distributional Analysis of Stochastic Algorithms\n\nSpeakers: Qiaomin Xie (University of Wisconsin-Madison), Yudong Chen (University of Wisconsin-Madison)\n\nThe speakers are not able to travel to Italy, the tutorial is therefore canceled.\n\nSorry for the inconvenience.\n\nDuration: 1.5 hours\n\nAbstract: Stochastic algorithms power modern machine learning and optimization. They instantiate as stochastic gradient descent for loss minimization, stochastic descent-ascent for min-max optimization, TD/Q-Learning for reinforcement learning, stochastic approximation for fixed-point problems, and methods for stochastic Variational Inequalities. Together with their many variants, these algorithms become increasingly vital in todays large-scale problems with finite noisy data. It is of imminent interest to obtain fine-grained characterization of stochastic algorithms and enhance their sample and computational efficiencies.\n\nTraditionally, stochastic algorithms are treated as the noisy versions of their deterministic counterparts, viewing their stochasticity as a nuisance. Prior work thus focuses on controlling the stochastic fluctuation of the iterates, both in terms of algorithm design (e.g., use of diminishing stepsizes) and analysis (e.g., bounding mean squared errors). A recent line of work deviates from the above paradigm and embraces the probabilistic behavior of stochastic algorithms. By viewing the iterate sequence as a stochastic process, its distribution can be studied using modern tools from Markov chain and stochastic analysis, which provides fine-grained characterization of the behaviors of the algorithms.\n\nIn this tutorial, we will present an overview of these new techniques and results for distributional analysis of stochastic algorithms. Three main ingredients of this approach will be covered. (1) Establishing finite-time distributional convergence of the iterates and relating their ergodicity properties to the characteristics of the problem instance, algorithm and data. (2) Characterization of the steady-state distribution of the iterates using the techniques of coupling and basic adjoint relationship. (3) Leveraging the precise probabilistic characterization for stepsize scheduling, variance reduction, bias refinement and efficient statistical inference. Our focus will be on the constant stepsize paradigm popular among practitioners, and emphasize disentangling the deterministic and stochastic behaviors of the algorithms as well as their transient and long-run behaviors. We will cover both background and the fundamental, state-of-the-art results, and applications in concrete optimization and RL problems. Open issues and potential future directions will also be discussed.\n\nSpeakers biographies:\n\nTrack 4\n\n↑\n\nTutorial T4.A: Unveiling privacy and data protection issues from the use of social media and online advertising platforms\n\nSpeakers: Ángel Merino (Universidad Carlos III de Madrid, Spain), Francisco Caravaca (Universidad Carlos III de Madrid, Spain), Ángel Cuevas (Universidad Carlos III de Madrid, Spain), Rubén Cueva (Universidad Carlos III de Madrid, Spain)\n\nDuration: 3 hours\n\nSlides available here.\n\nSocial Media platforms on the Internet are a huge source of information, often very useful for research purposes. An important part of these platforms is their advertising ecosystem, as these platforms rely on obtaining information from their users to offer advertisers accurate user targeting based on that information. Therefore, we have leveraged the automatic collection of data to conduct different research works related to user privacy on these platforms, such as user uniqueness and overprofiling. In this tutorial, you will learn how to face the process of obtaining information from different types of online services by automatic means, and how this information is useful for researching. We will combine a presentation of the contents, context, and our research with practical parts in which the audience will learn how we extract the specific data needed for our research analysis in an automated way, using their own Facebook and LinkedIn accounts and Python programming language to build the scripts. We will provide snippets of code in a Jupyter Notebook to work over them. Thus, the intended audience is people with knowledge of some programming language, preferably Python, and with an interest in social media, user privacy, and automated data extraction.\n\nSpeakers biographies:\n\n↑\n\nTutorial T4.B: A Comprehensive Overview of Network Tomography: Inverse Methods for Network State Monitoring from End-to-End Measurements\n\nSpeaker: Ting He (Pennsylvania State University, USA)\n\nDuration: 1.5 hours\n\nSlides available here.\n\nAbstract: Network state information (e.g., topology, link delays/loss rates) is needed for a number of management functions at network layer and above. However, the traditional ways of obtaining this information require either administrative access to the control plane (e.g., via SNMP or OpenFlow) or cooperation from internal nodes (e.g., via traceroute). In this tutorial, I will give an overview of an inference-based approach for obtaining network state information based on end-to-end measurements in the data plane, known as network tomography. As a field, network tomography dated back to 1999, and has evolved into a broad family of inversion problems including (i) network performance tomography, which aims at inferring the performance states of links from the performance measurements on selected paths, (ii) network topology tomography, which aims at jointly inferring the (routing) topology and the performance states of links from the performance measurements on paths between selected vantage points, and (iii) traffic matrix tomography, which aims at inferring the flow rates between given ingress/egress points from the aggregate rates measured at selected links. I will review all these problems, with focus on network performance tomography and network topology tomography, both about inferring network internal state from end-to-end measurements. The tutorial will cover the basic ideas in addressing each problem, the state-of-the-art solutions, the theoretical conditions for guaranteed accuracy, as well as the limitations of each approach. I will conclude the tutorial with an example of how the inferred information can facilitate upper-layer applications in the context of overlay networks, and an outlook of the directions of future research.\n\nSpeakers biography:\n\n↑\n\nTutorial T4.C: Causal Inference in Complex Systems with Network Interference and Temporal Dynamics\n\nSpeaker: Christina Lee Yu (Cornell University, USA)\n\nDuration: 1.5 hours\n\nSlides available here.\n\nAbstract: Randomized experiments are widely used to evaluate new policies or proposed \"treatments\" in domains spanning the physical and biological sciences, social sciences, engineering, medicine and health, as well as in public service domains and the technology industry. However, classical approaches to experimental design rely on critical independence assumptions that are violated in systems with network interactions or temporal dynamics. In this tutorial, we will introduce the challenges of causal inference under network interference and temporal dynamics and survey the different approaches proposed in the literature to account for such dependencies, highlighting ongoing open questions in the field.\n\nSpeakers biography:"
    }
}