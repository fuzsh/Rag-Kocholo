Lessons from the Microsoft Research India Lab (MSR) that could apply to the broader ecosystem of startups include hiring exceptional people and giving them the elbow room to work their magic. At the same time, ensuring useful feedback from peers within the organisation and the broader scientific community has made the difference, Sriram K Rajamani, corporate VP and managing director, tells Forbes India. Edited excerpts:

Q. Give us a sense of the research work that’s come out of this centre over the years.

Our research journey has been remarkable. Some of the hypotheses we formulated two decades ago still hold true today, alongside significant refinements and shifts. I can delve into both the constants and changes within our work.

One enduring area of our focus has been the mathematical foundations of computing, particularly algorithms and complex theoretical problems. Since the inception of our lab, we’ve been deeply engaged in advancing this domain, leveraging India’s strong tradition in theoretical computer science.

Our centre has achieved breakthroughs in tackling some long-standing open problems. One example is the work done by Nikhil Srivastava, a former colleague, on the Kadison-Singer Conjecture, bridging the realms of physics and computer science. He’s now continuing his career at Berkeley.

Another example involves the elucidation of theoretical properties in k-means clustering, a foundational technique in machine learning. This was led by our colleague Ravi Kannan, who established our theory group. These accomplishments exemplify our lab’s intellectual contributions in solving algorithmically challenging problems persisting over decades.

Beyond theoretical foundations, our exploration extended into machine learning, specifically in the field of extreme classification. This research area addresses the classification of vast categories, ranging from documents to advertisements, a feat crucial in diverse applications such as content classification and targeted advertising.

Moreover, we’ve been at the forefront of addressing contemporary challenges like data privacy regulations through initiatives such as DataMap. This project advanced how we manage and comply with stringent data privacy laws, akin to taking inventory of household belongings to comply with regulations.

Further, our innovations have extended into practical applications like HAMS (harnessing automobiles for safety), where we utilised inexpensive smartphones to enhance road safety monitoring. By integrating video feeds and onboard sensors, we devised a system to assess driver behaviour and adherence to safe driving practices.

In addition to these achievements, our lab has made significant strides in optimising cloud infrastructure efficiency, improving software quality and improving the efficiency of the use of expensive resources such as GPUs for enhanced computational performance.

We have also done work on tuberculosis TB) medication adherence, how to use technology to help manage the treatment of TB for the entire spectrum.

In essence, our research spans a wide spectrum of endeavours, from fundamental theoretical breakthroughs to impactful applications in machine learning, data privacy, road safety, and infrastructure efficiency, each contributing to advancements in their respective fields.

Also read: Deeptech in India will be a multi-decade journey: Rajan Anandan

Q. Artificial intelligence (AI) is now a household term, since the advent of LLMs generative AI. Can you tell us about work at the centre in some of these areas?

Machine learning and deep learning have been evolving for many decades, but the recent advancements in large language models (LLM) have astonished even experts. Over the past four to five years, the progress has been substantial.

Previously, developing deep learning systems required building separate models for each specific task, whether it was image classification or language translation. The emergence of LLMs, however, has changed the game. These models, pre-trained on vast amounts of internet data, can now tackle multiple problems across various domains simultaneously. This capability represents the core of the current revolution in machine learning.

Before this advancement, implementing machine learning applications required substantial investments in talent, resources, and data collection, limiting accessibility to a select few. LLMs democratise this process by allowing broader access to sophisticated machine learning capabilities.

Now deploying these models for specific applications is more accessible and less resource-intensive. Moreover, interacting with these models has become more intuitive—you can communicate with them directly using natural language, eliminating the need for specialised programming skills.

In essence, the advent of LLMs marks a significant shift towards democratising machine learning, making its powerful applications accessible to a wider audience and simplifying its integration into diverse practical scenarios.

Q. Can you tell us a bit more about how you’d look at extending the benefits of these more recent advances to non-English-speaking communities?

One fascinating aspect of non-English languages in relation to LLMs is their diversity and multimodality. While major languages like English, German, Spanish and Chinese dominate internet content, Indian languages such as Hindi, Tamil, and Telugu also have significant but varied amounts of content available. Smaller languages like Konkani or Marathi, however, often lack extensive digital content.

LLMs demonstrate the ability to understand and operate across different languages, albeit with varying proficiency depending on data availability. They leverage their training across multiple languages to transfer knowledge effectively, requiring a critical mass of data rather than an equivalent volume to English. This capability is crucial for our lab’s efforts in adapting LLMs for Indian languages, ensuring cultural appropriateness and effectiveness.

A notable project we are engaged in, Shiksha copilot, in collaboration with an organisation called Sikshana Foundation, in Bengaluru, exemplifies our focus. This initiative aids government school teachers in creating lesson plans in local languages like Kannada.

By integrating curriculum and textbooks from the Karnataka State Board, we ensure the quality and relevance of generated content while leveraging our expertise in language-specific data requirements and evaluation.

Q. In computer science, are there techniques to generate useful content like this, irrespective of the language?

Sure... let me tell you about embeddings. Embeddings are a pivotal concept in today’s deep learning landscape, particularly in how they revolutionise information retrieval compared to older methods like inverted indices used in traditional search engines.

In the past, search engines relied on building inverted indices to match specific terms across documents, such as finding documents containing both say, ‘Sachin Tendulkar’ and ‘Mumbai’. However, these methods couldn’t inherently recognise semantic relationships like ‘Mumbai’ and ‘Bombay’ as the same concept.

In contrast, deep neural networks use embeddings, which are internal representations of documents, videos or audio in a high-dimensional space. Each item is mapped to a specific point in this space, with similar items positioned closer together. For example, Mumbai and Bombay would map to nearby points, indicating their semantic equivalence.

Our lab has pioneered advancements in this field through projects like diskANN, a trillion-scale vector index designed to efficiently retrieve embeddings. This technology has been adopted in both academic and industrial circles, including by Microsoft for products like Opus, demonstrating its broad impact and utility in building sophisticated search and retrieval systems.

This work underscores our commitment to advancing the capabilities of deep neural networks in understanding and leveraging semantic relationships across vast datasets, transforming how information is processed and accessed in the modern era of AI and machine learning.

Q. What would you consider as deeptech in India?

In India’s tech evolution, we initially focussed on service-based solutions using Western technology. However, a significant shift occurred as we began creating startups tailored for our own market needs, innovating technology solutions for our vast population.

Projects like diskANN, originating in our lab, highlight this transformation, where Indian-origin technologies are not only used locally but also globally. This shift signifies India’s progression from technology consumers to originators, leveraging our growing expertise in indigenous science and technology.

This evolution marks a pivotal moment where India is increasingly recognised as a global producer of cutting-edge technological solutions.

Also read: 15-year funds have to emerge for deeptech in India: Blume Ventures' Arpit Agarwal

Q. Where would you place the Indian deeptech ecosystem in terms of its capabilities and maturity?

I’ve witnessed a significant evolution in India’s scientific contributions, particularly in deeptech fields. Papers originating from labs like ours, at IISc are now integral to courses at prestigious universities like Stanford and MIT. This shift marks India’s emergence as a global idea generator in computing and science. While we celebrate this recognition, the next phase involves translating these ideas into tangible products, either locally or internationally.

In India, unique challenges foster innovation geared towards cost-efficiency and resilience in the face of systemic failures. This approach not only shapes our domestic solutions but also makes them relevant globally. There are significantly many more specialists in deeptech fields in India today than when I returned in 2006. However, despite the increasing quality of deeptech talent, the quantity remains a challenge relative to India’s vast size.

We’re actively addressing this gap through educational initiatives, PhD supervision, and collaborations across universities, aiming to cultivate a larger pool of skilled professionals capable of driving future advancements in deep tech.

Our commitment to teaching and mentoring reflects our dedication to nurturing a thriving scientific community, essential for realising India’s potential as a powerhouse of innovation in the global landscape.

Q. What are some of the learnings from the success of MSR India that can be applied to develop the broader deeptech ecosystem in India?

As an organisation, firstly, prioritising the hiring of exceptionally talented individuals has been foundational. We’ve learnt that investing time in selecting high-calibre people is vital for long-term success. Second, providing these individuals with the autonomy and resources to tackle challenging problems, such as the Kadison-Singer conjecture and extreme classification, has been pivotal.

Initially, the outcomes of these projects were uncertain, but by trusting our team’s expertise and passion, we allowed them to drive our research agenda independently.

Fostering an environment of continuous peer feedback has been instrumental. By engaging with both internal colleagues and the global scientific community through publications and collaborations, we ensure rigorous evaluation and improvement of our ideas.

Encouraging our scientists not only to publish papers but also to translate their ideas into practical systems and deploy them in real-world settings has been transformative. This approach has created a feedback loop where innovations are refined based on real-world outcomes, reinforcing our commitment to pushing the boundaries of scientific knowledge and solving significant challenges.

For our community, whether at places like IISc or within startups, the number one thing we need is patience. We need high-quality people and we need patience so that we don’t look for what we can just build in three months or six months. If you do that, you will only skim the surface. So we have to give ourselves that grace.