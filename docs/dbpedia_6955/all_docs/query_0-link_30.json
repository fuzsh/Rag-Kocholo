{
    "id": "dbpedia_6955_0",
    "rank": 30,
    "data": {
        "url": "https://medium.com/%40dhiraj.sapkal/goodbye-gui-hello-text-824b6bfb0fab",
        "read_more_link": "",
        "language": "en",
        "title": "Goodbye GUI, hello text",
        "top_image": "https://miro.medium.com/v2/resize:fit:500/0*Sd1WhMG5keOQJxxh.jpg",
        "meta_img": "https://miro.medium.com/v2/resize:fit:500/0*Sd1WhMG5keOQJxxh.jpg",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:144:144/1*dmbNkD5D-u45r44go_cf0g.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Dhiraj Sapkal",
            "medium.com",
            "@dhiraj.sapkal"
        ],
        "publish_date": "2016-11-21T04:34:43.015000+00:00",
        "summary": "",
        "meta_description": "You just got a text from your old friend, looks like they’re planning to meet for lunch on the 12th of next month. What do you do? Do you go to your calendar, navigate to the 12th of the next month…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19",
        "meta_site_name": "Medium",
        "canonical_link": "https://medium.com/@dhiraj.sapkal/goodbye-gui-hello-text-824b6bfb0fab",
        "text": "You just got a text from your old friend, looks like they’re planning to meet for lunch on the 12th of next month. What do you do? Do you go to your calendar, navigate to the 12th of the next month, create a new event, fill in the details and save? Well you might, I wouldn’t. It’s 2016, I would rather tell my phone “I’m meeting David for lunch on the 12th, next month” and have my phone figure out the rest. From selecting a place, booking a table to creating an event on my calendar. Maybe even share the event with said friend. This is conversational UI, and it is going to be the way we interface with computers in the near future. Leave photoshop behind, the future looks like it’s going back to text editors.\n\nYes text editors! More specifically, command line. Before the advent of GUIs, text editors were the only means for a human to interact with a computer. You issue a bunch of commands, and watch the computer interpret and execute those commands. But there was a problem. The computer couldn’t understand our language, and therefore we had to communicate in a language that the computer would understand. Code. This is where GUIs came in\n\nA Graphic user interface (GUI), uses graphics, rich typography, iconography and colors to make the interface familiar, and easier to understand and therefore, use. We know that a hamburger icon means there’s a menu out there. Or the shiny red button in the middle of the screen which instantly grabs my attention and makes me want to click it. A GUI is familiar and is the UX designer’s bread and butter.\n\nGUIs were introduced way back in 1973 by the good chaps at Xerox. It was in response to the steep learning curve that command line interfaces had. GUIs made it easier for everyone else to use a computer without having to learn command line. All the commands were now represented visually to the user, allowing them to be more productive without having to worry about syntax. This led to computers becoming more mainstream, and they made their way into our homes, and our hearts.\n\nText based input didn’t disappear though. It stuck around, in the form of chat, and remained the main way to interact with other humans using computers over the internet.\n\nSo what’s wrong? Well, computers are faster now, and smaller. We have come to rely on our mobile phones for many of our daily tasks. They’re nothing but computers, really tiny ones that you can carry and watch cat videos on. They have pushed GUIs to the limit, because of the restricted screen space. Responsive design can only go so far until the user flow starts to look like a maze. What if you took the user out of the user flow? what if you could just express what you want to do through a conversation, and have the software understand your intent and go through the “user flow” for you?\n\nwith the advent of artificial intelligence and natural language processing, you could say the computer is almost able to understand our language. Instead of humans having to learn the computer’s language, the computer is learning ours. And that’s amazing! Take Google’s Personal Assistant for instance. It has no interface, no hamburger menu, no settings icon, nothing. It relies solely on audio and text based inputs. Right now, I can ask Google Assistant for directions, check emails, look up restaurants or even call grandma. And it feels so intuitive. When I was a child, I was fascinated by the cartoon “Dexter’s Laboratory” . Dexter had this supercomputer, and he would always talk to it. He would tell her his plans, and she would oversee the execution. She had a sense of humor, a personality… They were a team! That was how the animators had dreamt the future of computing would be. At it looks like it’s finally going to happen!\n\nRight now though robots are limited in terms of what they can do. Statements that are sarcastic or nuanced are still quite difficult for them to interpret with complete accuracy. Despite that, they can already do some pretty cool things. Take KLM for example. A new service used by the Dutch airline, Uses a plugin for Facebook messenger, allowing customers to receive flight documentation directly via messenger. They receive reminders about their flights, check in information, even updates about delays. All through one chat.\n\nApps like these are essentially mini applications running behind the scene, controlled by a conversation. Using chat to figure out a user’s intent, the application itself can trigger the appropriate flow.\n\nAnd this is where it gets tricky. Our regular UI tricks won’t work here. There’s no interface to work with. The key then is to keep the conversation going. The user needs to be assured that they’re not alone. And the conversation needs to flow as naturally as possible. Maybe the user doesn’t need to trigger the app to engage with it. The app could start the conversation, and it is up to the user to keep the conversation going. The possibilities are endless, and the future looks promising. AI is getting smarter, and there may be a time when we could have real virtual assistants in our pockets, ready to do everything from scheduling your day to buying cat food, when it knows you’re running out. Before they take over the planet and enslave the human race, that is."
    }
}