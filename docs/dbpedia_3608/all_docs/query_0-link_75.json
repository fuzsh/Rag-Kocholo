{
    "id": "dbpedia_3608_0",
    "rank": 75,
    "data": {
        "url": "https://docs.redpanda.com/redpanda-connect/configuration/unit_testing/",
        "read_more_link": "",
        "language": "en",
        "title": "Redpanda Connect",
        "top_image": "https://docs.redpanda.com/_/img/Redpanda_Favicon_32px.svg",
        "meta_img": "https://docs.redpanda.com/_/img/Redpanda_Favicon_32px.svg",
        "images": [
            "https://docs.redpanda.com/_/img/redpanda-docs-logo-white.svg",
            "https://docs.redpanda.com/_/img/octicons-24.svg#view-sun",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://docs.redpanda.com/_/img/nav-tree-chevron.svg",
            "https://static.scarf.sh/a.png?x-pxid=d953010f-d7bf-4f8e-8598-92e78619fdda",
            "https://docs.redpanda.com/_/img/collapse-icon.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-08-13T00:00:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "../../../_/img/Redpanda_Favicon_32px.svg",
        "meta_site_name": "",
        "canonical_link": "https://docs.redpanda.com/redpanda-connect/configuration/unit_testing/",
        "text": "Let’s imagine we have a configuration file foo.yaml containing some processors:\n\ninput: kafka: addresses: [ TODO ] topics: [ foo, bar ] consumer_group: foogroup pipeline: processors: - mapping: '\"%vend\".format(content().uppercase().string())' output: aws_s3: bucket: TODO path: '${! meta(\"kafka_topic\") }/${! json(\"message.id\") }.json'\n\nOne way to write our unit tests for this config is to accompany it with a file of the same name and extension but suffixed with _benthos_test, which in this case would be foo_benthos_test.yaml.\n\ntests: - name: example test target_processors: '/pipeline/processors' environment: {} input_batch: - content: 'example content' metadata: example_key: example metadata value output_batches: - - content_equals: EXAMPLE CONTENTend metadata_equals: example_key: example metadata value\n\nUnder tests we have a list of any number of unit tests to execute for the config file. Each test is run in complete isolation, including any resources defined by the config file. Tests should be allocated a unique name that identifies the feature being tested.\n\nThe field target_processors is either the label of a processor to test, or a JSON Pointer that identifies the position of a processor, or list of processors, within the file which should be executed by the test. For example a value of foo would target a processor with the label foo, and a value of /input/processors would target all processors within the input section of the config.\n\nThe field environment allows you to define an object of key/value pairs that set environment variables to be evaluated during the parsing of the target config file. These are unique to each test, allowing you to test different environment variable interpolation combinations.\n\nThe field input_batch lists one or more messages to be fed into the targeted processors as a batch. Each message of the batch may have its raw content defined as well as metadata key/value pairs.\n\nFor the common case where the messages are in JSON format, you can use json_content instead of content to specify the message structurally rather than verbatim.\n\nThe field output_batches lists any number of batches of messages which are expected to result from the target processors. Each batch lists any number of messages, each one defining conditions to describe the expected contents of the message.\n\nIf the number of batches defined does not match the resulting number of batches the test will fail. If the number of messages defined in each batch does not match the number in the resulting batches the test will fail. If any condition of a message fails then the test fails.\n\nInline tests\n\nSometimes it’s more convenient to define your tests within the config being tested. This is fine, simply add the tests field to the end of the config being tested.\n\nBloblang tests\n\nSometimes when working with large Bloblang mappings it’s preferred to have the full mapping in a separate file to your Connect configuration. In this case it’s possible to write unit tests that target and execute the mapping directly with the field target_mapping, which when specified is interpreted as either an absolute path or a path relative to the test definition file that points to a file containing only a Bloblang mapping.\n\nFor example, if we were to have a file cities.blobl containing a mapping:\n\nroot.Cities = this.locations. filter(loc -> loc.state == \"WA\"). map_each(loc -> loc.name). sort().join(\", \")\n\nWe can accompany it with a test file cities_test.yaml containing a regular test definition:\n\ntests: - name: test cities mapping target_mapping: './cities.blobl' environment: {} input_batch: - content: | { \"locations\": [ {\"name\": \"Seattle\", \"state\": \"WA\"}, {\"name\": \"New York\", \"state\": \"NY\"}, {\"name\": \"Bellevue\", \"state\": \"WA\"}, {\"name\": \"Olympia\", \"state\": \"WA\"} ] } output_batches: - - json_equals: {\"Cities\": \"Bellevue, Olympia, Seattle\"}\n\nAnd execute this test the same way we execute other Connect tests (rpk connect test ./dir/cities_test.yaml, rpk connect test ./dir/…​, etc).\n\nFragmented tests\n\nSometimes the number of tests you need to define in order to cover a config file is so vast that it’s necessary to split them across multiple test definition files. This is possible but Connect still requires a way to detect the configuration file being targeted by these fragmented test definition files. In order to do this we must prefix our target_processors field with the path of the target relative to the definition file.\n\nThe syntax of target_processors in this case is a full JSON Pointer that should look something like target.yaml#/pipeline/processors. For example, if we saved our test definition above in an arbitrary location like ./tests/first.yaml and wanted to target our original foo.yaml config file, we could do that with the following:\n\ntests: - name: example test target_processors: '../foo.yaml#/pipeline/processors' environment: {} input_batch: - content: 'example content' metadata: example_key: example metadata value output_batches: - - content_equals: EXAMPLE CONTENTend metadata_equals: example_key: example metadata value\n\nExecuting tests for a specific config can be done by pointing the subcommand test at either the config to be tested or its test definition, e.g. rpk connect test ./config.yaml and rpk connect test ./config_benthos_test.yaml are equivalent.\n\nThe test subcommand also supports wildcard patterns e.g. rpk connect test ./foo/*.yaml will execute all tests within matching files. In order to walk a directory tree and execute all tests found you can use the shortcut ./…​, e.g. rpk connect test ./…​ will execute all tests found in the current directory, any child directories, and so on.\n\nIf you want to allow components to write logs at a provided level to stdout when running the tests, you can use rpk connect test --log <level>. Please consult the logger docs for further details.\n\nBETA: This feature is currently in a BETA phase, which means breaking changes could be made if a fundamental issue with the feature is found.\n\nSometimes you’ll want to write tests for a series of processors, where one or more of them are networked (or otherwise stateful). Rather than creating and managing mocked services you can define mock versions of those processors in the test definition. For example, if we have a config with the following processors:\n\npipeline: processors: - mapping: 'root = \"simon says: \" + content()' - label: get_foobar_api http: url: http://example.com/foobar verb: GET - mapping: 'root = content().uppercase()'\n\nRather than create a fake service for the http processor to interact with we can define a mock in our test definition that replaces it with a mapping processor. Mocks are configured as a map of labels that identify a processor to replace and the config to replace it with:\n\ntests: - name: mocks the http proc target_processors: '/pipeline/processors' mocks: get_foobar_api: mapping: 'root = content().string() + \" this is some mock content\"' input_batch: - content: \"hello world\" output_batches: - - content_equals: \"SIMON SAYS: HELLO WORLD THIS IS SOME MOCK CONTENT\"\n\nWith the above test definition the http processor will be swapped out for mapping: 'root = content().string() + \" this is some mock content\"'. For the purposes of mocking it is recommended that you use a mapping processor that simply mutates the message in a way that you would expect the mocked processor to.\n\nIt’s not currently possible to mock components that are imported as separate resource files (using --resource/-r). It is recommended that you mock these by maintaining separate definitions for test purposes (-r \"./test/*.yaml\").\n\nMore granular mocking\n\nIt is also possible to target specific fields within the test config by JSON pointers as an alternative to labels. The following test definition would create the same mock as the previous:\n\ntests: - name: mocks the http proc target_processors: '/pipeline/processors' mocks: /pipeline/processors/1: mapping: 'root = content().string() + \" this is some mock content\"' input_batch: - content: \"hello world\" output_batches: - - content_equals: \"SIMON SAYS: HELLO WORLD THIS IS SOME MOCK CONTENT\""
    }
}