{
    "id": "dbpedia_2222_3",
    "rank": 91,
    "data": {
        "url": "https://dl.acm.org/doi/fullHtml/10.1145/3628516.3655814",
        "read_more_link": "",
        "language": "en",
        "title": "A Systematic Review of the Probes Method in Research with Children and Families",
        "top_image": "https://dl.acm.org/cms/attachment/html/10.1145/3628516.3655814/assets/html/images/idc24-34-fig2.jpg",
        "meta_img": "",
        "images": [
            "https://dl.acm.org/cms/attachment/html/10.1145/3628516.3655814/assets/html/images/idc24-34-fig2.jpg",
            "https://dl.acm.org/cms/attachment/html/10.1145/3628516.3655814/assets/html/images/idc24-34-fig3.jpg",
            "https://dl.acm.org/cms/attachment/html/10.1145/3628516.3655814/assets/html/images/idc24-34-fig4.jpg",
            "https://dl.acm.org/cms/attachment/html/10.1145/3628516.3655814/assets/html/images/idc24-34-fig5.jpg",
            "https://dl.acm.org/cms/attachment/html/10.1145/3628516.3655814/assets/html/images/idc24-34-fig6.jpg",
            "https://www.acm.org/binaries/content/gallery/acm/publications/cc-by/cc-by.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Seray B Ibrahim",
            "Department of Informatics",
            "King's College London",
            "United Kingdom",
            "Alissa N. Antle",
            "School of Interactive Arts",
            "Simon Fraser University",
            "aantle@sfu.ca",
            "Julie A. Kientz",
            "Human Centered Design"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "1 INTRODUCTION\n\nDeeply engaging with the lived experiences of stakeholders is a core concern for human computer interaction (HCI) research [21, 61, 98], but can be harder than usual during research with children and families [64, 91, 112]. For example, the process of involving family members across different stages of the process [36, 104], integrating child and adult perspectives within design decisions [37, 64], and managing the potential risk of participant burden [72, 88] is complex and challenging.\n\nPrior HCI research has used a range of situated approaches to address these challenges. Some of this work has included direct methods that involve a researcher presence in the field (e.g., through observation or in-situ interviews) [8, 63, 66, 69], some has included the use of in-direct methods (e.g., diary studies or probes) [1, 26, 103], and some has included a combination of the two [46, 58, 103]. Not all of these situated methods have the same impact on participants. For instance, there can be practical and pragmatic challenges in using direct methods in families research [56, 64, 70, 112], and families might be reluctant to allow a researcher to observe them at home, given that home and family life can be deeply private [52, 89]. On a practical level, negotiating access and finding an appropriate time to meet and carry out in-depth interviews might interfere with the busy schedules that parents and families are already navigating [25].\n\nCultural probes, or probes, offer one unique solution to the issues raised above. Probes are digital or physical tools deployed into the unknown to gather data. They work by collecting fragmented clues about people's lives and desires, often in playful ways, that are intended inspire ideas and prompt dialogue between researchers and participants [42, 45, 62]. In the context of child computer interaction (CCI) research, probes can resolve some of the issues of access, as they can enable family members to take part asynchronously at times that suit them, contributing personal insights about the aspects of family life that they are happy to share.\n\nBeyond the practical benefits, probes occupy a valuable space in CCI research for a number of other reasons as well. They can enable researchers to get closer to understanding in-situ, family perspectives in real time, which is important for understanding the daily practices, desires and needs that underpin what family members express as important in their daily lives. Also, probes are typically multimodal, inviting family members to collect traces of information through pictures, objects and crafted materials (e.g., [29, 30, 116, 118]). These situated, real time, and multimodal input methods are critical to design research as they provide opportunities for addressing the challenges of socio-technical design. For example, by gathering more inclusive perspectives about how people can use technology in daily life [21, 33] (including younger family members who do not confidently read and write), and richer accounts by highlighting different dimensions of family life that can typically go unnoticed.\n\nHowever, there is a wide ranging discussion about what data probes can provide and how they are used in the design process [13, 53, 121]. It is to date unclear how the CCI community has approached this. For instance, probes can provide data in the form of deep ethnographic accounts about home life [52, 75, 110], informational data about particular practices and needs (e.g., [3, 52, 53]), feedback from trying out future-facing technology (e.g., [44, 62, 102]), and inspiration for new ideas (e.g., [22, 43, 46]). In terms of the functions they serve, prior HCI studies have talked about using probes to understand lived experience and promote participant voice, gather requirements, seek formative feedback, and inspire creative ideation [43, 53, 102, 110]. These variations, alongside originator concerns about the misinterpretations [45] in how probes have been used, suggest that there is limited transparency in how probes are designed and used in research [111]. For example, there have been concerns over probes sometimes being used as poor substitutes for ethnography [13, 33]. Probes studies with children and families have also documented this variation in use, both in terms of the role of the probe (e.g., in offering traces of inspiration vs detailed accounts of family life), and the role of the participant (e.g., ranging from being briefly involved in data collection right through to being fully embedded in interpreting the data). This variation and limited transparency over how probes are used can be problematic for researchers who are planning on using probes as it can be difficult to know which approach is best suited to address the design problem or situation.\n\nThis paper is interested in providing an overview of the indirect approaches that have been taken, specifically in CCI research. In particular, we were interested in understanding the methodological decisions that researchers have made about using probes in their studies involving children and/or families, and what this might mean for the considerations that need particular attention when developing a probes study with children and/or families. To address these methodological concerns, we carried out a focused search of the ACM library and Interaction Journal of Children Computer Interaction over the past 20 years (January 2002 - December 2022), and developed and applied a descriptive coding framework, based on the methodological research questions. Our findings identified a range of characteristics that describe how probes are positioned in CCI research, what the probes and their data look like, how they contribute to design, and how participants have been involved in using the probes. In particular, we found that a large portion of prior studies described using probes for the purposes of gathering detailed information about particular daily practices, often through varied activities that produced mostly written, but also log data, photos, and in rarer cases, crafted objects, drawing or audio data. In the majority the studies we reviewed, children and families were often involved in contributing to data interpretation, often using their probe responses as participant elicitation tools during post deployment interviews.\n\nBased on our findings, in the discussion, we present a set of tensions that consider how the use of probes can interact with other goals in CCI research and the ongoing debate across the HCI literature about how probes are used. Using the review findings and tensions, to address RQ2, we identify salient questions that researchers/designers can ask themselves to guide their use of probes in future work. Overall, this work contributes:\n\na synthesis of the literature over the past 20 years for using probes in design research with children and families, and\n\ndecision-making considerations that can offer guidance for researchers and designers who are interested in using probes in this context.\n\n2 BACKGROUND\n\n2.1 Probes in HCI\n\nIn line with prior reviews and studies that have considered using probes across HCI research [13, 121], we refer to the distinct methodological approach of introducing to participants some form of instrument (digital or physical) that is deployed to find out about the unknown [62], and in the absence of the design researcher. We use the generic term probes to refer to a range of applications, for example, cultural probes [42], technology probes [62], empathy probes [80] and informational probes [27].\n\nCultural probes were originally introduced by a group of designers led by Bill Gaver as part of a project that explored how to better integrate older people within their communities [42]. The project spanned three European locations, and as such, through probes, the researchers and participants were able to communicate remotely. Since their inception, cultural probes have emphasized a focus on seeking open-ended insights about people's lives and cultures, through playful and gift-like tasks that are intended to elicit inspiring responses from people [121]. Therefore, the ways that researchers have analysed the probes have prioritised subjective inspiration, for example, by embracing uncertainties and ambiguities offered by the probe returns, and using these as generative tools for design [43, 45].\n\nThe flexibility and wide-spread interest in probes has meant that interaction design researchers have taken on and adapted probes in many ways, leading towards more varied applications. For example, using cultural probes to supplement and translate ethnographic work [18, 22, 110], technology probes for providing insights based on how people interact with digital artefacts [2, 62, 101], empathy probes for communicating to designers data about participant experiences and lifestyle [79, 80] and informational probes for informing needs assessments [27, 52, 53].\n\nOne common approach has been using probes for gathering deep insights about people's lived experiences. Wallace and Lindley (2015), for example, used cultural probes within an ethnographic tradition to study older people's experiences of residential care homes [110]. In this and other examples, probes were used alongside interviews and observation to promote verbal dialogue with participants about topics that were meaningful in their lives (e.g., [13, 19, 22, 31, 110]). In these cases, probes helped participants to explain or clarify meaning and consequently supported them to have a voice in interpreting the data in situations where it can be difficult to research by asking people to solely talk about their experiences.\n\nSeparately, probes have also been used to seek informational or proximal insights about what is happening in participants’ lives. For example, Hemmings et al used probes for collecting informational insights from former psychiatric patients in residential settings, as a way of agenda setting for addressing their abiding concerns, towards supporting daily living [27, 53]. Extending this view, Amin et al (2005) used the method to support user requirement gathering, by using probes in workshops with teens, as a way of identifying priorities for ways of improving instant messaging through non-verbal means [3]. In these examples, the use of probes prioritised ’as objective as possible’ accounts for the purposes of creating better products, rather than for example, exploring future possibilities through designer inspiration or the empowerment agenda. However by focusing on detailed and proximal insights, there have also been concerns with diluting the appeal of probes by trying to use them within epistemologically different traditions [45].\n\n2.2 Design methods in research with children and families\n\nThere are many decision making processes that influence the selection and use of methods in interaction design research with children and families. We argue that decision making about study design and particular methods is often guided by researcher goals that aim to either:\n\nempower people through their role and participation in design;\n\nsupport learning, sociability, health and behaviour change, or;\n\ncreate better artefacts or products [4, 6, 49, 72].\n\nFor example, CCI studies that have promoted participant voice and empowerment have often used creative and situated methods to understand about child and family lived experiences. For example, Van Mechelen et al achieved this by focusing on the multimodal ways that children contributed ideas in design workshops and by being explicit about the ways that children's ideas indicated the social values they held about designing for bullying [106]. Similarly, other studies have also used creative and situated methods such as journalling, sketching and video recording to capture first-person accounts of the different dimensions of child and family daily life [15, 51, 65].\n\nStudies that have focused on supporting development and well-being goals have often used theory-informed methods that embed learning, psychology or communication theory [35, 63, 83, 108], or clinical expertise [73, 113] to support with the interpretation of data. For example, Morris and colleagues [83] used sociological theory (in particular, the double empathy problem) to interpret expert interviews when considering ways of designing for social play between autistic and non autistic children. Separately, Lizsio and colleagues embedded play therapeutic strategies and psychological approaches of patient preparation in their questionnaires and game trial methods when designing a VR game for child patients undergoing MRI procedures [73] (for further examples of integrating psychology theory with methods, see also [35, 57, 82, 99, 101]).\n\nIn the case of creating better products, one focus has been to develop evaluation methods with children that can improve the design of artefacts. For instance, Barendregt and colleagues created the problem identification picture cards method to encourage young children to express usability and engagement problems as a think-aloud method when evaluating games [5] (see also [67, 78, 119]).\n\nIn a recent review of methods for supporting children's involvement in CCI research, Tsvyatkova and Storni [105] suggested that researcher decision making about methods is linked with the roles that child participants take in the research. For example, building on Allison Druin's [34] conceptualisation of the roles that children can take in the design process (i.e., as user, tester, informant, or design partner), Tsyyatkova and Storni suggested that when children take the most involved role as design partners, they are likely to contribute to all stages of the design process, and therefore engage with many methods. These methods can involve discussing existing practices through technology immersion, generating and developing ideas through sticky noting, journalling and video prototyping, and testing and evaluating potential futures through workshops and discussion [34, 36, 51, 65]. Lehnert and colleagues identified that in prior CCI research, methods were often used in natural settings (e.g., children's schools, homes, clinics) and the observation method was most commonly used. However, CCI research will often include mixed methods for the purposes of triangulation and to provide different interpretations of the data. For example, this included combining field notes with participant observation, interviews and technology trials [57, 59, 95].\n\n2.3 Summary & motivation\n\nIn summary, across HCI, probes have been adopted in different ways, producing variations in the types of data that is collected, and the ways that researchers interpret the probes to inform design and research [13, 121]. This variation has generated concerns about limited transparency in how probes are used [13, 111], and that they have been misinterpreted, either as substitutes for discount ethnography [33], or within epistemologically different traditions than originally intended [45]. This variation in using probes has also been present in CCI research, making it difficult for CCI researchers to identify which is the best approach to using probes based on the situation they are working on. Given that CCI research is often guided by a distinct set of values and processes for empowering participants through their involvement, improving development, sociability and well-being, and creating better artefacts/products [4, 49, 72], it is not yet clear how researcher decision making about the use of probes can interact with these distinct value sets.\n\nAs a starting point, through our review, we aim to identify the approaches that have guided how probes have been used in CCI research. We first consider:\n\nWhat methodological decisions have researchers made about using probes in their studies involving children and/or families? (RQ1).\n\nOur sub-questions ask:\n\nWhat are the aims of the probes use and how are they intended to inform the research?\n\nWhat do the probes and their activities typically look like?\n\nWhat data is produced, how is the data interpreted and what does it contribute to design and to the research?\n\nWhat role do children and their families take in the design process by using the probes?\n\nInformed by these methodological insights, we then consider tensions and and questions that can guide researcher/designer decision making about using probes in studies with children and families. Our second research question asks:\n\nWhat considerations need particular attention when developing a probes study with children and families? (RQ2).\n\n3 METHODOLOGY\n\n3.1 Collection\n\nA systematic review approach was used in line with the definition of explicitly and systematically collating and synthesising the findings of studies that directly address clearly formulated questions [55]. This also reflected similar systematic review approaches in HCI [20, 41, 72, 86]. We used the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines for identifying articles, synthesising the data and report our findings [85]. In line with related reviews within the CCI space (e.g., [7, 9, 35]), we were interested in identifying how the multidisciplinary CCI research community has studied a given topic from different disciplinary perspectives. Therefore, we were aware that we did not carry out an exhaustive search all possible databases but instead, carried out a focused review over the past 20 years (Jan 2002 - Dec 2022) of two representative outlets for design-oriented empirical work with children and/or families and/or parents: the ACM Digital Library's SIGCHI sponsored proceedings and IJCCI via Scopus. The first author was responsible for the data collection. Owing to the differences in terminology use across articles, the first author took a whole-to-part process that involved introducing key filter terms gradually to limit the selection. In particular, this is reflected in our decision to separate the query terms ’design’ and ’probe’ in our searches, and for the IJCCI search, to introduce the query term ’probe’ as a filter after our initial search. The query terms across all fields were: (’child*’ OR ’famil*’ OR ’parent*’) AND ’design’. Our eligibility criteria and process for identifying articles is presented in detail in figure 1. As part of our eligibility criteria, we included articles where the described methods aligned with our filtered key search terms therefore, we decided to include articles where the author descriptions of the method aligned with the key terms (i.e., including three additional articles that involved audio diary and narrative). We felt it was important to include these probe-like methods so that we could present a fuller account of closely semantically related, situated methods. As we were interested in situated methods that can be used in the absence of the researcher, we excluded articles where probes were used in researcher-led activities such as workshops (e.g., [77, 84, 117, 118]). In total, 25 articles were included in our review. We present the final corpus of 25 selected articles in appendix A.\n\n3.2 Coding procedure\n\nIn order to create a structured framework for coding and analysing the data, the first and last authors iteratively developed a set of guiding questions for extracting and categorising descriptive data from within the selected articles. To generate this coding framework, we first documented our shared understanding of the points in the design process where researchers were likely to make decisions about how probes would be used (see figure 2). Based on our understanding of the researcher's decision making process (which was informed by the first and last author's combined 18 years of experience in design-oriented research), we identified four decision making points. These related to study design, the probe itself, data and its use, and, participant involvement. The decision to formulate these guiding questions based on our experiences was prompted by the ongoing lack of transparency in prior probes studies about the kinds of decisions that guide how probes are used in research [111, 121]. The breakdown of questions is presented in figure 3.\n\nNext, the first author tested out the coding framework with five of the articles (reflecting 20% of the total data set). This provided opportunities to further develop and adapt the coding framework in consultation with the authoring team. The first author read and coded the first five papers in NVivo, paying attention to the 14 guiding questions. For each question, sections of text from within the articles were highlighted and grouped into subheadings that reflected different responses to the guiding questions. For example, for the question: ’who is the target?’, we extracted and grouped excerpts of text under the headings: ’school aged children’, ’parents’, ’hospitalised children’ etc. In line with similar literature review approaches (e.g., [17, 81]), we used a simple coding process that required little researcher interpretation, instead, extracting sections of text using the authors’ own words to inform informed early theme development. The first author then coded the remaining 20 articles in NVivo.\n\nTo address RQ2, we used the insights from the review to generate considerations for using probes in research with children and/or families. Our goal was to generate themes that would highlight differences in methodological decisions taken by authors of the selected articles. To achieve this, we used insights from the four sub research question areas (RQ1a-d, figure 3) to identify key differences in the approaches taken across the 25 articles. Using an emergent approach, we gradually developed these differences into contrasting tensions and then overarching considerations. Finally, we utilised examples from the selected papers to generate a set of methodological questions under each of the consideration area themes (e.g., relating to the goal for using the probe, its material quality, participant role etc.).\n\n3.3 Study limitations\n\nThe main limitation of this survey study relates to the selection strategy. First, in terms of the search strategy, we chose to only include examples where probes were used in the absence of the researcher, ruling out examples where probes were used in the context of design workshops (e.g., [77, 84, 117, 118]). This decision was informed by us wanting to identify how probes are often deployed into the unknown, without direct researcher support. Second, we chose to include empirical studies where the authors described using probe-like methods in line with our definition of probes (i.e., as situated, creative tasks that the researchers ask the participants to create in the researcher's absence). As such, we included three additional studies where the authors described the method as either creating narratives, memoirs or audio journals [11, 32, 94]. We included these papers so that we could present the widest possible account of probe-like methods, and recognise that this may have impacted on the methodological approaches we present. Third, owing to the large volume of identified papers (n=1386), we used the online systematic review tool rayyan.ai to filter articles that used a set of key terms within their full text (e.g., ’lived experience’, ’situated’, ’in the wild’). This may have resulted in us missing relevant articles in the screening stage. Lastly, we limited our search to full papers that were archived in the ACM library or IJCCI. This was connected with our understanding of these being the major venues for CCI research. We recognise that this may have limited our search results, but also feel that this provides a detailed first step for understanding how probes have been used in this context.\n\n4 FINDINGS\n\n4.1 Overview\n\nWe first present an overview of the distribution of empirical papers that have used probes with children and families over the past two decades. We then describe the perspectives and approaches that have guided probes use in this context. Following this, we identify what probes and their activities have typically looked like, and consider the role that children and their communities have taken in probe studies. Following this, we examine the characteristics of the dataset, including the stages in the development cycle that the data informs and the analytic approaches have frequently been used to interpret the data. Finally, we consider the kinds of contributions that the articles claim to make based on their use of probes.\n\nOverall, we observed a notable increase in probes uptake with child and family research, particularly since 2018 (see figure 4). This uptake has come somewhat later than the broader trend across HCI (where there has been greater interest over the past two decades [13, 121]), suggesting that probes might be filtering into CCI research more gradually, or that our selection criteria has identified more varied applications of probe-like methods in CCI. The distribution suggests that probe uptake in research with children and families is likely to continue increasing, supporting our motivation to better understand how probes are being used and for what purposes.\n\n4.2 What are the aims of the probes use and what do they seek to do in the research? (RQ1a)\n\nIn the majority of the selected papers (18/25 papers), the authors described their use of probes as tools for investigating peoples lives and desires across a number of populations (summarised in table 1), and suggesting an approach in line with the cultural probes tradition.\n\nFor example, this encompassed gathering local knowledge about peoples’ daily activities, concerns and values, often related to a specific topic [16, 23, 30, 32, 75, 94, 115]. Chauhan et al for example, describe their approach of using probes for collecting local knowledge from people (including caregivers of children) who were living in emergency shelters in disaster struck areas [23]. Similarly, Wyche used probes as a way of investigating domestic technology use in rural households in Kenya [115]. In both examples, probes were used to generate thematised insights about communities. Investigating lived experience also encompassed gathering culturally situated data [16, 29, 109, 115]. For example, by inviting participants to self-reflect on their daily cultural practices and then share these experiences with the research team via the probes. In the selected papers, this included cultural data about parent and child shared reading practices [109], person and family values about the home and community life [16, 23, 30], and parent and child experiences of interaction, socialisation and care through technology [39, 60, 62, 104].\n\nSeparately, a smaller but notable set of articles described using probes for the purposes of invoking empathy and compassion with participant groups alongside the goal of understanding lived experience [11, 32, 68, 111]. In these cases, probes were intended to highlight intimate or personal experiences through relaying emotional and visceral stories that participants had narrated.\n\nLastly, probes were also used as tools for speculating about future technology use connected with participants’ existing daily practices. For example, in seven out of the 25 articles, this related to speculating about domestic security, sleep, infant feeding, parent-child interaction, communication over distance, healthcare goal setting and home lighting [14, 24, 54, 62, 75, 87, 120].\n\nMany of the articles drew on different methodological approaches. In many cases, these approaches were not directly intended to inspire design moves [16, 28] or designer-led interpretation [43], but for the purposes of understanding lived experience. For example, methodological approaches included autoethnography [11, 32], participatory action research [94], experience sampling method or personal tracking [14, 39, 71, 87, 120], intersectionality [11, 39] and theory-driven approaches [100, 120]. These approaches highlighted that there was huge variety in the ways that probes were positioned as methods for studying lived experience.\n\n4.3 What do the probes and their activities typically look like? (RQ1b)\n\nIn this section, we consider the probe characteristics, including the types of activities involved (table 2), the material dimension of the probes themselves, and the context for probes use (summarised in table 3).\n\n4.3.1 Probe activities.\n\nProbe activity Citation Journal/diary [14, 23, 24, 29, 30, 38, 60, 68, 75] Note taking [16, 29, 39, 75, 96, 104, 111, 115] Photo capturing [16, 23, 29, 60, 68, 75, 100, 115] Storytelling [11, 23, 32, 38, 54, 111] Drawing or sketching [23, 60, 75, 96, 104, 109] Log data/auto tracking [14, 24, 71, 87] Crafting activity [68, 104, 109, 111] Audio capturing/sending [16, 54, 62, 94] Creating maps [23, 75, 111] Clay moulding/indentation [68, 111] Collecting and sorting [16, 111] Family/self tree making [30, 111] Postcard writing [29, 109] Creating games [68] Letter writing [38] Script writing [38] Polling [38] Answering surveys [68]\n\nContext of use Citation Family home [14, 29, 30, 68, 87, 100, 109, 111] Daily domestic life [11, 16, 32, 38, 39, 75] Hospital or health setting [60, 104, 120] Family communication across distance [54, 62] Rural households [24, 115] School or youth organisations [71, 96] Disaster or conflict zones [23, 94]\n\nOur analysis of probe activities showed that researchers drew on different activities to collect data. A full list of probe activities is presented in table 2. In nine out of 25 articles, authors described deploying a pack of probe activities (see also [13]) where different activities were intended to capture insights about different dimensions of the participants’ lives [16, 23, 29, 38, 60, 75, 96, 100, 109].\n\nParticipants were asked to keep journal/diary entries across more than a third of all selected articles (i.e., 9 out of 25 articles). As part of their journalling, typically, children and parents would be asked to document and reflect on daily activities by keeping a log, responding to specific prompts, or sharing more open-ended opinions about a given topic. Lucero et al (2007), for example, drew on all three of these journalling techniques to explore how people might experience and interact with future lighting systems in their bathrooms [75]. In their study, journalling involved keeping a timeline of thoughts and activities, responding to closed questions about routines, and expressing their opinions about bathroom lighting in more open-ended ways. Like in the case of other articles that used this method, diary probes were often used alongside other probe activities (see also [14, 23, 24, 29, 30, 68, 104], then followed up with interviews to further discuss the probe outputs [75].\n\nThe second most popular probe method was note-taking and featured in eight out of 25 articles. Unlike the diary or journal method, note-taking was more brief and often part of a focused activity whereby participants wrote a few words that directly responded to researcher prompts. For example, writing responses to open-ended questions or statements [38, 75, 96, 111, 115] or using note-taking to label and supplement information within participant scrapbooks or alongside collected objects [16, 29].\n\nPhoto capturing was also a prevalent activity and featured in eight out of 33 articles. It typically involved inviting participants to take photos of environments that researchers were not able to be physically present in, either by giving specific directions of what to capture and how, or by inviting participants to interpret this in their own ways. For example, Chauhan et al (2022) used photo capturing to investigate community needs for planning and managing disaster shelters [23]. The authors asked participants to take specific photos and provide explanations of items that they would bring to a shelter to take care of themselves and their families. In rarer examples of photo capturing, authors invited participants to make their own decisions about what to capture and how, guided by more open ended, ambiguous prompts, e.g., guided by the verbal prompts ’work’, ’fun’, or ’faith’ [16, 115].\n\nOther popular activities included asking participants to engage in storytelling, drawing, logging data, crafting objects and pictures, and capturing and sending audio recordings (see table 2).\n\n4.3.2 The material aspect of probes. Considering the physical or material aspect of the actual probes, our search found that there was huge variety in how researchers chose to present activities through physical or digital means. For example, written journals, note entries or story writing activities were deployed either through carefully hand-crafted artefacts [16, 111], traditional, paper-based notebooks or postcards [14, 23, 29, 30, 60, 96, 115] or through digital means [11, 32, 38]. Similarly, photo capturing involved deploying either single-use or basic cameras [23, 29, 68, 75, 115], hand-crafted cameras [16] or by inviting participants to use their own digital recording devices [60]. Researcher decision-making over whether to use single-use or digital cameras were not always clear, except on rarer occasions where the material and physical aesthetic of the probe itself was talked about as an important part of the probe method [16, 54, 111]. In a similar way, where the creation or presentation of a designed physical artefact was part of the probe activity, authors described in detail their decisions for particular probe materials and components [16, 32, 54, 62, 100, 111].\n\n4.4 What data is produced, how is the data interpreted, and what does it contribute to design and to the research? (RQ1c)\n\n4.4.1 The dataset. Our analysis showed that written text was the most commonly analysed data format, occurring in 16 out of 25 selected articles. This reflected a large portion of the probe activities that asked participants to complete diaries, researcher-prompted notes, manual activity logs, or stories, as described in section 4.3.1. Auto-generated log data (for motion, sound or text input) was the second most common data format across the selected articles with six studies that captured automatic log data through the deployment of a technology probe (e.g., [24, 39, 54, 71, 87]. Given that photo capturing was also a prevalent activity, digital or printed photos formed part of the dataset in five of the articles. Our search also highlighted that drawings and sketches were only described as part of the analysed dataset in two of the articles [62, 96], despite drawing/sketching beings listed as part of a pack of probe activities in six studies. The absence of drawings data may also be considered surprising given the high level of child involvement in 15 of the studies. A summary of the types of data is presented in table 4.\n\nData format Citation Written text [11, 14, 24, 32, 38, 39, 60, 62, 68, 75, 87, 96, 109, 120] Log data (motion, sound, text) [14, 24, 54, 62, 71, 87] Photos (digital, printed) [24, 62, 75, 100, 115] Designed or crafted objects [32, 68, 109] Drawings [62, 96] Audio recordings [94]\n\n4.4.2 Stage in development cycle. Identifying the stage within which probes data were used in the development cycle was important for developing a broader understanding of how probe insights informed design decisions. Using the authors’ own descriptions of their design process, we categorised the data into three main stages within the development cycle, in line with Sanches and colleagues [93]. These were: 1. Requirements and Context, 2. Design and Development, and 3. Evaluation. As described by Sanches et al, ’Requirements and Context’ referred to the studies that were focused on informing design work. The label ’Design and Development’ referred to studies that presented novel design insights (e.g. in the form of design implications or directions) but lacked validation. Finally, ’Evaluation’ referred to studies that used a validation measure to test their designs [93].\n\nOverwhelmingly, all 25 articles were categorised as using probes in the early ’Requirements and Context’ stage of the development cycle . This was characterised by studies that used probes for gathering detailed insights about participants existing lives and practices (e.g., [16, 23, 39]) and for speculating about possible practices that might then be a focus for future design (e.g., [62, 75, 87]).\n\nIn addition to this, seven of the studies used probes data to inform ’Design and Development’. Often, this involved taking probe study insights to inform the development of an artefact that was then deployed in a follow up activity within the same article. This was especially the case in studies that deployed a technology probe where there was a double aim of identifying how participants perceived a topic by interacting with and ’testing out’ a possible solution [14, 24, 54, 87, 100, 104, 120]. For example, in Zhao et al [120], child patients and their carers were invited to use a digital record keeping and goal setting app to explore their opinions and practices about possible joint goal setting in hospital environments.\n\n4.4.3 Analysing probe data. Given that prior research has highlighted the ’fuzziness’ of using and interpreting probes [13, 31, 121], we were keen to explore how this was reported in the selected articles. Our search suggested that a large proportion of articles focused on analysing the data for informational gains, i.e., to gather detailed information about a local context for the purposes of giving clearer guidance to inform the design process (cf., [13]). For instance, when seeking informational gains, authors predominantly described taking an inductive, open coding approach to generate patterns that were representative of the data. For example, using open coding to generate codes that \"reflect a variety of attitudes and approaches to their family's technology use\" [30], or finding \"common activities and patterns across participants\" [60]. This was the case for more than two thirds (17 out of 25) of the selected articles [14, 23, 24, 29, 30, 38, 39, 54, 60, 68, 75, 87, 94, 96, 100, 109, 120]. A subset of articles that used open coding also took a theory-informed approach to generate themes across the data [39, 87, 96]. For example, Pina and colleagues used a Family Systems Framework to interpret their technology probe data and to identify key practices that children engaged in with the technology probe [87]. Across articles that took an open coding approach, probe responses were often triangulated with other data to produce credible and trustworthy accounts of the reported patterns [14, 24, 30, 60, 87, 100, 104, 109]. This suggested that data analysis of probes was largely in keeping with a social sciences qualitative research tradition [50, 97].\n\nSeparately, a smaller selection of articles analysed the data in ways that was more in keeping with anti-solutionist design approaches [12, 121]. Across seven articles, probe responses were reported on descriptively as individual cases within the data [11, 16, 32, 62, 71, 111, 115]. Boucher et al describe their interpretation of the probe responses as \"shap[ing] our next design moves; we were less concerned with collecting data that would be generalizable or representative of an entire population\" [16]. For Wyche [115], qualitative analysis involved presenting specific examples from the data and acknowledging the researcher's subjective knowledge as a way of stimulating follow on conversations between designers and users. Separately, Devendorf et al [32] described their use of design memoirs as presenting first-person accounts that emphasized the felt or somatic memories of individual, lived experience. The findings suggest that only a smaller body of work focused on capturing individual traces or fragments from people's lives to inform and inspire design moves. Instead, the majority of studies analysed probe outputs by identifying commonalities and themes across the data.\n\n4.4.4 The proposed HCI contributions of probe studies. To identify and report on how the authors described the contribution of their work, we used the Wobbrock and Kientz classification of research contribution types in HCI [114]. We present a summary of HCI design contributions from the articles in table 5.\n\nMethodological contributions are typically characterised as new knowledge contributions that inform how one carries out the work [114]. In 15 of the articles, authors expressed making an empirical contribution that related to one of three areas. The first area concerned how the method could be used in a particular context [11, 23, 24, 60, 68, 71, 75, 115]. The second area related to how the method could be used to support co-designing with participants [38, 60, 62, 94, 96, 111]. Finally, the third area related to how the method could be used to advance design-led user research [16, 32].\n\nIn 11 articles, authors explicitly described their probes study as contributing empirical knowledge about the setting, people's practices, their desires and opinions [23, 24, 29, 30, 39, 75, 87, 96, 104, 109, 120]. This aligns with the prominent concern within HCI for investigating people's lives and desires (also reflected in section 4.2). Empirical research knowledge often encompassed developing local understandings about people and their practices with and without technology. For example, this related to healthcare practices [104, 120], daily routines [23, 24, 39, 75, 87], and family interactions [29, 30, 39, 87, 109, 120].\n\nA subset of articles that made empirical research contributions also presented design implications that were based on new empirical knowledge that their study had generated [14, 29, 38, 39, 54, 100, 120]. In these cases, empirical insights from using probe informed new focus areas for technology design. In one example of this, Garg [38] used the empirical findings to generate design implications for using voice agents by regulating privacy and ownership concerns.\n\nLastly, five out of 25 articles reported on making artefact contributions through their use of probes. In these articles, newly presented interactive artefacts were informed by generative design-driven activities [114]. Examples of artefact contributions included technology probes for home security awareness [24], family-centred personal data recording [87, 120], child emotion regulation [100] and family communication practices [54].\n\n4.5 What role do children and their communities take in the design process? (RQ1d)\n\nConnected with our interest in identifying if and how probe deployment can give children and their families a voice, we describe the ways that children, parents and carers were involved in creating and using the probes, and interpreting the probe outputs. Across all of the selected papers, the target audience (outlined earlier in table 1) was also involved in creating and/or using the probes.\n\nKnowing that not all participants were children, across all selected papers, children were actively involved in engaging with the probes in 15 out of 25 of the selected articles. This often aligned with the author's goal of understanding about family life or behaviour concerning a particular topic [29, 38, 39, 54, 60, 62, 68, 87, 100, 104, 109, 120]. As such, in these studies, children and parents/carers collaboratively engaged with the probes. Given that child and adult participants engaged with the probes in the researcher's absence, for younger children (e.g., under 10 years) involvement was implicitly supported by adult family members. For example, Dalsgaard and colleagues describe introducing the probes by first visiting the family home and giving clear instructions to parents and children about how they might use the cameras, scrapbook and diary [29]. Of the remaining 10 articles where only adult participants were involved, the focus of the study was specifically scoped towards understanding parental experiences [11, 14, 30, 32] or investigating lived experienced across the broader adult population, whereby being a parent was not the main focus [16, 23, 24, 75, 111, 115].\n\nIn line with Gaver and colleagues [42, 45], in 17 out of 25 of the articles (68% of articles) authors described handing over to participants probes that were primarily created by researchers. Rarer exceptions to this were when authors had taken an auto-ethnographic approach [11, 32] or were explicitly interested in co-creation and democratic gains. For example, Wallace et al describe the probe co-creation process as \"made in part by each party, there is a sense of shared creation....the process becomes a way of building a relationship in a more democratic manner than the roles of researcher and participant often affords\" [111]. In addition to these participatory studies, i.e., [11, 32, 111], in four articles, participant insights from earlier empirical work informed the creation of the probes (see table 6).\n\nInterestingly, our review showed that where probes were used in research with children, parents and families, participants were frequently involved in the interpretation of probe responses. This was evident in 19 of the 25 articles (see table 6). Often, this occurred through enabling participants to see and make sense of the data that they were generating (e.g., [71, 87, 94, 120]), or through post deployment interviews with participants, who were asked to expand on or clarify their probe responses to avoid inaccurate researcher interpretation [14, 24, 29, 54]. For example, Pina et al [87] invited families to track and reflect on their sleep data together. This consisted of auto-captured Fitbit sleep records and self-reported mood data which would be displayed on a centrally located technology probe within the home. By inviting child and adult participants to actively engage with the probe data then discuss this in pre- and post-deployment interviews, the authors closely attended to child and adult participant interpretations for how families might collaboratively make sense of their own data.\n\nPost-deployment interviews also aimed to provide contextual information about how families were interpreting the probes [29, 30], or to gain new data, inspired by the probes data. For example, Bogers et al [14] held participant interviews to \"gain more detailed insights in what bottle feeding entails or means to people\", which complemented data that the research team collected from a diary and sensor data capturing technology probe. In all of these cases, interviews helped to incorporate participant interpretation within the probes data. This approach positioned probe interpretation as distributed across researchers and participants, rather than designer-/ researcher-led (cf. [43, 45]).\n\n5 DISCUSSION\n\nWith this review, we aimed to provide an overview of how researchers who are working in the CCI space have used probes with children and/or families and/or parents. We were interested in understanding how HCI researchers positioned the roles of the probe and the participant. This was motivated by the ongoing debate about how probes are interpreted by HCI researchers [13, 53, 121] and by a gap in understanding how CCI researchers and designers might best use probes in their studies, based on their design situation. In the 25 papers we reviewed, we found a large variation in the uses and characteristics of probes. However, we also found that in a large portion of studies, one unifying aspect was that authors talked about using probes to gather local knowledge about people's daily lives and activities, concerns, and values about a specific topic. There was variety in the methodological approaches that guided the types of data that researchers were seeking (e.g., ranging from scattered traces through to detailed accounts), and the look and feel of the probes themselves (e.g., ranging from constructed, hand-crafted activities through to traditional paper-based or digital notes). In terms of participant role, many of the studies we reviewed described involving child and adult participants in interpreting the probe responses, often through post-deployment interviews that gave participants opportunities to clarify ambiguities about their data or add additional information. This suggested that in many studies, probes have been used to foreground first-person, participant perspectives about what is important, and what to design for.\n\nNext, we use the findings from our review (RQ1) to discuss tensions and questions that designers/researchers might use to explicitly guide decision making when designing probes studies with children and/or families (RQ2).\n\n5.1 Possible tensions when using probes in research with children and/or families\n\nThe range of goals, approaches and expected contributions of using the probes prompted us to consider potential tensions in decision-making. We consider how these tensions interact with ongoing debate in the literature on how probes are used across HCI (cf. section 2.1) and how the use of probes might interact with other goals in CCI research (cf. section 2.2).\n\n5.1.1 Tension 1 - The informational vs. inspiration gains of probes. A common trend across the selected articles was that probes were often motivated by the researcher's desire to investigate lived experience by gathering detailed information about people's lives and daily practices across many different dimensions. This aligns with core concerns within CCI research for deep engagement with stakeholders and a need for understanding the wider ecology surrounding technology design [61, 72]. For example, this was evident in studies that invited participants to keep detailed and informative logs about specific routines (e.g., [14, 24, 39, 87]) and in studies that asked participants to respond to researcher questions about their desires and motivations through a collection of modes that each highlighted different aspects of their experiences (e.g., [23, 38, 68]). In capturing comprehensive accounts of child and family life, researchers often triangulated the data to get closer to understanding what daily experiences, practices and interactions with and without technology typically entailed. However, in these studies, by gathering detailed, comprehensive accounts, the use of the probes moved away from enabling ambiguous interpretation on the designer's part (see for example, [43, 90]). This suggests that one main priority for probes in prior research with children and families has been to offer translation of credible and trustworthy accounts about a particular community [50, 97]. This deviates from how probes were originally designed by Gaver and colleagues, as offering inspiration and creative input through ambiguity [42, 43]. This is important, as it highlights that researcher goals in CCI studies with probes have tended to prioritise informational gains and proximal accounts for designing better artefacts or empowering participants, which we further discuss below.\n\n5.1.2 Tension 2 - Adopting an artistic-designerly vs. analytical or informational perspective. Connected with tension 1, the review of study designs and research goals highlighted that authors often talked about using probes in line with a cultural probes tradition, i.e., for eliciting insights, participant perspectives and culturally situated knowledge [42, 45]. However, in practice, researchers also drew on a broad range of epistemological perspectives and methodological approaches to guide how they deployed probes and then analysed the data. For instance, this included participatory action research [94], experience sampling method or personal tracking [14, 39, 71, 87, 120] and theory-driven approaches [38, 87, 96, 120]. The outcome of this was often to generate generalisable themes across the data. Considering that cultural probes have traditionally followed an artist-designer tradition of capturing fragmented traces that can offer creative or disruptive influences, caution is needed when applying artistic-designerly methods in studies that have epistemologically different study designs (see also [13, 111, 121]). For instance, using probes to capture fragmented traces about people's lives and cultures can work when considering new research or design inspiration in the early design stages. However, when this is combined with ethnographic or theory-driven approaches that focus on detailed, representative accounts across communities, researchers should be mindful of the trap of using probes as a method of discount ethnography [33]. As such, if probe outputs are used as the basis for analysis, researchers should clearly communicate what the goals or probes are and how they are using the data.\n\n5.1.3 Tension 3 - Gains and losses of traditional vs. hand-crafted activities. The findings highlighted that there was a frequently used set of familiar activities for presenting researcher prompts and collecting data. These activities typically involved the use of written journalling (on paper or electronically), brief note keeping (e.g., through logging practices) and photo capturing on mobile devices or study cameras (see table 2). The ways that these activities were presented to participants varied, based on the goals of the study. For example, the materials ranged from hand-crafted personalised packs of probes (e.g., [16, 30, 109, 111, 115]) right through to digital prompts within existing technology (e.g., [39, 71]). Whilst participant engagement with the material dimension of the probe itself was not always reported on in the articles, variation in how probes looked and felt made us wonder whether loosing the gift-like quality of the probes impacted on the data that was collected [42, 111]. Similarly, seeing that children were often involved in engaging with the probes (in 15 out of 25 articles), an implicit assumption about the look and feel of the probe materials was that they would be appealing and usable for children [10, 47, 92, 105]. However, the review findings showed that written text was overwhelmingly the most popular data format that was captured across the studies, followed by auto or manual captures of log data, then photographs. Crafted objects or drawings featured much less frequently in the reported data (in only five out of 10 studies that presented drawing or crafting tasks). This suggested that there may have been less engagement with these activities by participants, or that multimodal data was more difficult to analyse or interpret [76, 107] compared with written modes. These observations highlight a need for carefully considering the material qualities of the probes and their data, the demands that these material qualities could place on participants, and the ways that these varied data modes will be interpreted in line with the goals of using the probes. For instance, researchers might want to consider how the design of the probe can foster engagement for busy parents or children who are expected to engage with the probe independently of adults, i.e., How might the probes be created so that it is familiar, special, integrated in something they already use or purposefully unusual?\n\n5.1.4 Tension 4 - Participant vs. designer voice in probe interpretation. In 19 out of 25 articles, participants were actively involved in the interpretation of the probe responses (see table 6). This was often by participants engaging with the data that they were producing, or by clarifying their intended meaning during interviews. The desire to give participants an active role in the interpretation of probes was often present in the study motivations. Across many of the articles, authors expressed wanting to identify the things that child and adult participants expressed as important in their daily lives and practices (e.g., [23, 38, 40, 60, 96]), which is in line with a broader concerns across CCI [48, 61]. However at the same time, given that cultural probes were also often intended to spark inspiration by allowing designers to ’fill in the gaps’ and draw on their own subjectivity for interpretation (e.g., [16, 54, 75, 115]), we highlight that tensions exist in managing participant- and designer-led interpretation of the probe responses. The findings suggested that many prior probes studies with children and families have intended to highlight participant perspectives, but researchers/designers should also pay close attention to how child and adult participant contributions impact on the development of ideas and design decisions. In particular, researchers should consider how their chosen analytic approaches will align with the goals of the probes study and how designer-/researcher-led interpretation may or may not interact with participant level of say.\n\n5.2 Considerations for developing a probes study with children and/or families (RQ2)\n\nGiven that CCI research is inherently interdisciplinary, we imagine that there will be different priorities that inform researcher decision-making, and these will change based on the goals of the study. In our findings, we did not observe a pattern in terms of disciplinary approaches. Instead, we identified that researcher priorities were often varied and connected with the knowledge gains that probe insights were intended to generate, epistemological perspectives that guided how the probe was used, aesthetic and material qualities of the probe and its data, and the participant role and level of involvement in using and interpreting the probe data (see figure 5).\n\nBased our analysis of the data and identified tensions, we next identify questions under each of these four areas that can offer guidance to researchers/designers when planning future probes studies with children and families.\n\n5.2.1 Considerations about knowledge gains.\n\nAt what stage are probes used in the development cycle (e.g., requirements and context, design and development, or evaluation) and what next steps will the insights inform?\n\nWhat is the goal for using the probe (e.g., to provide creative input, informational insights or something else)?\n\nWhat form will the expected contributions take? (e.g., translation of research knowledge about people / empirical knowledge / disruptive input about what to design for / a designed artifact etc)\n\n5.2.2 Considerations about the epistemological perspective.\n\nHow do researchers/designers intend to generate knowledge?\n\nWill researchers/designers use qualitative, quantitative or a combination of approaches?\n\nWhat underpinning perspectives inform the study design? (e.g., experienced-based design, an empathy-based approach, research through design)\n\nHow do these perspectives inform the ways that the probe activities are presented?\n\nWill theory be used to make sense of the data?\n\nWhat methodological approaches will guide how the data is interpreted/analysed? (e.g., co-design, participatory action research, experience sampling method).\n\n5.2.3 Considerations about the aesthetic & material qualities of the probes and its data.\n\nIs the activity familiar or purposefully unusual?\n\nIs the activity engaging?\n\nDoes the activity allow for capturing multimodal accounts? (e.g., through image, motion, text or other modes)\n\nDoes the activity allow for capturing different dimensions of home/family life?\n\nDoes the activity potentially offer gains for child and adult participants?\n\nWhat extra demands does the activity place on families, and how are these managed?\n\nAre participants manually or auto capturing the data?\n\nIs the expected probe data format accessible for children and adults of different ages and profiles?\n\nDoes the intended format provide enough data to start to address the design problem?\n\nAre there other formats that would be more helpful for addressing the goals of using the probes?\n\nWill probes be used alongside other methods, and if so, how will the probes enrich/complement these methods?\n\n5.2.4 Considerations about participant role & involvement.\n\nWho are the participants, and what contexts are being studied?\n\nWill the probes capture data about certain groups or context directly or indirectly? (e.g., parent accounts of child / first-person accounts)\n\nAre children and adults expected to contribute equally to engaging with the probes?\n\nAre child and adult probe returns analysed separately; is this important for the study?\n\nDo child and adult participants engage with the data that they are collecting? (e.g., can they see and reflect on their logged data?)\n\nAre participants capturing subjective or objective accounts of how things are or how they behave?\n\nWho takes the lead in interpreting the probe data?\n\n(researcher, participant, both)\n\nAre child and adult participants asked to clarify any designer/researcher interpretation of the data?\n\nAre families actively involved in deciding what parts of the data inform future decisions?\n\n5.2.5 Connecting methodological decisions. The findings also showed that the four overarching areas were often linked. For example, in the early stages of the design process, where the goals for using the probes were to generate knowledge gains in the form of detailed and informative empirical accounts of home life, some researchers used naturalistic inquiry as the epistemological perspectives guiding their approach. This often involved generating trustworthy and credible accounts [50] by finding patterns in the data, and triangulating data sources (e.g., [14, 24, 29, 54]). Alternatively, when researchers/designers were seeking knowledge gains in the form of new ideas about what to design for in the early stages, the epistemological perspectives guiding the selection of materials, activities and data interpretation included inductive, anti-solutionist approaches, and research through design. In these cases participant role and involvement included presenting stand-alone, first-person stories that participants had narrated (e.g., [11, 32, 111]). In both scenarios, considerations about the aesthetic and material qualities of the probes and their data were connected with all three other areas.\n\n5.2.6 Reflections on the questions. Our goal for proposing these questions has been to encourage researchers/designers to explicitly consider methodological decision making when planning probes studies with children and families. We do not claim to provide an exhaustive list of things to consider, but see these questions as a starting point for guiding discussions about how to use probes in this context."
    }
}