{
    "id": "dbpedia_2222_1",
    "rank": 52,
    "data": {
        "url": "https://tc.copernicus.org/articles/17/4343/2023/",
        "read_more_link": "",
        "language": "en",
        "title": "Measuring the spatiotemporal variability in snow depth in subarctic environments using UASs â Part 1: Measurements, processing, and accuracy assessment",
        "top_image": "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-avatar-web.png",
        "meta_img": "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-avatar-web.png",
        "images": [
            "https://contentmanager.copernicus.org/800952/25/ssl",
            "https://contentmanager.copernicus.org/800952/25/ssl",
            "https://www.the-cryosphere.net/licenceSVG_16.svg",
            "https://www.the-cryosphere.net/licenceSVG_16.svg",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-avatar-thumb150.png",
            "https://www.the-cryosphere.net/mendeley.png",
            "https://www.the-cryosphere.net/reddit.png",
            "https://www.the-cryosphere.net/twitter.png",
            "https://www.the-cryosphere.net/facebook.png",
            "https://www.the-cryosphere.net/linkedin.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f01-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t01-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t02-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f02-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f03-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f04-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f05-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f06-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t03-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t04-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f07-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t05-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t06-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t07-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f08-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-f09-thumb.png",
            "https://tc.copernicus.org/articles/17/4343/2023/tc-17-4343-2023-t08-thumb.png",
            "https://www.the-cryosphere.net/mendeley.png",
            "https://www.the-cryosphere.net/reddit.png",
            "https://www.the-cryosphere.net/twitter.png",
            "https://www.the-cryosphere.net/facebook.png",
            "https://www.the-cryosphere.net/linkedin.png",
            "https://contentmanager.copernicus.org/319373/25/ssl",
            "https://contentmanager.copernicus.org/319376/25/ssl"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Leo-Juhani",
            "Ala-aho",
            "KlÃ¸ve",
            "BjÃ¸rn"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Abstract. Snow conditions in the Northern Hemisphere are rapidly changing, and information on snow depth is critical for decision-making and other societal needs. Uncrewed or unmanned aircraft systems (UASs) can offer data resolutions of a few centimeters at a catchment-scale and thus provide a low-cost solution to bridge the gap between sparse manual probing and low-resolution satellite data. In this study, we present a series of snow depth measurements using different UAS platforms throughout the winter in the Finnish subarctic site Pallas, which has a heterogeneous landscape. We discuss the different platforms, the methods utilized, difficulties working in the harsh northern environment, and the UAS snow depth results compared to in situ measurements. Generally, all UASs produced spatially representative estimates of snow depth in open areas after reliable georeferencing by using the structure from motion (SfM) photogrammetry technique. However, significant differences were observed in the accuracies produced by the different UASs compared to manual snow depth measurements, with overall root mean square errors (RMSEs) varying between 13.0 and 25.2âcm, depending on the UAS. Additionally, a reduction in accuracy was observed when moving from an open mire area to forest-covered areas. We demonstrate the potential of low-cost UASs to efficiently map snow surface conditions, and we give some recommendations on UAS platform selection and operation in a harsh subarctic environment with variable canopy cover.",
        "meta_lang": "en",
        "meta_favicon": "https://www.the-cryosphere.net/favicon_copernicus_16x16_.ico",
        "meta_site_name": "",
        "canonical_link": "https://tc.copernicus.org/articles/17/4343/2023/",
        "text": "2.2âEquipment\n\nThree quadcopters were utilized in mapping the subplots: a DJI Mavic Pro, a DJI Phantom 4 Advanced, and a DJI Phantom 4 RTK (TableÂ 1). The Phantom 4 RTK represents the recently popularized UAS type which utilizes two GNSS (global navigation satellite system) receivers, one operating as a base station and one as a rover. Using a RTK (real-time kinematic) or PPK (post-processing kinematic) solution, positioning accuracy can achieve a level of a few centimeters, compared to the accuracy of a few meters obtained by the autonomously operating single-frequency GNSS receiver found in consumer-grade UASs such as the DJI Mavic Pro or the DJI Phantom 4 Advanced (e.g., TomaÅ¡tÃ­k et al., 2019). Besides the quadcopters, a fixed-wing senseFly eBee Plus RTK drone was utilized during the four field campaigns to collect larger datasets encompassing either the subplots in a single flight or the whole catchment area (Fig.Â 1b).\n\nThe DJI Mavic Pro quadcopter is a comparably small UAS with a weight of less than 800âg and a folded size of 8.3Ã8.3Ã19.8 âcm; it thus represents a very portable option considering aerial mapping in areas that are difficult to traverse, especially during the winter months. The Mavic Pro has a comparably small 1/2.3 âin. sensor with 12.3Â megapixels and a 26âmm (35âmm equivalent) lens, with the focus being mostly on portability.\n\nThe DJI Phantom 4 Advanced and the DJI Phantom 4 RTK quadcopters are roughly 19Ã29Ã29 âcm in size and weigh around 1.4âkg, and both have 1âin. sensors with 20Â megapixels and a 24âmm (35âmm equivalent) lens. The DJI Phantom 4 quadcopters represent average-sized UASs when considering the portability in this context. Compared to the Mavic Pro, the Phantom 4 quadcopters have an increased maximum speed (65 vs. 72âkmâhâ1), increased maximum flight time (27 vs. 30âmin), and arguably better wind resistance. The larger sensor size of the Phantoms also improves their light gathering ability, which is generally linked to improved image quality.\n\nThe senseFly eBee Plus RTK fixed-wing UAS has a wingspan of 110âcm and a weight (including camera) of around 1.1âkg. The large size greatly reduces the portability of the eBee. However, being a fixed-wing UAS, the eBee has a greatly improved flight time (59âmin) and maximum speed (110âkmâhâ1) and consequently has a greatly improved areal coverage when compared to the quadcopters. The eBee was equipped with a senseFly S.O.D.A. with a 1âin. 20Â megapixel sensor and a 29âmm (35âmm equivalent) lens. As the eBee Plus RTK fixed-wing UAS cannot ascend and descend vertically, it requires a comparably flat and large clearing for takeoff and landing when compared to the quadcopters.\n\nExternal ground control points (GCPs) and an RTK GNSS receiver to measure location are needed for rectifying the gathered aerial imagery, especially with UASs which are not equipped with internal RTK correction. In this study, a Trimble R10 and a Topcon HiPerÂ V RTK GNSS receiver were utilized for measuring the GCP locations. The necessity of marking and measuring the GCPs can be burdensome for the field crew, especially during the polar nights, when the time window for flights is short and the GCPs might have to be crafted in the dark. Furthermore, carrying the extra equipment severely reduces the portability of the UAS, although, with a field crew of two or more people, it is somewhat easier to divide the load or use a sled, even when equipped with skis. The RTK-equipped UASs also require an RTK base station. However, as static equipment which can be placed into a suitable location, the RTK system is much less work-intensive, although the purchasing cost of it is many times higher.\n\n2.4âData processing and analysis\n\nThe acquired aerial data were processed using Agisoft Photoscan/Metashape Professional v1.4.5./v.1.6., which employs the SfM technique to produce orthomosaics and DSMs. The SfM technique is described in detail by Westoby et al.Â (2012). To better harmonize the data, each dataset was processed using high-quality and moderate depth filtering settings. The produced orthomosaics and DSMs were further processed in ESRI ArcGIS 10.6 (Fig.Â 2). Due to the poor sub-canopy penetration of the SfM technique (Harder et al., 2020), masking was used to omit data at the locations and in the immediate vicinity of trees (Fig.Â 3). The three masks were generated using maximum likelihood supervised classification, which is a probabilistic approach derived from Bayes' theorem (Ahmad and Quegan, 2012). In the classification, each pixel is assigned to one of the desired classes to which it has the highest likelihood of belonging, based on the training samples. The supervised classification was based on the orthomosaics from the 3Â AprilÂ 2019 survey that had snow-free tree canopies, thus showing the high contrast between the canopies and snowy ground. Further analysis revealed that sometimes the SfM technique struggled with depth mapping of deciduous and snow-covered trees, thus leading to artificially high snow depths immediately next to trees/masks. To mitigate the errors, the masks were further buffered by 36âcm, which was found to be a good compromise for removing artificially high values without losing too much data close to the trees.\n\nAfter manual cleanup of a few classification errors, the masks were utilized for canopy removal before subtracting the snow-free (bare-ground) DSM from each snow-covered DSM, thus producing the DEMs of difference (DoDs) highlighting the snow depth. Finally, the DoDs (used interchangeably with snow depth map) were aggregated to 50âcm per pixel resolution before further analysis. The aggregation allowed us to smoothen some small-scale variability while retaining a reasonable resolution for the snowâvegetation interaction analysis discussed in the accompanying paper (MeriÃ¶ et al., 2023). The 50âcm per pixel resolution was decided as a good middle ground following the findings of De Michele et al.Â (2016), who demonstrated how the standard deviation of UAS-derived snow depth increases with increasing resolution but stabilizes at a â¤â1âm pixel size.\n\nTo estimate the uncertainty of generated DSMs, the difference between UAS and RTK GNSS elevation Îz at each checkpoint was calculated following Eq.Â (1):\n\n(1) Î z t = DSM S , t - z CP , t ,\n\nwhere t is the date of survey, DSMS is the snow surface elevation from the UAS survey, and zCP is the checkpoint elevation measured with RTK GNSS. Considering error propagation when differentiating between two DSMs (e.g., Brasington et al., 2003), the precision of the DoDs highlighting the snow depth was estimated following Eq.Â (2):\n\n(2) u = Ï ( Î z t ) 2 + Ï ( Î z G ) 2 ,\n\nwhere Ï(Îzt) is the standard deviation for the difference between UAS and RTK GNSS elevation Îz for each winter survey and Ï(ÎzG) is the standard deviation for the difference between UAS and RTK GNSS elevations for the snow-free ground DSM. Since the DSMs are not free of bias (i.e., mean error), error propagation for mean errors highlighting the trueness of DoDs were calculated following Eq.Â (3):\n\n(3) m = Î¼ Î z t - Î¼ Î z G ,\n\nwhere Î¼ (Îzt) is the mean error for the difference between UAS and RTK GNSS elevation Îz for each winter survey and Î¼ (ÎzG) is the mean error for the difference between UAS and RTK GNSS elevations for the snow-free ground DSM. Snow depth for each pixel hsDSM was calculated following Eq.Â (4):\n\n(4) hs DSM , t = DSM S , t - DSM G ,\n\nwhere DSMS is snow surface elevation from the UAS survey and DSMG is the snow-free ground elevation from the UAS/ALS survey. The difference between UAS-derived snow depth and manual snow course measurements Îhs was calculated following Eq.Â (5):\n\n(5) Î hs t = hs DSM , t - hs SL , t ,\n\nwhere hsSL,t is the manual snow depth measurement.\n\n3.2âComparison to manual snow course measurements\n\nManual snow course measurements resulted in mean snow depths and standard deviations of 36.8 and 4.8âcm for the DEC 12 survey, 76.5 for the FEB 21 survey, 86.9 and 9.1âcm for the APR 03 survey, and 35.8 and 20.6âcm for the APR 24 survey. A general trend of increasing snow depth variation in the landscape was observed as winter progressed, indicated by the standard deviations. During the APR 24 survey, the variation was high due to the spring melt and resulting flooding already being especially pronounced in the mire area. If the mire area is ignored, the mean snow depth and standard deviations were 46.2 and 10.5âcm for APR 24. FigureÂ 7 shows examples of snow depth distributions, along with manual snow course and single automatic ultrasonic snow depth measurements during different surveys, obtained using the P4RTK data. The histogram shapes are generally long-tailed normal distributions. The biggest deviances from a normal distribution are seen on the mire and mixed subplots during the APR 24 spring melt.\n\nTable 5 shows the statistics for differences between the UAS-derived snow depths and the manual snow course measurements calculated following Eq.Â (4). The data are provided for snow depth DoDs utilizing the UAS-derived snow-free DEM and the ALS-derived snow-free DEM. It should be noted that the values do not account for any potential systematic or random errors in the manual snow course measurements. The snow depth measurements with P4RTK are of practically equal accuracy regardless of whether UAS or ALS data are used as the snow-free bare-ground model. With Mavic and eBee, utilizing the ALS bare-ground model produced generally more accurate results. Mavic and eBee tend to produce a higher number of outlier magnitude errors when compared to P4RTK, which clearly generates the most accurate data of the three, especially when UAS data are used as a snow-free model.\n\nNot including outliers, the greatest differences between the snow course and UAS-derived snow depths were observed in the mire subplot during the APR 24 survey. These differences are most probably related to the spring melt and flooding that were pronounced on the mire subplot (see Fig.Â 4), which resulted in some of the snow course points being under a mixture of muddy water and ice. In the manual snow course survey, these points were marked as having zero snow depth. However, the UAS approach, based on SfM photogrammetry and differentiating between the DEMs, produces average snow depths of 23â35.6âcm for these points. TableÂ 6 shows the statistics for differences between the UAS-derived snow depths and manual snow course measurements when the APR 24 survey data are removed from the dataset, i.e., when all UASs have an equal number of data points. The removal of the APR 24 data, including the spring melt data points from the mire subplot, further demonstrates the better accuracy of P4RTK compared to the other UASs.\n\nIn the early snow season with low snow depths, no clear correlation was observable on individual subplots/dates when comparing manual snow depth measurements and the UAS-derived snow depth pixels at the location of the manual measurement (Table 7). This is likely due to the snow depth being quite uniform in the early winter. Thus, the small variations in the snow depth are not captured well due to inherent random errors in the UAS-based snow depth measurements. A clear increase in correlation is observed when the winter progresses and the snow depths increase and/or local snow depth variability increases. If the flooding mire subplot during APR24 is excluded, the correlation coefficient for P4RTK would be as high as 0.86. When all subplots from different field trips were combined, statistically significant Pearson correlations were observed for each UAS at a significance level of 0.05. The correlations between UAS and field measurements were 0.89 for P4RTK, 0.64 for Mavic, and 0.60 for eBee, when utilizing UAS data as a snow-free bare-ground model. Correspondingly, the correlations were 0.87 for P4RTK, 0.74 for Mavic, and 0.81 for eBee when utilizing ALS data for the snow-free model.\n\nFigureÂ 8a combines measurements from the DEC 12, FEB 21, and APR 03 surveys to highlight the effect of land cover, and Fig.Â 8b combines all subplots to highlight the effect of survey date on the difference between UAS-derived snow depths and manual snow course measurements when UAS data are used as the snow-free bare-ground model. FigureÂ 9a and b provide corresponding data for when ALS data are used as the snow-free model. Separate boxplots for each subplot and date are provided in the Supplement (Fig.Â S3).\n\nWhen utilizing UAS data as a snow-free model, there are statistically significant differences in sample variances with respect to land cover (Fig.Â 8a) for each UAS, but there are no significant differences concerning survey date (Fig.Â 8b). A similar trend that was observed with the GNSS checkpoints can also be seen, with accuracy decreasing when moving from mire to mixedâforest subplot. When comparing the UASs to each other, there are statistically significant differences for each subplot and survey date with P4RTK always producing the most accurate data and eBee producing the second best, aside from the mixed subplot, where a large bias was observed with eBee when comparing the DEM and DoD data on GNSS checkpoints (TableÂ 4).\n\nWhen ALS data are used as a snow-free model, there are similarly significant differences in sample variances to land cover with each UAS (Fig.Â 9a) but also for survey date with Mavic and eBee (Fig.Â 9b). Again, the accuracies decrease with a move from mire to mixedâforest. With respect to survey date, Mavic performed poorly during the DEC 12 and FEB 21 surveys, and eBee performed poorly during the FEB 21 survey. There is noticeable positive bias with all UASs during the DEC 12 survey and a negative bias during the APR 03 survey. To a degree, these biases are also seen in comparison to checkpoints, especially in the case of the DEC 12 survey when all UASs had the tendency of overestimating the snow surface elevation. When comparing the UASs to each other, statistically significant differences in variances between the UASs are observed only with the forest subplot and DEC 12 survey. In both cases, Mavic clearly produces the least accurate data. In general, the utilization of ALS data as a snow-free model clearly benefits Mavic and eBee in all situations, whereas there is no practical difference with P4RTK, which again produces the most accurate data in each case. However, with the ALS, the accuracies of eBee and Mavic are in general much closer to P4RTK. Table 8 shows the RMSEs for the data displayed in Figs.Â 8 and 9 for a comparison, with existing literature discussed in the next section.\n\n4.1âAccuracy of UAS-based snow depth measurements for different platforms\n\nWhen considering the SfM approach and the resulting model accuracy to detect snow depth, the biggest differences in the specifications of the UAS and flight parameters used in the study were between the camera sensors and focal lengths, as well as the utilized flight height and georeferencing method. The flight heights had to be optimized to be able to fly individual missions in 15â20âmin with the multicopters to account for the reduced battery performance in cold weather. This resulted in slight differences in the resulting ground sample distances between the UASs. However, by far the greatest differences were in the georeferencing methods, with Mavic (and P4A) relying solely on GCPs and P4RTK and eBee relying more on RTK correction to ensure high positional accuracy of the UAS, with a single GCP utilized to mitigate possible elevation bias.\n\nThe accuracy of GCP-based georeferencing and the suitable number of GCPs have been discussed by several authors (Tonkin and Midgley, 2016; MartÃ­nez-Carricando et al., 2018; Sanz-Ablanedo et al., 2018; Yu et al., 2020). Generally, such assessments are done in open-area locations, where the planning and distribution of the GCP network is relatively easy. In complex, forested environments with thick snow cover, the distribution of GCPs is generally more challenging, considering the lack of mobility, time constraints, and a lack of open areas with an unrestricted view of the sky. Nevertheless, these kinds of studies can be used as a baseline to assess the quality of GCP placement in this study. The importance of uniform GCP distribution for high data accuracy was highlighted by Tonkin and MidgleyÂ (2016), although they also note that excess GCPs lead to diminishing returns. Sanz-Ablanedo et al.Â (2018) demonstrated that a planimetric RMSE accuracy similar to Â±GSD was achieved with approx. 2.5â3Â GCPs per 100 photos. Vertical accuracy improved towards 1.5Ã GSD when using more GCPs, with the maximum in their tests being achieved with 4 GCPs per 100 photos. MartÃ­nez-Carricando et al.Â (2018) demonstrated that with stratified GCP distribution, there was a clear improvement in vertical accuracy when moving from 0.25 to 1âGCP per hectare (RMSE from 30.8 to 5.2âcm), whereas moving from 1 to 2âGCPs per hectare (RMSE 4.3âcm) yielded diminishing returns. Yu et al.Â (2020) argued that for survey areas of 7â39âha, a minimum of 6âGCPs were required for an accuracy of 10âcm, and more than 12âGCPs were required for optimal results.\n\nIn recent years, multiple studies have also compared DSM accuracies produced by GCP georeferencing and DSM accuracies produced through RTK/PPK solutions (Benassi et al., 2017; Forlani et al., 2018; Bolkas, 2019; PadrÃ³ et al., 2019; TomaÅ¡tÃ­k et al., 2019; Zhang et al., 2019). TomaÅ¡tÃ­k et al.Â (2019) compared the PPK approach to georeferencing with 4 and 9âGCPs under two different canopy conditions (study area approx. 270âha) and concluded that the PPK approach offered better or equal accuracy and was not influenced by vegetation seasonal variation, unlike GCP georeferencing. Zhang et al.Â (2019) compared PPK to georeferencing with 8âGCPs on cultivated land (study area approx. 1.7âha) before and after plowing and concluded that a PPK solution produces the same accuracy as the GCP approach, but a single GCP is necessary to correct possible vertical bias. Comparing the RTK approach to georeferencing with 12âGCPs in an urban area (approx. 18âha) with buildings, roads, car parks, and meadows, Forlani et al.Â (2018) had similar results showing how RTK can offer a similar accuracy when at least 1âGCP is utilized to correct vertical bias.\n\nThe three subplots in this study were between approx. 14.4â15.9âha, and the average number of GCPs was 13 per subplot (8â17 depending on the survey), resulting in an average of 5.1âGCPs per 100 photos and 0.87âGCP per hectare or 7.38âGCPs per 100 photos and 1.27âGCP per hectare when the 6âPGCPs are also included. Thus, the number of GCPs utilized was within the range suggested by Sanz-Ablanedo et al.Â (2018), MartÃ­nez-Carricando et al.Â (2018), and Yu et al.Â (2020). Furthermore, there was no significant Kendall's rank correlation between the number of GCPs utilized and the accuracy (e.g., standard deviation or mean absolute error) of snow depth measurements with Mavic, which relied solely on GCP georeferencing. Nevertheless, with regards to accuracy, P4RTK utilizing a single GCP clearly outperformed Mavic utilizing all available GCPs and PGCPs, although it should be noted that Mavic has a smaller sensor size and had slightly lower (â¼â0.7âcm) GSD. More surprisingly, the accuracy of P4A utilized during the DEC 12 surveys was clearly worse compared to P4RTK and was more in line with Mavic data (see Supplement), although the two Phantoms have the same sensor size and focal length and had practically the same GSD. This might indicate that RTK-supported data acquisition outperforms the traditional GCP-based method in these conditions even when only utilizing a single GCP with the RTK. This is somewhat in line with the results of TomaÅ¡tÃ­k et al.Â (2019), who reported that the PPK approach was not influenced by seasonal variation in vegetation, unlike the GCP georeferencing approach. However, it should also be noted that the DEC 12 measurements were made during low-light polar-night conditions in which a comparably short time difference between the subsequent flights could significantly affect the amount of available light. The eBee data show a clear negative bias in the mire subplot and on some occasions positive bias in the forest subplot (see Fig.Â S2 in the Supplement), possibly indicating small orientational errors in the datasets acquired for the whole catchment. Thus, for large datasets, a single GCP might not be sufficient for RTK-equipped UASs. A recent study by RauhalaÂ (2023) highlighted that a UAS survey in a 1âkm2 area significantly benefitted from the utilization of multiple GCPs even when utilizing PPK correction.\n\nProcessing the non-RTK data with only PGCPs did not provide sufficiently accurate data, as broad-scale systematic errors were observed with a pattern sometimes referred to as âbowingâ or âdomingâ which can affect SfM-processed nadir-only imagery (James and Robson, 2014). However, solely using GCPs resulted in slightly reduced vertical accuracy compared to utilizing both GCPs and PGCPs. The PGCPs would have been particularly helpful in remedying potential vertical or horizontal offsets between different models with further georeferencing done using, for example, an iterative closest point (ICP) algorithm, which would provide comparably stable control points regardless of the snow depth. To be practical with the RTKâUAS workflow, the PGCPs would have to be shaped in a way that discourages the accumulation of snow on top of the PGCP to remove the need for manual cleaning of accumulated snow.\n\nRecently, Revuelto et al.Â (2021) did a comparison of different UASs in snow depth mapping, including two affordable multicopters (Parrot ANAFI and DJI Mavic Pro 2) and a senseFly eBee Plus fixed-wing UAS, which was also utilized in this study. They concluded that under same illumination conditions, all the tested platforms provide equivalent snow depth products in terms of accuracy. However, they noted that all the snow depth maps utilized the same snow-free point cloud (acquired by the eBee Plus) and thus are not fully independent. In our case, statistically significant differences were observed between the UASs in each subplot and survey date when utilizing independent UAS-derived snow-free models. When utilizing the non-independent ALS-derived snow-free model, however, significant differences were only observed in the forest subplot or during the low-light DEC 12 conditions. This clearly highlights the importance of an accurate snow-free model and how the snow-free model can be a bottleneck with regards to snow depth map accuracy when operating certain UASs (e.g., eBee or Mavic). It might be beneficial to acquire a very accurate snow-free model with lidar as a baseline for snow depth mapping, especially in a complex, forested landscape. Another option would be to make extra effort in acquiring a very high-resolution and high-accuracy snow-free model with UASâSfM utilizing professional UASs, even if the winter measurements would be performed with a more portable platform. Especially in northern locations, there generally are very long daily aerial survey windows as the Sun never sets and the fieldwork is overall less demanding.\n\nRevuelto et al.Â (2021) also noted that in challenging lighting (overcast sky), all of the UASs failed to properly retrieve the snow surface. Diffuse lighting during cloudy conditions and homogeneous snow cover, especially immediately after fresh snowfall, results in low contrast that can cause gaps and large outliers in the generated point clouds (Harder et al., 2016; BÃ¼hler et al., 2017). Some authors have also noted that direct sunlight and for example patchy snow cover can lead to similar issues due to overexposed pixels, especially if relying on automatically adjusted exposure (Harder et al., 2016). In our case, there were surprisingly no statistically significant differences for any UAS between the low-light conditions in December and sunny conditions in February and April when utilizing independent UAS-derived snow-free models, although a slight increase in accuracy is seen in the DEC 12 to FEB 21 survey. This could be explained by the polar twilight (civil twilight) providing enough directional light to create sufficient contrast during solar noon and clear-sky conditions. Also, the low snow depths with less spatial variability during the early winter results in a feature-rich snow surface due to the natural variability in the forest floor topography and vegetation. Further steps were taken to adjust the flight speed and camera parameters to allow a lower shutter speed and only a slight increase in ISO value (max two stops to ISO400) to keep the image noise tolerable.\n\nHowever, we observed that regardless of the utilized snow-free model, the accuracy was more dependent on land cover type. This seems to be the general trend observed in other studies utilizing a UASâSfM approach in snow depth measurements, although most studies report accuracy only in open areas or do not separate between different vegetation types, with reported RMSEs varying between â¼â6â58âcm depending on the study (Vander Jagt et al., 2015; De Michele et al., 2016; Harder et al., 2016; BÃ¼hler et al., 2017; Cimoli et al., 2017; Adams et al., 2018; Avanzi et al., 2018; Revuelto et al., 2021). BÃ¼hler et al.Â (2016) report an RMSE of 7âcm for areas with short grass and 30âcm for areas with brushes and/or high grass, while Broxton and van LeeuwenÂ (2020) report an RMSE of â¼â10âcm in sparsely forested area and â¼â10â20âcm in densely forested area. Harder et al.Â (2020) utilized the UASâSfM approach in mapping snow depths at study sites classified by vegetation height to open (<â0.5âm), shrub-covered, and tree-covered (>â2âm) areas, looking at two sites each. They report an RMSE of 10â30âcm in open areas, 13â19âcm in shrub areas, and 20â33âcm in tree areas with dense needleleaf forest having a higher RMSE (33âcm) compared to leaf-off deciduous trees (20âcm).\n\nIn our case, none of the GNSS checkpoints or snow stakes were directly under canopy, yet there is a clear difference between the accuracies obtained for open mire and mixedâforest subplots. It is difficult to determine whether the different studies that include forested areas have reference data points under canopy or between trees. Nevertheless, the general trend seems to be for forest areas providing less accurate snow depth data. Possible explanations for this may include reduced GNSS accuracy, understory vegetation, shadows, lighting-related issues, and the reduced accuracy of SfM procedure for more complex landscape.\n\nRecent studies have also started to investigate a UASâlidar approach to snow depth mapping partly due to the greater canopy penetration of lidar systems compared to SfM. Harder et al.Â (2020) compared UASâSfM and UASâlidar approaches and reported the UASâlidar approach as equally successful in penetrating deciduous and needleleaf canopies, although the errors were larger (RMSE 13â17âcm) in vegetated sites compared to open areas (9â10âcm). The UASâSfM approach had a wider variation in errors as discussed above. Jacobs et al.Â (2021) utilized a more moderately priced UASâlidar system, about a third of the price of the system utilized by Harder et al.Â (2020), and report RMSEs of 1.2âcm for open areas and 10.5âcm for mixed forest sites consisting of deciduous and coniferous trees. However, the system utilized by Jacobs et al.Â (2021) had a relatively short battery life, and the total reported survey time of 2âh for the 9.8âha survey was relatively high. Dharmadasa et al.Â (2022) also utilized a UASâlidar approach and report RMSEs of 4.3â22âcm for field sites, 7.9â12âcm for deciduous forest sites, and 19â22âcm for coniferous boreal forest sites. Furthermore, Dharmadasa et al.Â (2022) argue that remote sensing techniques alone are not able to provide comprehensive snow depth distribution under a coniferous canopy despite the increased point density provided by the UASâlidar approach when compared to a traditional ALS approach. Recent study by Å troner et al.Â (2023) highlighted that while mapping snow-free forest sites, low-cost UASâlidar (DJI Zenmuse L1) can produce much better coverage under the canopy but still has significantly lower vertical accuracy than a high-quality UASâSfM camera (DJI Zenmuse P1) that is half the price.\n\n4.2âOperational challenges and further considerations\n\nUAS platforms and their use in general topographic mapping have been reviewed by Nex and Remendino (2014) and Colomina and Molina (2014), whereas relevant camera system and camera setting considerations have been reviewed by Mosbrucker et al.Â (2017) and O'Connor et al.Â (2017), as well as different challenges related to, for example, location and weather by Duffy et al.Â (2018) and Kramar et al.Â (2022). Typical platform considerations, such as payload, flight speed, and wind resistance, are relevant for snow depth mapping, but there are also some special considerations to be made. First, battery life may drop severely in sub-zero temperatures. Secondly, as plowed roads may not be available, portability can become an issue depending on whether a snowmobile or sled is available or if the crew has to rely on snowshoes or skis. Considering the selection of suitable camera systems and camera settings for arctic and subarctic conditions, the short days and low-light conditions during winters in high latitudes require extra attention. An emphasis should be placed on selecting a lens with a relatively large aperture and a large sensor which allows a high enough ISO value (i.e., sensor gain) to provide sufficient shutter speeds without compromising the signal-to-noise ratio. The typically greater dynamic range of large sensors is also important, since the polar-night conditions have lower contrast over snow cover, while low sun angles during early spring create heavy shadows. However, a large sensor often increases the camera size and weight, which in turn affects the battery life, UAS platform size, and the portability of the system.\n\nWhen operating in subarctic winter, weather-related phenomena produce the clearest challenges in terms of preflight preparations, operation, data quality, and battery life. In our case, study site evaluation and preliminary flights were performed during the spring preceding the study winter to find the optimal flight parameters and suitable takeoff and landing areas. Due to the remoteness of the site, the amount of time and the field crew size required for the ground and aerial surveys were also considered, with a target of completing each survey within 1Â week. The most notable changes were to the size of the survey area in order to ensure it could be covered in the available time with the required data quality. This was needed because of the issues with the drone battery life, the short daily aerial survey window due to limited daylight time during midwinter, often unpredictable weather conditions, and deep soft snow conditions slowing down the deployment of GCPs. Unpredictable weather places unavoidable limitations on all UAS operations. In our case, the planned surveys were postponed several times during the winter due to weather conditions, including snowfall, very low temperatures, and high wind speeds.\n\nDuring fieldwork, wind and temperature data from local weather stations were used to find optimal time windows for the surveys. However, partly because of the nearby fells, sudden wind gusts forced flight operations to be halted a few times. On one occasion, sudden gusts stopped the autopilot-controlled UAS in its place during a mission and manual âtackingâ maneuvers were required to bring it back to the takeoff and landing location. The field experience indicated that the more robust drones (P4A, P4RTK, eBee) could be operated at up to 10âmâsâ1 with higher wind/gust speeds, whereas the lighter-weight Mavic could not be confidently operated in such conditions.\n\nFurthermore, the topography in the area caused rapid temperature changes, especially in the open mire located in lower elevations between the fells. The survey in January was unsuccessful due to very low temperatures (â30ââC), which caused freezing of the DJI Mavic lens system, leading to unfocused aerial photographs. One potential cause of this may be condensation and subsequent freezing of water in the lens machinery caused by temperature changes while moving from the warm storage area to a cold car and again to a warm research station premise before outdoor flights in cold conditions. One possible solution could be to use desiccant bags to reduce moisture and use a more heavily insulated bag for the storage of the UASs to help slow acclimation to a new environment.\n\nUAS manufacturer guidelines usually give general recommendations on the operational temperature range of the UAS batteries. In cold climates, the lower limit is naturally the concern, and significant drops in capacity or even malfunctions can be experienced in low, sub-zero temperatures (Ranquist et al., 2017). Some smart batteries can also have digital warning indicators or even power cutoffs preventing takeoff if the temperature is too low, thus requiring pre-heating. One good option is to store the batteries in a heat box to retain an optimal battery temperature and as much capacity as possible during fieldwork. The UAS powertrain in quadcopters was observed to create enough heat to keep the drone operational in cold temperatures. However, there might be variability between different models of UASs. Consumer-grade drones are usually certified to operate in above-zero temperatures with some exceptions to above â10ââC (Ranquist et al., 2017). Real-world experience has shown that P4RTKs rated as operating in temperatures between 0 and 40ââC can be fully operated in under â10ââC temperatures.\n\nTemperatures close to 0ââC also caused problems due to moisture, especially for the fixed-wing systems. As highlighted by Revuelto et al.Â (2021), fixed-wing models that rely on belly landing, such as eBee, can have issues with rugged or wet surfaces. We only experienced issues with eBee during the spring melt season, when a malfunction resulted in a loss of data, possibly due to water getting into the electronics during a landing on wet snow. Fixed-wing UASs with VTOL (vertical takeoff and landing) capabilities, which have recently become more widely available, may partly mitigate the issues of sub-optimal landing areas while still retaining the advantages of fixed-wing platform, such as longer flight times and larger mapping area extent compared to multicopters.\n\nThere are several advantages to the UASâlidar approach over the UASâSfM, including more accurate DEM extraction when flying over homogenous textures and the possibility of better penetration of the tree canopy. Compared to the UASâSfM approach, which uses passive RGB camera sensors, UASâlidar, as an active measurement technique, provides the possibility of nighttime operation, which becomes very useful during the winter months in northern latitudes when the day only lasts for a couple of hours. Furthermore, the price of a professional grade UASâlidar setup is considerably higher than a professional grade UASâSfM setup, although prices have dropped noticeably over recent years. Nonetheless, relatively cheap UASs relying on UASâSfM, such as DJI Mavic Pro, can do the job, especially in more open areas and under good lighting conditions. A slightly more expensive RTK-equipped UAS can be well worth the extra costs as the need for GCPs are reduced and the data quality is generally superior due to better sensor capabilities and improved georeferencing.\n\nFinally, some recommendations and observations can be summarized:\n\nThe obtained results indicate that UASs with RTK correction and a single GCP for bias correction can provide sufficient accuracy for snow depth mapping with much less fieldwork involved, thus improving efficiency and safety.\n\nFor considerably larger areas than the subplots (<â20âha), multiple GCPs would likely be beneficial even with RTK-capable UASs.\n\nAn accurate snow-free model is essential since any errors will propagate to snow depth models.\n\nA snow-free baseline obtained with ALS can benefit some UASs, especially in complex, forested landscapes.\n\nPolar twilight can provide enough (directional) light during solar noon and in clear-sky conditions for sufficient contrast required in UASâSfM processing.\n\nConsumer-grade and professional UASs can be fully operated in under â10ââC temperatures, but care should be taken to keep batteries warm and to avoid quick temperature changes moving outdoors."
    }
}