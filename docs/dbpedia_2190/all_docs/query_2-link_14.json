{
    "id": "dbpedia_2190_2",
    "rank": 14,
    "data": {
        "url": "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/plenary-talks.html",
        "read_more_link": "",
        "language": "en",
        "title": "Plenary Speakers",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/site/injcnn.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/images/ijcnn2017-banner-v3.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/site/facebook.png",
            "https://injcnn.memberclicks.net/assets/images/twitter.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/images/inns.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/images/ieee.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/images/sponsors/intel_rgb_3000.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/images/sponsors/bscs-small.png",
            "https://people.engr.tamu.edu/choe/choe/ijcnn2017-web/assets/images/sponsors/bmi-logo-small.png",
            "https://injcnn.memberclicks.net/assets/images/plenary/alexgraves.jpg",
            "https://injcnn.memberclicks.net/assets/images/plenary/grossberg.jpg",
            "https://injcnn.memberclicks.net/assets/images/plenary/jenkins.jpg",
            "https://injcnn.memberclicks.net/assets/images/plenary/koch.jpg",
            "https://injcnn.memberclicks.net/assets/images/plenary/principe.jpg",
            "https://injcnn.memberclicks.net/assets/images/plenary/siegelmann.jpg",
            "https://injcnn.memberclicks.net/assets/images/plenary/werbos.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jae Kwon"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "templates/mc-full-template-01-jt/favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Stephen Grossberg\n\nWang Professor of Cognitive and Neural Systems, Boston University\n\nBio: Wang Professor of Cognitive and Neural Systems, Boston University. Founding President, International Neural Network Society. Founding Editor-In-Chief, Neural Networks. Recipient of INNS Helmholtz Award (2003). IEEE Frank Rosenblatt Award (2017). INNS Fellow. [See full biosketch]\n\nTitle: Towards Solving the Hard Problem of Consciousness: The Varieties of Brain Resonances and the Conscious Experiences that they Support\n\nAbstract:\n\nWhat happens in our brains when we consciously experience sights, sounds, feelings, and knowledge about them? The Hard Problem of Consciousness is the problem of explaining how this happens. To solve this problem, a theory of consciousness needs to link brain to mind by modeling how brain dynamics give rise to conscious experiences, and specifically how the emergent properties of brain dynamics generate properties of individual experiences and of the psychological and neurobiological data that they generate. This talk summarizes evidence that Adaptive Resonance Theory, or ART, is accomplishing this goal. ART is a cognitive and neural theory of how advanced brains autonomously learn to attend, recognize, and predict objects and events in a changing world. ART has predicted that “all conscious states are resonant states” as part of its specification of mechanistic links between processes of consciousness, learning, expectation, attention, resonance, and synchrony. It hereby provides functional and mechanistic explanations of data ranging from individual spikes and their synchronization to the dynamics of conscious perceptual, cognitive, and cognitive-emotional behaviors. ART has now reached sufficient maturity to begin classifying the brain resonances that support conscious experiences of seeing, hearing, feeling, and knowing. The talk will review various of these resonances, their similarities and differences, including where they occur in our brains; how they interact when we feel and know about what we see and hear; and various of the normal and clinical psychological and neurobiological data that they explain and predict, and which have not been explained by alternative theories. The talk will mention some resonances that do not become conscious, and why, including why not all brain dynamics are resonant in terms of the computationally complementary organization of cortical processing streams.\n\nOdest Chadwicke Jenkins\n\nAssociate Professor of Computer Science and Engineering, University of Michigan\n\nBio: Associate Professor of Computer Science and Engineering, University of Michigan. Sloan Research Fellow, Recepient of the Presidential Early Career Award for Scientists and Engineers (PECASE), and young investigator award from Office of Naval Research and Air Force Office of Scientific Research.\n\nTitle: Perception of People and Scenes for Robot Learning from Demonstration\n\nAbstract:\n\nWe are at the dawn of a robotics revolution where the visions of interconnected heterogeneous robots in widespread use will become a reality. Similar to \"app stores\" for modern computing, people at varying levels of technical background will contribute to \"robot app stores\" as designers and developers. However, current paradigms to program robots beyond simple cases remains inaccessible to all but the most sophisticated of developers and researchers.\n\nIn order for people to fluently program autonomous robots, a robot must be able to interpret commands that accord with a human’s model of the world. The challenge is that many aspects of such a model are difficult or impossible for the robot to sense directly. We posit the critical missing component is the grounding of symbols that conceptually tie together low-level perception with user programs and high-level reasoning systems. Such a grounding will enable robots to perform tasks that require extended goal-directed autonomy as well as fluidly work with human partners.\n\nTowards making robot programming more accessible and general, I will present our work on improving perception of people and scenes to enable robot learning from human demonstration. Robot learning from demonstration (LfD) has emerged as a compelling alternative to explicit coding in a programming language, where robots are programmed implicitly from a user’s demonstration. Phrasing LfD as a statistical regression problem, our multivalued regression algorithms will be presented for learning robot controllers in the face of perceptual aliasing. I will also describe how such regressors can be used within physics-based estimation systems to learn controllers for humanoids from monocular video of human motion. With respect to learning for sequential manipulation tasks, our recent work aims to perceive axiomatic descriptions of scenes from depth for planning goal-directed behavior.\n\nChristof Koch\n\nPresident and Chief Scientific Officer, Allen Institute for Brain Science\n\nBio:Professor of Biology and Engineering at the California Institute of Technology in Pasadena. Chief Scientific Officer of the Allen Institute for Brain Science in Seattle. INNS Fellow.\n\nTitle: Big Science, Team Science, Open Science for Neuroscience\n\nAbstract:\n\nOver the past decade, the Allen Institute for Brain Science has produced a series of brain atlases. These are large (3 TB, > million slides) public resources, integrating genome-wide gene expression, and neuroanatomical data across the entire brain for developing and adult humans, non-human primates and mice, complemented by high-resolution, cellular-based anatomical connectivity data in several thousand mice. It is the largest integrated neuroscience database world-wide. Anybody can freely access this data without any restrictions at www.brain-map.org.\n\nSix years ago, we embarked on an ambitious 10-year initiative to understand the structure and function of the neocortex and associated satellite structures in humans and mice. We are setting up high through-put pipelines to exhaustively characterize the morphology, electrophysiology and transcriptome of cell types well as their synaptic interconnections in the laboratory mouse and in human neocortex (via a combination of fetal, neurosurgical and post-mortem tissues). We are building brain observatories to image the activities of 10,000s of neurons throughout the cortico-thalamic system in behaving mice, to record their electrical activities, and to analyze their connectivity at the ultra-structural level. We are constructing biophysically detailed as well as simplified computer simulations of these networks and of their information processing capabilities focusing on how the neocortical tissue gives rise to perception, behavior and consciousness.\n\nPaul Werbos\n\nProgram Director (retired), National Science Foundation\n\nBio: Former program director of National Science Foundation. Recipient of INNS Hebb Award (2011). INNS Fellow.\n\nTitle: Backpropagation in the Brain and More Advanced Learning Systems\n\nAbstract:\n\nThe recent explosion of interest in deep learning based on backpropagation is the result of empirical demonstration and testing of methods developed long ago, funded by NSF, DARPA and Google. The usual convolutional neural networks are not a valid model of computing in the cerebral cortex, because they assume Euclidean symmetry and are unable to learn simple mappings required, for example, in learning how to navigate a cluttered space; however, more general networks were also developed years ago, and demonstrated on less popular problems like power grid forecasting and incremental chess playing. This year empirical tests were also carried out on 24khz data from prefrontal cortex, strongly supporting our original theory of brain intelligence in which regular clocks and alternative forward and backward passes explain the power of cortical computation, and are preferred in the data over the more ancient theories of pure asynchronous computing by spiking networks or ODE. An empirical pathway has also been laid out to allow physical backpropagation of information, which promises to enable a new level of general intelligence through analog quantum computing more “conscious” than what we see in the mammal brain."
    }
}