{
    "id": "dbpedia_5470_0",
    "rank": 23,
    "data": {
        "url": "https://www.pelicancrossing.net/netwars/new_tech_old_knowledge/",
        "read_more_link": "",
        "language": "en",
        "title": "net.wars: New tech, old knowledge Archives",
        "top_image": "https://WWW.pelicancrossing.net/netwars/assets_c/2021/12/coyote-roadrunner-cliff-thumb-370x201-1121-thumb-370x201-1122.png",
        "meta_img": "",
        "images": [
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/12/coyote-roadrunner-cliff-thumb-370x201-1121-thumb-370x201-1122.png",
            "https://WWW.pelicancrossing.net/netwars/SphericalCow-IngridKallick-370.jpg",
            "https://WWW.pelicancrossing.net/netwars/Screenshot%20from%202022-11-04%2012-56-46-370.jpg",
            "https://WWW.pelicancrossing.net/netwars/We%20Robot%20-%202022%20-%20boston%20dynamics.JPG",
            "https://WWW.pelicancrossing.net/netwars/boris-johnson-on-his-bike-European-Cycling-Federation-370.jpg",
            "https://WWW.pelicancrossing.net/netwars/Tesla-crash-NYTimes-370.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2022/04/Protest_against_Amazon_by_East_African_workers_(32446948818)-thumb-370x246-1154.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2022/03/ElliQ7-thumb-370x256-1148.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2022/02/IPFS-medium-zkcapital-thumb-370x172-1142.jpeg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/11/512px-Web_2.0_Map.svg-thumb-370x277-1115.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/10/Frari_(Venice)_nave_left_-_Monument_to_Doge_Giovanni_Pesaro_-_Statue_of_the_Doge-thumb-370x294-1111.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/10/amazon-astro-thumb-370x237-1102.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/07/The_National_Archives_at_Kew_-_geograph.org.uk_-_2127149-thumb-370x277-1085.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2018/07/IBM-watson-jeopardy-thumb-370x191-761-thumb-370x191-762.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2018/06/sidewalklabs-streetcrossing-thumb-370x207-746.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/04/Sinan-Aral-20210422_224835-thumb-370x208-1066.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/04/swiss-cheese-virus-defence-thumb-370x236-1059.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/03/Zuck-congress-20210325_212525-thumb-370x212-1057.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/03/Screenshot from 2021-03-18 12-51-27-thumb-370x209-1055.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2021/02/Houston-HV-FINAL-Mobile-Van-2-thumb-370x166-1051.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2015/10/2015_Max_Schrems_(17227117226)-thumb-370x388-113.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2020/09/Official_portrait_of_Chi_Onwurah_crop_3-thumb-370x367-1008.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2016/05/bush-gore-hanging-chad-florida-thumb-370x235-279.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2020/05/squires-rainbow-thumb-370x208-972.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2020/03/china-alihealth-thumb-370x246-958.jpeg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2020/04/wizard-of-oz-crystal-ball-thumb-370x238-970.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2020/02/Vinci_-_Hammer_2A-PD-Wikimedia-thumb-370x251-954.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2020/01/Bug_de_l'an_2000-thumb-370x277-946.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/06/Wilcox, Dominic - Stained Glass car-thumb-370x244-872.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/10/zittrain-cim-iphone-thumb-370x277-924.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/10/cis50-banner-thumb-370x200-922.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/10/cropped-view-from-walkie-talkie-2017-thumb-370x222-917.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/08/Anomalisa-Fregoli-thumb-370x154-905.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/08/JI-sunrise--2-20190107_071706-thumb-370x208-892.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/07/Bambi-forest-thumb-370x277-884.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/06/sweat-nottage-thumb-370x208-878.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/05/2001-stewardess-thumb-370x205-868.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/04/Twitter-moral-labyrinth-thumb-370x277-852.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/04/Google koala car-thumb-220x146-854.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/03/nemeth-osi-9layer-tshirt-thumb-370x385-842.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2017/05/2001-hal-thumb-370x187-523.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/02/Metropolis-openingshot-thumb-370x277-836.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/02/kashmir-hill-untech-gizmodo-thumb-370x235-832.png",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2019/01/1155px-New_Year_2019_NZ7_1370_(31616532097)-thumb-370x288-822.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2018/10/Unity_sculpture,_Rochdale_(1)-thumb-270x360-798.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2018/10/Ada_Lovelace_Chalon_portrait-thumb-370x370-796.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2018/08/benjaminfranklin-pd-thumb-370x457-763.jpg",
            "https://WWW.pelicancrossing.net/netwars/assets_c/2018/07/IBM-watson-jeopardy-thumb-370x191-761.png",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2018/06/1891_Telegraph_Lines-thumb-370x232-743-thumb-370x232-744.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2018/05/whogetsthekidney-thumb-370x188-741.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2018/04/tennisballonclay-thumb-370x240-736.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/12/Bitcoin_Digital_Currency_Logo-thumb-360x357-690.png",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/11/werbach-final-panel-cropped-thumb-360x158-682.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/11/Tornado-Manitoba-2007-jpg-thumb-220x335-678.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/11/lanier-lrm-2017-thumb-360x200-676.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2016/07/new-22portobelloroad-thumb-360x219-314.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/10/cybersalon-october-thumb-220x165-664.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/09/London_Skyline-thumb-360x270-644.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/09/Travis_Kalanick_at_DLD_Munich_2015_(cropped)-thumb-220x247-646.jpg",
            "http://WWW.pelicancrossing.net/netwars/assets_c/2017/09/Black_London_Cab-thumb-220x164-648.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "It's hard to properly enjoy I-told-you-so schadenfreude when you know, from Juan Vargas (D-CA)'s comments this week, that disproportionately the people most affected by the latest cryptocurrency collapse are those who can least afford it. What began as a cultish libertarian desire to bypass the global financial system became a vector for wild speculation, and is now the heart of a series of collapsing frauds.\n\nFrom the beginning, I've called bitcoin and its sequels as \"the currency equivalent of being famous for being famous\". Crypto(currency) fans like to claim that the world's fiat currencies don't have any underlying value either, but those are backed by the full faith and credit of governments and economies. Logically, crypto appeals most to those with the least reason to trust their governments: the very rich who resent paying taxes and those who think they have nothing to lose.\n\nThis week the US House and Senate both held hearings on the collapse of cryptocurrency exchange and hedge fund FTX and its deposed, arrested, and charged CEO Sam Bankman-Fried. The key lesson: we can understand the main issues surrounding FTX and its fellow cryptocurrency exchanges without understanding either the technical or financial intricacies.\n\nA key question is whether the problem is FTX or the entire industry. Answers largely split along partisan lines. Republican member chose FTX, and tended to blame Securities and Exchange Commission chair Gary Gensler. Democrats were more likely to condemn the entire industry.\n\nAs JesÃºs G. \"Chuy\" GarcÃ­a (D-IL) put it, \"FTX is not an anomaly. It's not just one corrupt guy stealing money, it's an entire industry that refuses to comply with existing regulation that thinks it's above the law.\" Or, per Brad Sherman (D-CA), \"My fear is that we'll view Sam Bankman-Fried as just one big snake in a crypto garden of Eden. The fact is, crypto is a garden of snakes.\"\n\nWhen Sherrod Brown (D-OH) asked whether FTX-style fraud existed at other crypto firms, all four expert speakers said yes.\n\nRelated is the question of whether and how to regulate crypto, which begins with the problem of deciding whether crypto assets are securities under the decades-old Howey test. In its ongoing suit against Ripple, Gensler's SEC argues for regulation as securities. Lack of regulation has enabled crypto \"innovation\" - and let it recreate practices long banned in traditional financial markets. For an example see Ben McKenzie's and Jacob Silverman's analysis of leading crypto exchange Binance's endemic conflicts of interest and the extreme risks it allows customers to take that are barred under securities regulations.\n\nRegulation could correct some of this. McKenzie gave the Senate committee numbers: fraudulent financier Bernie Madoff had 37,000 clients; FTX had 32 times that in the US alone. The collective lost funds of the hundreds of millions of victims worldwide could be ten times bigger than Madoff.\n\nBut: would regulating crypto clean up the industry or lend it legitimacy it does not deserve? Skeptics ask this about alt-med practitioners.\n\nSome background. As software engineer Stephen Diehl explains in his new book, Popping the Crypto Bubble, securities are roughly the opposite of money. What you want from money is stability; sudden changes in value spark cost-of-living crises and economic collapse. For investors, stability is the enemy: they want investments' value to go up. The countervailing risk is why the SEC's requires companies offering securities to publish sufficient truthful information to enable investors to make a reasonable assessment.\n\nIn his book, Diehl compares crypto to previous bubbles: the Internet, tulips, the railways, the South Sea. Some, such as the Internet and the railways, cost early investors fortunes but leave behind valuable new infrastructure and technologies on which vast new industries are built. Others, like tulips, leave nothing of new value. Diehl, like other skeptics, believes cryptocurrencies are like tulips.\n\nThe idea of digital cash was certainly not new in 2008, when \"Satoshi\" published their seminal paper on bitcoin; the earliest work is usually attributed to David Chaum, whose 1982 dissertation contained the first known proposal for a blockchain protocol, proposed digital cash in a 1983 paper, and set up a company to commercialize digital cash in 1990 - way too early. Crypto's ethos came from the cypherpunks mailing list, which was founded in 1992 and explored the idea of using cryptography to build a new global financial system.\n\nDiehl connects the reception of Satoshi's paper to its timing, just after the 2007-2008 financial crisis. There's some logic there: many have never recovered.\n\nFor a few years in the mid-2010s, a common claim was that cryptocurrencies were bubbles but the blockchain would provide enduring value. Notably disagreeing was Michael Salmony, who startled the 2016 Tomorrow's Transactions Forum by saying the blockchain was a technology in search of a solution. Last week, IBM and Maersk announced they are shutting down their enterprise blockchain because, Dan Robinson writes at The Register, despite the apparently idea use case, they couldn't attract industry collaboration.\n\nMore recently we've seen the speculative bubble around NFTs, but otherwise we've heard only about their wildly careening prices in US dollars and the amount of energy mining them consumes. Until this year, when escalating crashes and frauds are taking over. Distrust does not build value.\n\nIllustrations: The Warner Brothers coyote, realizing he's standing on thin air.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nThe early months of 2020 were a time of radical uncertainty - that is, decisions had to be made that affected the lives of whole populations where little guidance was available. As Leonard Smith and David Tuckett explained at their 2018 conference on the subject (and a recent Royal Society scientific meeting) decisions under radical uncertainty are often one-offs whose lessons can't inform the future. Tuckett's and Smith's goal was to understand the decision-making process itself in the hope that this part of the equation at least could be reused and improved.\n\nInevitably, the discussion landed on mathematical models, which attempt to provide tools to answer the question, \"What if?\" This question is the bedrock of science fiction, but science fiction writers' helpfulness has limits: they don't have to face bereaved people if they get it wrong; they can change reality to serve their sense of fictional truth; and they optimize for the best stories, rather than the best outcomes. Beware.\n\nIn the case of covid, humanity had experience in combating pandemics, but not covid, which turned out to be unlike the first known virus family people grabbed for: flu. Imperial College epidemiologist Neil Ferguson became a national figure when it became known that his 2006 influenza model suggesting that inaction could lead to 500,000 deaths had influenced the UK government's delayed decision to impose a national lockdown. Ferguson remains controversial; Scotland's The Ferrett offers a fact check that suggests that many critics failed to understand the difference between projection and prediction and the importance of the caveat \"if nothing is done\". Models offer possible futures, but not immutable ones.\n\nAs Erica Thompson writes in her new book, Escape From Model Land: How Mathematical Models Can Lead Us Astray and What We Can Do About It, models also have limits that we ignore at our peril. Chief among them is the fact that the model is always an abstracted version of reality. If it weren't, our computers couldn't calculate them any more than they can calculate all the real world's variables. Thompson therefore asks: how can we use models effectively in decision making without becoming trapped inside the models' internal worlds, where their simplified assumptions are always true? More important, how can we use models to improve our decision making with respect to the many problems we face that are filled with uncertainties?\n\nThe science of covid - or of climate change - is only a small part of the factors a government must weigh in deciding how to respond; what science tells us must be balanced against the economic and social impacts of different approaches. In June 2020, Ferguson estimated that locking down a week earlier would have saved 20,000 lives. At the time, many people had already begun withdrawing from public life. And yet one reason the government delayed was the belief that the population would quickly give in to lockdown fatigue and resist restrictions, rendering an important tool unusable later, when it might be needed even more. This assumption turned out to be largely wrong, as was the assumption in Ferguson's 2006 model that 50% of the population would refuse to comply with voluntary quarantine. Thompson calls this misunderstanding of public reaction a \"gigantic failure of the model\".\n\nWhat else is missing? she asks. Ferguson had to resign when he himself was caught breaking the lockdown rules. Would his misplaced belief that the population wouldn't comply have been corrected by a more diverse team?\n\nThompson began her career with a PhD in physics that led her to examine many models of North Atlantic storms. The work taught her more about the inferences we make from models than about storms, and it opened for her the question of how to use the information models provide without falling into the trap of failing to recognize the difference between the real world and Model Land - that is, the assumption-enclosed internal world of the models.\n\nFrom that beginning, Thompson works through different aspects of how models work and where their flaws can be found. Like Cathy O'Neil's Weapons of Math Destruction, which illuminated the abuse of automated scoring systems, this is a clearly-written and well thought-out book that makes a complex mathematical subject and accessible to a general audience. Thompson's final chapter, which offers approaches to evaluating models and lists of questions to ask modelers, should be read by everyone in government.\n\nThompson's focus on the dangers of failing to appreciate the important factors models omit leads her to skepticism about today's \"AI\", which of course is trained on such models: \"It seems to me that rather than AI developing towards the level of human intelligence, we are instead in danger of human intelligence descending to the level of AI by concreting inflexible decision criteria into institutional structures, leaving no room for the human strengths of empathy, compassion, a sense of fairness and so on.\" Later, she adds, \"AI is fragile: it can work wonderfully in Model Land but, by definition, it does not have a relationship with the real world other than one mediated by the models that we endow it with.\"\n\nIn other words, AI works great if you can assume a spherical cow.\n\nIllustrations: The spherical cow that mocks unrealistic scientific models drawn jumping over the moon by Ingrid Kallick for the 1996 meeting of the American Astronomical Association (via Wikimedia).\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\n\"We talk as if being online is a choice,\" Sonia Livingstone commented on , \"but we live in a context and all the decisions around us matter.\"\n\nAs we've observed before, it's only for the most privileged that *not* being online or *not* carrying a smartphone comes without cost.\n\nLivingstone was speaking on a panel on digital inequalities at this week's UK IGF, an annual forum that mulls UK concerns over Internet governance in order to feed them into the larger global conversation on such matters (IGF). The panel highlighted two groups most vulnerable to digital exclusion: old people and children.\n\nAccording to Ofcom's 2022 Online Nations report, in 2021 6% of British over-18s did not have Internet access at home. That average is, however, heavily skewed by over-65s, 20% of whom don't have Internet access at home and another 7% of whom have Internet access at home but don't use it. In the other age groups, the percentage without home access starts at 1% for 18-24 and rises to 3% for 44-54. The gap across ages is startlingly larger than the gap across economic groups, although obviously there's overlap: Age UK estimated in 2021 that 2 million pensioners were living in poverty.\n\nI know one of the people in that 20%. She is adamant that there is nothing the Internet has to offer that she could possibly want. (I feel this way about cryptocurrencies.) Because, fortunately, the social groups she's involved in are kind, tolerant, and small, the impact of this refusal probably falls more on them than on her: they have to make the phone calls and send the printed-out newsletters to ensure she's kept in the loop. And they do.\n\nAnother friend, whose acquaintance with the workings of his computer is so nodding that he gets his son round to delete some files when his hard drive fills up, would happily do without it - except that his failing mobility means that he finds entertainment by playing online poker. To him, the computer is a necessary, but despised, evil. In Ofcom's figures, he'd look all right - Internet access at home, uses it near-daily. But the reality is that despite his undeniable intelligence he's barely capable of doing much beyond reading his email and loading the poker site. Worse, he has no interest in learning anything more; he just hates all of it. Is that what we mean by \"Internet access\"?\n\nThese two are what people generally think of when they talk about the \"digital divide\".\n\nAs Sally West, policy manager for Age UK, noted, if you're not online it's becoming increasingly difficult to do mundane things like book a GP appointment or do any kind of banking. Worse, isolation during the pandemic led some to stop using the Internet because they didn't have their customary family support. In its report on older people and the Internet, Age UK found that about half a million over-65s have stopped using the Internet. And, West said, unlike riding a bike, Internet skills don't necessarily stay with you when you stop using them. Even if they do, they lose relevance as the technology changes.\n\nFor children, lack of access translates into educational disadvantage and severely constricted life opportunities. Despite the government's distribution of laptops. Nominet's Digital Youth Index finds that a quarter of young people lack access to one, and 16% rely primarily on mobile data. And, said Jess Barrett, children lack understanding of privacy and security yet are often expected to be their family's digital expert.\n\nMore significantly, the Ofcom report finds that 20% of people - and a *third* of people aged 25-34 - used only a smartphone to go online 2021. That's *double* the number in 2020. Ofcom suggests that staying home much of 2020 and newer smartphones' larger screens may be relevant factors. I'd guess that economic uncertainty played an important role and that 2022's cost-of-living crisis will cause these numbers to rise again. There's also a generational aspect; today's 30-year-olds got their teenaged independence via smart phones.\n\nTo Old Net Curmudgeons, phone-only access isn't really *Internet* access; it's walled-garden apps. Where the open Internet promised that all of us could build and distribute things, apps limit us to consuming what the apps' developers allow. This is not petty snobbery; creating the next generation of technology pioneers requires learning as active users instead of lurkers.\n\nThis disenfranchisement led Lizzie Coles-Kemp to an approach that's rarely discussed: \"We need to think how to design services for limited access, and we need to think what access means. It's not binary.\" This approach is essential as the of the mobile phone world's values risk overwhelming those of the open Internet.\n\nIn response, Livingstone mooted the idea of \"meaningful access\": the right device for the context and sufficient skills and knowledge that you can do what you need to.\n\nThe growing cost-of-living crisis, exacerbated this week by an interest rate rise, makes it easy to predict a marked further rise in households that jettison fixed-line broadband. This year may be the first since the Internet began in which online access in the UK shrinks.\n\n\"We are just highlighting two groups,\" Livingstone concluded. \"But the big problem is poverty and exclusion. Solve those, and it fixes it.\"\n\nIllustrations: UK IGF's panel on digital inequalities: Cliff Manning, Sally West, Sonia Livingstone, Lizzie Coles-Kemp, Jess Barrett,\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week on Twitter or @wendyg@mastodon.xyz.\n\nRobots have stopped being robots. This is a good thing.\n\nThis is my biggest impression of this year's We Robot conference: we have moved from the yay! robots! of the first year, 2012, through the depressed doldrums of \"AI\" systems that make the already-vulnerable more vulnerable circa 2018 to this year, when the phrase that kept twanging was \"sociotechnical systems\". For someone with my dilettantish conference-hopping habit, this seems like the necessary culmination of a long-running trend away from robots as autonomous mobile machines to robots/AI as human-machine partnerships. We Robot has never talked much about robot rights, instead focusing on considering the policy challenges that arise as robots and AI become embedded in our lives. This is realism; as We Robot co-founder Michael Froomkin writes, we're a long, long way from a self-aware and sentient machine.\n\nThe framing of sociotechnical systems is a good thing in part because so much of what passes for modern \"artificial intelligence\" is humans all the way down, as Mary L. Gray and Siddhart Suri documented in their book, Ghost Work. Even the companies that make self-driving cars, which a few years ago were supposed to be filling the streets by now, are admitting that full automation is a long way off. \"Admitting\" as in consolidating or being investigated for reckless hyping.\n\nIf this was the emerging theme, it started with the first discussion, of a paper on humans in the loop, by Margot Kaminski, Nicholson Price, and Rebecca Crootof. Too often, the proposed policy-making proposal for handling problems with decision making systems is to insert a human, a \"solution\" they called the \"MABA-MABA trap\", for \"Machines Are Better At / Men Are Better At\". While obviously humans and machines have differing capabilities - people are creative and flexible, machines don't get bored - just dropping in a human without considering what role that human is going to fill doesn't necessarily take advantage of the best capabilities of either. Hybrid systems are of necessity more complex - this is why cybersecurity keeps getting harder - but policy makers may not take this into account or think clearly about what the human's purpose is going to be.\n\nAt this conference in 2016, Madeleine Claire Elish foresaw that the human would become a moral crumple zone or liability sponge, absorbing blame without necessarily being at fault. No one will admit that this is the human's real role - but it seems an apt description of the \"safety driver\" watching the road, trying to stay alert in case the software driving the car needs backup or the poorly-paid human given a scoring system and tasked with awarding welfare benefits. What matters, as Andrew Selbst said in discussing this paper, is the *loop*, not the human - and that may include humans with invisible control, such as someone who can massage the data they enter into a benefits system in order to help a particularly vulnerable child, or who have wide discretion, such as a judge who is ultimately responsible for parole decisions no matter what the risk assessment system says.\n\nThis is not the moment to ask what constitutes a human.\n\nIt might be, however, the moment to note the commentator who said that a lot of the problems people are suggesting robots/AI can solve have other, less technological solutions. As they said, if you are putting a pipeline through a community without its consent, is the solution to deploy police drones to protect the pipeline and the people working on it - or is it to put the pipeline somewhere else (or to move to renewables and not have a pipeline at all)? Change the relationship with the community and maybe you can partly disarm the police.\n\nOne unwelcome forthcoming issue, discussed in a paper by Kate Darling and Daniella DiPaola is the threat merging automation and social marketing poses to consumer protection. A truly disturbing note came from DiPaola, who investigated manipulation and deception with personal robots and 75 children. The children had three options: no ads, ads allowed only if they are explicitly disclosed to be ads, or advertising through casual conversation. The kids chose casual conversation because they felt it showed the robot *knew* them. They chose this even though they knew the robot was intentionally designed to be a \"friend\". Oy. In a world where this attitude spreads widely and persists into adulthood, no amount of \"media literacy\" or learning to identify deception will save us; these programmed emotional relationships will overwhelm all that. As DiPaola said, \"The whole premise of robots is building a social relationship. We see over and over again that it works better if it is more deceptive.\"\n\nThere was much more fun to be had - steamboat regulation as a source of lessons for regulating AI (Bhargavi Ganesh and Shannon Vallor), police use of canid robots (Carolin Kemper and Michael Kolain), and - a new topic - planning for the end of life of algorithmic and robot systems (Elin BjÃ¶rling and Laurel Riek). The robots won't care, but the humans will be devastated.\n\nIllustrations: Hanging out at We Robot with Boston Dynamics' \"Spot\".\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nAn unexpected bonus of the gradual-then-sudden disappearance of Boris Johnson's government, followed by his own resignation, is that the Online Safety bill is being delayed until after Parliament's September return with a new prime minister and, presumably, cabinet.\n\nThis is a bill almost no one likes - child safety campaigners think it doesn't go far enough; digital and human rights campaigners - Big Brother Watch, Article 19, Electronic Frontier Foundation, Open Rights Group, Liberty, a coalition of 16 organizations (PDF) - because it threatens freedom of expression and privacy while failing to tackle genuine harms such as the platforms' business model; and technical and legal folks because it's largely unworkable.\n\nThe DCMS Parliamentary committee sees it as wrongly conceived. The he UK Independent Reviewer of Terrorism Legislation, Jonathan Hall QC, says it's muzzled and confused. Index on Censorship calls it fundamentally broken, and The Economist says it should be scrapped. The minister whose job it has been to defend it, Nadine Dorries (C-Mid Bedfordshire), remains in place at the Department for Culture, Media, and Sport, but her insistence that resigning-in-disgrace Johnson was brought down by a coup probably won't do her any favors in the incoming everything-that-goes-wrong-was-Johnson's-fault era.\n\nIn Wednesday's Parliamentary debate on the bill, the most interesting speaker was Kirsty Blackman (SNP-Aberdeen North), whose Internet usage began 30 years ago, when she was younger than her children are now. Among passionate pleas that her children should be protected from some of the high-risk encounters she experienced, was: \"Every person, nearly, that I have encountered talking about this bill who's had any say over it, who continues to have any say, doesn't understand how children actually use the Internet.\" She called this the bill's biggest failing. \"They don't understand the massive benefits of the Internet to children.\"\n\nThis point has long been stressed by academic researchers Sonia Livingstone and Andy Phippen, both of whom actually do talk to children. \"If the only horse in town is the Online Safety bill, nothing's going to change,\" Phippen said at last week's Gikii, noting that Dorries' recent cringeworthy TikTok \"rap\" promoting the bill focused on platform liability. \"The liability can't be only on one stakeholder.\" His suggestion: a multi-pronged harm reduction approach to online safety.\n\nUK politicians have publicly wished to make \"Britain the safest place in the world to be online\" all the way back to Tony Blair's 1997-2007 government. It's a meaningless phrase. Online safety - however you define \"safety\" - is like public health; you need it everywhere to have it anywhere.\n\nAlong those lines, \"Where were the regulators?\" Paul Krugman asked in the New York Times this week, as the cryptocurrency crash continues to flow. The cryptocurrency market, which is now down to $1 trillion from its peak of $3 trillion, is recapitulating all the reasons why we regulate the financial sector. Given the ongoing collapses, it may yet fully vaporize. Krugman's take: \"It evolved into a sort of postmodern pyramid scheme\". The crash, he suggests, may provide the last, best opportunity to regulate it.\n\nThe wild rise of \"crypto\" - and the now-defunct Theranos - was partly fueled by high-trust individuals who boosted the apparent trustworthiness of dubious claims. The same, we learned this week was true of Uber 2014-2017, Based on the Uber files,124,000 documents provided by whistleblower Mark MacGann, a lobbyist for Uber 2014-2016, the Guardian exposes the falsity of Uber's claims that its gig economy jobs were good for drivers.\n\nThe most startling story - which transport industry expert Hubert Horan had already published in 2019 - is the news that the company paid academic economists six-figure sums to produce reports it could use to lobby governments to change the laws it disliked. Other things we knew about - for example, Greyball, the company's technology denying regulators and police rides so they couldn't document Uber's regulatory violations and Uber staff's abuse of customer data - are now shown to have been more widely used than we knew. Further appalling behavior, such as that of former CEO Travis Kalanick, who was ousted in 2017, has been thoroughly documented in the 2019 book, Super Pumped, by Mike Isaac, and the 2022 TV series based on it, Super Pumped.\n\nBut those scandals - and Thursday/s revelation that 559 passengers are suing the company for failing to protect them from rape and assault by drivers - aren't why Horan described Uber as a regulatory failure in 2019. For years, he has been indefatigably charting Uber's eternal unprofitability. In his latest, he notes that Uber has lost over $20 billion since 2015 while cutting driver compensation by 40%. The company's share price today is less than half its 2019 IPO price of $45 - and a third of its 2021 peak of $60. The \"misleading investors\" kind of regulatory failure.\n\nSo, returning to the Online Safety bill, if you undermine existing rights and increase the large platforms' power by devising requirements that small sites can't meet *and* do nothing to rein in the platforms' underlying business model...the regulatory failure is built in. This pause is a chance to rethink.\n\nIllustrations: Boris Johnson on his bike (European Cyclists Federation via Wikimedia).\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nThis week provided two examples of the dangers of believing too much hype about modern-day automated systems and therefore overestimating what they can do.\n\nThe first is relatively minor: Google employee Blake Lemoine published his chats with a bot called LaMDA and concluded it was sentient \"basd on my religious beliefs\". Google put Lemoine on leave and the press ran numerous (many silly) stories. Veterans shrugged and muttered, \"ELIZA, 1966\".\n\nThe second, however...\n\nOn Wednesday, the US National Highway Traffic Safety Administration released a report (PDF) studying crashes involving cars under the control of \"driver-assist\" technologies. Out of 367 such crashes in the nine months after NHTSA began collecting data in July 2021, 273 involved Teslas being piloted by either \"full self-driving software\" or its precursor, \"Tesla Autopilot\".\n\nThere are important caveats, which NTHSA clearly states. Many contextual details are missing, such as how many of each manufacturer's cars are on the road and the number of miles they've traveled. Some reports may be duplicates; others may be incomplete (private vehicle owners may not file a report) or unverified. Circumstances such as surface and weather conditions, or whether passengers were wearing seat belts, are missing. Manufacturers differ in the type and quantity of crash data they collect. Reports may be unclear about whether the car was equipped with SAE Level 2 Advanced Driver Assistance Systems (ADAS) or SAE Levels 3-5 Automated Driving Systems (ADS). Therefore, NTHSA says, \"The Summary Incident Report Data should not be assumed to be statistically representative of all crashes.\" Still, the Tesla number stands out, far ahead of Honda's 90, which itself is far ahead of the other manufacturers listed.\n\nSAE, ADAS, and ADS refer to the system of levels devised by the Society of Automotive Engineers (now SAE International) in 2016. Level 0 is no automation at all; Level 1 is today's modest semi-automated assistance such as cruise control, lane-keeping, and automatic emergency braking. Level 2, \"partial automation\", is now: semi-automated steering and speed systems, road edge detection, and emergency braking.\n\nTesla's Autopilot is SAE Level 2. Level 3 - which may someday include Tesla's Full Self Drive Capability - is where drivers may legitimately begin to focus on things other than the road. In Level 4, most primary driving functions will be automated, and the driver will be off-duty most of the time. Level 5 will be full automation, and the car will likely not even have human-manipulable controls.\n\nRight now, in 2022, we don't even have Level 3, though Tesla CEO Elon Musk keeps promising we're on the verge of it with his company's Full Self-Drive Capability, its arrival always seems to be one to two years away. As long ago as 2015, Musk was promising Teslas would be able to drive themselves while you slept \"within three years\"; in 2020 he estimated \"next year\" - and he said it again a month ago. In reality, it's long been clear that cars autonomous enough for humans to check out while on the road are further away than they seemed five years ago, as British transport commentator Christian Wolmar accurately predicted in 2018.\n\nMany warned that Levels 2 and 3 are would be dangerous. The main issue, pointed out by psychologists and behavorial scientists, is that humans get bored watching a computer do stuff. In an emergency, where the car needs the human to take over quickly, said human, whose attention has been elsewhere, will not be ready. In this context it's hard to know how to interpret the weird detail in the NTHSA report that in 16 cases Autopilot disengaged less than a second before the crash.\n\nThe NHTSA news comes just a few weeks after a New York Times TV documentary investigation examining a series of Tesla crashes. Some it links to the difficulty of designing software that can distinguish objects across the road - that is, the difference between a truck crossing the road and a bridge. In others, such as the 2018 crash in Mountain View, California, the NTSB found a number of contributing factors, including driver distraction and overconfidence in the technology - \"automation complacence\", as Robert L. Sumwalt calls it politely.\n\nThis should be no surprise. In his 2019 book, Ludicrous, auto industry analyst Edward Niedermeyer mercilessly lays out the gap between the rigorous discipline embraced by the motor industry so it can turn out millions of cars at relatively low margins with very few defects and the manufacturing conditions Niedermeyer observes at Tesla. The high-end, high-performance niche sports cars Tesla began with were, in Niedermeyer's view, perfectly suited to the company's disdain for established industry practice - but not to meeting the demands of a mass market, where affordability and reliability are crucial. In line with Nidermeyer's observations, Bloomberg Intelligence predicts that Volkswagen will take over the lead in electric vehicles by 2024. Niedermeyer argues that because it's not suited to the discipline required to serve the mass market, Tesla's survival as a company depends on these repeated promises of full autonomy. Musk himself even said recently that the company is \"worth basically zero\" if it can't solve self-driving.\n\nSo: financial self-interest meets the danger zone of Level 2 with perceptions of Level 4. I can't imagine anything more dangerous.\n\nIllustrations: One of the Tesla crashes investigated in New York Times Presents.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\n\"This isn't over,\" we predicted in April 2021 when Amazon warehouse workers in Bessemer, Alabama voted against unionizing. And so it has proved: on April 1 workers at its Staten Island warehouse voted to join the Amazon Labor Union.\n\nThere will be more of this, and there needs to be. As much as people complain - often justifiably - about unions, no one individual can defend themselves and their rights in the face of the power of a giant company. Worse, as the largest companies continue to get bigger and the number of available employers shrinks, that power imbalance is still growing. Antitrust law can only help reopen the market to competition with smaller and newer businesses; organized labor and labor law are required to ensure fair treatment for workers (see also Amazon's warehouse injury rate, which is about double the industry average). Even the top class of Silicon Valley engineers have lost out; in 2015 Apple, Google, Adobe, and Intel were fined $415 million for operating a \"no-poaching\" cartel; Lucasfilm, Pixar, and Intuit settled earlier for a joint $20 million.\n\nOne lesson to take from this is that instead of treating multi-billionaires as symbols of success we should take the emergence of that level of wealth disparity as a bad sign.\n\nIn 1914, Henry Ford famously doubled wages for the factory workers building his cars. At Michigan Radio, Sarah Cwiek explains that it was a gamble intended to produce a better, more stable workforce. Cwiek cites University of California-Berkeley labor economist Harley Shaiken to knock on the head the notion that it was solely in order to expand the range of people who could afford to buy the cars - but that also was one of the benefits to his business.\n\nThe purveyors of \"pay-with-data-and-watching-ads\" services can't look forward to that sort of benefit. For one thing, as multi-sided markets their primary customers aren't us but advertisers who don't sell directly to the masses. For another, a company like Google or Facebook doesn't benefit directly from the increasing wealth of its users; it can collect their data either way. Even the companies like Amazon and Uber, that actually sell people things or services, see faster returns from squeezing both their customers and their third-party suppliers - which they can do because of their dominant positions.\n\nOn Twitter, Cory Doctorow has a long thread arguing that antitrust law also has a role to play in securing workers' rights against the hundreds of millions companies like Uber and DoorDash are pouring into lobbying for legislation that keeps their gig workers classed as \"independent contractors\" instead of employees with rights such as paid sick leave, health insurance, and workmen's compensation.\n\nDoctorow's thread is based on analyzing two articles: a legal analysis by Marshall Steinbaum laying out the antitrust case against the gig economy platforms, which fail to deliver their promises of independence and control to workers. Steinbaum highlights the value of antitrust law to the self-employed, who rely on being able to work for many outlets. In what the law calls \"vertical restraint\", the platforms dictate prices to customers and require exclusivity - both the opposite of the benefits self-employment is supposed to deliver. Any freelance in any business knows that too-great dependence on one or two employers is dangerous; a single shift in personnel or company policy can threaten your ability to make rent. It is the joint operation of antitrust law and labor regulation that is necessary, Steinbaum writes: \"...taking away their ability to exercise control in the absence of an employment relationship is a necessary condition for the success of any effort to curtail the gig economy and the threat it poses to worker power and to workers' welfare.\"\n\nDoctorow goes on to add that using antitrust law in this way would open the way to requiring interoperability among platform apps, so that a driver could assess which platform would pay them the best and direct customers to that one. It's an idea with potential - but unfortunately it reminds me of Mark Huntley-James' story \"Togetherness\", which formed part of Tales of the Cybersalon - A New High Street. In it, a hapless customer trying to get a parcel delivery is shunted from app to app as the pickup shop keeps shifting to get a better deal. (The story, along with the rest of the Tales of the Cybersalon, will be published later this year.) I'm not sure that the urgent-lift-seeking customer experience will be enhanced by, \"Sorry, luv, I can't take you unless you sign up for NewApp.\" However, Doctorow's main point stands.\n\nAll of this is yet another way that the big technology companies benefit from negative externalities - that is, the costs they impose on society at large. The content moderators who work for Facebook, Uber's and Lyft's drivers, the behind-the-scenes ghost-worker intermediaries that pass for \"AI\", Amazon's Amazon's time-crunched warehouse workers...together add up to a large economy of underpaid, stressed workers deliberately kept outside of standard employment contracts and workers' rights. Such a situation cannot be sustainable for a society.\n\nIllustrations: Amazon warehouse workers protesting in Minnesota in 2018 (by Czar at Wikimedia, cc-by-2.0.)\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nOne of the first things the magician and paranormal investigator James Randi taught all of us in the skeptical movement was the importance of consulting the right kind of expert.\n\nRandi made this point with respect to tests of paranormal phenomena such as telekinesis and ESP. At the time - the 1970s and 1980s - there was a vogue for sending psychic claimants to physicists for testing. A fair amount of embarrassment ensued. As Randi liked to say, physicists, like many other scientists, are not experienced in the art of deception. Instead, they are trained to assume that things in their lab do not lie to them.\n\nNot a safe assumption when they're trying to figure out how a former magician has moved an empty plastic film can a few millimeters, apparently with just the power of their mind. Put in a magician who knows how to set up the experiment so the claimant can't cheat, and *then* if the effect still occurs you know something genuinely weird is going on.\n\nI was reminded of this reading this quote from Fabio Urbina, Filippa Lentzos, CÃ©dric Invernizzi, and Sean Ekins, writing in Nature: \"When we think of drug discovery, we normally do not consider technology misuse potential. We are not trained to consider it, and it is not even required for machine learning research,\"\n\nThe article itself is scary enough for one friend to react to it with, \"This is the apocalypse\". The researchers undertook a \"thought experiment\" after the Swiss Federal Institute for NBC Protection (Spiez Laboratory), asked theiir company, Collaborations Pharmaceuticals Inc, to provide a presentation on how their AI technology could be misused in drug discovery to its biennial conference on new technologies and their implications for the Chemical and Biological Weapons conventions. They work, they write, in an entirely virtual world; their molecules exist only in their computer. It had never previously occurred to them to wonder if the machine learning models they were building to help design new molecules that could be developed into new, life-saving drugs could be turned to generating toxins instead. Asked to consider it, they quickly discovered that it was disturbingly easy to generate prospective lethal neurotoxins. Because: generating potentially helpful molecules required creating models to *avoid* toxicity - which meant being able to predict its appearance.\n\nAs they go on to say, our general discussions of the potential harms AI can enable are really very limited. The biggest headlines go to putting people out of work; the rest is privacy, discrimination, fairness, and so on. Partly, that's because those are the ways AI has generally been most visible: automation that deskills or displaces humans, or algorithms that make decisions about government benefits, employment, education, content recommendations, or criminal justice outcomes. But also it's because the researchers working on this technology blinker their imagination to how they want their new idea to work.\n\nThe demands of marketing don't help. Anyone pursuing any form of research, whether funded by industry or government grant, has to make the case for why they should be given the money. So of course in describing their work they focus on the benefits. Those working on self-driving cars are all about how they'll be safer than human drivers, not scary possibilities like widespread hundred-car pileups if hackers were to find a way to exploit unexpected software bugs to make them all go haywire at the same time.\n\nSadly, many technology journalists pick up only the happy side. On Wednesday, as one tiny example, the Washington Post published a cheery article about EliiQ, an Alexa-like AI device \"designed for empathy\" meant to keep lonely older people company. The commenters saw more of the dark side than the writer did: ongoing $30 subscription, data collection and potential privacy invasion, and, especially, potential for emotional manipulation as the robot tells its renter what it (not she, as per writer Steven Zeitchik) calculates they want to hear.\n\nIt's not like this is the first such discovery. Malicious Generative Adversarial Networks (GANs) are the basis of DeepFakes. If you can use some new technology for good, why *wouldn't* you be able to use it for evil? Cars drive sick kids to hospitals and help thieves escape. Computer programmers write word processors and viruses, the Internet connects us directly to medical experts and sends us misinformation, cryptography protects both good and bad secrets, robots help us and collect our data. Why should AI be different?\n\nI'd like to think that this paper will succeed where decades of prior experience have failed, and make future researchers think more imaginatively about how their work can be abused. Sadly, it seems a forlorn hope.\n\nIn Gemma Milne's 2020 book examining how hype interferes with our ability to make good decisions about new technology, Smoke and Mirrors, she warns that hype keeps us from asking the crucial question: Is this new technology worth its cost? Potential abuse is part of that cost-benefit assessment. We need researchers to think about what can go wrong a lot earlier in the development cycle - and we need them to add experts in the art of forecasting trouble (science fiction writers, perhaps?) to their teams. Even technology that looks like magic...isn't.\n\nIllustrations: EliiQ (company PR photo).\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nThe mythology goes like this. In the beginning, the Internet was decentralized. Then came money and Web 2.0, and they warped the best dreams of Web 2.0 into corporate giants. Now, web3 is going to restore the status ante?\n\nInitial reaction: why will it be different this time?\n\nMaybe it won't. Does that mean people shouldn't try? Ah. No. No, it does not.\n\nOne reason it's so difficult to write about web3 is that under scrutiny it dissolves into a jumble of decentralized web, cryptocurrencies, blockchain, and NFTs, though the Economist has an excellent explanatory podcast. Decentralizing the web I get: ever since Edward Snowden decentralization has been seen as a way to raise the costs of passive surveillance. The question has been: how? Blockchain and bitcoin sound nothing like the web - or a useful answer.\n\nBut even if you drop all the crypto stuff and just say \"decentralized web to counter surveillance and censorship, it conveys little to the man on the Clapham omnibus. Try to explain, and you rapidly end up in a soup of acronyms that are meaningful only to technologists. In November, on first encountering web3, I suggested there are five hard problems. The first of those, ease of use, is crucial. Most people will always flock to whatever requires least effort; the kind of people who want to build a decentralized Internet are emphatically unusual. The biggest missed financial opportunity of my lifetime will likely have been ignoring the advice to buy some bitcoin in 2009 because it was just too much trouble. Most of today's big Internet companies got that way because whatever they were offering was better - more convenient, saved time, provided better results.\n\nThis week, David Rosenthal, developer of core Nvidia technologies, published a widely-discussed dissection of cryptocurrencies and blockchain, which Cory Doctorow followed quickly with a recap/critique. Tl;dr: web3 is already centralized, and blockchain and cryptocurrencies only pay off if their owners can ignore the external costs they impose on the rest of the world. Rosenthal argues that ignoring externalities is inherent in theSilicon Valley-type libertarianism from which they sprang.\n\nRosenthal also makes an appearance in the Economist podcast to explain that if you ask most people what the problems are with the current state of the Web, they don't talk centralization. They talk about overwhelming amounts of advertising, harassment, scams, ransomware, and expensive bandwidth. In his view, changing the technical infrastructure won't change the underlying economics - scale and network effects - that drive centralization, which, as all of these commentators note, has been the eventual result of every Internet phase since the beginning.\n\nIt's especially easy to be suspicious about this because of the venture capital money flooding in seeking returns.\n\n\"Get ready for the crash,\" Tim O'Reilly told CBS News. In a blog posting last December, he suggestshow to find the good stuff in web3: look for the parts that aren't about cashing out and getting rich fast but *are* about solving hard problems that matter in the real world.\n\nThis is all helpful in understanding the broader picture, but doesn't answer the question of whether there's presently meat inside web3. Once bitten, twice shy, three times don't be ridiculous.\n\nWhat gave me pause was discovering that Danny O'Brien has gone to work for the Filecoin Foundation and the Filecoin Foundation for the Distributed Web - aka, \"doing something in web3\". O'Brien has a 30-year history of finding the interesting places to be. In the UK, he was one-half of the 1990s must-read newsletter NTK, whose slogan was \"They stole our revolution. Now we're stealing it back.\" Filecoin - a project to develop blockchain-based distributed storage, which he describes as \"the next generation of something like Bittorrent\" - appears to be the next stage of that project. The mention of Bittorrent reminded how technologically dull the last few years have been.\n\nO'Brien's explanation of Filecoin and distributed storage repeatedly evoked prior underused art that only old-timers remember. For example, in 1997 Cambridge security engineer Ross Anderson proposed the Eternity Service, an idea for distributing copies of data around the world so its removal from the Internet would be extremely difficult. There was Ian Clarke's 1999 effort to build such a thing, Freenet, a peer-to-peer platform for distributing data that briefly caused a major moral panic in the UK. Freenet failed to gain much adoption - although it's still alive today - because no one wanted to risk hosting unknown caches of data. Filecoin intends to add financial economic incentives: think a distributed cloud service.\n\nO'Brien's mention of the need to ensure that content remains addressable evokes Ted Nelson's Project Xanadu, a pre-web set of ideas about sharing information. Finally, zero-knowledge proofs make it possible to show a proof that you have run a particular program and gotten back a specific result without revealing the input. The mathematics involved is arcane, but the consequence is far-reaching: you can prove results *and* protect privacy.\n\nIf this marriage of old and new research is \"web3\", suddenly it sounds much more like something that matters. And it's being built, at least partly, by people who remember the lessons of the past well enough not to repeat them. So: cautious signs that some part of \"web3\" will do something.\n\nIllustrations: Diagram of centralized vs decentralized (IPFS) systems (from zK Capital at Medium).\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nIt seems like only yesterday that we were hearing that Web 2.0 was the new operating system of the Internet. Pause to look up. It was 2008, in the short window between the founding of today's social media giants (2004-2006) and their smartphone-accelerated explosion (2010).\n\nThis week a random tweet led me to discover Web3. As Aaron Mak explains at Slate, \"Web3\" is an idea for running a next-generation Internet on public blockchains in the interests of decentralization (which net.wars has long advocated). To date, the aspect getting the most attention is decentralized finance (DeFi, or, per Mary Branscombe, deforestation finance), a plan for bypassing banks and governments by conducting financial transactions on the blockchain.\n\nAt Freecode, Nader Dabit goes into more of the technical underpinnings. At Fabric Ventures (Medium), Max Mersch and Richard Muirhead explain its importance. Web3 will bring a \"borderless and frictionless\" native payment layer (upending mediator businesses like Paypal and Square), bring the \"token economy\" to support new businesses (upending venture capitalists), and tie individual identity to wallets (bypassing authentication services like OAuth, email plus password, and technology giant logins), thereby enabling multiple identities, among other things. Also interesting is the Cloudflare blog, where Thibault Meunier states that as a peer-to-peer system Web3 will use cryptographic identifiers and allow users to selectively share their personal data at their discretion. Some of this - chiefly the robustness of avoiding central points of failure - is a return to the Internet's original design goals.\n\nStandards-setter W3C is working on at least one aspect - cryptographically verifiable Decentralized Identifiers, and it's running into opposition, from Google, Apple, and Mozilla, whose browsers control 87% of the market.\n\nLet's review a little history.\n\nThe 20th century Internet was sorta, kinda decentralized, but not as much as people like to think. The technical and practical difficulties of running your own server at home fueled the growth of portals and web farms to do the heavy lifting. Web design went from plain text (see for example, Live Journal and Blogspot (now owned by Google). You can argue about how exactly it was that a lot of blogs died off circa 2010, but I'd blame Twitter, writers found it easier to craft a sentence or two and skip writing the hundreds of words that make a blog post. Tim O'Reilly and Clay Shirky described the new era as interactive, and moving control \"up the stack\" from web browsers and servers to the services they enabled. Data, O'Reilly predicted, was the key enabler, and the \"long tail\" of niche sites and markets would be the winner. He was right about data, and largely wrong about the long tail. He was also right about this: \"Network effects from user contributions are the key to market dominance in the Web 2.0 era.\" Nearly 15 years later, today's web feels like a landscape of walled cities encroaching on all the public pathways leading between them.\n\nPoint Network (Medium) has a slightly different version of this history; they call Web 1.0 the \"read-only web\"; Web 2.0 the \"server/cloud-based social Web\", and Web3 the \"decentralized web\".\n\nThe pattern here is that every phase began with a \"Cambrian\" explosion of small sites and businesses and ended with a consolidated and centralized ecosystem of large businesses that have eaten or killed everyone else. The largest may now be so big that they can overwhelm further development to ensure their future dominance; at least, that's one way of looking at Mark Zuckerberg's metaverse plan.\n\nSo the most logical outcome from Web3 is not the pendulum swing back to decentralization that we may hope, but a new iteration of the existing pattern, which is at least partly the result of network effects. The developing plans will have lots of enemies, not least governments, who are alert to anything that enables mass tax evasion. But the bigger issue is the difficulty of becoming a creator. TikTok is kicking ass, according to Chris Stokel-Walker, because it makes it extremely easy for users to edit and enhance their videos.\n\nI spy five hard problems. One: simplicity and ease of use. If it's too hard, inconvenient, or expensive for people to participate as equals, they will turn to centralized mediators. Two: interoperability and interconnection. Right now, anyone wishing to escape the centralization of social media can set up a Discord or Mastodon server, yet these remain decidedly minority pastimes because you can't message from them to your friends on services like Facebook, WhatsApp, Snapchat, or TikTok. A decentralized web in which it's hard to reach your friends is dead on arrival. Three: financial incentives. It doesn't matter if it's venture capitalists or hundreds of thousands of investors each putting up $10, they want returns. As a rule of thumb, decentralized ecosystems benefit all of society; centralized ones benefit oligarchs - so investment flows to centralized systems. Four: sustainability. Five: how do we escape the power law of network effects?\n\nGloomy prognostications aside, I hope Web3 changes everything, because in terms of its design goals, Web 2.0 has been a bust.\n\nIllustrations: Tag cloud from 2007 of Web 2.0 themes (Markus Angermeier and Luca Cremonini, via Wikimedia.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nHow do democracy and algorithmic governance live together? This was the central question of a workshop this week on computational governance. This is only partly about the Internet; many new tools for governance are appearing all the time: smart contracts, for example, and AI-powered predictive systems. Many of these are being built with little idea of how they can go wrong.\n\nThe workshop asked three questions:\n\n- What can technologists learn from other systems of governance?\n\n- What advances in computer science would be required for computational systems to be useful in important affairs like human governance?\n\n- Conversely, are there technologies that policy makers can use to improve existing systems?\n\nImplied is this: who gets to decide? On the early Internet, for example, decisions were reached by consensus among engineers, funded by hopeful governments, who all knew each other. Mass adoption, not legal mandate, helped the Internet's TCP/IP protocols dominate over many other 1990s networking systems: it was free, it worked well enough, and it was *there*. The same factors applied to other familiar protocols and applications: the web, email, communications between routers and other pieces of infrastructure. Proposals circulated as Requests for Comments, and those that found the greatest acceptance were adopted. In those early days, as I was told in a nostalgic moment at a conference in 1998, anyone pushing a proposal because it was good for their company would have been booed off the stage. It couldn't last; incoming new stakeholders demanded a voice.\n\nIf you're designing an automated governance system, the fundamental question is this: how do you deal with dissenting minorities? In some contexts - most obviously the US Supreme Court - dissenting views stay on the record alongside the majority opinion. In the long run of legal reasoning, it's important to know how judgments were reached and what issues were considered. You must show your work. In other contexts where only the consensus is recorded, minority dissent is disappeared - AI systems, for example, where the labelling that's adopted is the result of human votes we never see.\n\nIn one intriguing example, a panel of judges may rule a defendant is guilty or not guilty depending on whether you add up votes by premise - the defendant must have both committed the crime and possessed criminal intent - or by conclusion, in which each judge casts a final vote and only these are counted. In a small-scale human system the discrepancy is obvious. In a large-scale automated system, which type of aggregation do you choose, and what are the consequences, and for whom?\n\nDecentralization poses a similarly knotty conundrum. We talk about the Internet's decentralized origins, but its design fundamentally does not prevent consolidation. Centralized layers such as the domain name system and anti-spam blocking lists are single points of control and potential failure. If decentralization is your goal, the Internet's design has proven to be fundamentally flawed. Lots of us have argued that we should redecentralize the Internet, but if you adopt a truly decentralized system, where do you seek redress? In a financial system running on blockchains and smart contracts, this is a crucial point.\n\nYet this fundamental flaw in the Internet's design means that over time we have increasingly become second-class citizens on the Internet, all without ever agreeing to any of it. Some US newspapers are still, three and a half years on, ghosting Europeans for fear of GDPR; videos posted to web forums may be geoblocked from playing in other regions. Deeper down the stack, design decisions have enabled surveillance and control by exposing routing metadata - who connects to whom. Efforts to superimpose security have led to a dysfunctional system of digital certificates that average users either don't know is there or don't know how to use to protec themselves. Efforts to cut down on attacks and network abuse have spawned a handful of gatekeepers like Google, Akamai, Cloudflare, and SORBS that get to decide what traffic gets to go where. Few realize how much Internet citizenship we've lost over the last 25 years; in many of our heads, the old cooperative Internet is just a few steps back. As if.\n\nAs Jon Crowcroft and I concluded in our paper on leaky networks for this year's this year's Gikii, \"leaky\" designs can be useful to speed development early on even though they pose problems later, when issues like security become important. The Internet was built by people who trusted each other and did not sufficiently imagine it being used by people who didn't, shouldn't, and couldn't. You could say it this way: in the technology world, everything starts as an experiment and by the time there are problems it's lawless.\n\nSo this the main point of the workshop: how do you structure automated governance to protect the rights of minorities? Opting to slow decision making to consider the minority report impedes decision making in emergencies. If you limit Internet metadata exposure, security people lose some ability to debug problems and trace attacks.\n\nWe considered possible role models: British corporate governance; smart contracts;and, presented by Miranda Mowbray, the wacky system by which Venice elected a new Doge. It could not work today: it's crazily complex, and impossible to scale. But you could certainly code it.\n\nIllustrations: Monument to the Doge Giovanni Pesaro (via Didier Descouens at Wikimedia).\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nIf you want to shape a technology, the time to start is before it becomes fixed in the mindset of \"'twas ever thus\". This was the idea behind the creation of We Robot. At this year's event (see below for links to previous years), one clear example of this principle came from Thomas Krendl Gilbert and Roel I. J. Dobbe, whose study of autonomous vehicles pointed out the way we've privileged cars by coining \"jaywalkification\". On the blank page in the lawbook, we chose to make it illegal for pedestrians to get in cars'' way.\n\nWe Robot's ten years began with enthusiasm, segued through several depressed years of machine learning and AI, and this year has seemingly arrived at a twist on Arthur C. Clark's famous dictum To wit: maybe any technology sufficiently advanced to seem like magic can be well enough understood that we can assign responsibility and liability. You could say it's been ten years of progressively removing robots' glamor.\n\nSomething like this was at the heart of the paper by Andrew Selbst, Suresh Venkatasubramanian, and I. Elizabeth Kumar, which uses the computer science staple of abstraction as a model for assigning responsibility for the behavior of complex systems. Weed out debates over the innards - is the system's algorithm unfair, or was the training data biased? - and aim at the main pointâ: this employer chose this system that produced these results. No one needs to be inside its \"black box\" if you can understand its boundaries. In one analogy, it's not the manufacturer's fault if a coffee maker fails to produce drinkable coffee from poisoned water and ground acorns; it *is* their fault if the machine turns potable water and ground coffee into toxic sludge. Find the decision points, and ask: how were those decisions made?\n\nGilbert and Dobbe used two other novel coinages: \"moral crumple zoning\" (from Madeleine Claire Elish's paper at We Robot 2016) and \"rubblization\", for altering the world to assist machines. Exhibit A, which exemplifies all three, is the 2018 incident in which an Uber car on autopilot killed a pedestrian in Tempe, Arizona. She was jaywalking; she and the inattentive safety driver were moral crumple zoned; and the rubblized environment prioritized cars.\n\nPart of Gilbert's and Dobbe's complaint was that much discussion of autonomous vehicles focused on the trolley problem, which has little relevance to how either humans or AIs drive cars. It's more useful instead to focus on how autonomous vehicles reshape public space as they begin to proliferate.\n\nThis reshaping issue also arose in two other papers, one on smart farming in East Africa by Laura Foster, Katie Szilagyi, Angeline Wairegi, Chidi Oguamanam, and Jeremy de Beer, and one by Annie Brett on the rapid, yet largely overlooked expansion of autonomous vehicles in ocean shipping, exploration, and data collection. In the first case, part of the concern is the extension of colonization by framing precision agriculture and smart farming as more valuable than the local knowledge held by small farmers, the majority of whom are black women, and viewing that knowledge as freely available for appropriation. As in the Western world, where manufacturers like John Deere and Monsanto claim intellectual property rights in seeds and knowledge that formerly belonged to farmers, the arrival of AI alienates local knowledge by stowing it in algorithms, software, sensors, and equipment and makes the plants on which our continued survival depends into inert raw material. Brett, in her paper, highlights the growing gaps in international regulation as the Internet of Things goes maritime and changes what's possible.\n\nA slightly different conflict - between privacy and the need to not be \"mis-seen\" - lies at the heart of Alice Xiang's discussion of computer vision. Elsewhere, Agathe Balayn and Seda GÃ¼rses make a related point in a new EDRi report that warns against relying on technical debiasing tweaks to datasets and algorithms at the expense of seeing the larger social and economic costs of these systems.\n\nIn a final example, Marc Canellas studied whole cybernetic systems and finds they create gaps where it's impossible for any plaintiff to prove liability, in part because of the complexity and interdependence inherent in these systems. Canellas proposes that the way forward is to redefine intentional discrimination and apply strict liability. You do not, Cynthia Khoo observed in discussing the paper, have to understand the inner workings of complex technology in order to understand that the system is reproducing the same problems and the same long history if you focus on the outcomes, and not the process - especially if you know the process is rigged to begin with. The wide spread of move fast and break things, Canellas noted, mostly encumbers people who are already vulnerable.\n\nI like this overall approach of stripping away the shiny distraction of new technology and focusing on its results. If, as a friend says, Facebook accurately described setting up an account as \"adding a line to our database\" instead of \"connecting with your friends\", who would sign up? Similarly, don't let Amazon get cute about its new \"Astro\" comprehensive in-home data collector.\n\nMany look at Astro and see instead the science fiction robot butler of decades hence. As Frank Pasquale noted, we tend to overemphasize the far future at the expense of today's decisions. In the same vein, Deborah Raji called robot rights a way of absolving people of their responsibility. Today's greater threat is that gig employers are undermining workers' rights, not whether robots will become sentient overlords. Today's problem is not that one day autonomous vehicles may be everywhere, but that the infrastructure needed to make partly-autonomous vehicles safe will roll over us. Or, as Gilbert put it: don't ask how you want cars to drive; ask how you want cities to work.\n\nPrevious years: 2013; 2015; 2016 workshop; 2017; 2018 workshop and conference; 2019 workshop and conference; 2020.\n\nIllustrations: Amazon photo of Astro.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nOne part of our brains knows that software can be fragile. Another part of our brains, when faced with the choice of trusting the human or trusting the machine...trusts the machine. It may have been easier to pry trust away from the machine twenty years ago, when systems crashed more often, sometimes ruining months of work and the mantra, \"Have you tried turning it off and back on again?\" didn't yet work as a reliable way of restoring function. Perhaps more important, we didn't *have* to trust software because we had canonical hard copies. Then, as predicted, the copies became \"backups\". Now, often, they don't exist at all, with the result that much of what we think we know is becoming less well-attested. How many of us even print out our bank statements any more? Three recent stories highlight this.\n\nFirst is the biggest UK computer-related scandal for many years, the outrageous Post Office prosecution of hundreds of subpostmasters of theft and accounting fraud, all while insisting that their protests of innocence must all be lies because its software, sourced from Fujitsu, could not possibly be wrong. Eventually, the Court of Appeal quashed 39 convictions and excoriated both the Post Office and Fujitsu for denying the existence of two known bugs that led to accounting discrepancies. They should never have been able to get away with their claim of infallibility - first, because generations of software engineers could have told the court that all software has bugs, and second, because Ross Anderson's work proving that software vulnerabilities were the cause of phantom ATM withdrawals, overriding the UK banking industry's insistence that its software, too, was infallible.\n\nAt Lawfare, Susan Landau, discussing work she did in collaboration with Steve Bellovin, Matt Blaze, and Brian Owsley. uses the Post Office fiasco as a jumping-off point to discuss the increasing problem of bugs in software used to produce evidence presented in court. Much of what we think of as \"truth\" - Breathalyzer readings, forensic tools, Hawkeye line calls in tennis matches - are not direct measurements but software-derived interpretations of measurements. Hawkeye at least publishes its margin for error even though tennis has decided to pretend it doesn't exist. Manufacturers of evidence-producing software, however, claim commercial protection, leaving defendants unable to challenge the claims being made about them. Landau and her co-authors conclude that courts must recognize that they can't assume the reliability of evidence produced bysoftware and that defendants must be able to conduct \"adversarial audits\".\n\nSecond story. At The Atlantic, Jonathan Zittrain complains that the Internet is \"rotting\". Link rot - broken links when pages get deleted or reorganized - and content drift, which sees the contents of a linked page change over time, are familiar problems for anyone who posts anything online. Gabriel Weinberg, the founder of search engine DuckDuckGo, has has talked about API rot, which breaks dependent functionality. Zittrain's particular concern is legal judgments, which increasingly may incorporate disappeared or changed online references like TikTok videos and ebooks. Ebooks in particular can be altered on the fly, leaving no trace of that thing you distinctly remember seeing.\n\nZittrain's response has been to help create sites to track these alterations and provide permanent links. It probably doesn't matter much that the net.wars archive has (probably) thousands of broken links. As long as the Internet Archive's Wayback Machine continues to exist as a source for vaped web pages, most of the ends of those links can be recovered. The Archive is inevitably incomplete, and only covers the open web. But it *does* matter if the basis for a nation's legal reasoning and precedents - what Zittrain calls \"long-term writing\" - can't be established with any certainty. Hence the enormous effort put in by the UK's National Archives to convert millions of pages of EU legislation so all could understand the legitimacy of post-Brexit UK law.\n\nThird story. It turns out the same is true for the brick-by-brick enterprise we call science. In the 2020 study Open is not forever, authors Mikael Laakso, Lisa Matthias, and Najko Jahn find journal rot. Print publications are carefully curated and preserved by librarians and archivists, as well as the (admittedly well-funded) companies that publish them. Open access journals, however, have had a patchy record of success, and the study finds that between 2000 and 2019 174 open access journals from all major research disciplines and from all geographical regions vanished from the web. In science, as in law, it's not enough to retain the end result; you must be able to show your work and replicate your reasoning.\n\nIt's more than 20 years since I heard experts begin to fret about the uncertain durability of digital media; the Foundation for Information Research included the need for reliable archives in its 1998 founding statement. The authors of the journal study note that the journals themselves are responsible for maintaining their archives and preserving their portion of the scholarly record; they conclude that solving this problem will require the participation of the entire scholarly community.\n\nWhat isn't clear, at least to me, is how we assure the durability of the solutions. It seemed a lot easier when it was all on paper in a reassuringly solid building.\n\nIllustrations: The UK National Archives, in Kew (photo by Erian Evans via Wikimedia)..\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\n\"It.\" \"It.\" \"It.\"\n\nIn the first two minutes of a recent episode of the BBC program Panorama, \"Are You Scared Yet, Human?\", the word that kept popping out was \"it\". The program is largely about the AI race between the US and China, an obviously important topic - see Amy Webb's recent book, The Big Nine. But what I wanted to scream at the show's producers was: \"AI is not *it*. AI is *they*.\" The program itself proved this point by seguing from commercial products to public surveillance systems to military dreams of accurate targeting and ensuring an edge over the other country.\n\nThe original rantish complaint I thought I was going to write was about gendering AI-powered voice assistants and, especially, robots. Even though Siri has a female voice it's not a \"she\". Even if Alexa has a male voice it's not a \"he\". Yes, there's a long tradition of dubbing ships, countries, and even fiddles \"she\", but that bothers me less than applying the term to a compliant machine. Yolande Strengers and Jenny Kennedy made this point quite well in their book The Smart Wife, in which they trace much of today's thinking about domestic robots to the role model of Rosie, in the 1960s outer space animated TV sitcom The Jetsons. Strengers and Kennedy want to \"queer\" domestic robots so they no longer perpetuate heteronormative gender stereotypes.\n\nThe it-it-it of Panorama raised a new annoyance. Calling AI \"it\" - especially when the speaker is, as here, Jeff Bezos or Elon Musk - makes it sound like a monolithic force of technology that can't be stopped or altered, rather than what it is: am umbrella term for a bunch of technologies, many of them experimental and unfinished, and all of which are being developed and/or exploited by large companies and military agencies for their own purposes, not ours. \"It\" hides the unrepresentative workforce defining AI's present manifestation, machine learning. *This* AI is \"systems\", not a *thing*, and their impact varies depending on the application.\n\nLast week, Pew Research released the results of a survey it conducted in 2020, in which two-thirds of the experts they consulted predicted that ethics would not be embedded in AI by 2030. Many pointed out that societies and contexts differ; that who gets to define \"ethics\" is crucial, and that there will always be bad actors who ignore whatever values the rest of us agree on. The report quotes me saying it's not AI that needs ethics, it's the *owners*.\n\nI made a stab at trying to categorize the AI systems we encounter every day. The first that spring to mind are scoring applications whose impact on most people's lives appears to be in refusing access to things we need - asylum, probation in the criminal justice system, welfare in the benefits system, credit in the financial system - and assistance systems that answer questions and offer help, such as recommendation algorithms, search engines, voice assistants, and so on. I forgot about systems playing games, and since then a fourth type has accelerated into public use, in the form of identification systems, almost all of them deeply flawed but being deployed anyway: automated facial recognition, emotion recognition, smile detection, and fancy lie detectors.\n\nI also forgot about medical applications, but despite many genuine breakthroughs - such as today's story that machine learning has helped develop a blood test to detect 50 types of early-stage cancer - many highly touted efforts have been failures.\n\n\"It\"ifying AI makes many machine learning systems sound more successful than they are. Today's facial recognition is biased and inaccurate . Even in the pandemic, Benedict Dellot told a recent Westminster Health Forum seminar on AI in health care, the big wins in the pandemic have come from conventional data analysis underpinned by new data sharing arrangements. As examples, he cited sharing lists of shielding patients with local authorities to ensure they got the support they needed, linking databases to help local authorities identify vulnerable people, and repurposing existing technologies. But shove \"AI\" in the name and it sounds more exciting; see also \"nano\" before this and \"e-\" before that.\n\nMaybe - *maybe* - one day we will say \"AI\" and mean a conscious, superhuman brain as originally imagined by science fiction writers and Alan Turing. Machine learning is certainly not that. as Kate Crawford writes in her recent Atlas of AI. Instead, we're talking about a bunch of computers calculating statistics from historical data, forever facing backward. And, as authors such as Sarah T. Roberts and Mary L. Gray and Siddharth Suri have documented, very often today's AI is humans all the way down. Direct your attention to the poorly-paid worker behind the curtain.\n\nCrawford's book reminded me of Arthur C. Clarke's famous line, \"Any sufficiently advanced technology is indistinguishable from magic.\" After reading her structural analysis of machine-learning-AI, it morphed into: \"Any technology that looks like magic is hiding something.\" For Crawford, what AI is hiding is its essential nature as an extractive industry. Let's not grant these systems any more power than we have to. Breaking \"it\" apart into \"them\" allows us to pick and choose the applications we want.\n\nIllustrations: IBM's Watson winning at Jeopardy; its later adventures in health care were less successful.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nI may be reaching the \"get off my lawn!\" stage of life, except the things I'm yelling at are not harmless children but new technologies, many of which, as Charlie Stross writes, leak human stupidity into our environment.\n\nCase in point: a conference this week chose for its platform an extraordinarily frustrating graphic \"virtual congress center\" that was barely more functional than Second Life (b. 2003). The big board displaying the agenda was not interactive; road signs and menu items pointed to venues by name, but didn't show what was going on in them. Yes, there was a reception desk staffed with helpful avatars. I do not want to ask for help, I want simplicity. The conference website advised: \"This platform requires the installation of a dedicated software in your computer and a basic training.\" Training? To watch people speak on my computer screen? Why can't I just \"click here to attend this session\" and see the real, engaged faces of speakers, instead of motionless cartoon avatars?\n\nThis is not a new-technology issue but a usability issue that hasn't changed since Donald Norman's 1988 The Design of Everyday Things sought to do away with user manuals.\n\nI tell myself that this isn't just another clash between generational habits.\n\nEven so, if current technology trends continue I will be increasingly left behind, not just because I don't *want* to join in but because, through incalculable privilege, much of the time I don't *need* to. My house has no smart speakers, I see no reason to turn on open banking, and much of the time I can leave my mobile phone in a coat pocket, ignored.\n\nBut Out There in the rest of the world, where I have less choice, I read that Amazon is turning on Sidewalk, a proprietary mesh network that uses Bluetooth and 900MHz radio connections to join together Echo speakers, Ring cameras, and any other compatible device the company decides to produce. The company is turning this thing on by default (free software update!), though if you're lucky enough to read the right press articles you can turn it off. When individuals roam the streets piggybacking on open wifi connections, they're dubbed \"hackers\". But a company - just ask forgiveness, not permission, yes?\n\nThe idea appears to be that the mesh network will improve the overall reliability of each device when its wifi connection is iffy. How it changes the range and detail of the data each device collects is unclear. Connecting these devices into a network is a step change in physical tracking; CNet suggests that a Tile tag attached to a dog, while offering the benefit of an alert if the dog gets loose, could also provide Amazon with detailed tracking of all your dog walks. Amazon says the data is protected with three layers of encryption, but protection from outsiders is not the same as protection from Amazon itself. Even the minimal data Amazon says in its white paper (PDF) it receives - the device serial number and application server ID - reveal the type of device and its location.\n\nWe have always talked about smart cities as if they were centrally planned, intended to offer greater efficiency, smoother daily life, and a better environment, and built with some degree of citizen acceptance. But the patient public deliberation that image requires does not fit the \"move fast and break things\" ethos that continues to poison organizational attitudes. Google failed to gain acceptance for its Toronto plan; Amazon is just doing it. In London in 2019, neither private operators nor police bothered to inform or consult anyone when they decided to trial automated facial recognition.\n\nIn the white paper, Amazon suggests benefits such as finding lost pets, diagnostics for power tools, and supporting lighting where wifi is weak. Nice use cases, but note that the benefits accrue to the devices' owner while the costs belong to neighbors who may not have actively consented, but simply not known they had to change the default settings in order to opt out. By design, neither device owners nor server owners can see what they're connected to. I await the news of the first researcher to successfully connect an unauthorized device.\n\nThose external costs are minimal now, but what happens when Amazon is inevitably joined by dozens more similar networks, like the collisions that famously plague the more than 50 companies that dig up London streets? It's disturbingly possible to look ahead and see our public spaces overridden by competing organizations operating primarily in their own interests. In my mind, Amazon's move opens up the image of private companies and government agencies all actively tracking us through the physical world the way they do on the web and fighting over the resulting \"insights\". Physical tracking is a sizable gap in GDPR.\n\nAgain, these are not new-technology issues, but age-old ones of democracy, personal autonomy, and the control of public and private spaces. As Nicholas Couldry and Ulises A. Mejias wrote in their 2020 book The Costs of Connection, this is colonialism in operation. \"What if new ways of appropriating human life, and the freedoms on which it depends, are emerging?\" they asked. Even if Amazon's design is perfect, Sidewalk is not a comforting sign.\n\nIllustrations: A mock-up from Google's Sidewalk Labs plan for Toronto.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\n\"I want solutions,\" Sinan Aral challenged at yesterday's Social Media Summit, \"not a restatement of the problems\". Don't we all? How many person-millennia have we spent laying out the issues of misinformation, disinformation, harassment, polarization, platform power, monopoly, algorithms, accountability, and transparency? Most of these have been debated for decades. The big additions of the last decade are the privatization of public speech via monopolistic social media platforms, the vastly increased scale, and the transmigration from purely virtual into physical-world crises like the January 6 Capitol Hill invasion and people refusing vaccinations in the middle of a pandemic.\n\nAral, who leads the MIT Initiative on the Digital Economy and is author of the new book The Hype Machine, chose his panelists well enough that some actually did offer some actionable ideas.\n\nThe issues, as Aral said, are all interlinked. (see also 20 years of net.wars). Maria Ressla connected the spread of misinformation to system design that enables distribution and amplification at scale. These systems are entirely opaque to us even while we are open books to them, as Guardian journalist Carole Cadwalladr noted, adding that while US press outrage is the only pressure that moves Facebook to respond, it no longer even acknowledges questions from anyone at her newspaper. Cadwalladr also highlighted the Securities and Exchange Commission's complaint that says clearly: Facebook misled journalists and investors. This dismissive attitude also shows in the leaked email, in which Facebook plans to \"normalize\" the leak of 533 million users' data.\n\nThis level of arrogance is the result of concentrated power, and countering it will require antitrust action. That in turn leads back to questions of design and free speech: what can we constrain while respecting the First Amendment? Where is the demarcation line between free speech and speech that, like crying \"Fire!\" in a crowded theater, can reasonably be regulated? \"In technology, design precedes everything,\" Roger McNamee said; real change for platforms at global or national scale means putting policy first. His Exhibit A of the level of cultural change that's needed was February's fad, Clubhouse: \"It's a brand-new product that replicates the worst of everything.\"\n\nIn his book, Aral opposes breaking up social media companies as was done incases such as Standard Oil, the AT&T. Zephyr Teachout agreed in seeing breakup, whether horizontal (Facebook divests WhatsApp and Instagram, for example) or vertical (Google forced to sell Maps) as just one tool.\n\nThe question, as Joshua Gans said, is, what is the desired outcome? As Federal Trade Commission nominee Lina Khan wrote in 2017, assessing competition by the effect on consumer pricing is not applicable to today's \"pay-with-data-but-not-cash\" services. Gans favors interoperability, saying it's crucial to restoring consumers' lost choice. Lock-in is your inability to get others to follow when you want to leave a service, a problem interoperability solves. Yes, platforms say interoperability is too difficult and expensive - but so did the railways and telephone companies, once. Break-ups were a better option, Albert Wenger added, when infrastructures varied; today's universal computers and data mean copying is always an option.\n\nUnwinding Facebook's acquisition of WhatsApp and Instagram sounds simple, but do we want three data hogs instead of one, like cutting off one of Lernean Hydra's heads? One idea that emerged repeatedly is slowing \"fast, free, and frictionless\"; Yael Eisenstat wondered why we allow experimental technology at global scale but policy only after painful perfection.\n\nMEP Marietje Schaake (Democrats 66-NL) explained the EU's proposed Digital Markets Act, which aims to improve fairness by preempting the too-long process of punishing bad behavior by setting rules and responsibilities. Current proposals would bar platforms from combining user data from multiple sources without permission; self-preferencing; and spying (say, Amazon exploiting marketplace sellers' data), and requires data portability and interoperability for ancillary services such as third-party payments.\n\nThe difficulty with data portability, as Ian Brown said recently, is that even services that let you download your data offer no way to use data you upload. I can't add the downloaded data from my current electric utility account to the one I switch to, or send my Twitter feed to my Facebook account. Teachout finds that interoperability isn't enough because \"You still have acquire, copy, kill\" and lock-in via existing contracts. Wenger argued that the real goal is not interoperability but programmability, citing open banking as a working example. That is also the open web, where a third party can write an ad blocker for my browser, but Facebook, Google, and Apple built walled gardens. As Jared Sine told this week's antitrust hearing, \"They have taken the Internet and moved it into the app stores.\"\n\nReal change will require all four of the levers Aral discusses in his book, money, code, norms, and laws - which Lawrence Lessig's 1996 book, Code and Other Laws of Cyberspace called market, software architecture, norms, and laws - pulling together. The national commission on democracy and technology Aral is calling for will have to be very broadly constituted in terms of disciplines and national representation. As Safiya Noble said, diversifying the engineers in development teams is important, but not enough: we need \"people who know society and the implications of technologies\" at the design stage.\n\nIllustrations: Sinan Aral, hosting the summit.l\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nEver since 1952, when Clarence Willcock took the British government to court to force the end of wartime identity cards, UK governments have repeatedly tried to bring them back, always claiming they would solve the most recent public crisis. The last effort ended in 2010 after a five-year battle. This backdrop is a key factor in the distrust that's greeting government proposals for \"vaccination passports\" (previously immunity passports). Yesterday, the Guardian reported that British prime minister Boris Johnson backs certificates that show whether you've been vaccinated, have had covid and recovered, or had a test. An interim report will be published on Monday; trials later this month will see attendees to football matches required to produce proof of negative lateral flow tests 24 hours before the game and on entry.\n\nSimultaneously, England chief medical officer Chris Whitty told the Royal Society of Medicine that most experts think covid will become like the flu, a seasonal disease that must be perennially managed.\n\nWhitty's statement is crucial because it means we cannot assume that the forthcoming proposal will be temporary. A deeply flawed measure in a crisis is dangerous; one that persists indefinitely is even more so. Particularly when, as this morning, culture secretary Oliver Dowden tries to apply spin: \"This is not about a vaccine passport, this is about looking at ways of proving that you are covid secure.\" Rebranding as \"covid certificates\" changes nothing.\n\nPrivacy advocates and human rights NGOs saw this coming. In December, Privacy International warned that a data grab in the guise of immunity passports will undermine trust and confidence while they're most needed. \"Until everyone has access to an effective vaccine, any system requiring a passport for entry or service will be unfair.\" We are a long, long way from that universal access and likely to remain so; today's vaccines will have to be updated, perhaps as soon as September. There is substantial, but not enough, parliamentary opposition.\n\nA grassroots Labour discussion Wednesday night showed this will become yet another highly polarized debate. Opponents and proponents combine issues of freedom, safety, medical efficacy, and public health in unpredictable ways. Many wanted safety - \"You have no civil liberties if you are dead,\" one person said; others foresaw segregation, discrimination, and exclusion; still others cited British norms in opposing making compulsory either vaccinations or carrying any sort of \"papers\" (including phone apps).\n\nAside from some specific use cases - international travel, a narrow range of jobs - vaccination passports in daily life are a bad idea medically, logistically, economically, ethically, and functionally. Proponents' concerns can be met in better - and fairer - ways.\n\nThe Independent SAGE advisory group, especially Susan Michie, has warned repeatedly that vaccination passports are not a good solution for solution life. The added pressure to accept vaccination will increase distrust, she has repeatedly said, particularly among victims of structural racism.\n\nInstead of trying to identify which people are safe, she argues that the government should be guiding employers, businesses, schools, shops, and entertainment venues to make their premises safer - see for example the CDC's advice on ventilation and list of tools. Doing so would not only help prevent the spread of covid and keep *everyone* safe but also help prevent the spread of flu and other pathogens. Vaccination passports won't do any of that. \"It again puts the burden on individuals instead of spaces,\" she said last night in the Labour discussion. More important, high-risk individuals and those who can't be vaccinated will be better protected by safer spaces than by documentation.\n\nIn the same discussion, Big Brother Watch's Silkie Carlo predicted that it won't make sense to have vaccination passports and then use them in only a few places. \"It will be a huge infrastructure with checkpoints everywhere,\" she predicted, calling it \"one of the civil liberties threats of all time\" and \"medical apartheid\" and imagining two segregated lines of entry to every venue. While her vision is dramatic, parts of it don't go far enough: imagine when this all merges with systems already in place to bar access to \"bad people\". Carlo may sound unduly paranoid, but it's also true that for decades successive British governments at every decision point have chosen the surveillance path.\n\nWe have good reason to be suspicious of this government's motives. Throughout the last year, Johnson has been looking for a magic bullet that will fix everything. First it was contact tracing apps (failed through irrelevance), then test and trace (failing in the absence of \"and isolate and support\"), now vaccinations. Other than vaccinations, which have gone well because the rollout was given to the NHS, these failed high-tech approaches have handed vast sums of public money to private contractors. If by \"vaccination certificates\" the government means the cards the NHS gives fully-vaccinated individuals listing the shots they've had, the dates, and the manufacturer and lot number, well fine. Those are useful for those rare situations where proof is really needed and for our own information in case of future issues, it's simple, and not particularly expensive. If the government means a biometric database system that, as Michie says, individualizes the risk while relieving venues of responsibility, just no.\n\nIllustrations: The Swiss Cheese Respiratory Virus Defence, created by virologist Ian McKay.\n\nWendy M. Grossman is the 2013 winner of the Enigma Award. Her Web site has an extensive archive of her books, articles, and music, and an archive of earlier columns in this series. Stories about the border wars between cyberspace and real life are posted occasionally during the week at the net.wars Pinboard - or follow on Twitter.\n\nOne of the longest-running conflicts on the Internet surrounds whether and what restrictions should be applied to the content people post. These days, those rules are known as \"platform governance\", and this week saw the first conference by that name. In the background, three of the big four CEOs returned to Congress for more questioning, the EU is planning the Digital Services Act; the US looks serious about antitrust action, and debate about revising Section 230 of the Communications Decency Act continues even though few understandwhat it does; and the UK continues to push \"online harms.\n\nThe most interesting thing about the Platform Governance conference is how narrow it makes those debates look. The second-most interesting thing: it was not a law conference!\n\nFor one thing, which platforms? Twitter may be the most-studied, partly because journalists and academics use it themselves an"
    }
}