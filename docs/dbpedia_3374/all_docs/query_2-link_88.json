{
    "id": "dbpedia_3374_2",
    "rank": 88,
    "data": {
        "url": "https://epdf.pub/formulaic-language-and-the-lexicon.html",
        "read_more_link": "",
        "language": "en",
        "title": "Formulaic Language and the Lexicon",
        "top_image": "https://epdf.tips/assets/img/epdf_logo.png",
        "meta_img": "https://epdf.tips/assets/img/epdf_logo.png",
        "images": [
            "https://epdf.tips/assets/img/epdf_logo.png",
            "https://epdf.tips/img/300x300/formulaic-language-and-the-lexicon_5ad2c3ceb7d7bc1b31722c51.jpg",
            "https://epdf.tips/img/300x300/perspectives-on-formulaic-language-acquisition-and_5aff96d1b7d7bc7969fdba78.jpg",
            "https://epdf.tips/img/300x300/language-and-the-lexicon-an-introduction_5ba55668b7d7bc006e0ff905.jpg",
            "https://epdf.tips/img/300x300/language-and-the-lexicon-an-introduction_5ea812b1097c4749648b59c9.jpg",
            "https://epdf.tips/img/300x300/language-and-the-lexicon-an-introduction_5ba5565bb7d7bcfd6dc82fc2.jpg",
            "https://epdf.tips/img/300x300/formulaic-genres_5abeac13b7d7bc2b4ac26c63.jpg",
            "https://epdf.tips/img/300x300/lexicon_5be43e2ab7d7bcf41f4ecd89.jpg",
            "https://epdf.tips/img/300x300/lexicon_5ea812fb097c4749648b5a5a.jpg",
            "https://epdf.tips/img/300x300/inheritance-defaults-and-the-lexicon-studies-in-na_5b8c31d5b7d7bcd16c5cc029.jpg",
            "https://epdf.tips/img/300x300/formulaic-sequences-acquisition-processing-and-use_5a838619b7d7bc4756e50b54.jpg",
            "https://epdf.tips/img/300x300/formulaic-language-vol-1-distribution-and-historic_5aa0381eb7d7bc4515d3fdd9.jpg",
            "https://epdf.tips/img/300x300/lexicon-syntax-interface-in-second-language-acquis_5b4d6654b7d7bce551127644.jpg",
            "https://epdf.tips/img/300x300/loudspeaker-handbook-and-lexicon_5b96f17db7d7bc015957286b.jpg",
            "https://epdf.tips/img/300x300/formulaic-language-vol-2-acquisition-loss-psycholo_5a90dd2eb7d7bca64eb4ecff.jpg",
            "https://epdf.tips/img/300x300/lexicon-athanasianum_5bf127f6b7d7bcf71f8d7a07.jpg",
            "https://epdf.tips/img/300x300/the-ayn-rand-lexicon_5b4f86e5b7d7bce809a9ddf2.jpg",
            "https://epdf.tips/img/300x300/the-leadership-lexicon_5b495cd4b7d7bc417f5b53ea.jpg",
            "https://epdf.tips/img/300x300/the-demons-lexicon_5b9ea937b7d7bc596379b1c2.jpg",
            "https://epdf.tips/img/300x300/ontology-and-the-lexicon-a-natural-language-proces_5ade7ca0b7d7bc824d48273c.jpg",
            "https://epdf.tips/img/300x300/the-acquisition-of-the-lexicon_5abfe4e0b7d7bc5360a4f89b.jpg",
            "https://epdf.tips/img/300x300/the-generative-lexicon_5ab29d04b7d7bc9473ecab46.jpg",
            "https://epdf.tips/img/300x300/the-ayn-rand-lexicon_5ecce065097c47770a8b6326.jpg",
            "https://epdf.tips/img/300x300/the-multilingual-lexicon_5a88d331b7d7bca57e01e0b9.jpg",
            "https://epdf.tips/img/300x300/the-philosophical-lexicon_5ac02f8fb7d7bc7e78659cba.jpg",
            "https://epdf.tips/img/300x300/the-generative-lexicon_5ab28c9fb7d7bc5763c034d8.jpg",
            "https://epdf.tips/img/300x300/ayn-rand-lexicon-the_5b4f86d1b7d7bce609ac51a1.jpg",
            "https://epdf.tips/img/300x300/the-leadership-lexicon_5b495d95b7d7bc457fc1f21b.jpg",
            "https://epdf.tips/img/300x300/coarticulation-and-the-structure-of-the-lexicon_5b72254cb7d7bcfd3f222f01.jpg",
            "https://epdf.tips/img/300x300/motivation-in-grammar-and-the-lexicon_5bf20433b7d7bcf41f500d01.jpg",
            "https://epdf.tips/img/300x300/lexicon-plotinianum_5b2f4b06b7d7bccc0d4957d5.jpg",
            "https://epdf.tips/img/60x80/formulaic-language-and-the-lexicon_5ad2c3ceb7d7bc1b31722c51.jpg",
            "https://epdf.tips/img/60x80/perspectives-on-formulaic-language-acquisition-and_5aff96d1b7d7bc7969fdba78.jpg",
            "https://epdf.tips/img/60x80/language-and-the-lexicon-an-introduction_5ba55668b7d7bc006e0ff905.jpg",
            "https://epdf.tips/img/60x80/language-and-the-lexicon-an-introduction_5ea812b1097c4749648b59c9.jpg",
            "https://epdf.tips/img/60x80/language-and-the-lexicon-an-introduction_5ba5565bb7d7bcfd6dc82fc2.jpg",
            "https://epdf.tips/img/60x80/formulaic-genres_5abeac13b7d7bc2b4ac26c63.jpg",
            "https://epdf.tips/img/60x80/lexicon_5be43e2ab7d7bcf41f4ecd89.jpg",
            "https://epdf.tips/img/60x80/lexicon_5ea812fb097c4749648b5a5a.jpg",
            "https://epdf.tips/img/60x80/inheritance-defaults-and-the-lexicon-studies-in-na_5b8c31d5b7d7bcd16c5cc029.jpg",
            "https://epdf.tips/img/60x80/formulaic-sequences-acquisition-processing-and-use_5a838619b7d7bc4756e50b54.jpg"
        ],
        "movies": [
            "/pdfviewer/web/viewer.html?file=https%3A%2F%2Fepdf.tips%2Fdownload%2Fformulaic-language-and-the-lexicon.html%3Freader%3D1"
        ],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Guest"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Formulaic Language and the Lexicon A considerable proportion of our everyday language is ‘formulaic’. It is predictable ...",
        "meta_lang": "en",
        "meta_favicon": "https://epdf.tips/assets/img/apple-icon-57x57.png",
        "meta_site_name": "epdf.tips",
        "canonical_link": "https://epdf.tips/formulaic-language-and-the-lexicon.html",
        "text": "Formulaic Language and the Lexicon A considerable proportion of our everyday language is ‘formulaic’. It is predictable in form and idiomatic, and seems to be stored in ﬁxed, or semi-ﬁxed, chunks. This book explores the nature and purposes of formulaic language and looks for patterns across the research ﬁndings from the ﬁelds of discourse analysis, ﬁrst language acquisition, language pathology and applied linguistics. It gradually builds up a uniﬁed description and explanation of formulaic language as a linguistic solution to a larger, nonlinguistic, problem, the promotion of self. The book culminates in a new model of lexical storage, which accommodates the curiosities of non-native and aphasic speech. It proposes that parallel analytic and holistic processing strategies are able to reconcile, on the one hand, our capacity for understanding and producing novel constructions using grammatical knowledge and small lexical units and, on the other, our use of prefabricated material which, although less ﬂexible, also requires less processing. The result of these combined operations is language that is ﬂuent and idiomatic, yet crafted for its referential and communicative purpose. Dr. Alison Wray is a Senior Research Fellow at the Centre for Language and Communication Research, Cardiff University,Wales. She is the author of The Focusing Hypothesis: The Theory of Left Hemisphere Lateralised Language Re-Examined (1992) and the coauthor of Projects in Linguistics: A Practical Guide to Researching Language (1998).\n\nFormulaic Language and the Lexicon\n\nALISON WRAY Cardiff University, UK\n\nPUBLISHED BY THE PRESS SYNDICATE OF THE UNIVERSITY OF CAMBRIDGE\n\nThe Pitt Building, Trumpington Street, Cambridge, United Kingdom CAMBRIDGE UNIVERSITY PRESS\n\nThe Edinburgh Building, Cambridge CB2 2RU, UK 40 West 20th Street, New York, NY 10011-4211, USA 477 Williamstown Road, Port Melbourne, VIC 3207, Australia Ruiz de Alarcón 13, 28014 Madrid, Spain Dock House, The Waterfront, Cape Town 8001, South Africa http://www.cambridge.org © Cambridge University Press 2002 This book is in copyright. Subject to statutory exception and to the provisions of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press. First published 2002 Printed in the United Kingdom at the University Press, Cambridge Typeface Times Roman 10/12.5 pt.\n\nSystem QuarkXPress [BTS]\n\nA catalog record for this book is available from the British Library. Library of Congress Cataloging in Publication Data Wray, Alison. Formulaic language and the lexicon / Alison Wray. p.\n\ncm.\n\nIncludes bibliographical references and index. ISBN 0-521-77309-1 1. Lexicology – Methodology. 2. Linguistic analysis (Linguistics) acquisition. 4. Aphasia. I. Title.\n\n3. Language\n\nP326 .W73 2001 413¢.028 – dc21 2001025455 ISBN\n\n0 521 77309 1\n\nhardback\n\nContents\n\nList of Figures and Tables Preface and Acknowledgements\n\npage vii ix\n\nPart I. What Formulaic Sequences Are 1 The Whole and the Parts\n\n3\n\n2 Detecting Formulaicity\n\n19\n\n3 Pinning Down Formulaicity\n\n44\n\nPart II. A Reference Point 4 Patterns of Formulaicity in Normal Adult Language\n\n69\n\n5 The Function of Formulaic Sequences: A Model\n\n93\n\nPart III. Formulaic Sequences in First Language Acquisition 6 Patterns of Formulaicity in Child Language\n\n105\n\n7 Formulaic Sequences in the First Language Acquisition Process: A Model\n\n128\n\nPart IV. Formulaic Sequences in a Second Language 8 Non-native Language: Overview\n\n143\n\n9 Patterns of Formulaicity in Children Using a Second Language\n\n150\n\n10 Patterns of Formulaicity in Adults and Teenagers Using a Second Language\n\n172 v\n\nvi 11 Formulaic Sequences in the Second Language Acquisition Process: A Model\n\nContents\n\n199\n\nPart V. Formulaic Sequences in Language Loss 12 Patterns of Formulaicity in Aphasic Language\n\n217\n\n13 Formulaic Sequences in Aphasia: A Model\n\n247\n\nPart VI. An Integrated Model 14 The Heteromorphic Distributed Lexicon\n\n261\n\nNotes\n\n283\n\nReferences\n\n301\n\nIndex\n\n327\n\nFigures and Tables\n\nFigures 1.1. 1.2. 2.1. 3.1. 3.2.\n\n4.1. 4.2.\n\n4.3. 4.4. 5.1. 5.2. 6.1. 6.2. 6.3. 7.1.\n\nAdvice on using prefabricated chunks of text page 6 Terms used to describe aspects of formulaicity 9 Hickey’s “Conditions for formula identiﬁcation” 40 Hudson’s “Levels of interaction in ﬁxedness” 61 Van Lancker’s “Subsets of nonpropositional speech and their common properties, presented on a hypothetical continuum from most novel to reﬂexive” 64 Formulaic structure of part of the New Zealand weather forecast 80 A comparison of the structure of the ﬁrst half of three Shipping Forecasts from the British Meteorological Ofﬁce 80 Comparison of a BBC Radio 4 weather forecast with one 24 hours earlier and another one hour later 82 Kuiper and Flindall’s “Greeting formulae of individual checkout operators” 86 The functions of formulaic sequences 97 Schema for the use of formulaic sequences in serving the interests of the speaker 98 Uses of no in a two year old 120 Predicted fate of different types of analytic and holistic language 123 Agendas and responses of the young child 125 The balance of holistic and analytic processing from birth to adulthood 133 vii\n\nviii\n\nFigures and Tables\n\n9.1. Distribution of child L2 studies in Table 9.1, by age 11.1. The creation of the lexicon in ﬁrst language acquisition (including the effect of literacy) 11.2. The creation of the lexicon in classroom-taught L2 (after childhood) 12.1. Code’s “Preliminary model of initial and subsequent production of aphasic lexical and nonlexical speech automatisms” 13.1. Normal production using a distributed lexicon 14.1. Notional balance of three types of lexical unit (formulaic sequence) in distribution: The Heteromorphic Distributed Lexicon model\n\n152 207 208\n\n234 249\n\n263\n\nTables 3.1. Howarth’s collocational continuum 4.1. Formulaic sequences as devices for situation manipulation 9.1. Studies of formulaic sequences in young children acquiring L2 in a naturalistic environment 10.1. Studies examining formulaic sequences in adults acquiring L2 ‘naturally’ 10.2. Studies examining formulaic sequences in adults and teenagers acquiring L2 in the classroom\n\n63 89 151 174 178\n\nPreface and Acknowledgements\n\nThis book began with a mystery. I had been reading about formulaic language in the context of language proﬁciency, and had been struck by three observations made in the literature. The ﬁrst was that native speakers seem to ﬁnd formulaic (that is, prefabricated) language an easy option in their processing and/or communication. The second was that in the early stages of ﬁrst and second language acquisition, learners rely heavily on formulaic language to get themselves started. The third observation, however, seemed to ﬂy in the face of the ﬁrst two. For L2 learners of intermediate and advanced proﬁciency, the formulaic language was the biggest stumbling block to sounding nativelike. How could something that was so easy when you began with a language, and so easy when you were fully proﬁcient in it, be so difﬁcult in between? I set myself the challenge of ﬁnding out, and focussed on two possibilities, both of which I now judge to be true. One was that the formulaic language described in the various areas of study was not quite the same thing in each case. The second was that there was some other key to understanding the nature of formulaic language, one which would be difﬁcult to spot by looking only at the different types of data in isolation. The common link between formulaic language across different speakers might even not be linguistic at all. Very little attempt had been made up till then to draw together what was known about formulaic language in the native adult population, ﬁrst language acquisition, second language acquisition of all types, and language pathology. A critical synthesis was a prerequisite for getting a sense of how they differed, and what they had in common. The second stage was developing a theoretical model – or rather a series of models – which would account for the similarities and differences. At ﬁrst, I imagined that a single journal article would be adequate to ix\n\nx\n\nPreface and Acknowledgements\n\ntell the story, but it was soon very evident that much more space was needed. The result was this book. The “big picture” that I present, will, I hope, provide useful ideas for others to explore. However, it will undoubtedly disappoint some.Those still wedded to the idea that lexis, grammar, interaction and discourse structure can be understood in mutual isolation will be frustrated by my proposal that language knowledge and language use are highly sensitive to the moment-by-moment inﬂuences of mind and environment, so that we are able to switch with ease between processing modes to match the requirements of efﬁciency and accuracy in message delivery and comprehension. And those who place their faith in frequency counts as the only valid arbiter of formulaicity will not welcome my call for the reinstatement of native-speaker intuition as the best witness to the part of our lexicon which we use with most creative ﬂexibility. The models which I propose are a beginning. My aim is to stimulate debate across the relevant disciplines and subdisciplines and to encourage research within each area to take into account what the others have to offer. The goal is a full integration of the wealth of insights currently imprisoned within each ﬁeld, and this book is a ﬁrst attempt at such an integration. The detail may be challenged – indeed, I hope it will be – but the inclusive approach to explaining what language is and how we manage it is, I believe, here to stay. A great many people have been generous with their time, advice and material during the preparation of this book. I am particularly grateful to the following: Ellen and Naomi Visscher and Hannah and Jane Soilleux for data in Chapter 6; Reg Fletcher of The Kellogg Company, Catherine Coleman of the American Advertising Museum and Kate Maxwell of J. Walter Thomson, who all chased after information about the Rice Krispies advertising campaign on my behalf; Gwen Awbery, Ellen Schur and Anne Thalheim, who advised me on the translation of data and/or quotes from Welsh, Hebrew and French, respectively; Gill Brown, Paul Meara and his Vocabulary Acquisition Research Group at the University of Wales Swansea, Andy Pawley, David Tuggy, Renee Waara, Dave Willis and Jane Willis, with all of whom I have discussed one or more of the ideas presented in the book; Chris Butler, Chris Code, Kon Kuiper, Mick Perkins, Norman Segalowitz, Mike Stubbs and two anonymous readers, who were kind enough to read drafts of all or parts of the book and who provided detailed and challenging comments. I should emphasize that they do not necessarily endorse the views expressed in this\n\nPreface and Acknowledgements\n\nxi\n\nbook, and any inaccuracies or misunderstandings expressed in it are entirely my responsibility. Finally, I want to thank Mike Wallace for his consistent support, interest and good humour during what has been a mighty project. Alison Wray Cardiff, June 2001\n\nPART I\n\nWHAT FORMULAIC SEQUENCES ARE\n\n1 The Whole and the Parts\n\n‘Twelve-inches-one-foot. Three-feet-make-a-yard. Fourteen-pounds-make-astone. Eight-stone-a-hundred-weight’. . . . Unhearing, unquestioning, we rocked to our chanting, hammering the gold nails home. ‘Twice-two-are-four. One-God-isLove. One-Lord-is-King. One-King-is-George. One-George-is-Fifth . . .’ So it was always; had been, would be for ever; we asked no questions; we didn’t hear what we said; yet neither did we ever forget it. Laurie Lee: Cider with Rosie. Penguin:53–4 She would go and smile and be nice and say ‘So kind of you. I’m so pleased. One is so glad to know people like one’s books’. All the stale old things. Rather as you put a hand into a box and took out some useful words already strung together like a necklace of beads. Agatha Christie: Elephants Can Remember. Pan:12\n\nIntroduction In a series of advertisements run on British TV early in 1993 by the breakfast cereal manufacturer Kellogg, people were asked what they thought Rice Krispies were made of, and expressed surprise at discovering that the answer was rice.1 Somehow they had internalized this household brand name without ever analyzing it into its component parts. It was as if the name of the product had taken on a life of its own, and required no more reference back to its ‘meaning’ than do words of foreign origin such as chop suey (‘mixed bits’) and spaghetti (‘little cords’). But how could this come about in the case of a name which, although oddly spelled, so transparently refers to crisp rice? In actual fact, overlooking the internal composition of names is a far more common phenomenon than we might at ﬁrst think. Many personal names have ‘meanings’ which we simply ignore: we do not expect someone called ‘Verity Baker’ to be a truthful bread maker, or someone called 3\n\n4\n\nWhat Formulaic Sequences Are\n\n‘Victor Cooper’ to win barrel-making competitions.2 Since interpreting such names in a literal way would be a distraction, it is actually very useful that we can choose the level at which we stop breaking down a chunk of language into its constituent parts. Nor is it just names that we treat in this way. We also overlook the internal composition of a great many words. Although there is a historical reason why a ladybird is so called, there is no more sense in decomposing the word than there is in falsely breaking down carpet into ‘car’ and ‘pet’. If this phenomenon were restricted to proper names and single words, it would be remarkable enough. But this is just the thin end of the wedge, for we are also able to treat entire phrases, clauses, and even lengthy passages of prose in this way. Just as with the name Rice Krispies, which, in effect, means both ‘crisp rice’ and ‘common breakfast cereal of indeterminate composition’, the result is often, though not always, two layers of meaning. If you break the phrase up, it means one thing, but if you treat it whole, in its accustomed way, it possesses a meaning that is something other than, or in addition to, its constituent parts. Idioms are a clear example of this. The phrase pull someone’s leg has a literal, if rather improbable, meaning, which involves a person, the person’s leg, and the action of pulling. But the phrase as a whole has the meaning ‘tease’, and it is difﬁcult, in that interpretation, to work out why there is any reference to legs or pulling at all. Words and word strings which appear to be processed without recourse to their lowest level of composition are termed formulaic, and they are the focus of this book. They are interesting because their widespread existence is an embarrassment for certain modern theories of linguistics, which have unashamedly pushed them aside and denied their undoubted signiﬁcance. In exploring the way in which formulaicity contributes to our management of linguistic communication, we shall address such questions as: Just how common is formulaic language? What forms can it take? What is it used for? What role does it play in our production and comprehension of normal discourse? How is it to be accommodated within linguistic theory? How do ﬁrst language learners acquire it? Why is it so problematic for second language learners? What happens to it when someone loses language capabilities through brain damage? And what role might it play in the general and linguistic recovery of such individuals? In the course of the book, we shall see that research on formulaic language has lacked a clear and uniﬁed direction, and has been diverse in its methods and assumptions. Both within and across subﬁelds such as child language, language pathology and applied linguistics, different terms have been used for the same thing, the same term for different things, and entirely different starting places have been taken for identi-\n\nThe Whole and the Parts\n\n5\n\nfying formulaic language within data. As a result, little headway has been made in spotting larger, more general patterns, and no attempt has been made before, to compare and contrast the full range of ﬁndings and to reconcile them within a single theoretical account. The momentum of the book is towards a uniﬁed description and explanation of formulaic language and its status relative to the lexicon. Parts I and II culminate in the assertion that recognizing the role of formulaicity is fundamental to understanding the freedoms and constraints of language as a formal and functional system. Speciﬁcally, it is proposed that formulaic language is more than a static corpus of words and phrases which we have to learn in order to be fully linguistically competent. Rather, it is a dynamic response to the demands of language use, and, as such, will manifest differently as those demands vary from moment to moment and speaker to speaker. This hypothesis, developed with reference to what is known about formulaicity in the language of adult native speakers, is then tested through a comprehensive survey of ﬁndings in the published research of three other ﬁelds: ﬁrst language acquisition (Part III), second language acquisition (Part IV) and aphasia (Part V). For each area of research, individual descriptive and explanatory models are developed, and these are drawn into a uniﬁed model in Part VI. Setting the Scene The Shape of Formulaicity It is something of a joke amongst those who write for a living that it is possible to construct plausible text out of prefabricated chunks (Figure 1.1). The humour of such examples resides in our recognition that “just as we are creatures of habit in other aspects of our behavior, so apparently are we in the ways we come to use language” (Nattinger & DeCarrico 1992:1). Despite Pinker’s (1994:90ff) assertion that using prefabricated chunks of language is a peripheral pursuit that tells us nothing about real language processing, there is plenty of evidence to the contrary. For, in our everyday language, “the patterning of words and phrases . . . manifests far less variability than could be predicted on the basis of grammar and lexicon alone” (Perkins 1999:55–56). There are words and phrases that we are likely to say when we see a particular friend, or ﬁnd ourselves in a certain situation (Coulmas 1981). If we tell the same story, or deliver the same lecture, more than once, we will soon ﬁnd that whole ideas are expressed in the same chunks of language each time (Peters 1983:80, 109). We may re-echo a form of words that we used earlier, or which someone else has just used (Pawley & Syder 2000:178). In the context of ‘collocation’ we ﬁnd that some words seem to belong\n\n6\n\nTo pad out a report or an essay which is short on words without having to do any original thinking simply take one phrase from each column and join them as a sentence. I On the other hand Similarly However, we must not forget that The weight and meaning of these problems does not need justiﬁcation as Richly diversiﬁed experiences and The concern of the organization, in particular Higher ideological assumptions, and also In this way Broadly speaking,\n\nII the realization of preset programme assignments the scope of staff schooling permanent growth volume and the range of our activities the current structure of organizations the new model of organizational activity further development of various forces of activity permanent safety of our activities in information and propaganda consultation with active members any alternative approach to the questions\n\nIII compels us to reanalyze thoroughly the forms requires the explicit formulation and deﬁnition helps in the preparation and realization safeguards the involvement of a wider group in the forming fulﬁls important tasks in the elaboration enables the creation, to some extent, is causing appreciation of the scale of importance presents an interesting veriﬁcation test draws after itself the initiation and modernization processes\n\nFigure 1.1. Advice on using prefabricated chunks of text (origin unknown).\n\nIV of existing administrative and ﬁnancial conditions. of further directions of development. of the system of universal participation. of participants’ attitudes in the face of the tasks set by organizations. of new propositions. of the directions of progressive education. of needs-related systems. of appropriate conditions of activation. of the model’s development.\n\nThe Whole and the Parts\n\n7\n\ntogether in a phrase, while others, that should be equally good, sound odd. For instance, Biber, Conrad and Reppen (1998) report that, in a 2.7 million word corpus of academic prose, large number was more than ﬁve times more common than great number (48.3 per million versus 8.9 per million).3 Whether these preferred strings are actually stored and retrieved as a unit or simply constructed preferentially, it has been widely proposed that they are handled, effectively, like single “big words” (Ellis 1996:111). They are “single choices, even though they might appear to be analysable into segments” (Sinclair 1991:110). Some are fully ﬁxed in form (e.g., Fancy seeing you here; Nice to see you) and can bypass the entire grammatical construction process (Bateson 1975:61). Others, termed semipreconstructed phrases, such as NPi set + tense POSSi sights on (V) NPj, require the insertion of morphological detail and/or open class items, normally referential ones (giving, for instance, The teacher had set his sights on promotion; I’ve set my sights on winning that cup).\n\nA Long-Recognized Phenomenon Observations of unexpected levels of ﬁxedness in language can be traced back to the mid-nineteenth-century writings of John Hughlings Jackson, whose interest was in the ability of aphasic patients ﬂuently to utter rhymes, prayers, routine greetings and so on, even though they had no ability to construct novel utterances (see Chapter 12). Half a century later, Saussure (1916/1966) talked of “synthesizing the elements of [a] syntagm into a new unit . . . [such that] when a compound concept is expressed by a succession of very common signiﬁcant units, the mind gives up analysis – it takes a short cut – and applies the concept to the whole cluster of signs, which then becomes a simple unit” (p. 177). Jespersen (1924/1976) observed that “a language would be a difﬁcult thing to handle if its speakers had the burden imposed on them of remembering every little item separately” (p. 85). He characterized the formula as follows: [it] may be a whole sentence or a group of words, or it may be one word, or it may be only part of a word, – that is not important, but it must always be something which to the actual speech instinct is a unit which cannot be further analyzed or decomposed in the way a free combination can. (p. 88)\n\nBloomﬁeld (1933) observed that “many forms lie on the border-line between bound forms and words, or between words and phrases” (p. 181). According to Firth (1937/1964), “when we speak . . . [we] use a whole sentence . . . the unit of actual speech is the holophrase” (p. 83). Firth\n\n8\n\nWhat Formulaic Sequences Are\n\nconsidered it central to characterizing communication within a speech community to identify and list the “usual collocations” (1957/1968:180ff). Hymes (1962/1968) proposed that “a vast portion of verbal behavior . . . consists of recurrent patterns, of linguistic routines . . . [including] the full range of utterances that acquire conventional signiﬁcance for an individual, group or whole culture” (pp. 126–127). Bolinger (1976) asserted that “our language does not expect us to build everything starting with lumber, nails, and blueprint, but provides us with an incredibly large number of prefabs” (p. 1), and Charles Fillmore (1979) argued that “a very large portion of a person’s ability to get along in a language consists in the mastery of formulaic utterances” (p. 92). However, insofar as these descriptions applied beyond the realm of the noncomponential idiom, they became increasingly marginalized as Chomsky’s approach to syntactic structure gained prominence. Only with the new generation of grammatical theories, based on performance rather than competence (see later), has the idea of holistically managed chunks of language been slowly reinstated, and its implications recognized. Terminology Figure 1.2 lists some of the terms which can be found in the literature to describe a larger or smaller part of the set of related phenomena that we shall be examining in this book. While there is undoubtedly a certain measure of conceptual duplication, where several words are used to describe the same thing, it is also evident that some of the terms shared across different ﬁelds do not mean entirely the same thing in all instances. The label used by a given commentator may reﬂect anything from the careless appropriation of a nontechnical word to denote a speciﬁc meaning, to the deliberate selection of a particular technical term along with all its preexisting connotations. Overall, we must exercise some doubt about the likelihood that “while labels vary, it seems that researchers have very much the same phenomenon in mind” (Weinert 1995:182), for we shall see in Chapter 3 that this large and unwieldy set of types has been carved up and categorized in innumerable ways, all of which have something useful to say, but none of which seems fully to capture the essence of the wider whole. Because of this plethora of terms, and the individual ways in which they are implicitly or explicitly deﬁned,4 we encounter a certain difﬁculty in wanting to refer to ﬁndings within and across research areas without appearing to impose one or another theoretical position. The survey which will unfold in the course of the book is intended to cast a fresh\n\nThe Whole and the Parts\n\n9\n\namalgams – automatic – chunks – clichés – co-ordinate constructions – collocations – complex lexemes – composites – conventionalized forms – F[ixed] E[xpressions] including I[dioms] – ﬁxed expressions – formulaic language – formulaic speech – formulas/formulae – fossilized forms – frozen metaphors – frozen phrases – gambits – gestalt – holistic – holophrases – idiomatic – idioms – irregular – lexical simplex – lexical(ized) phrases – lexicalized sentence stems – listemes – multiword items/units – multiword lexical phenomena – noncompositional – noncomputational – nonproductive – nonpropositional – petriﬁcations – phrasemes – praxons – preassembled speech – precoded conventionalized routines – prefabricated routines and patterns – ready-made expressions – ready-made utterances – recurring utterances – rote – routine formulae – schemata – semipreconstructed phrases that constitute single choices – sentence builders – set phrases – stable and familiar expressions with specialized subsenses – stereotyped phrases – stereotypes – stock utterances – synthetic – unanalyzed chunks of speech – unanalyzed multiword chunks – units Figure 1.2. Terms used to describe aspects of formulaicity.\n\neye over the range of accounts and data, in order to establish the larger pattern into which they all ﬁt. What is needed, then, is a term which does not carry previous baggage, and which can be clearly deﬁned. The neutral term formulaic language is too commonly used in the literature to be free of such associations. In its place, therefore, we shall use formulaic sequence.5 The word formulaic carries with it some associations of ‘unity’ and of ‘custom’ and ‘habit’, while sequence indicates that there is more than one discernible internal unit, of whatever kind. As we shall see, there are good reasons for avoiding any implication that these internal units must be words. Our working deﬁnition of the formulaic sequence will be as follows: a sequence, continuous or discontinuous, of words or other elements, which is, or appears to be, prefabricated: that is, stored and retrieved whole from memory at the time of use, rather than being subject to generation or analysis by the language grammar.6\n\nIt is clear from this deﬁnition that the term aims to be as inclusive as possible, covering any kind of linguistic unit that has been considered formulaic in any research ﬁeld.7 The intention is to make reference easier, not to constrain the discussion, so, despite the features of the deﬁnition, the term will have to be used fairly loosely as a coverall. In particular, although our starting place is a recognition that there is\n\n10\n\nWhat Formulaic Sequences Are\n\nsomething about a formulaic sequence that makes it appear to be unitary, we shall also cover accounts which do not embrace, or do not require, holistic storage, including purely frequency-based descriptions. At times, especially in Chapters 11 and 13, we shall be focussing on the ability of morphemes and polymorphemic words to count as formulaic sequences. In such contexts, we shall need to differentiate between types of formulaic sequence and the terms formulaic word string, formulaic word and morpheme will be used. Selecting a Theoretical Reference Point “Linguists seem to underestimate the great capacity of the human mind to remember things while overestimating the extent to which humans process information by complex processes of calculation rather than by simply using prefabricated units from memory” (Lamb 1998:169). It will be proposed in this book that although we have tremendous capacity for grammatical processing, this is not our only, nor even our preferred, way of coping with language input and output. In particular, it will be argued that much of our entirely regular input and output is not processed analytically, even though it could be. Clearly, in order to explore this idea, it is necessary to engage with at least one established model of grammatical processing. Several recent models intrinsically accommodate some or all aspects of formulaicity, including Cognitive Grammar (e.g., Langacker 1987, 1991), Construction Grammar (e.g., Fillmore, Kay & O’Connor 1988; Michaelis & Lambrecht 1996; Tomasello & Brooks 1999), the Emergent Lexicon (Bybee 1998), Lexical-Functional Grammar (Bresnan 1982a, 1982b), the Cardiff Grammar, a version of Systemic Functional Grammar (e.g., Tucker 1998), and Pattern Grammar (Hunston & Francis 2000). However, to adopt one of these for our current purposes would be premature, since their very tolerance of formulaicity means that they will not challenge the core assumptions about its nature which this book seeks to tease out and examine. Rather, we need a model which directly opposes those assumptions, so that every claim about what formulaicity is and why it exists has to be fully justiﬁed. The theoretical positions least sympathetic to formulaicity as a principle feature of language structure are the ones which propose a single grammatically based processing system. Within those, it is Chomsky’s (1965) claim, that we have a greater understanding of language structure than we could possibly construe only from the observation of input, which remains the most difﬁcult to defeat. Therefore, the argument of this book will be directed against the traditional generative account of syntax, in which language structure is founded on abstract universal and local rules. The Chomskian position offers the clearest contrast to the\n\nThe Whole and the Parts\n\n11\n\nwhole notion of circumstantial associations between words, is least tolerant of internally complex units, and holds itself separate from performance and pragmatics, the two axes of the model of formulaicity developed here. There is also a particular advantage in pitching what will be a model of part-analytic, part-holistic processing against a purely analytic one. It invites us to construe the analytic grammatical system and the holistic formulaic one as essentially separate. Now this may well not be desirable in the end, but it will make much clearer the path of the argument. It would be short-sighted simply to ignore the alternative theories, however, especially since they may offer plausible solutions to the problem of how formulaicity is to be accommodated within a productive knowledge of grammar.8 So we shall return to the question of theoretical models of grammatical structure and processing in Chapter 14, when we shall be able to assess more directly the demands that the existence of formulaicity makes on explanatory adequacy. Formulaicity and Our Capacity for Novelty The reason why formulaicity has been somewhat overlooked in the last few decades is that, from the standard perspective of how linguistic systems must be designed, it does not sit easily with our capacity for novel expression. Novelty in language, or rather the potential for it, has lain at the centre of modern linguistic theory for several decades: “an essential property of language is that it provides the means for expressing indeﬁnitely many thoughts and for reacting appropriately in an indeﬁnite range of new situations” (Chomsky 1965:6). Chomsky’s observations about our inherent capacities to generate and to understand sentences that we have never encountered before are fundamental and entirely valid. But the signiﬁcance of this capability has been considerably overstated, relative to our actual use of language on a minute-by-minute basis: native speakers do not exercise the creative potential of syntactic rules to anything like their full extent, and . . . indeed, if they did so they would not be accepted as exhibiting nativelike control of the language. The fact is that only a small proportion of the total set of grammatical sentences are nativelike in form – in the sense of being readily acceptable to native informants as ordinary, natural forms of expression, in contrast to expressions that are grammatical but are judged to be ‘unidiomatic’, ‘odd’, or ‘foreignisms’. (Pawley & Syder 1983:193)\n\nIn order to understand the signiﬁcance of this fundamental misalignment of positions, we need to consider just what ‘novelty’ is in this context, and how it can be reconciled with the repetitiveness of much of our everyday language.\n\n12\n\nWhat Formulaic Sequences Are\n\nNovelty Poetry is a clear case in which the writer’s success in achieving a particular effect often relies on novel juxtapositions of ideas: The shrill, demented choirs of wailing shells; Young death sits in a café smiling; With Time’s injurious hand crush’d and o’erworn; You are his repartee.9 Our capacity to interpret such strings has reasonably been taken as evidence that we possess a ﬂexible lexicon and grammar which enable us to ﬁnd meaning in combinations of words we have not encountered before.10 That capacity is particularly useful when, for instance, word classes are changed (e.g., he sang his didn’t he danced his did),11 or unaccustomed morphological relations are created (e.g., and you and I, light-tenderholdly, ached together in bliss-me-body).12 However, in most cases ‘novelty’ is much less a question of doing things with grammar than juxtaposing new ideas in commonplace grammatical frames. So, although the sentence there’s a man-eating tiger on the sugar lump is novel both in the sense that it is unlikely to have been encountered before, and also in that it expresses a new idea, this effect is created by the juxtaposition of the referential subject matter, not by any grammatical creativity. Most of our language, then, is novel in a rather uninteresting way (cf. Schmidt & Frota 1986:309–310). Yet because there is the possibility that we will encounter the more challenging kind of novelty that poetry, and speaker errors, bring, we need to be equipped to deal with it. This capacity for handling novelty, both ideational and grammatical, is sufﬁcient to rule out the possibility that language knowledge consists only of a set of prefabricated phrases and sentences memorized from previous encounters with them (Bloom 1973:17). Whatever determines our preferences for certain phrases – their storage in prefabricated form, or something else – the most that we could argue is that this process coexists with our ability to create and understand entirely novel strings. Although we customarily say, Hi, how are you doing? or some other idiomatic greeting on meeting a friend, there is nothing at all to stop us saying, What a pleasant event it is to see you. Tell me, how is your life progressing at the moment? The real issue is whether it is, or isn’t, possible to account for real language data without invoking prefabrication. The Theoretical Signiﬁcance of Formulaic Sequences Until quite recently, only two arguments really challenged the Chomskian claim that the language of normal adult native speakers is fully generated at the time of production and fully analyzed in comprehension. The ﬁrst was that idioms cannot be so processed, if\n\nThe Whole and the Parts\n\n13\n\nthey are to render their real meaning (e.g., Chafe 1968; Jackendoff 1997; Lyons 1968:177ff; Weinreich 1969). The only way to decode and encode an expression like pig in a poke is to have a direct link from its phonological or graphemic form to its meaning. It is, as Kiparsky put it, “a ready-made surface structure” (Watkins 1992:392). However, since the idioms are a small set, it was relatively easy to propose that they are an awkward exception, and need to be listed whole in the lexicon. There were no major further implications to this. The second argument was the one which we have seen illustrated above from Pawley and Syder (1983): not all possible grammatical sentences occur with equal frequency or are judged equally idiomatic by native speakers. This observation, along with explanations of it, has been made many times over the last few decades, but had little impact on the theoretical stance of the powerful syntax fraternity, because it seemed focussed on the circumstantial practice of real speakers, whereas “[a] grammar of a language purports to be a description of the ideal speaker-hearer’s intrinsic competence” (Chomsky 1965:4). Since there is no gain-saying the fact that an “ideal speakerhearer” of standard English is entirely capable of constructing, and understanding, a sentence such as The captain has illuminated the seatbelt sign as an indication that landing is imminent,13 it could reasonably be viewed as irrelevant that, in actual fact, a native speaker probably never would construct such a sentence because one or more other ways would tend to come to mind ﬁrst, such as The captain has put the seatbelt sign on, which means we’re about to land. The mighty resilience of the Chomskian position relates to its avoidance of any engagement with what people actually say, or which grammatically possible constructions of their language they might ﬁnd more difﬁcult to encode and/or decode than others. For as long as the unease with this mismatch of theory and data was primarily reliant on small samples and armchair intuition, ‘idiomaticity’ could be kept at arm’s length and relegated to the ‘lesser’ ﬁelds of sociolinguistics and pragmatics. However, that is now no longer the case. Corpus linguistics has upped the ante for the traditional accounts, revealing formulaicity, in its widest sense, to be all-pervasive in language data (see Chapter 2). Whereas it was previously possible to imagine that words combined fairly freely, their restrictions attributable to context and pragmatics, and to easily deﬁnable social signalling, it is now clear that, once you actually map out the patterns of distribution for words, no such piecemeal and superimposed explanation is possible. Words belong with other words not as an afterthought but at the most fundamental level. John Sinclair, a central ﬁgure in the development of techniques in corpus linguistics and their application to the practical task of\n\n14\n\nWhat Formulaic Sequences Are\n\ndictionary-writing, and the ﬁrst to uncover the full extent of word patterning, ﬁrmly believes that any plausible description of normal language must take this “unrandomness” (Sinclair 1991:110) in the distribution of words into account. Explaining ‘unrandomness’ requires a model of linguistic knowledge which preferentially associates some regular combinations of words relative to others, and this creates a fundamental problem for generative grammar. It would be, at the very least, inelegant for such models to have any sizeable store of complex as well as simple items, and total anathema if such items were actually regular in form and meaning, consisting of predictable subcomponents. This is because two central requirements of these accounts of language are explanatory simplicity (Hjelmslev 1943/1969:18) and streamlined modelling of mental storage and processing. This means that the language descriptions are directed towards the potential for the free combination of minimal units, subject to the constraints of general principles and of local co-occurrence restrictions (Marantz 1995:352; Webelhuth 1995a:9). Chomsky’s Minimalist Program is a case in point, identifying operations that represent ‘least effort’ as the preferred ones, with other, more effortful ones termed ‘last resort’; the procedural rule is that of “a striving for the cheapest or minimal way of satisfying principles” (Marantz 1995:353).\n\nTwo Systems Sinclair’s (1987, 1991) explanation of ‘unrandomness’ is that we handle linguistic material in two different ways. The open choice principle results in the selection of individual words, and gives us the same kind of creative leeway as the Chomskian account. The idiom principle brings about the selection of two or more words together, on the basis of their previous and regular occurrence together (Sinclair 1991:110f). Sinclair proposes that the ﬁrst mode to be applied is the idiom principle, since most of the text will be interpretable by this principle. Whenever there is good reason, the interpretive process switches to the open-choice principle, and quickly back again. Lexical choices which are unexpected in their environment will presumably occasion a switch. (1991:114)\n\nWray (1992) also proposes a dual-systems solution. Analytic processing entails the interaction of words and morphemes with grammatical rules, to create, and decode, novel, or potentially novel, linguistic material. Holistic processing relies on prefabricated strings stored in memory. The strategy preferred at any given moment depends on the demands of\n\nThe Whole and the Parts\n\n15\n\nthe material and on the communicative situation, and so, importantly, holistic processing is not restricted to only those strings which cannot be created or understood by rule, such as idioms. It can also deal with linguistic material for which grammatical processing would have rendered exactly the same result. The explanatory power of dual-processing systems accounts is considerable (see, for instance, Erman & Warren 2000). Neither a grammaronly nor a formula-only model can accommodate both the linguistic competence of the “ideal speaker listener” (Chomsky 1965:3) and the idiomaticity associated with a preference for some grammatical strings over others.14 The grammar on its own will overgenerate acceptable strings, relative to what sounds nativelike (Pawley & Syder 1983), while prefabricated units offer only a restricted range of forms and meanings, and so are of little use when dealing with something novel.15 But between them, they can explain both novelty and idiomaticity. At ﬁrst glance, a dual-systems model is inelegant because it means that there is multiple representation of linguistic items (e.g., Bolinger 1975:297; Peters 1983:3–4). Accounts concur that prefabricated strings must run into many thousands (Jackendoff 1997:155–156; Van Lancker 1987:56), and, as corpus studies show, they will contain many of the same words in different formulations. However, although a dual-systems account lacks the particular elegance of a streamlined model, that is of no signiﬁcance if, in the light of all the available evidence, it becomes clear that a single-system model is implausible. Occam’s Razor invites us to select the most elegant of the possible explanations. As Langacker (1987) points out, “the principle of economy must be interpreted in relation to other considerations, in particular the requirement of factuality: true simplicity is not achieved just by omitting relevant facts” (p. 41). In any case, as we shall see now, storing often-used word strings whole constitutes, in itself, an alternative type of efﬁciency.16 Formulaic Sequences and Processing Pressures A given communicative situation will tax one’s resources, with the result that a demand placed on the individual may actually exceed the resources available. For example, understanding a spoken message in a noisy room or during an emotionally charged exchange will normally make greater demands on the listener than will a casual conversation. If the demands are too great, then the individual will not be able to engage in all the complex processing that the situation requires. (Segalowitz 1997:105)\n\nIn this light, it seems reasonable that “the main reason for the prevalence of formulaicity in the adult language system appears to be the\n\n16\n\nWhat Formulaic Sequences Are\n\nsimple processing principle of economy of effort” (Perkins 1999:56). This economy occurs because it gives us access to “ready-made frameworks on which to hang the expression of our ideas, so that we do not have to go through the labor of generating an utterance all the way out from ‘S’ every time we want to say something” (Becker 1975:17). If Becker is right, then it suggests that some aspects of our processing ability can fail to match the power of our analytical grammar.17 In one respect, this has been long accepted in syntactic theory. Recursivity permits multiple self-embedding, including centre-embedding, as with Chomsky’s (1965) example the man who the boy who the students recognized pointed out is a friend of mine (p. 11), but our limited memory makes it difﬁcult to hold all the unﬁnished structures in an orderly way until they are resolved (Miller & Chomsky 1963:473ff; Yngve 1961). Centreembedding is rare (though, as Sampson 1996 argues, perhaps not as rare as many have claimed), but much more common constructions can also create processing problems in certain situations. Some kinds of input are substantially more difﬁcult to follow than others, and if, as later argument will suggest, our output has to be ﬂuent in order to be successful in its impact, then the dysﬂuency which producing complex constructions can lead to will be dispreferred, in favour of, for example, chaining together short, self-contained strings (Pawley & Syder 1983). As mentioned previously, one explanation for the shortfall between grammatical capability and on-line processing capability is limitations in short-term memory. Others are biologically or chemically imposed limitations on processing speed (e.g., Crick 1979:134), competition for the focus of attention (Pawley & Syder 2000:196; Wray 1992), and limited facility with switching the focus of attention (Segalowitz 2001). Miller (1956), Bower (1969) and Simon (1974) have shown how chunking information into single complex units increases the overall quantity of material that can be stored in short-term or working memory. Ellis and Sinclair (1996) note that a person’s phonological working memory span correlates with his or her language learning capacity.18 This links short-term memory to the question of processing speed: It would be physiologically impossible for us to produce speech with the rapidity and proﬁciency that we are able to if we had to plan and perform each segment individually. Speech appears to be under a mixture of closed-loop and open-loop control. . . . In closed-loop control, speech is feed-back-controlled, segmentally planned and executed. Under open-loop control whole chunks are holistically planned and automatically produced. The speed and ﬂuency of normal speech production from a neuromuscular system under physiological and mechanico-inertial constraints, means that a signiﬁcant amount of automaticity is required for speech to proceed. (Code 1994:139–140)\n\nThe Whole and the Parts\n\n17\n\nIt seems to be in our interests to be ﬂuent, and “it is our ability to use lexical phrases . . . that helps us speak with ﬂuency” (Nattinger & DeCarrico 1992:32). The advantage of ﬂuency19 seems to be in “permitting speakers (and hearers) to direct their attention to the larger structure of the discourse, rather than keeping it focused narrowly on individual words as they are produced” (ibid.). Thus, it is advantageous for us to be able to exercise ﬂexibility, by trading off processing effort against novelty (Kuiper 1996:96ff; Oppenheim 2000). The dual-system model proposed here has much in common with that of Wray (1992), but is also different in some important ways. Wray (1992) suggests that holistic processing, associated with the right hemisphere of the brain, may be preferred for all commonplace linguistic material up to clausal level, through the recognition of familiar frames, while the analytic mechanisms (left hemisphere) focus on the juxtaposition of propositions, and on troubleshooting when dysﬂuencies, errors or unexpected structures interrupt routine decoding. This emphasis divides grammatical abilities between the two systems. In our current model, the formulaic system will not entail any grammatical processing, only lexical retrieval, though the internal complexity of the units retrieved may give the impression that grammatical construction has taken place. In this respect, it has more in common with Becker’s (1975) formulation: We start with the information we wish to convey and the attitudes toward that information that we wish to express or evoke, and we haul out of our phrasal lexicon some patterns that can provide the major elements of this expression . . . Then the problem is to stitch these phrases together into something roughly grammatical, to ﬁll in the blanks with the particulars of the case in hand, to modify the phrases if need be, and if all else fails to generate phrases from scratch to smooth over the transitions or ﬁll in any remaining conceptual holes. (p. 28)\n\nThe ﬂexibility afforded by novel construction will be sacriﬁced both in routine interaction, where it is not needed, and also where processing pressures are abnormally high, such as when a person is trying to concentrate on something else while speaking, like listening to the radio or negotiating a difﬁcult junction on the road. In those cases, very little nonformulaic language may be produced, and even ﬁlling open class slots may be achieved using default pronouns and ﬁllers like thing and whatchamacallit rather than searching for the appropriate lexical item. In the case of comprehension, focussing on difﬁcult ideas will encourage the hearer or reader to use context and pragmatics to help identify where the novelty (if any) of the message lies, and take shortcuts in decoding the packaging around it, by identifying blocks of material as formulaic. Because such material will not be subjected to full linguistic\n\n18\n\nWhat Formulaic Sequences Are\n\nanalysis, errors such as semantic incongruities, agreement errors, slips of the tongue and typos, will often go unnoticed (see Wray 1992:chap. 1). Conclusion We have seen that the advantage of the analytic system, which creates grammatical strings out of small units by rule, is its ﬂexibility for novel expression and the interpretation of novel and unexpected input. The advantage of the holistic system is that it reduces processing effort. It is more efﬁcient and effective to retrieve a prefabricated string than create a novel one. In adult speakers (though not necessarily in children – see Chapter 7), the relative balance of the two systems in operation appears to be in favour of the holistic, for we prefer a pragmatically plausible interpretation over a literal one, and we seem able to use with ease formulaic sequences whose internal form we have, apparently, never engaged with. The use of the holistic system extends much farther than just that small subset of idioms which could not be handled any other way, and, on a moment-by-moment basis, “the fact that we can analyze does not necessarily mean that we do” (Bolinger 1975:297). As Widdowson (1989) observes: communicative competence is not a matter of knowing rules for the composition of sentences and being able to employ such rules to assemble expressions from scratch as and when occasion requires. It is much more a matter of knowing a stock of partially pre-assembled patterns, formulaic frameworks, and a kit of rules, so to speak, and being able to apply the rules to make whatever adjustments are necessary according to contextual demands. Communicative competence in this view is essentially a matter of adaptation, and rules are not generative but regulative and subservient. This is why the Chomsky concept cannot be incorporated into a scheme for communicative competence. (p. 135)\n\nIn Chapters 4 and 5, we shall use evidence from the language of adult native speakers to assess the plausibility of processing constraints as a full explanation for formulaicity. But ﬁrst we turn to the interrelated procedural issues of identifying formulaic sequences in text and pinning down just what it is that makes them formulaic.\n\n2 Detecting Formulaicity\n\nIntroduction Of two constructions made according to the same pattern, one may be an ad hoc construction of the moment and the other may be a repetition or reuse of one coined long ago. . . . This may be reﬂected in a number of ways other than that of their grammatical structure, which is presumed constant. They may be characterized by different internal entropy proﬁles. They may have different text frequencies. They may have different latency patterns, these being reﬂected in observably different timing patterns and in differences in the introduction of hesitation pauses. (Lounsbury 1963:561)\n\nIn this chapter, we shall consider how various features associated with formulaic sequences might be used to help identify them, and in Chapter 3 we shall review approaches to deﬁnition. It might seem rather odd to do things in this order, since identifying something obviously relies on how you deﬁne it. However, the relationship between deﬁnition and identiﬁcation is circular: in order to establish a deﬁnition, you have to have a reliable set of representative examples, and these must therefore have been identiﬁed ﬁrst.1 In actual fact, in the case of formulaic sequences, identiﬁcation relies less on formal deﬁnitions than the deﬁnitions rely on identiﬁcation, and that tips the balance in favour of dealing with the two in this order. We do, of course, have our working deﬁnition of formulaic sequences (Chapter 1) to guide us. Because it focusses on the manner of storage – an internal and notional characteristic, rather than external and observable – this deﬁnition is deliberately inclusive and should not force the exclusion of any linguistic material for which any kind of argument can be made for inclusion. We shall ﬁnd, in the course of this review, that there are two basic ways in which formulaic sequences can be collected. One is to use an experiment, questionnaire or other empirical method to target the 19\n\n20\n\nWhat Formulaic Sequences Are\n\nproduction of formulaic sequences (as deﬁned by the study in question) as data. The other is to collect general or particular linguistic material and then hunt through it in some more or less principled way, pulling out strings which, according to some criterion or group of criteria, can justiﬁably be held up as formulaic.2 We shall focus mostly on the latter approach here, since it is the isolation of formulaic sequences from standard data sets that is most consistently problematic and subject to variation. We begin with the least scientiﬁc, but most commonly used, method of extraction: intuition. Intuition and ‘Shared Knowledge’ There is a close link between formulaicity and idiomaticity,3 though whether it is a causal link or just one of association is open to debate. Idiomaticity, in turn, can only be deﬁned in terms of the intuition of members of the relevant speech community: an expression is idiomatic if it ‘sounds right’, and is “regularly considered by a language community as being a unit” (Moon 1997:44). Researchers, as members of their speech community, often are the self-appointed arbiters of what is idiomatic or formulaic in their data (e.g., Erman & Warren 2000). Even where some other measure is primarily in use, intuition still tends to guide the design of experiments, the interpretation of results and the choice of examples used in the published reports. However, intuition is generally treated with suspicion in scientiﬁc research, since it is obstinately independent of other kinds of observation. Objections to Intuition Chomsky’s reason for discounting intuition was that the processes of interest to the theoretical linguist are too deeply embedded for introspection: Any interesting generative grammar will be dealing, for the most part, with mental processes that are far beyond the level of actual or even potential consciousness; furthermore, it is quite apparent that a speaker’s reports and viewpoints about his behavior and his competence may be in error. Thus a generative grammar attempts to specify what the speaker actually knows, not what he may report about his knowledge. (Chomsky 1965:8)\n\nDespite this clear assertion, Chomsky’s theories have consistently made intuitive pronouncements about what is and is not grammatical, often to the consternation of those who disagree about particular classes of example, or who do not believe that one person’s grammaticality judgement has anything to say about another person’s grammar.\n\nDetecting Formulaicity\n\n21\n\nIt is now a contention of several theories that the entire notion of a central grammatical system for the individual is erroneous, and that “grammatical knowledge [is] more like a collection of know-hows to deal with various contingencies” (Grace 1995:1). Ironically, this tends to place intuition back at the centre of things, as a legitimate expression of, and potential external means of observing, the piecemeal knowledge accumulated through our many encounters with language in use, in the absence of a coherent or common grammar. It is, then, a matter of theoretical conviction whether intuition is regarded as the ultimate arbiter in reﬂecting the ‘true state of affairs’, or an unwelcome distraction from it. A quite different objection to intuition as a way of judging linguistic structure comes from corpus research. Before the advent of the technology for searching large corpora, it was generally assumed that our intuitions about language were basically accurate, so it seemed to make little difference whether you found an illustrative example in real text or made one up. However, corpus research has revealed that “human intuition about language is highly speciﬁc, and not at all a good guide to what actually happens when the same people actually use the language” (Sinclair 1991:4). Thus, Sinclair argues that intuition is only useful for gaining insights into the nature of intuition itself, not the nature of language (ibid.). Corpora are viewed as “the only reliable authority”, challenging us “to abandon our theories at any moment and posit something new on the basis of the evidence” (Francis 1993:139). One consequence of this position has been a fundamental challenge to assumptions about the validity of standard grammatical models based on intuitive judgements. Speciﬁcally: [n]ative speakers have no reliable intuitions about . . . statistical tendencies [in lexical distribution]. Grammars based on intuitive data will imply more freedom of combination than is in fact possible. . . . Every sense or meaning of a word has its own grammar: each meaning is associated with a distinct formal patterning. Form and meaning are inseparable. (Stubbs 1993:17)\n\nNevertheless, we shall see later in this chapter that the frequency counts which corpus research provides are a mixed blessing in the context of identifying all, and only, the formulaic sequences of a language.\n\nNative-Speaker Intuition in SLA Research While research focussed on the knowledge of native speakers can afford the luxury of agonizing about the status of intuition, second language acquisition research is generally less squeamish, since there is a far more\n\n22\n\nWhat Formulaic Sequences Are\n\npressing problem: non-native speaker intuition, or the lack of it. In a context of trying to ascertain precisely what it is about learner output that makes it ‘incorrect’, heavy reliance is generally placed on the intuitive judgement of native speakers. After all, the learner is, at some level, aspiring to precisely those insights which a native speaker has, irrespective of what grammatical theories or frequency counts may say about them (Cornell 1999:5). The problem with identifying formulaic sequences in the second language acquisition context, then, has less to do with whether native speaker intuition is drawn upon, than how. There is a strong temptation to be unashamedly unscientiﬁc; for example, “we eventually listed a number of expressions that we intuitively regarded as formulas” (Bahns, Burmeister & Vogel 1986:700). Preferable, on balance, is using a panel of independent judges, since there should be a certain resilience in a consensus achieved in this way. All the same, there can be a wide variation in the overall number of sequences spotted by different judges (Jane Willis, personal communication). Foster (2001) has attempted to formalize the procedures and make them as reliable as possible, using seven native speaker judges,“all university teachers of Applied Linguistics with many years experience in English as a foreign language” (p. 83).4 Their instructions were “without consulting anyone else, to mark any language which they felt had not been constructed word by word, but had been produced as a ﬁxed ‘chunk’, or as part of a sentence ‘stem’ to which some morphological adjustments or lexical additions had been required” (p. 83). Foster then applied an exclusion threshold according to which only chunks identiﬁed by at least ﬁve of the seven judges were counted in her analysis. Foster’s report of how the judges handled their task clearly shows that intuition is a slippery customer, eliciting a complex mixture of conﬁdence and doubt in the mind of the conscientious judge: According to the written comments of all seven informants, theirs was not an easy task. Lapses of concentration with reading meant missing even obvious examples of prefabricated language, so progress was slow and exhausting. All seven reported difﬁculty in knowing where exactly to mark boundaries of some lexical chunks and stems as one could overlap or even envelop another. Nevertheless, after a certain amount of self-imposed revision, each reported feeling reasonably conﬁdent with their coding. (p. 84)\n\nInherent Problems with Intuition Foster’s method represents a signiﬁcant milestone in this highly problematic area of identifying formulaic sequences in text, and although there are arguably ‘better’ solutions for each of the difﬁculties inherent\n\nDetecting Formulaicity\n\n23\n\nin relying on intuition, we shall see that each of those solutions also brings its own further problems by very dint of its failure to anchor onto intuition. Speciﬁcally, the weaknesses of even Foster’s relatively robust analytic method are endemic: • It has to be restricted to small data sets. Foster used only one third of\n\n•\n\n•\n\n•\n\n•\n\nher 60,000 word data set, as asking the judges to deal with any more would have been impractical. In contrast, frequency-based computer searches can handle corpora of any size. There is no way to avoid inherent inconsistency within the range of judgements made by an individual, because of factors such as tiredness and unintended alterations in the judgement thresholds across time. Computers do not suffer from such problems. There is a danger of signiﬁcant variation between judges. Foster alleviated this problem by using a high threshold of consensus, and by selecting individuals with similar backgrounds. She also gave them all the same instructions. However, the very need for several judges rather than one is because there are risks of error that computers are not subject to. There is no guarantee that formulaic sequences have ﬁrm borders in the sense that we have come to expect in the context of phrase structure analysis, so, even if all judges were actually operating identical criteria, for any given string there may not be one single answer to ﬁnd. A computer analysis would not operate any kind of variable or discretionary judgement, and would have to be preset to ﬁnd particular things. As we shall see, while this is an advantage if you already know how to identify the thing you are looking for, it is a potential disadvantage if you do not, since a clear-cut analysis will be unable to point up the areas of doubt. As Chomsky observes (see earlier), the application of intuition makes subjective externalized insights valid, at the expense of any knowledge we may have that is not available at the surface level of our awareness. A computer program will identify, without favour, all the patterns that it is set up to ﬁnd. However, as we shall see, that still leaves the onus on the researcher to explain the patterns that appear to run counter to our intuition, and if no explanation can be found, they are likely to be discarded as noise.\n\nShared Knowledge As a Basis for Identiﬁcation ‘Shared knowledge’ is another aspect of intuition that we can brieﬂy explore here. It is important because it pervades the literature and is the very basis of how researchers come to share a sense of what constitutes\n\n24\n\nWhat Formulaic Sequences Are\n\na formulaic sequence. The following example5 is a useful starting point. The author is making a point about the ubiquity and naturalness of formulaic sequences, by deliberately incorporating as many as possible into his text and highlighting their presence: /In-a-nutshell/ it-is-important-to-note-that/ a-large-part-of-communication /makes-use-of-/ ﬁxed-expressions./As-far-as-I-can-see/ for-many-of-these-atleast/ the-whole-is-more-than-the-sum-of-its-parts./ The meaning of an idiomatic expression cannot be deduced by examining the meanings of the constituent lexemes. /On-the-other-hand/ there-are-lots-of phrases that/ although they can be analyzed using normal syntactic principles/ nonetheless/ are not created or interpreted that way./ Rather, /they are picked-off-the-shelf/ ready-made/ because they-say-what-you-want-to-say./ /I-don’t-think-I’m-going-out-on-a-limbhere./ However /it-is-appropriate-to-say-at-this-point/ that-much-work-remainsto-be-done./ (Ellis 1996:118–119)\n\nThis represents a kind of insider joke, which is based upon the expectation of shared knowledge between writer and reader – the use of formulaic sequences to talk about formulaic sequences. In the wider world, the same expectation of shared knowledge makes possible the shortening of well-known idioms, as in a stitch in time and sleeping like the proverbial, and can also be a source of humour, as with the interpretation of the clause I hold your hand in mine in Tom Lehrer’s song: I hold your hand in mine, dear, I press it to my lips, I take a healthy bite from your dainty ﬁngertips. My joy would be complete, dear, if you were only near, But still I keep your hand as a precious souvenir.6\n\nSuch humour juxtaposes ‘shared knowledge’ with semantic transparency to provide two readings of the same string. Often, however, transparency and shared knowledge are not closely allied. Clearly, any string that is formulaic for, say, the speaker, but not for the hearers, will simply not be understood unless it is transparent (Peters 1983:81), while sequences which a whole community stores holistically can be much more irregular and opaque, since all the hearers possess a form-meaning mapping already. “In fact, the very opacity of certain expressions can be used as a sort of verbal fence to include certain hearers who have the knowledge to decode the expressions and to exclude those others who lack that knowledge” (ibid.). As a result, shared knowledge can be the badge of belonging to a speech community, and not possessing that knowledge can be a mark of social exclusion (see Chapters 4 and 5). Returning to the question of how formulaic sequences can be identiﬁed in text, shared knowledge means that, for members of the same speech community, it\n\nDetecting Formulaicity\n\n25\n\nmight be possible to use, as a measure of formulaicity, the extent to which a word string, started by one person, can be reliably completed by others, without any of the deviation in form that the application of creative processes would predict (Van Lancker 1987:56). However, such a measure would only be suitable for the subset of formulaic sequences which are not dependent on current interactional demands (see Chapter 5). Furthermore, it would run into problems where there is natural variation in the format of formulaically delivered messages (Chapter 4). Frequency In corpus linguistics, computer searches are conducted to establish the patterns of distribution of words within text. This is done on the basis of frequency counts, which reveal which other words a given target word most often occurs with. These patterns of collocation turn out to be far from random. For instance, Hunston and Francis (2000) show how the word ‘matter’ characteristically occurs in the pattern ‘a matter of V-ing’ (e.g., a matter of developing skills; a matter of learning . . . ; a matter of becoming able to . . .) (p. 2). It is structures like ‘a matter of V-ing’ that, in the wider literature, are characteristically proposed to be formulaic ‘frames’ (see Chapter 3). Furthermore, if you take a word string which is indisputably formulaic, such as happy birthday or high time, it can be searched for through a large corpus and shown to have a frequency consistent with the intuition that it is common as well as idiomatic (we shall unpack this assertion later). Both these associations invite us to see frequency as a salient, perhaps even a determining, factor in the identiﬁcation of formulaic sequences. It seems, on the surface, entirely reasonable to use computer searches to identify common strings of words, and to establish a certain frequency threshold as the criterion for calling a string ‘formulaic’. The reasoning, of course, is that the more often a string is needed, the more likely it is to be stored in prefabricated form to save processing effort, and once it is so stored, the more likely it is to be the preferred choice when that message needs to be expressed. Since the preferential selection of the prefabricated form will actually suppress the frequency with which any other possible expression of the same message is selected, the contrast in frequency should be clear. The process of identifying formulaic sequences should, then, be unproblematic, because “their normality is a function of their occurrence as holistic units. So it becomes a relatively straightforward matter to list them as an inventory” (Widdowson 1990:92). The advantage of relying on computer searches for the identiﬁcation of formulaic sequences would seem enormous:\n\n26\n\nWhat Formulaic Sequences Are\n\nThe retrieval systems, unlike human beings, miss nothing if properly instructed – no usage can be overlooked because it is too ordinary or too familiar. The statistical evidence is helpful, too, because it distinguishes the commoner patterns of usage, which occur very frequently indeed, from the less common usage, which occurs very infrequently. (Sinclair & Renouf 1988:151)\n\nSinclair and Renouf go on to observe that “no description of usage should be innocent of frequency information” (p. 152). However, they distance themselves from the idea that frequency is the only factor relevant to capturing patterns of usage (ibid.), and their caution is well placed. There are several reasons for taking care when applying frequency information to the identiﬁcation of formulaic sequences. Procedures Using computer searches to identify formulaic sequences might seem to be a simple matter. The researcher must decide what will count and what will not, and set up the search accordingly. For instance, it is possible to search for co-occurrences of two or more words, either adjacent or up to a speciﬁed distance apart – the optimal distance for two words seems to be up to four intervening words (Sinclair 1998:15). When searching for multiword strings, decisions have to be made about how big the strings should be, and how frequent an association has to be in order to count.7 Such frequency thresholds are inevitably arbitrary, and, in practical terms, are chosen on the basis of the size of the corpus, the desired quantity of data and the size of the chunks being sought, since “the length of the recurrent word combinations is inversely related to their frequency” (DeCock, Granger, Leech & McEnery 1998:71). In their study, for instance, DeCock et al. searched for two-word chunks with a frequency greater than nine occurrences, three-word chunks occurring more than four times, four-word chunks more than three times and ﬁveword chunks more than twice, using two independent corpora of around 63,000 and 80,500 words, respectively. However, frequency counts are still somewhat overpowerful, and while some effort can be made in honing them to provide all and only the items of interest (Clear 1993:275), additional decisions have to be made post hoc, about which of the identiﬁed associations to discard. For example, where the search tools ignore major constituent and sentence boundaries, changes of speaker, false starts, and so on, it may be decided to apply structural criteria (Butler 1997:62) and eliminate those which are “phraseologically uninteresting” (Altenberg 1990:133). In addition, spoken corpora tend to contain transcriptions of hesitation phenomena such as erm and er, and the researcher must decide whether these are to\n\nDetecting Formulaicity\n\n27\n\ncount as words (e.g., DeCock et al. 1998:73). Finally, it is often clear from looking at a particular example that there is nothing intrinsically interesting about it, as with gol, gol, gol, gol, gol, from Butler’s (1997) Spanish corpus, presumably shouted by a sports commentator when a goal was scored in a football match (p. 69). Thus, while it might seem sensible simply to count everything, it is often intuitively clear that some patterns are more important and relevant than others. However, ad hoc intuitive decisions (such as those used by Nattinger & DeCarrico 1992:20, for instance) have the potential to bring about the same problems as we identiﬁed in the last section. Foremost of these, of course, is the undermining of the very value of a computer search, namely, the avoidance of subjective judgement. We neither fully understand the nature and causes of formulaicity, nor have any entirely satisfactory alternative means of identifying examples. It is, then, premature to be deciding which patterns of words are and are not relevant. Further problems regarding the procedures of frequency counts can be identiﬁed. Firstly, corpora are probably unable to capture the true distribution of certain kinds of formulaic sequences. Indisputably, what they offer is considerably better than anything we had before. However, the selectiveness of small corpora may exclude certain types of common, but less easily gathered or analyzed, material (see, for instance, Butler’s 1997:64 criticism of his own corpus). ‘Fifteen minutes of fame’ expressions,8 which become very popular in a limited context for a short time, perhaps as a result of a news item or a TV series, are also a problem. Corpora will, characteristically, either entirely miss such examples, or overrepresent them, according to the input material. Meanwhile, the very breadth of a large corpus, drawing from a wide range of different types of source text (e.g., Moon 1998a:48), means that it is not likely to be representative of the rather narrower linguistic experience of any one individual. It is probably fair to suggest that the research tends to hope that the patterns in the corpus actually do reﬂect those of individual speakers, since it might be difﬁcult to justify the study of language as an external phenomenon if this did not offer useful insights into language as an internal, personal phenomenon. But presumably only relatively few people regularly read both tabloid and broadsheet newspapers and listen to both pop quizzes and heavy current affairs programmes on the radio – the sorts of data that are thrown together in a corpus. Finally, as Butler (1997:69) points out, corpora which combine spoken and written data are almost certainly fudging important distinctions which are revealed by their separate analysis. The second problem is that the tools used in corpus analysis are no more able to help decide where the borders between formulaic\n\n28\n\nWhat Formulaic Sequences Are\n\nsequences fall than native speaker judges are. Altenberg (1990) shows how even a simple word string like thank you creates difﬁculties, since, besides occurring entirely alone, it is also found in longer strings such as thank you very much, thank you very much indeed and thank you bye (p. 136). Are these different strings? Is the basic string thank you and the rest unimportant? Or is one string embedded in another? These questions cannot be answered without the application of common sense and a clear idea of the direction of one’s research: the latter automatically creates bias in the interpretation of the raw data. Measurements Further difﬁculties in relating frequency counts to the reliable identiﬁcation of formulaic sequences arise when we consider just what we are trying to measure, and how. One of the most striking general observations is that there are vast discrepancies across studies, regarding the proportion of language that is viewed as formulaic. To take just a few examples, Altenberg (1990) states that “roughly 70% of the running words in the London-Lund Corpus9 form part of recurrent word combinations of some kind” (p. 134), and by 1998 he has increased this estimate to 80% (p. 102). Moon (1998a), on the other hand, estimates that only between 4% and 5% of the Oxford Hector Pilot Corpus of over 18 million words were parts of the FEIs (ﬁxed expressions including idioms) which she was studying. Butler (1997) identiﬁes repeated phrases as 12.5% of the spoken part of his corpus of Spanish (total 10,000 words), 9% and 8.2% of two transcribed interviews (each 14,000 words), and 5% of the written corpus (57,500 words). Why are there such enormous differences? As we might expect, the devil is in the detail. Altenberg applied a low threshold, counting “any continuous string of words occurring more than once in identical form” (1998:101), though this, of course, will only pick up discontinuous sequences insofar as they possess two consecutive words.10 Butler’s threshold was higher: strings had to be at least three words long, and occur at least 10 times (1997:66). Moon’s criterion was different again. She did not do an open-ended search at all, but rather checked the corpus for occurrences of a preestablished list of 6,776 strings recognized as expressions in the Collins Cobuild English Language Dictionary (Moon 1998a:45). Clearly, one lesson that this teaches us is that different studies are not easy to compare. But it also highlights the fundamental lack of agreement about precisely what deserves most attention and how to identify it. Various suggestions have been made about how to establish ratio measures which will capture the essence of repetitive language. Bateson\n\nDetecting Formulaicity\n\n29\n\n(1975) proposes that a ratio of morphemes to praxons (formulaic sequences)11 would differentiate a highly fused text (i.e., one with many formulaic sequences in it) from a less highly fused one (p. 63). This calculation works on the basis that the more novel the language in a text, the more different morphemes it will contain.While that assumption may be true in a very large data set, where the same formulaic sequences appear many times, in a small text there is likely to be too much message variety for the formulaicity to impact in this way. Church and Hanks’s (1989) association ratio measures degrees of word association strength in corpora, by calculating the probability that two words will occur together (i.e., within a speciﬁed ‘window’ of continuous text), given their probability of occurring in the corpus overall (p. 77). Perkins (1994) has developed a method of “quantifying the extent to which a sample of language is repetitive or stereotyped by focusing on the reciprocal relationship between the frequency of occurrence and the degree of productivity of its component elements” (pp. 333–334). Although intended for small samples of disordered speech, the calculation seems suitable for large quantities of computer-analyzed data. Ratio measures, including the rather problematic type-token ratio,12 take account of the need to juxtapose the frequency with which a particular item occurs within a given pattern and its overall frequency in the corpus. This procedure reveals the ﬂexibility of that item relative to its context. Some items have no ﬂexibility at all, such as kith, which, according to Moon (1998a:78–79), occurs only in kith and kin, and dint, which is found only in by dint of (ibid.), while others, including the preposition class, are common both within and outside recognized expressions. However, even this measure can be misleading. The primary reason for any content word to be frequent is that its meaning is fragmented. Willis (1990) nicely illustrates this fact with reference to the word way, which he argues could usefully be a key vocabulary item in ESL teaching. This is not because way in the sense of ‘minor road’, or even ‘direction’, is particularly frequent, but because way ﬁgures in numerous expressions (e.g., in a way, by the way, by way of, ways and means) which, between them, propel the word virtually to the top of the frequency counts in a large corpus. In a standard dictionary, dozens of entries may be needed to capture all the different aspects of a word’s meaning, and it is often difﬁcult to judge just where to draw the line between one word having multiple, related meanings and there actually being two (or more) words which happen to be spelled and pronounced the same way. Even the very notion of a separate meaning for a word becomes problematic. As Sinclair and Renouf (1988) observe, “the more frequent a word is, the less independent meaning it has, because it is likely to be\n\n30\n\nWhat Formulaic Sequences Are\n\nacting in conjunction with other words, making useful structures or contributing to familiar idiomatic phrases” (p. 153; see also Sinclair 1991:113). In this, they consider that English may be somewhat unusual: “English makes excessive use, e.g., through phrasal verbs, of its most frequent words” (p. 155). It is, of course, self-evident that language makes most use of its most frequent words, and the key word in their statement is “excessive”. After all this, it could be argued that all such frequency-based measures are missing the mark. Undoubtedly, many word strings are indisputably formulaic, but not frequent (e.g., The King is dead, long live the King). Foster (2001) points out that “Even a corpus as large as The Bank of English at the University of Birmingham, now nearly three hundred million words, fails to show even a single example of many phrases that would be considered a normal part of any native speaker’s repertoire” (p. 81). Amongst the idioms that Moon (1998a) failed to ﬁnd in her 18million-word corpus were bag and baggage, by hook or by crook, kick the bucket, hang ﬁre and out of practice. Moon points out that there is no way of differentiating between a current expression which simply fails to occur in the corpus, and one that fails to occur because it is not in current usage. The problem is even worse when it comes to collocation: “even if words are individually quite frequent, collocations of these words may drop to zero in corpora as large as 100-million words” (Stubbs 2000). This observation suggests that raw frequency is not an adequate measure of formulaicity. To capture the extent to which a word string is the preferred way of expressing a given idea (for this is at the heart of how prefabrication is claimed to affect the selection of a message form), we need to know not only how often that form can be found in the sample, but also how often it could have occurred. In other words, we need a way to calculate the occurrences of a particular message form as a proportion of the total number of attempts to express that message.13 This can be clearly illustrated with the examples happy birthday and many happy returns. To ﬁnd out that happy birthday occurs n times in a corpus, while many happy returns occurs only n - x times, certainly tells us something about the relative frequency of those two expressions, but it is not until we know that, between them, these two expressions account for, say, 98% of the occasions when birthday wishes were conveyed, that we really understand the power of their formulaicity. In the case of Moon’s analysis, then, what we cannot tell is whether out of practice failed to occur in the corpus because in every case of that idea being expressed, other ways of saying it were preferred, or because the idea never got expressed (and, if it had, out of practice is the string that would\n\nDetecting Formulaicity\n\n31\n\nhave been used). Some messages are much more common than others, and so it is a ratio of message to message-expression that will best help us to understand how some expressions of a given message are favoured over others.14 There has not, to my knowledge, been any attempt to analyze and tag a corpus for utterance function in the way that we should require for the calculation of such ratios. The Relationship Between Frequency and Formulaicity We have already seen that, for various practical reasons, the frequencybased analyses conducted in corpus linguistics do not fully meet our needs when it comes to identifying formulaic sequences. There are further grounds for caution too. Firstly, a frequency count will not be able to differentiate between the occurrences of a conﬁguration when it is formulaic and the same conﬁguration as a novel juxtaposition of smaller units. For instance, keep your hair on is not formulaic when it means ‘don’t remove your wig’, but it is formulaic in its meaning ‘calm down’. Spotting the word string is the least of the problems here. Contextual and pragmatic cues15 would be used to disambiguate a sentence like this, and frequency counts are not sensitive to such cues. Secondly, just as there is evidence that a string generally agreed to be formulaic may or may not have a high frequency in even the largest of corpora, so it is also not possible to assert that all frequent strings are prefabricated. It can, it is true, be argued on theoretical grounds that, if a string is required regularly, it is likely to be stored whole for easier access (e.g., Becker 1975; Langacker 1986:19–20), but it does not have to be. In order to distinguish between frequent strings that were and were not prefabricated, we should therefore need an independent set of supplementary criteria. Possible candidates are reviewed in the remainder of this chapter. Structure Is it possible to identify formulaic sequences on the basis of their form? Several possible ways of doing so have been proposed. The most basic, and least useful in the context of researching the nature of formulaicity, is to deﬁne formulaic sequences as the set of multiword strings listed in a particular dictionary (e.g., Kerbel & Grunwell 1997; Moon 1998a, 1998b). More productive are criteria deriving from empirical investigation. Butler (1997), on the basis of his frequency-based exploration of Spanish text, notes that “the majority of the longer repeated sequences . . . begin with conjunctions, articles, pronouns, prepositions or discourse\n\n32\n\nWhat Formulaic Sequences Are\n\nmarkers” (p. 76). This ﬁnding requires closer consideration. An intuitive examination of a piece of text may convince us that a sequence whose ﬁrst ﬁxed item is, say, a preposition, actually begins with a slot for an open class item, such as a noun or verb. For instance, the frame NPi be-TENSE past PROi-POSSESSIVE sell-by date (e.g., This cheese is past its sell-by date; Dad is past his sell-by date) could be represented as past PROiPOSSESSIVE sell-by date, but since the subject NP is compulsorily coindexed with the pronoun, it seems intrinsic to the whole. Because the content of an open class slot will vary, a corpus search alone will fail to recognize it as part of a recurrent sequence. Butler’s observation only informs us that the ﬁrst-occurring invariable word in a repeated sequence tends to be a function word or discourse marker, not that this word is necessarily the ﬁrst word of the entire sequence.16 A further possible difﬁculty with form-based criteria for identiﬁcation comes from the case of formulaic paradigms with no common lexical material. One example is the limerick, and another is the set of Is the Pope a Catholic? responses (Bouton 1988). Members of this set occur when a question is asked to which the answer is a deﬁnite ‘yes’ (e.g., Do you like beer? – Is the Pope a Catholic?), the response being another question to which the answer is obviously (or obviously intended to be) ‘yes’. The speaker is free to offer any such response, with credit given for wit (e.g., Do ﬂeas like cats? Does a one-legged duck swim round in circles?). With the absence of common lexical or morphological forms across the set members, the formulaicity resides in the context-structure interface rather than the form per se. This challenges the idea of a formbased criterion, for what, precisely, is being stored, when all the words can be novel? However, one reasonable resolution is to argue that ‘empty-frame’ paradigms like this are not formulaic sequences at all. Normal prefabricated frames, with some ﬁxed items and some gaps for open class items, lead to a genuine mix of routine and novelty, since the purpose of the novel items in the frame is to provide speciﬁc referentiality which tunes the string to the context. Thus, products of the frame are expressly not semantically interchangeable, so if it’s good enough for my sister, it’s good enough for him does not mean the same as if they’re good enough for a wedding reception, they’re good enough for her party, and so on. In contrast, the Is the Pope a Catholic? frame is not varied according to the needs of speciﬁc reference, but for other reasons. In fact, it is probably fair to say that any expectation of spontaneous variation in this structure is more a case of wishful thinking than reality. Much more likely is that any given individual has heard, or invented, one or two alternatives to Is the Pope a Catholic? which he or she can retrieve easily because they,\n\nDetecting Formulaicity\n\n33\n\nlike the original, are stored whole. In other words, the individual possesses a small set of synonymous phrases, and selects the one which seems most desirable for the occasion (the funniest, the least offensive, or whatever). If this is the case, then the lexicon is not storing the underlying structure, but the examples themselves. Just as this predicts, and in contrast to frames like If PROi BE good enough for NPj PROi BE good enough for NPk, a speaker is not in a position to produce more and more novel examples of the Pope paradigm on request, but rather is restricted only to those which he or she already knows. The construction of a new one is a difﬁcult and deliberate process. As such, the ‘structural’ characteristics have nothing to do with the lexicon, beyond their having been abstracted analytically by juxtaposing individual examples to see what made them similar. As for comprehension, the fact that, when we hear a new example of the Is the Pope a Catholic? paradigm, we recognize and appreciate it, owes more to precedent and pragmatics than the storage of an empty frame. Being novel, it will have to be analyzed, as any novel string is, and this will render two important pieces of information: its content is superﬁcially irrelevant to the context and it is a yesno question with an obvious ‘yes’ answer. Pragmatics will do the rest. If we are familiar with the genre,17 the string will be identiﬁed as ‘another of those Is the Pope a Catholic? expressions’ and, if possible, stored whole for later use, since new examples are highly prized. Compositionality One way to identify formulaic sequences in text could be to examine their internal composition (something which will be explored more directly in Chapter 3). At the heart of this approach is the observation that a sequence of words, once it is formulaic, is subject to detachment from the effects of the live grammar and lexicon. The string is no longer obliged to be grammatically regular or semantically logical. Sequences become frozen, or fossilized, and as a result often retain words or grammatical forms which are no longer current in the language. For example, if I were you contains the subjunctive form of be, and by dint of features an obsolete lexical item. The meaning may also become detached from the literal. Thus, the two formulae I couldn’t care less and I could care less mean the same thing, even though they appear to be opposites (Tannen & Öztek 1981:37). In extreme cases, the only way to guarantee understanding a noncompositional sequence is to have previously learned it whole. For those who view formulaicity in language as a peripheral feature (e.g., Pinker 1994:149), the idea that formulaic sequences might be\n\n34\n\nWhat Formulaic Sequences Are\n\nidentiﬁed as nonliteral and noncanonical is appealing. At this end of the variability spectrum, there is little to choose between a morphological and an etymological analysis, and it is useful to use the criteria of semantic transparency and grammatical regularity as a measuring gauge. However, for our present purposes, an identiﬁcation procedure of this kind will be too conservative, because it excludes the formulaic sequences that are entirely regular in form and transparent in meaning (Jespersen 1924/1976:84). An alternative use of the transparency and regularity gauge might be in subcategorizing types of formulaic sequence. In other words, the feature ± idiom could be a deﬁning variable in a typology of formulaic sequences along a continuum from fully bound to fully free. Howarth (1998a, 1998b), who engages in some detail with the best criteria for such a classiﬁcation, argues convincingly against this, however, showing that is it more useful to separate out this variable from the main structure of the deﬁnition. He argues that fossilization, which creates the idiom, is determined not by predictable formal and semantic pressures, but by a range of independent criteria. For further discussion of the idiom as a type of formulaic sequence, see Chapter 3. Fixedness We shall see in Chapter 3 that there has been much discussion about the ﬁxedness of formulaic sequences. One variable is the scope for the insertion of elements into a sequence. Pawley (1986) compares ﬁrst (and only) attempt with ﬁrst (*and only) aid (pp. 107–108), and shows how such insertions undermine the idiomatic nature of a formulaic expression. The phrase lead up the garden path is a ﬁgurative formulaic sequence, but lead, happily singing, up the winding garden path, even if ﬁguratively interpreted, does not retain the particular meaning of the formula (ibid.: 108). For certain kinds of formulaic sequences this, and other possible tests of ﬁxedness, could have a role, but it would be a limited one. We are so accustomed to playing with language, both formulaic and nonformulaic, that the dividing line between what does, and does not, offend the integrity of a sequence may not always be clear, particularly as what is a novel and jokey adaptation one day can be formulaic the next, if it is picked up and repeated a few times. A further difﬁculty is that only a small subset of formulaic sequences are entirely ﬁxed: those which are not, legitimately permit insertions. Indeed, the ﬁxedness criterion does not sit well with the existence of semi-ﬁxed sequences, which contain slots for a variety of compulsory and optional material to be inserted.\n\nDetecting Formulaicity\n\n35\n\nPhonological Form The identiﬁcation of formulaic sequences on the basis of “phonological coherence” (Hickey 1993:32) is, of course, restricted to the spoken language, though written texts could reﬂect those characteristics to some extent, through punctuation and layout. Features such as overall ﬂuency, intonation pattern and changes in speed of articulation are all potential pointers to a stretch of prefabricated material (Pawley & Syder 2000:173). The scope of phonological information to aid the identiﬁcation of formulaic sequences is well illustrated in experiments by Van Lancker and her team. In a series of experiments, Van Lancker and Canter (1981) tested the hypothesis that hearers should be able to differentiate formulaic and nonformulaic sequences via subtle phonological cues deriving from the difference between holistic and analytic processing. Recordings were made of texts containing idiom and literal interpretations of strings such as skating on thin ice (in this case, one text was about a boy skating on a lake, the other about a man taking a risk). The sentences containing the relevant strings were removed from their context and played to subjects, who had to judge whether the intended meaning was ﬁgurative or literal, that is, whether the expression was a formulaic idiom or a novel string. They were unable to make such a differentiation above chance level, but in a second test, in which the readers had been asked to emphasize which meaning was intended, the average score was over 85% correct. In a follow-up study, Van Lancker et al. (1981) analyzed the phonological properties of the recordings, to identify the substance of the differences perceptible to the hearers. They found that the literal readings were of greater duration, because they contained more pauses and because the key lexical items were spoken more slowly. The literal readings also contained more pitch changes and more of the clusters of phonological information (pauses, pitch drops, etc.) associated with the marking of open junctures, “the phonetic phenomenon which signals linguistic (lexical or syntactic) boundaries” (Van Lancker et al. 1981:331). They were also more articulatorily precise (pp. 333–334). It follows, then, that particular phonological features might be used to help identify formulaic sequences. Fluency According to Pawley (1986), “pauses within lexicalized phrases are less acceptable than pauses within free expressions, and after a hesitation the speaker is more likely to restart from the beginning of the expression” (p. 107). It certainly seems a reasonable hypothesis that, if formulaic\n\n36\n\nWhat Formulaic Sequences Are\n\nsequences are retrieved whole from memory (or at least with less recourse to on-line rule application and lexical retrieval than novel utterances), they should be produced more ﬂuently than novel ones. For any given speaker, ﬂuency is relative, of course, but it might be measured by comparing the number of words per unit time in different types of language production, or by counting t"
    }
}