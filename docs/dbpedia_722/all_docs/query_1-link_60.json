{
    "id": "dbpedia_722_1",
    "rank": 60,
    "data": {
        "url": "https://www.nvidia.com/en-us/glossary/recommendation-system/",
        "read_more_link": "",
        "language": "en",
        "title": "What is a Recommendation System?",
        "top_image": "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/Data-Science-Glossary-Twitter-image-web.png",
        "meta_img": "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/Data-Science-Glossary-Twitter-image-web.png",
        "images": [
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-1.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-2.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-3.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-4.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-5.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-6.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-7.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-8.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-9.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-10.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-11.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-12.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-13.jpg",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-14.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-15.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-16.png",
            "https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/recommendation-system/img-17.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Definition of Recommendation System",
            "NVIDIA",
            "Data Science Glossary",
            "Dictionary"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "A recommendation system is an artificial intelligence or AI algorithm, usually associated with machine learning.",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "NVIDIA Data Science Glossary",
        "canonical_link": "https://www.nvidia.com/en-us/glossary/recommendation-system/",
        "text": "A recommendation system is an artificial intelligence or AI algorithm, usually associated with machine learning, that uses Big Data to suggest or recommend additional products to consumers. These can be based on various criteria, including past purchases, search history, demographic information, and other factors. Recommender systems are highly useful as they help users discover products and services they might otherwise have not found on their own.\n\nRecommender systems are trained to understand the preferences, previous decisions, and characteristics of people and products using data gathered about their interactions. These include impressions, clicks, likes, and purchases. Because of their capability to predict consumer interests and desires on a highly personalized level, recommender systems are a favorite with content and product providers. They can drive consumers to just about any product or service that interests them, from books to videos to health classes to clothing.\n\nTypes of Recommendation Systems\n\nWhile there are a vast number of recommender algorithms and techniques, most fall into these broad categories: collaborative filtering, content filtering and context filtering.\n\nCollaborative filtering algorithms recommend items (this is the filtering part) based on preference information from many users (this is the collaborative part). This approach uses similarity of user preference behavior, given previous interactions between users and items, recommender algorithms learn to predict future interaction. These recommender systems build a model from a user’s past behavior, such as items purchased previously or ratings given to those items and similar decisions by other users. The idea is that if some people have made similar decisions and purchases in the past, like a movie choice, then there is a high probability they will agree on additional future selections. For example, if a collaborative filtering recommender knows you and another user share similar tastes in movies, it might recommend a movie to you that it knows this other user already likes.\n\nContent filtering, by contrast, uses the attributes or features of an item (this is the content part) to recommend other items similar to the user’s preferences. This approach is based on similarity of item and user features, given information about a user and items they have interacted with (e.g. a user’s age, the category of a restaurant’s cuisine, the average review for a movie), model the likelihood of a new interaction. For example, if a content filtering recommender sees you liked the movies You’ve Got Mail and Sleepless in Seattle, it might recommend another movie to you with the same genres and/or cast such as Joe Versus the Volcano.\n\nHybrid recommender systems combine the advantages of the types above to create a more comprehensive recommending system.\n\nContext filtering includes users’ contextual information in the recommendation process. Netflix spoke at NVIDIA GTC about making better recommendations by framing a recommendation as a contextual sequence prediction. This approach uses a sequence of contextual user actions, plus the current context, to predict the probability of the next action. In the Netflix example, given one sequence for each user—the country, device, date, and time when they watched a movie—they trained a model to predict what to watch next.\n\nHow a recommender model makes recommendations will depend on the type of data you have. If you only have data about which interactions have occurred in the past, you’ll probably be interested in collaborative filtering. If you have data describing the user and items they have interacted with (e.g. a user’s age, the category of a restaurant’s cuisine, the average review for a movie), you can model the likelihood of a new interaction given these properties at the current moment by adding content and context filtering.\n\nMatrix Factorization for Recommendation\n\nMatrix factorization (MF) techniques are the core of many popular algorithms, including word embedding and topic modeling, and have become a dominant methodology within collaborative-filtering-based recommendation. MF can be used to calculate the similarity in user’s ratings or interactions to provide recommendations. In the simple user item matrix below, Ted and Carol like movies B and C. Bob likes movie B. To recommend a movie to Bob, matrix factorization calculates that users who liked B also liked C, so C is a possible recommendation for Bob.\n\nMatrix factorization using the alternating least squares (ALS) algorithm approximates the sparse user item rating matrix u-by-i as the product of two dense matrices, user and item factor matrices of size u × f and f × i (where u is the number of users, i the number of items and f the number of latent features) . The factor matrices represent latent or hidden features which the algorithm tries to discover. One matrix tries to describe the latent or hidden features of each user, and one tries to describe latent properties of each movie. For each user and for each item, the ALS algorithm iteratively learns (f) numeric “factors” that represent the user or item. In each iteration, the algorithm alternatively fixes one factor matrix and optimizes for the other, and this process continues until it converges.\n\nCuMF is an NVIDIA® CUDA®-based matrix factorization library that optimizes the alternate least square (ALS) method to solve very large-scale MF. CuMF uses a set of techniques to maximize the performance on single and multiple GPUs. These techniques include smart access of sparse data leveraging GPU memory hierarchy, using data parallelism in conjunction with model parallelism, to minimize the communication overhead among GPUs, and a novel topology-aware parallel reduction scheme.\n\nDeep Neural Network Models for Recommendation\n\nThere are different variations of artificial neural networks (ANNs), such as the following:\n\nANNs where information is only fed forward from one layer to the next are called feedforward neural networks. Multilayer perceptrons (MLPs) are a type of feedforward ANN consisting of at least three layers of nodes: an input layer, a hidden layer and an output layer. MLPs are flexible networks that can be applied to a variety of scenarios.\n\nConvolutional Neural Networks are the image crunchers to identify objects.\n\nRecurrent neural networks are the mathematical engines to parse language patterns and sequenced data.\n\nDeep learning (DL) recommender models build upon existing techniques such as factorization to model the interactions between variables and embeddings to handle categorical variables. An embedding is a learned vector of numbers representing entity features so that similar entities (users or items) have similar distances in the vector space. For example, a deep learning approach to collaborative filtering learns the user and item embeddings (latent feature vectors) based on user and item interactions with a neural network.\n\nDL techniques also tap into the vast and rapidly growing novel network architectures and optimization algorithms to train on large amounts of data, use the power of deep learning for feature extraction, and build more expressive models.\n\nCurrent DL–based models for recommender systems: DLRM, Wide and Deep (W&D), Neural Collaborative Filtering (NCF), Variational AutoEncoder (VAE) and BERT (for NLP) form part of the NVIDIA GPU-accelerated DL model portfolio that covers a wide range of network architectures and applications in many different domains beyond recommender systems, including image, text and speech analysis. These models are designed and optimized for training with TensorFlow and PyTorch.\n\nNeural Collaborative Filtering\n\nThe Neural Collaborative Filtering (NCF) model is a neural network that provides collaborative filtering based on user and item interactions. The model treats matrix factorization from a non-linearity perspective. NCF TensorFlow takes in a sequence of (user ID, item ID) pairs as inputs, then feeds them separately into a matrix factorization step (where the embeddings are multiplied) and into a multilayer perceptron (MLP) network.\n\nThe outputs of the matrix factorization and the MLP network are then combined and fed into a single dense layer that predicts whether the input user is likely to interact with the input item.\n\nVariational Autoencoder for Collaborative Filtering\n\nAn autoencoder neural network reconstructs the input layer at the output layer by using the representation obtained in the hidden layer. An autoencoder for collaborative filtering learns a non-linear representation of a user-item matrix and reconstructs it by determining missing values.\n\nThe NVIDIA GPU-accelerated Variational Autoencoder for Collaborative Filtering (VAE-CF) is an optimized implementation of the architecture first described in Variational Autoencoders for Collaborative Filtering. VAE-CF is a neural network that provides collaborative filtering based on user and item interactions. The training data for this model consists of pairs of user-item IDs for each interaction between a user and an item.\n\nThe model consists of two parts: the encoder and the decoder. The encoder is a feedforward, fully connected neural network that transforms the input vector, containing the interactions for a specific user, into an n-dimensional variational distribution. This variational distribution is used to obtain a latent feature representation of a user (or embedding). This latent representation is then fed into the decoder, which is also a feedforward network with a similar structure to the encoder. The result is a vector of item interaction probabilities for a particular user.\n\nContextual Sequence Learning\n\nA Recurrent neural network (RNN) is a class of neural network that has memory or feedback loops that allow it to better recognize patterns in data. RNNs solve difficult tasks that deal with context and sequences, such as natural language processing, and are also used for contextual sequence recommendations. What distinguishes sequence learning from other tasks is the need to use models with an active data memory, such as LSTMs (Long Short-Term Memory) or GRU (Gated Recurrent Units) to learn temporal dependence in input data. This memory of past input is crucial for successful sequence learning. Transformer deep learning models, such as BERT (Bidirectional Encoder Representations from Transformers), are an alternative to RNNs that apply an attention technique—parsing a sentence by focusing attention on the most relevant words that come before and after it. Transformer-based deep learning models don’t require sequential data to be processed in order, allowing for much more parallelization and reduced training time on GPUs than RNNs.\n\nIn an NLP application, input text is converted into word vectors using techniques, such as word embedding. With word embedding, each word in the sentence is translated into a set of numbers before being fed into RNN variants, Transformer, or BERT to understand context. These numbers change over time while the neural net trains itself, encoding unique properties such as the semantics and contextual information for each word, so that similar words are close to each other in this number space, and dissimilar words are far apart. These DL models provide an appropriate output for a specific language task like next-word prediction and text summarization, which are used to produce an output sequence.\n\nSession context-based recommendations apply the advances in sequence modeling from deep learning and NLP to recommendations. RNN models trained on the sequence of user events in a session (e.g. products viewed, data and time of interactions) learn to predict the next item(s) in a session. User item interactions in a session are embedded similarly to words in a sentence. For example, movies viewed are translated into a set of numbers before being fed into RNN variants such as LSTM, GRU, or Transformer to understand context.\n\nWide & Deep\n\nWide & Deep refers to a class of networks that use the output of two parts working in parallel—wide model and deep model—whose outputs are summed to create an interaction probability. The wide model is a generalized linear model of features together with their transforms. The deep model is a Dense Neural Network (DNN), a series of five hidden MLP layers of 1024 neurons, each beginning with a dense embedding of features. Categorical variables are embedded into continuous vector spaces before being fed to the DNN via learned or user-determined embeddings.\n\nWhat makes this model so successful for recommendation tasks is that it provides two avenues of learning patterns in the data, “deep” and “shallow”. The complex, nonlinear DNN is capable of learning rich representations of relationships in the data and generalizing to similar items via embeddings, but needs to see many examples of these relationships in order to do so well. The linear piece, on the other hand, is capable of “memorizing” simple relationships that may only occur a handful of times in the training set.\n\nIn combination, these two representation channels often end up providing more modelling power than either on its own. NVIDIA has worked with many industry partners who reported improvements in offline and online metrics by using Wide & Deep as a replacement for more traditional machine learning models.\n\nDLRM\n\nDLRM is a DL-based model for recommendations introduced by Facebook research. It’s designed to make use of both categorical and numerical inputs that are usually present in recommender system training data. To handle categorical data, embedding layers map each category to a dense representation before being fed into multilayer perceptrons (MLP). Numerical features can be fed directly into an MLP.\n\nAt the next level, second-order interactions of different features are computed explicitly by taking the dot product between all pairs of embedding vectors and processed dense features. Those pairwise interactions are fed into a top-level MLP to compute the likelihood of interaction between a user and item pair.\n\nCompared to other DL-based approaches to recommendation, DLRM differs in two ways. First, it computes the feature interaction explicitly while limiting the order of interaction to pairwise interactions. Second, DLRM treats each embedded feature vector (corresponding to categorical features) as a single unit, whereas other methods (such as Deep and Cross) treat each element in the feature vector as a new unit that should yield different cross terms. These design choices help reduce computational/memory cost while maintaining competitive accuracy.\n\nDLRM forms part of NVIDIA Merlin, a framework for building high-performance, DL-based recommender systems, which we discuss below."
    }
}