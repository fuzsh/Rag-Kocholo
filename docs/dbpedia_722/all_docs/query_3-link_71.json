{
    "id": "dbpedia_722_3",
    "rank": 71,
    "data": {
        "url": "https://aws.amazon.com/what-is/gpu/",
        "read_more_link": "",
        "language": "en",
        "title": "What is a GPU?",
        "top_image": "https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png",
        "meta_img": "https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png",
        "images": [
            "https://d1.awsstatic.com/Free-Tier_64.f14d1a130811a363bbea22de4bb589f9ab801dfb.png",
            "https://d1.awsstatic.com/Compute_64.72db591feb90f4ca9d441ea54260e9937c83ac0e.png",
            "https://d1.awsstatic.com/Learn-More_64.dc6d454a262eb880a9dd0d8cb283dca5bc00cb18.png",
            "https://d1.awsstatic.com/All-Products_64.78a4c2cdfdd82b7abc3fda6b44371491bdf5963e.png",
            "https://d1.awsstatic.com/asset-repository/products/amazon-ec2/Website/HA_P2_GENERAL.63cd6f600f0824529b8f7f52207cefb20d6fdf1f.png",
            "https://d1.awsstatic.com/webteam/product-pages/Product-Page_Standard-Icons_01_Product-Features_SqInk.a8d5666758afc5121b4eb818ae18126031c4b61e.png",
            "https://d1.awsstatic.com/webteam/product-pages/Product-Page_Standard-Icons_02_Sign-Up_SqInk.f43d5ddc9c43883eec6187f34c68155402b13312.png",
            "https://d1.awsstatic.com/webteam/product-pages/Product-Page_Standard-Icons_03_Start-Building_SqInk.6a1ef4429a6604cda9b0857084aa13e2ee4eebca.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "What is a GPU (Processor) how and why businesses use Graphics Processing Unit, and how to use GPU with AWS.",
        "meta_lang": "en",
        "meta_favicon": "https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico",
        "meta_site_name": "Amazon Web Services, Inc.",
        "canonical_link": "https://aws.amazon.com/what-is/gpu/",
        "text": "A GPU is excellent at performing general-purpose parallel processing, but historically, this wasn’t always the case. As the name suggests, GPUs were initially designed for one specific task: controlling image display.\n\nOrigin of the GPU\n\nBefore the GPU, we had dot matrix screens, which released in the 1940s and 1950s. Vector and raster displays released after, then later the first video game consoles and PCs released. At the time, a non-programmable device called a graphics controller coordinated display to the screen. Graphics controllers traditionally relied on the CPU for processing, although some included on-chip processors.\n\nAround the same time, there was a 3D imaging project concerned with generating a single pixel on a screen with a single processor. The goal was to produce an image that combines many pixels in a short amount of time. This project was the origin of the GPU as we know it.\n\nIt wasn’t until the late 1990s that the first GPUs came out. These were aimed at the gaming and computer-aided design (CAD) markets. The GPU integrated a previously software-based rendering engine and transformation and lighting engine with the graphics controller—all on a programmable chip.\n\nEvolution of GPU technology\n\nNvidia was the first to market the single-chip GeForce 256 GPUs in 1999. The 2000s and 2010s marked a growth era where GPUs gained functions like ray tracing, mesh shading, and hardware tessellation. These led to increasingly advanced image generation and graphics performance.\n\nIt wasn’t until 2007 that Nvidia released CUDA, a software layer making parallel processing available on the GPU. Around this time, it became clear that GPUs were very effective at performing highly specific tasks. Specifically, they excelled at tasks that require a large amount of processing power to achieve a particular outcome.\n\nWhen Nvidia released CUDA, it opened up GPU programming to a wider audience. Developers could then program GPU technology for all sorts of different compute-intensive practical applications. GPU computing started to become far more mainstream.\n\nGPUs are an in-demand chip for blockchain and other emerging applications. They're increasingly being put towards artificial intelligence and machine learning (AI/ML).\n\nGPUs can be used across a wide range of compute-intensive applications, including large-scale finance, defense applications, and research activities. Here are some of the most prevalent uses of GPUs today.\n\nGaming\n\nThe GPU’s first applications that extended beyond large business and government visualization applications were in personal gaming. They were used in the gaming consoles of the 1980s and still are in PCs and current gaming consoles. GPUs are essential for complex graphical rendering.\n\nProfessional visualization\n\nGPUs are used in professional applications such as CAD drawing, video editing, product walkthroughs and interactivity, medical imagery, and seismic imaging. They are also applied to other complex image and video editing and visualization applications. Browser-based applications can even exploit the GPU through libraries such as WebGL.\n\nMachine learning\n\nTraining a machine learning (ML) model requires a large amount of compute power. They can now run on GPUs for accelerated results. While it might take a long time to train a model on self-purchased hardware, you can achieve results quickly by using a cloud GPU.\n\nBlockchain\n\nCryptocurrencies are built on blockchains. A particular type of blockchain, proof of work, typically heavily relies on GPUs for operation. Application-specific integrated circuits (ASIC), a similar but different chip, are now a common replacement for GPU processing for blockchain.\n\nProof of stake blockchain algorithmic proofs remove the need for massive amounts of compute power, but proof of work is still pervasive.\n\nSimulation\n\nAdvanced simulation applications such as those used in molecular dynamics, weather forecasting, and astrophysics can all be accomplished through GPUs. GPUs are also behind a lot of applications in automotive and large vehicle design, including fluid dynamics.\n\nModern GPUs typically contain a number of multiprocessors. Each has a shared memory block, plus a number of processors and corresponding registers. The GPU itself has constant memory, plus device memory on the board it is housed on.\n\nEach GPU works slightly differently depending on its purpose, the manufacturer, the specifics of the chip, and the software used for coordinating the GPU. For instance, Nvidia’s CUDA parallel processing software allows developers to specifically program the GPU with almost any general-purpose parallel processing application in mind.\n\nGPUs can be standalone chips, known as discrete GPUs, or integrated with other computing hardware, known as integrated GPUs (iGPUs).\n\nDiscrete GPUs\n\nDiscrete GPUs exist as a chip that is fully dedicated to the task at hand. While that task has traditionally been graphics, now discrete GPUs can be used as dedicated processing for tasks like ML or complex simulation.\n\nWhen used in graphics, the GPU typically resides on a graphics card that slots into a motherboard. In other tasks, the GPU may reside on a different card or slot directly onto the motherboard itself.\n\nIntegrated GPUs\n\nIn the early 2010s, we started to see a move away from discrete GPUs. Manufacturers embraced the introduction of the combined CPU and GPU on a chip, known as the iGPU. The first of these iGPUs for PC were Intel’s Celeron, Pentium, and Core lines. These remain popular across laptops and PCs.\n\nAnother type of iGPU is the system on a chip (SoC) that contains components like a CPU, GPU, memory, and networking. These are the types of chips typically found in smartphones.\n\nVirtual\n\nLike other types of computing hardware infrastructure, GPUs can also be virtualized. Virtualized GPUs are a software-based representation of a GPU that shares space alongside other virtual GPUs on cloud server instances. You can use them to run your workloads without having to worry about underlying hardware maintenance."
    }
}