{
    "id": "correct_foundationPlace_00075_3",
    "rank": 38,
    "data": {
        "url": "https://groups.google.com/g/comp.databases.sybase/c/t_2IBlITMkE",
        "read_more_link": "",
        "language": "en",
        "title": "Informix vs. Sybase vs. Oracle vs. (gasp) MS SQL Server",
        "top_image": "https://www.gstatic.com/images/branding/product/1x/groups_32dp.png",
        "meta_img": "https://www.gstatic.com/images/branding/product/1x/groups_32dp.png",
        "images": [
            "https://fonts.gstatic.com/s/i/productlogos/groups/v9/web-48dp/logo_groups_color_1x_web_48dp.png",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a-/ALV-UjXAPNufl8fN29CDry_1BvTJAYc7Ns1-UvHhdzEWOWZNSUuioA=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c",
            "https://lh3.googleusercontent.com/a/default-user=s40-c"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "//www.gstatic.com/images/branding/product/1x/groups_32dp.png",
        "meta_site_name": "",
        "canonical_link": "https://groups.google.com/g/comp.databases.sybase/c/t_2IBlITMkE",
        "text": "Hi CDI peeps,\n\nPablo Sanchez wrote:\n\n> In article <3357D8...@informix.com>, Dan Crowley <dcro...@informix.com> writes:\n\n> I don't agree with the above justification for 1 gig data cache. On a machine with 4\n\n> gig memory, we only get to use 25% of it?\n\nWell, okay the buffer cache is limited to 1 Gb in 32-bit ports. But we can use some\n\nofthe extra memory for virtual segment (thread stacks, sort space, dictionary/stored\n\nprocedure\n\ncache etc. etc.) so it's not quite the limitation you make out. Also, the 64-bit ports\n\ndon't\n\nhave this limitation anyway.\n\n> > >\n\n> > > o variable I/O read/writes: o based on platform, only 2/4K read/writes -\n\n> > > 2/4/8/16K although on the log there are\n\n> > > group writes\n\n>\n\n> > Informix does 16K I/O when doing light scans. Also, checkpoint writes\n\n> > are sorted for better performance\n\n>\n\n> Great! A definitive answer. Thx.\n\nIn fact, the I/O size for light scans is not fixed but is calculated dynamically for\n\neach scan.\n\nAlso, checkpoint writes are done in units of 8 buffers which makes them 16k (2k\n\npagesize) or 32k (4k page size) writes. Also for read ahead and other sequential I/O we\n\nwill group I/O for contiguous pages and do a larger physical read if possible.\n\n> > (keeps disk heads from randomly\n\n> > seeking - I'm not sure if Sybase does this).\n\n>\n\n> It doesn't. This is a really neat feature of Informix, simple and\n\n> effective.\n\n>\n\n> > Finally, are there any controllers that make use of I/O > 16k?\n\n> snip...\n\n> > However, with Sybase you MUST log. You have no options (less knobs if\n\n> > you will).\n\n> > With Informix, for each database you can choose to do\n\n> > unbuffered, buffered, or no logging. No logging is great for Data\n\n> > Warehouse situations where you load once a day, week, or month, and the\n\n> > rest of the time you're only doing reads.\n\n>\n\n> You raise some good points here. This is a very nice feature of\n\n> Informix. I think that \"no logging\" is a bit of a misnomer in that\n\n> the RDBMS must do some logging in order to conform to ACID.\n\nAn unlogged database in Informix does not support transactions and does not log changes\n\ntodata. Certain DDL and internal operations are logged however.\n\n> >\n\n> > Another thing to mention is the parallel use of threads - particularly\n\n> > useful for data warehousing, parallel index builds, or any time you want\n\n> > to reduce the time to execute a time consuming SQL statement.\n\n> >\n\n>\n\n> Most definitely. Although I find it a bit strange that the\n\n> connections must specify the percentage to allocate. Sounds\n\n> klunky... however the feature is great. Sybase 11.5 will\n\n> have... but that's future...\n\nYou don't need to specify the percentage for parallel index builds. It isessential for\n\nheavy DSS queries to have some resource regulation to\n\nprevent (if desired) any single query hogging the entire machine (unless\n\nthat is what you want of course). You have a choice to prioritise\n\nindicidual queries.\n\n> > o Only Page Level Locking o Page or Row Level Locking\n\n> >\n\n> > Advantage Informix. This is a huge weakness with Sybase.\n\n>\n\n> No, this is a great marketing whitewash. I won't get into this\n\n> religious war.\n\nSorry but it is a *big* limitation. Row level locking provides much greaterconcurrency,\n\neven for a well designed application database.\n\n> This is true, this is nice defensive RDBMS for a bad application. A\n\n> good application will increase throughput by reducing latency.\n\n> Reducing latency is accomplished by decreasing the duration of locks\n\n> and internal processing. This is why the row level versus page\n\n> level religious war is silly. Vendors try to play this up like it's\n\n> some great advantage. But it's not. Informix allows the user the\n\n> *option* to have row level locking. If it was such a great thing\n\n> with no overhead, why make it an option and not have it built in?\n\n> Hmmmm....\n\nThe only reason that the default is page level locking is historical. It usedto be that\n\nway so we haven't changed the default to maintain backwards\n\ncompatibility. We always encourage use of row level locking these days.\n\nPablo Sanchez wrote:\n\n[Stuff deleted]\n\n> 1) The ER diagram and\n\n> 2) The business problem that we're solving\n\n>\n\n> There are *many* ways to solve an application so I'd love to\n\n> see The Application (you claim) that:\n\n>\n\n> There are applications where anything other than row\n\n> level locking simply won't do.\n\nOk. Here is an easy one. Only involves 2 tables (master and detail).\n\nThis is of course very simlified and I have not checked the syntax :-)\n\nCREATE TABLE master (id INT PRIMARY KEY,\n\nname VARCHAR(31),\n\naddress VARCHAR(21),\n\namount DECIMAL(16,4) );\n\nCREATE INDEX x1 ON master (name);\n\nCREATE INDEX x2 ON master (address);\n\nCREATE TABLE detail (id INT REFERENCES master,\n\nline_no INT,\n\nitem_no INT,\n\ndescr VARCHAR(100),\n\ncost DECIMAL(10,4));\n\nALTER TABLE detail PRIMARY KEY(id, line_no);\n\nNow what the app does is it allows users to select a record from the\n\nmaster table, get all child records from the detail table and allow the\n\nusers to add/delete/modify those records as needed. After the user exits\n\nit updates the\n\nmaster table by selecting the sum of cost from the detail table. The sql\n\nstatements involved are something like this: (assume everything is under\n\ntransaction control)\n\n-- We need to lock the master table so nobody else will update it while\n\nwe are.\n\nSELECT * FROM master WHERE id = ? FOR UPDATE;\n\n-- No need to lock the detail recs 'cause the master rec is locked.\n\nSELECT * FROM detail WHERE id = ? ORDER BY line_no;\n\n-- After the user exits we update all detail recs, probably by deleting\n\nthem first, and then inserting whatever the user has typed in.\n\n-- Then we'll need to update the master table and release the lock.\n\nUPDATE master SET amount = (SELECT sum(cost) FROM detail WHERE id = ?)\n\nWHERE id = ?;\n\nCOMMIT;\n\nIf you have row level locking, the first select stmt will lock one row.\n\nAs the primary key is 4 bytes you can potentially put 4-500 keys on any\n\npage (if you have 2K pages). In a page lock system (like Sybase and\n\nMSSQL) the probability of a user trying to access one of the ~499 key\n\nvalues another user has locked is pretty high.\n\nPage lock workarounds could be:\n\n1) Make the primary key >1Kb, so you would only have one key per page.\n\n(Disks are cheap, right?)\n\n2) Use optimistic locking. (So users who have been typing in for hours\n\nget the message: Somebody else has modified this rec while you were\n\nworking. Please try again).\n\n3) Swich to Informix :-)\n\nTake care,\n\n-Snorri\n\n--\n\nSnorri Bergmann | Mail: sno...@strengur.is\n\nStrengur Consulting Engineers | WWW: http://www.strengur.is/\n\nArmuli 7 | Phone: +354 550 9000 (9007 direct)\n\n108 Reykjavik Iceland | Telefax: +354 550 9010\n\nSnorri Bergmann wrote:\n\n> Ok. Here is an easy one. Only involves 2 tables (master and detail).\n\n> This is of course very simlified and I have not checked the syntax :-)\n\n[DDL definitions snipped]\n\n> Now what the app does is it allows users to select a record from the\n\n> master table, get all child records from the detail table and allow the\n\n> users to add/delete/modify those records as needed. After the user exits\n\n> it updates the\n\n> master table by selecting the sum of cost from the detail table. The sql\n\n> statements involved are something like this: (assume everything is under\n\n> transaction control)\n\n>\n\n> -- We need to lock the master table so nobody else will update it while\n\n> we are.\n\nHere is the crux of your problem. \"We need to lock\".\n\nIts this mindset that doesn't allow you to see a better\n\nsolution, so you let your DB server do it for you.\n\n> SELECT * FROM master WHERE id = ? FOR UPDATE;\n\n>\n\n> -- No need to lock the detail recs 'cause the master rec is locked.\n\nYes, no need to lock. Its how you lock master thats the\n\nproblem. I'll explain below.\n\n> SELECT * FROM detail WHERE id = ? ORDER BY line_no;\n\n>\n\n> -- After the user exits we update all detail recs, probably by deleting\n\n> them first, and then inserting whatever the user has typed in.\n\nWhat an overhead, delete followed by insert. An in situ\n\nupdate is far more efficient. Use it wherever possible.\n\n> -- Then we'll need to update the master table and release the lock.\n\nYou can use a non-server generated lock instead. Then it\n\njust becomes a matter of updating the master table. The\n\naction of this update is also the action of releasing the\n\nlock. No other process is locked out of reading the record\n\nbut others can't update or delete while that record is marked\n\nas being in use (provided that they observe the rules).\n\n> If you have row level locking, the first select stmt will lock one row.\n\n> As the primary key is 4 bytes you can potentially put 4-500 keys on any\n\n> page (if you have 2K pages). In a page lock system (like Sybase and\n\n> MSSQL) the probability of a user trying to access one of the ~499 key\n\n> values another user has locked is pretty high.\n\nThats the reason why server-generated locks should be fast,\n\nand not held for an indefinite period. the initial select\n\nshould NOT be part of the transaction. This rule should\n\napply to all locking methods, including row level.\n\n> Page lock workarounds could be:\n\n>\n\n> 1) Make the primary key >1Kb, so you would only have one key per page.\n\n> (Disks are cheap, right?)\n\nWrong approach. This is the BFI method favoured by those who\n\njust can't grasp the concepts.\n\n> 2) Use optimistic locking. (So users who have been typing in for hours\n\n> get the message: Somebody else has modified this rec while you were\n\n> working. Please try again).\n\nSame wrong approach.\n\n>\n\n> 3) Swich to Informix :-)\n\nI feel tempted to state the same here, but I'd rather ask why\n\nsome of Informix's top programmers have jumped ship and joined\n\nOrable? (According to what I've read recently in the trade\n\npapers)\n\n-am\n\nMatt wrote:\n\n\n\nFirstly, don't create a lock on the initial select. Its\n\na poor practice (especially when trying to port apps from\n\nrow to page locking databases). There are a few alternates\n\nyou can use instead. Two of the simplest are:\n\n1) Use a field in a key table to act as a marker for a\n\nuser's intentions. The field can default to null, zero\n\nor whatever when its not being accessed or its only\n\nbeing read. When its accessed with the intention of\n\na later transactional change, flag the field with\n\nan identifying value. Avoid boolean values. Use\n\nsomething like a user's identity value. This way\n\nothers can run a query to see who's accessing this\n\ndata. Only produce a lock(s) when the actual updates/\n\ninserts happen, and only on the appropraite tables.\n\nReset this field back to its default value when done.\n\nAll applications that access the same data must honour\n\nthe set flag.\n\nDrawbacks of this method under Sybase - apps that ignore\n\nor don't honour the set flag may cause data inconsistency.\n\nYou shouldn't have an index on this field (for performance\n\nreasons). You'd need to manually clear the field if an\n\napp crashes and check the related data (should be OK\n\nif any data manipulation was done solely within the\n\nscope of one transaction). You can improve granularity\n\nof this method by changing the field's value just\n\nprior to any manipulation, so you can check at what\n\npoint things were at when an error occured.\n\n2) Run a \"lock\" table. By this I mean a seperate table\n\nthat marks that a user is processing a specific object.\n\nRecord the key of the object here, the user's id, the date\n\nand time and anything else you feel is appropriate. This\n\nway you can tell who's accesing what and for how long.\n\nAll apps have to access objects via this lock table\n\n(unless they are only reading objects to produce summaries\n\netc.). This has an advantage that in the unlikely event\n\nof a server crash, you can easily scan this table to\n\ncheck what was being processed (model 1 is more difficult\n\nif the key table is very large).\n\nDrawbacks: you could manually remove one of these 'locks'.\n\nYou'll need to tune this 'lock' table under Sybase in a\n\nhighly contentious environment.\n\n-am\n\nAnthony Mandic wrote:\n\n>\n\n> Snorri Bergmann wrote:\n\n>\n\n> > Ok. Here is an easy one. Only involves 2 tables (master and detail).\n\n> > This is of course very simlified and I have not checked the syntax :-)\n\n>\n\n> [DDL definitions snipped]\n\n>\n\n> > Now what the app does is it allows users to select a record from the\n\n> > master table, get all child records from the detail table and allow the\n\n> > users to add/delete/modify those records as needed. After the user exits\n\n> > it updates the\n\n> > master table by selecting the sum of cost from the detail table. The sql\n\n> > statements involved are something like this: (assume everything is under\n\n> > transaction control)\n\n> >\n\n> > -- We need to lock the master table so nobody else will update it while\n\n> > we are.\n\n>\n\n> Here is the crux of your problem. \"We need to lock\".\n\n> Its this mindset that doesn't allow you to see a better\n\n> solution, so you let your DB server do it for you.\n\n>\n\n> > SELECT * FROM master WHERE id = ? FOR UPDATE;\n\n> >\n\n> > -- No need to lock the detail recs 'cause the master rec is locked.\n\n>\n\n> Yes, no need to lock. Its how you lock master thats the\n\n> problem. I'll explain below.\n\n>\n\n> > SELECT * FROM detail WHERE id = ? ORDER BY line_no;\n\n> >\n\n> > -- After the user exits we update all detail recs, probably by deleting\n\n> > them first, and then inserting whatever the user has typed in.\n\n>\n\n> What an overhead, delete followed by insert. An in situ\n\n> update is far more efficient. Use it wherever possible.\n\n>\n\n> > -- Then we'll need to update the master table and release the lock.\n\n>\n\n> You can use a non-server generated lock instead. Then it\n\n> just becomes a matter of updating the master table. The\n\n> action of this update is also the action of releasing the\n\n> lock. No other process is locked out of reading the record\n\n> but others can't update or delete while that record is marked\n\n> as being in use (provided that they observe the rules).\n\n>\n\n> > If you have row level locking, the first select stmt will lock one row.\n\n> > As the primary key is 4 bytes you can potentially put 4-500 keys on any\n\n> > page (if you have 2K pages). In a page lock system (like Sybase and\n\n> > MSSQL) the probability of a user trying to access one of the ~499 key\n\n> > values another user has locked is pretty high.\n\n>\n\n> Thats the reason why server-generated locks should be fast,\n\n> and not held for an indefinite period. the initial select\n\n> should NOT be part of the transaction. This rule should\n\n> apply to all locking methods, including row level.\n\n>\n\n> > Page lock workarounds could be:\n\n> >\n\n> > 1) Make the primary key >1Kb, so you would only have one key per page.\n\n> > (Disks are cheap, right?)\n\n>\n\n> Wrong approach. This is the BFI method favoured by those who\n\n> just can't grasp the concepts.\n\n>\n\n> > 2) Use optimistic locking. (So users who have been typing in for hours\n\n> > get the message: Somebody else has modified this rec while you were\n\n> > working. Please try again).\n\n>\n\n> Same wrong approach.\n\n> >\n\n> > 3) Swich to Informix :-)\n\n>\n\n> I feel tempted to state the same here, but I'd rather ask why\n\n> some of Informix's top programmers have jumped ship and joined\n\n> Orable? (According to what I've read recently in the trade\n\n> papers)\n\n>\n\nM O N E Y\n\n:-)\n\n> -am\n\nThe secret is indeed: in not performing a lock on the row till you're\n\nabsolutely damn sure it's time to perform the update. Simply select\n\nthe data into the form, and save off the original information in a save\n\nbuffer. Allow the user to edit the form, and allow them to either update\n\nor change their mind and restore the screen.\n\nIf the user is camped out on a row, and then decides to do something\n\nelse, no lock on the data base whilst they edit the row. If they\n\nchange their mind, abort the change, and refresh the screen with\n\nthe save-buffer information. The larger the OLTP organization of people\n\ndoing the work the greater the factor for people camping out on data.\n\nShould they get around to actually updating the row, check first to\n\nsee if it *can* be done ( DECLARE CURSOR ... FOR UPDATE ) If the declare\n\ncomes back clean, by checking the SQLCA, perform the update. Otherwise\n\nalert the user that the row is locked please wait.\n\nMy code generators do this. It's still no excuse to allow page-level\n\nlocking. Row-level locking in my not so humble opinion *is*\n\nimportant. :-) If you have a highly active OLTP environment, you\n\nshould not introduce a page-level only data base into that environment\n\nand add risk. I know a Sybase programmer who shared his \"trick\" for\n\nworking with this inherent problem. But it involves a stored procedure\n\nwhich adds overhead, and I think the above numbering scheme for serial\n\nnumbers. More work than is really necessary, and a lot of wasted\n\nspace in the data base.\n\nThose that argue against sloppy programming definitely are on the\n\nright track. Programs should include the additional management of\n\nchecking the row to see if it can be updated, and only do the update\n\nwhen it's absolutely time to do so. That should make it a\n\nget-in-and-get-out proposition.\n\nAs far as Pablo's comments, I saw bait, and that silly smile with a\n\nbaloon on his head.\n\n:-)\n\nTimmy\n\n--\n\nTim Schaefer \\\\|//\n\ntsch...@mindspring.com 6 6\n\n-------------------------------oOOo---( )---o00o----------------------\n\nhttp://www.inxutil.com http://www.informix.com\n\nhttp://www.iiug.org news://comp.databases.informix\n\nmailto:majo...@iiug.org no subject body: subscribe linux-informix\n\n======================================================================\n\nPablo Sanchez wrote:\n\n>\n\n> >>>>> \"Paul\" == Paul Brown <pbr...@triplerock.Berkeley.EDU> writes:\n\n> Paul>\n\n> Paul> To quote from Jim Gray, (_Transaction_Processing_:_Concepts_and_\n\n> Paul> Techniques_ pp. 420-21);\n\n> Paul>\n\n>\n\n> Paul,\n\n>\n\n> Unless something has changed, aren't you still an Informix\n\n> employee (or employed in some fashion by them)? If so, then\n\n> of course you're going to post supporting literature...\n\n>\n\n> Anyway, I think the answer lies with the TPC-C. I think\n\n> that they prove that row-level vs page-level locking is not\n\n> an issue. The -C's are a finely tuned OLTP application.\n\nI think we may have drifted into a small tangent here...I think\n\nthe real question that many developers are interested in (at least\n\nconsciencious (sp?) ones) is whether or not the page level\n\nlocking (PLL) concurrency solutions are a hinderance on performance\n\nof the application.\n\nIt is a given, I believe, that RLL is an *easier* model to work\n\nwith--and IMHO, I think for some simple RAD type applications it\n\nis great to have just so you don't need to concern yourself with\n\nconcurrency as much, which is why I am pleased to see it being added\n\nto Sybase. But, the real question is, for the remainder of the\n\napplications out there (which are pushing the server to its limits),\n\nis there a situation in which a PLL concurrency solution is less\n\nefficient than the associated RLL solution? (Note, I am not saying\n\nthat easier to implement, because it usually isn't). Or, better\n\nyet, if you implemented PLL logic in an RLL database, would it\n\nhelp, hinder, or have no effect on performance?\n\nI cannot think of any application in which a properly designed\n\nPLL solution would perform any worse than its RLL counter part\n\n(but, as has been pointed out, it may very well take more\n\ndesign effort to achieve these results). And, in fact, I think\n\nthat for a very large sub-set of these applications, performance\n\ncan actually improve using PLL.\n\nThis is what really gripes me about companies that sell cross-\n\nvendor software that does not work effectively in a PLL\n\nenvironment...with just a little bit of effort (which these\n\ncompanies don't seem willing to invest) the application could\n\neasily work across any vendor's environment, and may even\n\ngain a slight performance improvement.\n\n-scott\n\n--\n\nScott C. Gray gr...@voicenet.com \"my keybard is\n\nbrken\"\n\nSybase Professional Services scott...@sybase.com\n\nhttp://www.voicenet.com/~gray/sqsh.html\n\nPablo Sanchez (pa...@sgi.com) wrote:\n\n: >>>>> \"Paul\" == Paul Brown <pbr...@triplerock.Berkeley.EDU> writes:\n\n: Paul>\n\n: Paul> To quote from Jim Gray, (_Transaction_Processing_:_Concepts_and_\n\n: Paul> Techniques_ pp. 420-21);\n\n: Paul>\n\n:\n\n: Unless something has changed, aren't you still an Informix\n\n: employee (or employed in some fashion by them)? If so, then\n\n: of course you're going to post supporting literature...\n\nYes. I am an Informix Employee. You're the keeper of the\n\nSybase FAQ. Religon counts for something.\n\nWhen I'm speaking on behalf of Informix, I'll post from an\n\nInformix account.\n\nWhen I'm simply trying to contribute to a technical debate, and\n\ndon't want my affiliations to obscure my contributions, I\n\npost from UCB. I said *nothing* positive or negative about\n\nanyone. If you like, I can post references to the IBM\n\nresearch (some of which is also attributed to Jim Gray) which\n\nargues for your case.\n\nThe irony here is that I actually agree with you! A well\n\ndesigned schema should require only page granularity. (Another\n\nimportant topic unbroached in this thread concerns\n\nlock escallation strategies.) But the practical reality is\n\nthat people don't always do 'the right thing'. This is the\n\n'hard lesson' Gray refers to.\n\nWe all start out convinced, for the best technical reasons,\n\nthat page locking is all you need. Then you go to your first\n\ncustomer who has a god-awful schema, a profound unwillingness\n\nto change anything, and the demand that you get their hunk-o-junk\n\nto work. (Paging SAP. Please pick up the white courtesy\n\nphone . . )\n\n: Anyway, I think the answer lies with the TPC-C. I think\n\n: that they prove that row-level vs page-level locking is not\n\n: an issue. The -C's are a finely tuned OLTP application.\n\nTPC-C proves it isn't a technical problem. And it isn't. It's\n\npurely an economic one.\n\nNote: I do think that the case may change for extensible DBMSs.\n\nConsider what goes on when you're doing query that includes an\n\nexpensive function (it may take a minute to complete). The case\n\nfor row level locking (even value level locking) becomes more\n\nimpressive.\n\nIn article <347BCB...@agd.nsw.gov.au>, Anthony Mandic\n\n<no_s...@agd.nsw.gov.au> writes\n\n>Snorri Bergmann wrote:\n\n>\n\n>> Ok. Here is an easy one. Only involves 2 tables (master and detail).\n\n>> This is of course very simlified and I have not checked the syntax :-)\n\n>\n\n>[DDL definitions snipped]\n\n>\n\n>> Now what the app does is it allows users to select a record from the\n\n>> master table, get all child records from the detail table and allow the\n\n>> users to add/delete/modify those records as needed. After the user exits\n\n>> it updates the\n\n>> master table by selecting the sum of cost from the detail table. The sql\n\n>> statements involved are something like this: (assume everything is under\n\n>> transaction control)\n\n>>\n\n>> -- We need to lock the master table so nobody else will update it while\n\n>> we are.\n\n>\n\n> Here is the crux of your problem. \"We need to lock\".\n\n> Its this mindset that doesn't allow you to see a better\n\n> solution, so you let your DB server do it for you.\n\n>\n\nThats's the idea, the DB server SHOULD do the locking. see below.\n\n>> SELECT * FROM master WHERE id = ? FOR UPDATE;\n\n>>\n\n>> -- No need to lock the detail recs 'cause the master rec is locked.\n\n>\n\n> Yes, no need to lock. Its how you lock master thats the\n\n> problem. I'll explain below.\n\n>\n\n>> SELECT * FROM detail WHERE id = ? ORDER BY line_no;\n\n>>\n\n>> -- After the user exits we update all detail recs, probably by deleting\n\n>> them first, and then inserting whatever the user has typed in.\n\n>\n\n> What an overhead, delete followed by insert. An in situ\n\n> update is far more efficient. Use it wherever possible.\n\n>\n\nIt think he means say 10 detail rows, in the screen array the user\n\nupdates 5 , deletes 2, inserts 3. What SQL do you generate?\n\nYou could try to generate the needed inserts/updates/deleted but it's\n\ntoo complex and error prone, just delete and insert.\n\n>> -- Then we'll need to update the master table and release the lock.\n\n>\n\n> You can use a non-server generated lock instead. Then it\n\n> just becomes a matter of updating the master table. The\n\n> action of this update is also the action of releasing the\n\n> lock. No other process is locked out of reading the record\n\n> but others can't update or delete while that record is marked\n\n> as being in use (provided that they observe the rules).\n\n>\n\nOh, you mean soft locking where you have a database table that\n\ncontains the locks e.g.\n\ncreate table lock_table\n\n(\n\nentity char(10) (effetively table name),\n\nentity_key integer (primary key)\n\ntransaction_id (uses to remove locks for a given transaction just\n\nbefore commiting).\n\n)\n\nOK what happens when you have commited entries into this table\n\n(which you have to for other users to see them) and\n\na) you program SIGSEV's in the middle of a transaction with open\n\nlocks?\n\nb) Someone does a kill -9 on your process when it has open locks?\n\nc) A power failure occurs whilst you have open locks?\n\nA database server will cleanup locks if a client dies or when\n\nrestarted if the server dies.\n\nYOUR CLIENT PROGRAM CANNOT GUARANTEE LOCKS ARE RELEASED IF A CLIENT\n\nPROGRAM DIES.\n\nAlso which is faster a\n\nBEGIN WORK\n\nINSERT INTO lock_table..\n\nCOMMIT\n\n(including flushing 'dirty' data to disk and transaction logging\n\nor the database server putting an entry into an in memory lock table?\n\n>> If you have row level locking, the first select stmt will lock one row.\n\n>> As the primary key is 4 bytes you can potentially put 4-500 keys on any\n\n>> page (if you have 2K pages). In a page lock system (like Sybase and\n\n>> MSSQL) the probability of a user trying to access one of the ~499 key\n\n>> values another user has locked is pretty high.\n\n>\n\n> Thats the reason why server-generated locks should be fast,\n\n> and not held for an indefinite period. the initial select\n\n> should NOT be part of the transaction. This rule should\n\n> apply to all locking methods, including row level.\n\n>\n\nAgreed, have a little as possibly in the transaction.\n\n>> Page lock workarounds could be:\n\n>>\n\n>> 1) Make the primary key >1Kb, so you would only have one key per page.\n\n>> (Disks are cheap, right?)\n\n>\n\n> Wrong approach. This is the BFI method favoured by those who\n\n> just can't grasp the concepts.\n\n>\n\nAgreed.\n\n>> 2) Use optimistic locking. (So users who have been typing in for hours\n\n>> get the message: Somebody else has modified this rec while you were\n\n>> working. Please try again).\n\n>\n\n> Same wrong approach.\n\n>>\n\n>> 3) Swich to Informix :-)\n\n>\n\n> I feel tempted to state the same here, but I'd rather ask why\n\n> some of Informix's top programmers have jumped ship and joined\n\n> Orable? (According to what I've read recently in the trade\n\n> papers)\n\n>\n\n>-am\n\n--\n\nDavid Williams\n\nJim Smith wrote:\n\n> I wouldn't go as far as essential but it certainly helps. I would guess that\n\n> most applications do not have serious\n\n> concurrency problems caused by locking, but for those that do the fact that\n\n> a single row update locks one row as against many\n\n> rows must help.\n\nIt would help only if the application wasn't developed with a\n\nclear understanding of the issues and processes involved. Locking\n\nshould be fast. Only lock when you need to within the scope of the\n\nreal transaction. This should be fast. And this type of lock would\n\nbe transitory.\n\n> I can't speak about Informix, but the Sybase locking model where readers block\n\n> writers is probably more of a constraint\n\n> (compared to Oracle ) than the page/row difference.\n\nOnly when the readers hold their lock for longer than it takes to\n\ndo the actual read. The concept of holding a read lock until a\n\npotential insert/update transaction is specious.\n\n> > Since when? The level of locking should be transparent to\n\n> > well written applications. It only becomes an issue with\n\n> > poorly written ones.\n\n>\n\n> This is the techie answer which frequently comes up with Sybase.\n\nMaybe, but its the correct one.\n\n> An alternative reading is that you have to code round\n\n> limitations. You have to do that with any system of course\n\n> (except for my new application development tool Magic(tm)), but it\n\n> seems to come up more often with Sybase.\n\nBeing forced to think of a better design pays off better\n\nin the long run. I suspect that any application developed\n\non Sybase first would be inherently more portable to other\n\nbackends than vice-versa.\n\n> Either way, if you always have to employ top-flight programmers, then\n\n> that increases the cost of ownership.\n\nI don't buy that argument. Having at least one superman in\n\na bunch of turkeys may cost slightly more up front, but it\n\nworks out cheeper in the long run. Think if you had no\n\ntop-flighters. How much longer would your project take\n\nwith just the turkeys trying to get the work done? What\n\nwould you end up with? How many problems would you have\n\nto resolve after deployment because none of the turkeys\n\nhad the nouce and experience to know better. I've seen it\n\nhappen time and time again over more years than I'd care to\n\nremember. How much more does it cost to have to rewrite a\n\nbadly designed and written app than to do it properly the\n\nfirst time? How many projects fail? This has been well\n\ndocumented by researchers. You NEED people who know\n\nwhat their doing.\n\n-am\n\nTim Schaefer wrote:\n\n> I wrote:\n\n> > > 3) Swich to Informix :-)\n\n> >\n\n> > I feel tempted to state the same here, but I'd rather ask why\n\n> > some of Informix's top programmers have jumped ship and joined\n\n> > Orable? (According to what I've read recently in the trade\n\n> > papers)\n\n> >\n\n>\n\n> M O N E Y\n\nIt must have been a lot to be so easily seduced. Either that or\n\nInformix weren't paying well. The impression I got was that Informix\n\nare in trouble. Can anyone confirm or deny?\n\n> The secret is indeed: in not performing a lock on the row till you're\n\n> absolutely damn sure it's time to perform the update. Simply select\n\n> the data into the form, and save off the original information in a save\n\n> buffer. Allow the user to edit the form, and allow them to either update\n\n> or change their mind and restore the screen.\n\n[snip]\n\n> Should they get around to actually updating the row, check first to\n\n> see if it *can* be done ( DECLARE CURSOR ... FOR UPDATE ) If the declare\n\n> comes back clean, by checking the SQLCA, perform the update. Otherwise\n\n> alert the user that the row is locked please wait.\n\nThey'd still have to signal their intent so that the data\n\ndoesn't get changed underneath them in the intrim. Using a\n\nserver lock for this is the wrong approach. Setting a flag\n\nin a key table or making an entry somewhere else (with no held\n\nlock) is better.\n\n> My code generators do this. It's still no excuse to allow page-level\n\n> locking. Row-level locking in my not so humble opinion *is*\n\n> important. :-) If you have a highly active OLTP environment, you\n\n> should not introduce a page-level only data base into that environment\n\n> and add risk. I know a Sybase programmer who shared his \"trick\" for\n\n> working with this inherent problem. But it involves a stored procedure\n\n> which adds overhead, and I think the above numbering scheme for serial\n\n> numbers. More work than is really necessary, and a lot of wasted\n\n> space in the data base.\n\nI had worked with a Sybase setup that used a \"lock\" table.\n\nThe environment was highly active. Absolutely everything\n\nwas done via stored procedures (for added performance). Making\n\none extra call at the start to record a \"lock\" and one at the\n\nend to delete it was a negligible overhead. Space usage was\n\nnegligible too. At the close of each day no space was used\n\n(apart from the extra transactions recorded in the log).\n\n> Those that argue against sloppy programming definitely are on the\n\n> right track. Programs should include the additional management of\n\n> checking the row to see if it can be updated, and only do the update\n\n> when it's absolutely time to do so. That should make it a\n\n> get-in-and-get-out proposition.\n\n>\n\n> As far as Pablo's comments, I saw bait, and that silly smile with a\n\n> baloon on his head.\n\nYeah, the pretzelhead fools everyone.\n\n-am\n\nIn article <yut90ub...@mew.corp.sgi.com>, pa...@sgi.com says...\n\n>\n\n>>>>>> \"Paul\" == Paul Brown <pbr...@triplerock.Berkeley.EDU> writes:\n\n>\n\n>Paul> But the practical reality is\n\n>Paul> that people don't always do 'the right thing'. This is the\n\n>Paul> 'hard lesson' Gray refers to.\n\n>\n\n>Unfortunately what you say is true... this is why Oracle's\n\n>versionings works so well... they appeal to the general\n\n>masses who don't do things right. I guess therein lies opportunity.\n\n>\n\nA reflection from a member of the 'general masses'...\n\nWhy is Oracle's versionings bad?\n\nBeing able to get the response I would have gotten had my query been\n\ninstantaneous, without needing to fear read locks or other clients changes\n\nduring the time my query is running, is something I consider a 'good thing'.\n\nIt is the feature highest on my Wish-list for Informix.\n\nWith regards to row/page locks.\n\nThis all boils down to concurrency, the finer granularity the better\n\nconcurrency. If we had value locks we would have the potential for even better\n\nconcurrency than today. This all comes at a price of course, but I would like\n\nthe option to choose, not be restricted by the technical shortcomings of the\n\ndatabase system.\n\nThere is a related issue here, long transactions. I believe Mr Bergmann put\n\nhis finger on it when he wrote:\n\nIn article <347B239E...@strengur.is>, sno...@strengur.is says...\n\n>\n\n>Page lock workarounds could be:\n\n>\n\n>[....]\n\n>\n\n>2) Use optimistic locking. (So users who have been typing in for hours\n\n>get the message: Somebody else has modified this rec while you were\n\n>working. Please try again).\n\n>\n\nIf long transactions are allowed, then the database system can be used to\n\nsupport a pessimistic locking scheme.\n\nThis relates to row level locking because a common solution today is to map\n\n'objects' of some sort into one or more rows in a database(1). When a user\n\nchanges an object in an interactive process taking everything from seconds to\n\nhours, the user must be guaranteed that the changes can be made (This is\n\nSnorris point I believe). The easiest way to guarantee this is to use\n\npessimistic locking.\n\nMy point here is that in a modern system, the user is all to often a part of\n\nthe transaction, we can not ignore that. When making the choice, as an\n\napplication developer, of being nice to the user or the database, I know who\n\ncomes out on top :-)\n\n/Johan Andersson\n\n(1) Object Oriented modeling and design / James Rumbaugh, ISBN 0-13-630054-4\n\n--\n\n________________________________________________________________________\n\n| >>> The opinions herein are mine and not neccessarily my employers <<< |\n\n| Johan Andersson, Msc CSE j...@carmenta.se |\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nDavid Williams wrote:\n\n>\n\n> Anthony Mandic writes:\n\n>\n\n> >> -- After the user exits we update all detail recs, probably by deleting\n\n> >> them first, and then inserting whatever the user has typed in.\n\n> >\n\n> > What an overhead, delete followed by insert. An in situ\n\n> > update is far more efficient. Use it wherever possible.\n\n> >\n\n> It think he means say 10 detail rows, in the screen array the user\n\n> updates 5 , deletes 2, inserts 3. What SQL do you generate?\n\nI remember when I started of years ago and I used to do this\n\n(until I learnt better). Well, since its SQL you're generating\n\nyou should be able to do it a row (and lock) at a time.\n\n> You could try to generate the needed inserts/updates/deleted but it's\n\n> too complex and error prone, just delete and insert.\n\nI disagree. Its not hard, unless you're lasy or incompetent.\n\nFrom a cost point of view, its also more cost effective.\n\n> Oh, you mean soft locking where you have a database table that\n\n> contains the locks e.g.\n\nYep.\n\n> create table lock_table\n\n> (\n\n> entity char(10) (effetively table name),\n\nobject_key interger,\n\nuser_id ...\n\nYou only need to identify the core table's key.\n\n> entity_key integer (primary key)\n\n> transaction_id (uses to remove locks for a given transaction just\n\n> before commiting).\n\n> )\n\n>\n\n> OK what happens when you have commited entries into this table\n\n> (which you have to for other users to see them) and\n\n>\n\n> a) you program SIGSEV's in the middle of a transaction with open\n\n> locks?\n\nAnd another user says \"Why has this object been locked for\n\nN hours?\". Its the same as when someone sets a server lock\n\nand goes off to lunch and lock's their PC's screen. At least\n\nyou can find the culprit \"soft lock\" and fix things up.\n\n> b) Someone does a kill -9 on your process when it has open locks?\n\nSame thing. You can clear it. Its not that big a deal.\n\n> c) A power failure occurs whilst you have open locks?\n\nSame again. You can list all of them and generate a report.\n\nIf the same happens to a server with server locks, how do you\n\nknow who was working on what? In other words, you'd either\n\nhave just one big server transaction or start worrying about\n\ndata consistency. At leat with \"soft locks\" you have some\n\nhope of tracking them down.\n\n> A database server will cleanup locks if a client dies or when\n\n> restarted if the server dies.\n\nYes, unfortunately, and you're stuck if you need to track\n\ndown who was doing what to what/who.\n\n> YOUR CLIENT PROGRAM CANNOT GUARANTEE LOCKS ARE RELEASED IF A CLIENT\n\n> PROGRAM DIES.\n\nI wouldn't want it to. The 'soft lock' is a useful debugging tool\n\nin this very case. How do you debug your client apps otherwise\n\nif a user says \"Oh, it just died.\". Most users can't tell you\n\nanything useful, so you have to rely on your wits. Knowing\n\nwhere they were up to tells you where the app was when it died.\n\nThis feature helped me on numerous occasions in fixing a badly\n\nwritten application.\n\n> Also which is faster a\n\n>\n\n> BEGIN WORK\n\n> INSERT INTO lock_table..\n\n> COMMIT\n\n> (including flushing 'dirty' data to disk and transaction logging\n\n>\n\n> or the database server putting an entry into an in memory lock table?\n\nAn extra insert and delete doesn't hurt. I think the overall\n\nadvantages outweight the disadvantages. Sure its pain to have\n\nto delete stale ones that got left around after a crash and\n\ndon't mark an active transaction, but then users can delete\n\nthem themselves with a well-written app.\n\n> > Thats the reason why server-generated locks should be fast,\n\n> > and not held for an indefinite period. the initial select\n\n> > should NOT be part of the transaction. This rule should\n\n> > apply to all locking methods, including row level.\n\n> >\n\n> Agreed, have a little as possibly in the transaction.\n\nDo you mean have little data or just keep the transaction to as\n\nshort as it should be?\n\n-am\n\nFirst, please excuse me if some of my arguments have already been\n\ncovered in this thread, our newsserver was out for a week and I\n\nhaven't seen all of it.\n\nAnthony Mandic <no_s...@agd.nsw.gov.au> wrote:\n\n>Joel Garry wrote:\n\n>>\n\n>> That is the whole problem with\n\n>> page locking, you can get locked by something that you should not\n\n>> care about.\n\n> Only if that lock was held for longer than it ought to have been.\n\nRegardless, I think one should NOT be troubled by things being done to\n\nrecords that are of no concern to that user. With PLL you can (and\n\nwill) be troubled in such a way.\n\nI think, even in a set-based thinking environment, it should not be\n\nthe database that causes these problems. I strongly support the\n\navailability of RLL (even if sometimes PLL would be a performance\n\nadvantage, I still want the option of RLL without cumbersome tricks or\n\nfake identifiers).\n\n>> The transaction may need to be long. What you are calling a \"real\" transaction\n\n>> may be an artificial construct solely to deal with the page-locking problem.\n\n> No, I've been implying that \"read for update\" or \"select with lock\"\n\n> or whatever its called is the wrong approach. The read/select\n\n> should not be part of the real transaction. They could be held\n\n> indefinitely, in theory. The real tansaction is the\n\n>insert/update/delete.\n\nI totally agree. But this is not a valid argument IMHO, it just\n\nreduces the timespan in which locking occurs, it doesn't alter the\n\n'theoretical' premises.\n\n> These should be fast. If there are a lot of them in one hit, I'd\n\n> consider rethinking the approach used to design the app that\n\n> does this. The implication here is that the app may be far too\n\n> complex, thus being more vulnerable to problems. Keeping it\n\n> simple never hurts.\n\nJust 'blaming' the apps complexity is no real solution too, I think we\n\nshould see the apps complexity and way of operating as a given.\n\nJust because a RDBMS acts on sets and likes set-like operations, that\n\ndoesn't mean the customer does the same or should be trained to do so\n\n(that sets us back some 30 years, when we still wanted to adapt the\n\nusers to the programs instead of the other way around).\n\nIMHO a RDBMS should let the user operate on rows, completely\n\nindependent of the status and concurrent use of 'nearby' rows by other\n\nusers.\n\nThat implies RLL in my opinion.\n\nAlso, in a set-based thinking environment: why is some element\n\n'closer' to another element than another element, and why does\n\nmodifying one element influence the success of modifications to SOME\n\nother elements but not to ALL other elements?\n\nElements in a set should IMO be independent objects.\n\nI look at PLL as if the operating system would not let me change\n\nfoo.txt in directory c:\\tmp, just because someone else is currently\n\nupdating foo1.txt in c:\\tmp. That's absurd.\n\nI think RDBMS suppliers should work hard to make RLL or even VLL as\n\nefficient as 'easy' PLL schemes that currently outperform RLL schemes.\n\nJust because the suppliers do it don't make it right!\n\nJean-Marc.\n\n+------------------------------------------------------------+\n\n|Jean-Marc.van.Leerdam@| All opinions expressed are just ... |\n\n|ingbank.com | opinions (and my personal ones!). |\n\n+-- (AntiSpam:note the xxremovexx in the reply-to address) --+\n\n>>>>> \"Johan\" == Johan Andersson <j...@carmenta.se> writes:\n\nJohan>\n\nJohan> In article <yut90ub...@mew.corp.sgi.com>, pa...@sgi.com says...\n\n>>\n\n>>>>>>> \"Paul\" == Paul Brown <pbr...@triplerock.Berkeley.EDU> writes:\n\n>>\n\nPaul> But the practical reality is\n\nPaul> that people don't always do 'the right thing'. This is the\n\nPaul> 'hard lesson' Gray refers to.\n\n>>\n\n>> Unfortunately what you say is true... this is why Oracle's\n\n>> versionings works so well... they appeal to the general\n\n>> masses who don't do things right. I guess therein lies opportunity.\n\n>>\n\nJohan> A reflection from a member of the 'general masses'...\n\n:-)\n\nJohan> Why is Oracle's versionings bad?\n\nI didn't say it was bad, what I'm saying is that this allows\n\nfor sloppy programming. When applications are done right,\n\nthere's no need to do the versioning.\n\nJohan> Being able to get the response I would have gotten\n\nJohan> had my query been instantaneous, without needing to\n\nJohan> fear read locks or other clients changes during the\n\nJohan> time my query is running, is something I consider a\n\nJohan> 'good thing'.\n\nI understand what you're saying... look at it in the\n\nfollowing light:\n\nIf the total application (not just your part) was\n\ndone well, there wouldn't be a need for the\n\nversioning. Also, in that case, you could use\n\nInformix/Oracle/Sybase to do the work with no\n\nissues. Instead, IMHO, versioning allows sloppy\n\nprogramming. It allows weenies like me to stay in\n\nbusiness because when the performance problems come,\n\nI know where to look. I guess that's okay... but\n\nsome times I like to be altruistic and educate\n\nfolks to help themselves. My approach must suck\n\nbecause I have a knack of making folks rabid.\n\nJohan> With regards to row/page locks. This all boils down\n\nJohan> to concurrency, the finer granularity the better\n\nJohan> concurrency.\n\nAs I've mentioned before, if the application is finely\n\ntuned, then it's a non-issue.\n\nJohan> If we had value locks we would have the potential for even better\n\nJohan> concurrency than today. This all comes at a price of course, but I would like\n\nJohan> the option to choose, not be restricted by the technical shortcomings of the\n\nJohan> database system.\n\nIt's not the RDBMS that has the shortcoming but rather\n\nsloppy application writers... it's been proven with the\n\nnormalized application (TPC-C's) that row-level vs\n\npage-level is not an issue.\n\n\n\nIn article <347D44...@agd.nsw.gov.au>, Anthony Mandic\n\n<no_s...@agd.nsw.gov.au> writes\n\n>David Williams wrote:\n\n>>\n\n>> Anthony Mandic writes:\n\n>>\n\n>> >> -- After the user exits we update all detail recs, probably by deleting\n\n>> >> them first, and then inserting whatever the user has typed in.\n\n>> >\n\n>> > What an overhead, delete followed by insert. An in situ\n\n>> > update is far more efficient. Use it wherever possible.\n\n>> >\n\n>> It think he means say 10 detail rows, in the screen array the user\n\n>> updates 5 , deletes 2, inserts 3. What SQL do you generate?\n\n>\n\n> I remember when I started of years ago and I used to do this\n\n> (until I learnt better). Well, since its SQL you're generating\n\n> you should be able to do it a row (and lock) at a time.\n\n>\n\nBut what if the user wants to be able to undo all the changes they\n\nmade since they entered the screen?\n\nUsers goes into screen, deletes 20 rows and then want to undo\n\neverything. If you commit after each delete you cannot undo it,\n\nif you don;t commit you hold locks...\n\n\n\nonstat -k, lists locks, tables, rowids, sessionids.\n\n>> b) Someone does a kill -9 on your process when it has open locks?\n\n>\n\n> Same thing. You can clear it. Its not that big a deal.\n\n>\n\nIt is.. I've had users complain the locks are held and call the system\n\nCRAP. The users demand a tool to clear the locks. Then they\n\na) say why can't the application clear the locks automatically. If\n\ninformix does I don't see why your application can't.\n\nb) how do DBA indentify stale locks.\n\nc) DBAs delete the wrong users locks...then things get really\n\ninteresting when two users get the ability to update the same rows.\n\nThey both hit the \"DO IT\" key at different times and one user\n\n\"loses\" their updates. Then you get support calls when a user\n\ncomplains of bugs in the application as it \"failed to update the\n\ndata and gives no warning\". You can't reproduce the bug and users\n\nsay they can't reproduce it on demand as \"it only happens\n\noccasionally\".\n\nd) DBA's say \"why do we have to bother clearing out locks each time\n\nwe reboot Online? (This from a site with one crash per day for 6\n\nmonths before Informix supplied a bug fix).\n\n>> c) A power failure occurs whilst you have open locks?\n\n>\n\n> Same again. You can list all of them and generate a report.\n\n> If the same happens to a server with server locks, how do you\n\n> know who was working on what? In other words, you'd either\n\n> have just one big server transaction or start worrying about\n\n> data consistency. At leat with \"soft locks\" you have some\n\n> hope of tracking them down.\n\n>\n\nonstat -k list locks.\n\n>\n\n>> A database server will cleanup locks if a client dies or when\n\n>> restarted if the server dies.\n\n>\n\n> Yes, unfortunately, and you're stuck if you need to track\n\n> down who was doing what to what/who.\n\n>\n\n>> YOUR CLIENT PROGRAM CANNOT GUARANTEE LOCKS ARE RELEASED IF A CLIENT\n\n>> PROGRAM DIES.\n\n>\n\n> I wouldn't want it to. The 'soft lock' is a useful debugging tool\n\n> in this very case. How do you debug your client apps otherwise\n\n> if a user says \"Oh, it just died.\". Most users can't tell you\n\n> anything useful, so you have to rely on your wits. Knowing\n\n> where they were up to tells you where the app was when it died.\n\nSo does Informix 4GL, with startlog() function, all errors are t\n\ntrapped by the Informix runtime library and logged.\n\nOr you can trap them yourself with WHENEVER ERROR CALL do_panic()\n\nand a do_panic functon that calls the Informix errorlog() function\n\nto log errors.\n\nIf the error is bad your application SEGV's of course you get a core\n\ndump.\n\n> This feature helped me on numerous occasions in fixing a badly\n\n> written application.\n\n>\n\n>> Also which is faster a\n\n>>\n\n>> BEGIN WORK\n\n>> INSERT INTO lock_table..\n\n>> COMMIT\n\n>> (including flushing 'dirty' data to disk and transaction logging\n\n>>\n\n>> or the database server putting an entry into an in memory lock table?\n\n>\n\n> An extra insert and delete doesn't hurt. I think the overall\n\n> advantages outweight the disadvantages. Sure its pain to have\n\n> to delete stale ones that got left around after a crash and\n\n> don't mark an active transaction, but then users can delete\n\n> them themselves with a well-written app.\n\n>\n\n>> > Thats the reason why server-generated locks should be fast,\n\n>> > and not held for an indefinite period. the initial select\n\n>> > should NOT be part of the transaction. This rule should\n\n>> > apply to all locking methods, including row level.\n\n>> >\n\n>> Agreed, have a little as possibly in the transaction.\n\n>\n\n> Do you mean have little data or just keep the transaction to as\n\n> short as it should be?\n\nBoth, update as few rows and columns as possible and avoid selects\n\nwithin a transaction.\n\n>\n\n>-am\n\n--\n\nDavid Williams\n\nDavid Williams wrote:\n\n>\n\n> Anthony Mandic writes:\n\n> >David Williams wrote:\n\n> >\n\n> >> It think he means say 10 detail rows, in the screen array the user\n\n> >> updates 5 , deletes 2, inserts 3. What SQL do you generate?\n\n> >\n\n> > I remember when I started of years ago and I used to do this\n\n> > (until I learnt better). Well, since its SQL you're generating\n\n> > you should be able to do it a row (and lock) at a time.\n\n> >\n\n> But what if the user wants to be able to undo all the changes they\n\n> made since they entered the screen?\n\nEr? Perhaps I didn't make myself clear enough. I'm not advocating\n\nthat you do the changes immediately. I should have said after the\n\nuser commits, you process the changes. Doing it concurrently is a\n\nnightmare. Of course, there's no easy way to roll back after the\n\ncommit.\n\n> Users goes into screen, deletes 20 rows and then want to undo\n\n> everything. If you commit after each delete you cannot undo it,\n\n> if you don;t commit you hold locks...\n\n[snip]\n\n> >> b) Someone does a kill -9 on your process when it has open locks?\n\n> >\n\n> > Same thing. You can clear it. Its not that big a deal.\n\n> >\n\n> It is.. I've had users complain the locks are held and call the system\n\n> CRAP. The users demand a tool to clear the locks. Then they\n\n>\n\n> a) say why can't the application clear the locks automatically. If\n\n> informix does I don't see why your application can't.\n\nMy last application did.\n\n> b) how do DBA indentify stale locks.\n\nCheck against existing user connections. I had a stored procedure\n\nto do this. If the user responsible for the lock isn't connected\n\nor has a different process id (or whatever identifier you'd use)\n\nthen the lock is stale. My app would have done the checking if the\n\nuser reconnected, otherwise priveledged users had another app that\n\nwould manage it. Now of this is really that hard to do and there\n\nwasn't much need for DBA intervention. Although I'll admit I used\n\nto monitor the number of locks from time to time to check how busy\n\nthe users really were, etc.\n\n> c) DBAs delete the wrong users locks...then things get really\n\n> interesting when two users get the ability to update the same rows.\n\n> They both hit the \"DO IT\" key at different times and one user\n\n> \"loses\" their updates. Then you get support calls when a user\n\n> complains of bugs in the application as it \"failed to update the\n\n> data and gives no warning\". You can't reproduce the bug and users\n\n> say they can't reproduce it on demand as \"it only happens\n\n> occasionally\".\n\nTisk, tisk. This would happen if it were just deleted manually.\n\nThe way I used to do it was thru a stored procedure that did all\n\nthe correct checking. (Either that or I'd run the lock checking\n\napp myself.)\n\n> d) DBA's say \"why do we have to bother clearing out locks each time\n\n> we reboot Online? (This from a site with one crash per day for 6\n\n> months before Informix supplied a bug fix).\n\nData consistency/integrity. End users could pick up where they\n\nleft off by finding their last lock. The app also stored current\n\ninfo on the client side (via files). This minimised data loss\n\n(critical when its a paperless office. Data came in over the\n\nphone).\n\n> >> YOUR CLIENT PROGRAM CANNOT GUARANTEE LOCKS ARE RELEASED IF A CLIENT\n\n> >> PROGRAM DIES.\n\n> >\n\n> > I wouldn't want it to. The 'soft lock' is a useful debugging tool\n\n> > in this very case. How do you debug your client apps otherwise\n\n> > if a user says \"Oh, it just died.\". Most users can't tell you\n\n> > anything useful, so you have to rely on your wits. Knowing\n\n> > where they were up to tells you where the app was when it died.\n\n>\n\n> So does Informix 4GL, with startlog() function, all errors are t\n\n> trapped by the Informix runtime library and logged.\n\nGood, thats the correct approach. Except that it only relates\n\nto the server side of things. You'd have to rely on core dumps\n\n(if on UNIX) and/or a debugger to debug a client app. Note that\n\nthere are two basic scenarios, the app failing or the app working\n\nbut doing the wrong thing. Which is harder to resolve?\n\n> >> Agreed, have a little as possibly in the transaction.\n\n> >\n\n> > Do you mean have little data or just keep the transaction to as\n\n> > short as it should be?\n\n> Both, update as few rows and columns as possible and avoid selects\n\n> within a transaction.\n\nYes to the latter. I think the former really depends on the business\n\nmodel. Sometimes it just can't be helped (or can it?).\n\n-am\n\nIn article <347E2D...@agd.nsw.gov.au>, Anthony Mandic\n\n<no_s...@agd.nsw.gov.au> writes\n\n>David Williams wrote:\n\n>>\n\n>> Anthony Mandic writes:\n\n>> >David Williams wrote:\n\n>> >\n\n>> >> It think he means say 10 detail rows, in the screen array the user\n\n>> >> updates 5 , deletes 2, inserts 3. What SQL do you generate?\n\n>> >\n\n>> > I remember when I started of years ago and I used to do this\n\n>> > (until I learnt better). Well, since its SQL you're generating\n\n>> > you should be able to do it a row (and lock) at a time.\n\n>> >\n\n>> But what if the user wants to be able to undo all the changes they\n\n>> made since they entered the screen?\n\n>\n\n> Er? Perhaps I didn't make myself clear enough. I'm not advocating\n\n> that you do the changes immediately. I should have said after the\n\n> user commits, you process the changes. Doing it concurrently is a\n\n> nightmare. Of course, there's no easy way to roll back after the\n\n> commit.\n\n>\n\nSo if the user deletes 1000 rows, where do you store them. Not in the\n\nscreen array because they are visible....\n\nwhat if the user deletes, then inserts a new row in the same entry in\n\nthe array?\n\n>> Users goes into screen, deletes 20 rows and then want to undo\n\n>> everything. If you commit after each delete you cannot undo it,\n\n>> if you don;t commit you hold locks...\n\n>\n\n>[snip]\n\n>\n\n>> >> b) Someone does a kill -9 on your process when it has open locks?\n\n>> >\n\n>> > Same thing. You can clear it. Its not that big a deal.\n\n>> >\n\n>> It is.. I've had users complain the locks are held and call the system\n\n>> CRAP. The users demand a tool to clear the locks. Then they\n\n>>\n\n>> a) say why can't the application clear the locks automatically. If\n\n>> informix does I don't see why your application can't.\n\n>\n\n> My last application did.\n\n>\n\n>> b) how do DBA indentify stale locks.\n\n>\n\n> Check against existing user connections. I had a stored procedure\n\nHow? Session ids can wrap and be reused...\n\n> to do this. If the user responsible for the lock isn't connected\n\n> or has a different process id (or whatever identifier you'd use)\n\n> then the lock is stale. My app would have done the checking if the\n\nProcess ids wrap. User ids are now reliable since user can have\n\n>1 connection....only the server can deceide for certain if a lock is\n\nstale...\n\n> user reconnected, otherwise priveledged users had another app that\n\n> would manage it. Now of this is really that hard to do and there\n\n> wasn't much need for DBA intervention. Although I'll admit I used\n\n> to monitor the number of locks from time to time to check how busy\n\n> the users really were, etc.\n\n>\n\n>> c) DBAs delete the wrong users locks...then things get really\n\n>> interesting when two users get the ability to update the same rows.\n\n>> They both hit the \"DO IT\" key at different times and one user\n\n>> \"loses\" their updates. Then you get support calls when a user\n\n>> complains of bugs in the application as it \"failed to update the\n\n>> data and gives no warning\". You can't reproduce the bug and users\n\n>> say they can't reproduce it on demand as \"it only happens\n\n>> occasionally\".\n\n>\n\n> Tisk, tisk. This would happen if it were just deleted manually.\n\n> The way I used to do it was thru a stored procedure that did all\n\n> the correct checking. (Either that or I'd run the lock checking\n\n> app myself.)\n\n>\n\n>> d) DBA's say \"why do we have to bother clearing out locks each time\n\n>> we reboot Online? (This from a site with one crash per day for 6\n\n>> months before Informix supplied a bug fix).\n\n>\n\n> Data consistency/integrity. End users could pick up where they\n\n> left off by finding their last lock. The app also stored current\n\n> info on the client side (via files). This minimised data loss\n\n> (critical when its a paperless office. Data came in over the\n\n> phone).\n\nthe client cannot gurantee to remember about stale lock, what happens\n\nif they power supply fails on the client (or the cleaner pulls the\n\nplug to plug in her Hooever - it has happened).\n\n>\n\n>> >> YOUR CLIENT PROGRAM CANNOT GUARANTEE LOCKS ARE RELEASED IF A\n\nCLIENT\n\n>> >> PROGRAM DIES.\n\n>> >\n\n>> > I wouldn't want it to. The 'soft lock' is a useful debugging\n\ntool\n\n>> > in this very case. How do you debug your client apps\n\notherwise\n\n>> > if a user says \"Oh, it just died.\". Most users can't tell you\n\n>> > anything useful, so you have to rely on your wits. Knowing\n\n>> > where they were up to tells you where the app was when it\n\ndied.\n\n>>\n\nDebug logs,screen messages.\n\n>> So does Informix 4GL, with startlog() function, all errors are t\n\n>> trapped by the Informix runtime library and logged.\n\n>\n\n> Good, thats the correct approach. Except that it only relates\n\n> to the server side of things. You'd have to rely on core dumps\n\n> (if on UNIX) and/or a debugger to debug a client app. Note that\n\n> there are two basic scenarios, the app failing or the app working\n\n> but doing the wrong thing. Which is harder to resolve?\n\n>\n\nEither is easy with debug logs. Switch on, get a trace, debug it.\n\nMost debugging can be narrowed down to one screen operation by the\n\nuser, plaster with debug and that 's it.\n\n>> >> Agreed, have a little as possibly in the transaction.\n\n>> >\n\n>> > Do you mean have little data or just keep the transaction to as\n\n>> > short as it should be?\n\n>> Both, update as few rows and columns as possible and avoid selects\n\n>> within a transaction.\n\n>\n\n> Yes to the latter. I think the former really depends on the business\n\n> model. Sometimes it just can't be helped (or can it?).\n\nRows can, columns can (prepare updates) but I usually do tables rather\n\nthen columns.\n\n>\n\n>-am\n\n--\n\nDavid Williams\n\nDavid Williams wrote:\n\n>\n\n> Anthony Mandic writes\n\n> >David Williams wrote:\n\n> >\n\n> >> But what if the user wants to be able to undo all the changes they\n\n> >> made since they entered the screen?\n\n> >\n\n> > Er? Perhaps I didn't make myself clear enough. I'm not advocating\n\n> > that you do the changes immediately. I should have said after the\n\n> > user commits, you process the changes. Doing it concurrently is a\n\n> > nightmare. Of course, there's no easy way to roll back after the\n\n> > commit.\n\n> >\n\n> So if the user deletes 1000 rows, where do you store them. Not in the\n\n> screen array because they are visible....\n\n>\n\n> what if the user deletes, then inserts a new row in the same entry in\n\n> the array?\n\nWell, now we're entering the territory of screen/form display\n\ndesign. You'd have to decide whether you'd want to display the\n\ndeleted rows by having them marked as deleted or not. Then the user\n\nwould be at liberty to undelete or alter etc. A delete/insert\n\nis really an update - however this depends on the design of\n\nthe key(s) and the business rules. In a audited system you may\n\nnot be allowed to physically delete a row once its been\n\nadded, you can only mark it as inactive (or whatever) and\n\nrecord details like who and when.\n\n> >> b) how do DBA indentify stale locks.\n\n> >\n\n> > Check against existing user connections. I had a stored procedure\n\n> How? Session ids can wrap and be reused...\n\nTrue, but you'd have to have to have a very active system for\n\nthem to do so so quickly. But you have more than one id to\n\nhelp - the OS's process id and the server's user process id.\n\nWhat's the likelihood of them both being the same ones again for\n\nthe same user? I'd never seen the problem come up. But this isn't\n\nto say that it might happen.\n\n> > Data consistency/integrity. End users could pick up where they\n\n> > left off by finding their last lock. The app also stored current\n\n> > info on the client side (via files). This minimised data loss\n\n> > (critical when its a paperless office. Data came in over the\n\n> > phone).\n\n> the client cannot gurantee to remember about stale lock, what happens\n\n> if they power supply fails on the client (or the cleaner pulls the\n\n> plug to plug in her Hooever - it has happened).\n\nYep, thats what was being guarded against. The app could have\n\nbeen termed overly retentive for this reason. It had to be\n\nas failsafe as possible. If a connection failed the app was\n\nsmart enough to be able to reconnection when possible and\n\ncontinue. If it died it could recover from its client-side\n\ncreated files. It didn't give up without a fight. But of course,\n\nthis didn't mean that we became complacent.\n\n> Debug logs,screen messages.\n\nYep, anything and everything.\n\n> >> So does Informix 4GL, with startlog() function, all errors are t\n\n> >> trapped by the Informix runtime library and logged.\n\n> >\n\n> > Good, thats the correct approach. Except that it only relates\n\n> > to the server side of things. You'd have to rely on core dumps\n\n> > (if on UNIX) and/or a debugger to debug a client app. Note that\n\n> > there are two basic scenarios, the app failing or the app working\n\n> > but doing the wrong thing. Which is harder to resolve?\n\n> >\n\n> Either is easy with debug logs. Switch on, get a trace, debug it.\n\n> Most debugging can be narrowed down to one screen operation by the\n\n> user, plaster with debug and that 's it.\n\nThis is a point in time issue. But you have to work back thru\n\nthe app to work out how it got into that state and how the\n\ndata became incorrect. Often times it was as the result of\n\nsome hairly written code in a module made by a programmer\n\nwho either didn't have a proper grasp of what was required or\n\ndidn't care.\n\nOf course, we've drifted off topic now. But while we're here,\n\nhow many others have designed apps to guard against problems\n\nand what measures did they take?\n\n-am\n\nPablo Sanchez <pa...@sgi.com> wrote:\n\n>>>>>> \"Gary\" == Gary Kuever <gku...@ix.netcom_remove_this_.com> writes:\n\n>Gary>\n\n>Gary> 2 - On the minus side of row locking, it encourages developers to continue\n\n>Gary> with a record oriented mentality instead of a set mentality. An example is\n\n>Gary> Oracle's row_id. I've seen this on every Oracle project, i.e. the shortcut\n\n>Gary> is taken instead of thinking the set operation through properly.\n\n>Gary>\n\n>... and of course you end up with crappier performance with\n\n>the row at a time vs set based approach.\n\n>I was doing a bench for a customer and they were doing some\n\n>nightly processing... looking at their code, I saw that one\n\n>section was taking 2.5 hours. I rewrote it and that same\n\n>section took a couple of minutes.\n\n>What was the magic? Converted their row at a time logic to\n\n>set based logic.\n\nSure, that is the way to go. But in this set based logic it still\n\nwould be nice if just the involved members of the set get locked when\n\nupdating the set, and not all other members in the same table that\n\njust happen to be in the neighbourhood.\n\nThat is the point RLL fans try to make, not that they want to process\n\n10,000 rows in a 1,000,000 row table one at a time.\n\nIf I update all rows with an odd key, I do not want to block others\n\nthat are only interested in even keys (for example).\n\nI think we actually don't disagree, it's just that some people just\n\nwant RLL because of their way of thinking (and it's that mindset that\n\nthe PLL defenders are arguing against in this and the previous\n\nthread), but some others see valid arguments in favor of RLL in a well\n\ndesigned application (which IMO are not refuted by the PLL defenders\n\nin the current threads, better yet: which are agreed on).\n\nIn my opinion, to summarize the current status quo:\n\n1. We all are against a row-at-a-time approach to application design\n\n2. We all see PLL schemes perform better than RLL schemes\n\n(not going into the reasons why...)\n\n3. We all see RLL advantages in that it gives a better relational/\n\nsetwise granularity with less unintended dependencies between rows\n\nin a table.\n\nThat will conclude my contribution to this thread (unless ... ;-)\n\n\n\n>>>>> \"Jean-Marc\" == Jean-Marc van Leerdam <Jean-Marc....@xxremovexx.ingbank.com> writes:\n\nJean-Marc>\n\nJean-Marc> In my opinion, to summarize the current status quo:\n\nJean-Marc>\n\nJean-Marc> 1. We all are against a row-at-a-time approach to application design\n\nJean-Marc> 2. We all see PLL schemes perform better than RLL schemes\n\nJean-Marc> (not going into the reasons why...)\n\nJean-Marc> 3. We all see RLL advantages in that it gives a better relational/\n\nJean-Marc> setwise granularity with less unintended dependencies between rows\n\nJean-Marc> in a table.\n\nJean-Marc>\n\nI concur with your points one and two (and of course) not three.\n\nThat is, the type of granularity that you are describing\n\nisn't fine enough such that RLL would give you a benefit.\n\nIf we were talking about something like database locking vs\n\nPLL/RLL then I'd concur with item number three.\n\nNow, to restate my position, I have *never* said that RLL is\n\nnot good, what I have said is that RLL vs. PLL isn't worth\n\nall the hype that the RDBMS vendors would like you to\n\nbelieve. That's my point... I argue this position using a\n\nnormalized OLTP application: TPC-C's. With the TPC-C's,\n\nit's shown that an RDBMS doing page-level locking can\n\noutperform an RDBMS doing row-level locking (at this point\n\nin time*).\n\nWhen it comes to performance, what I look at are two issues:\n\nBandwidth vs. Latency\n\nBandwidth is pretty easy to solve: faster network, wise use\n\nof stored procedures, scalable hardware, appropriate\n\ndistribution of data (be it 'data' and/or 'log) on\n\ndisk... anyway, you can Throw Hardware At It [tm] for this\n\ntype of solution.\n\nLatency is the tougher one to deal with. Whether it's how\n\nthe RDBMS implements its own mutex'ing or the application\n\nholding locks too long or row-at-a-time processing or the\n\nO/S not scaling with a system call's invocation ... you get\n\nmy drift... it's a tough cookie to solve because it requires\n\ncode changes: app, O/S, RDBMS\n\n(For the record, our group is responsible for the porting of\n\nInformix/Oracle/Sybase to our platform... I get to see the\n\nproblems involved with all three RDBMS... hence, why I can\n\nhave no opinion on which is \"best\").\n\nIf we have a problem where the application is holding locks\n\nfor too long, it's not going to be solved with RLL. It's\n\ngoing to be solved by educating the app developers and\n\nre-writing those transactions. Because as those who are\n\nfamiliar with performance and tuning, it's a process of\n\nrefinement.\n\nLive with this motto and you'll live a long and wonderful life:\n\nFor an OLTP app, short transactions are a Good Thing [tm].\n\n* - TPC-C's are somewhat worthless, IMHO, because they\n\nreally are just snapshots in time and they aren't too\n\nrealistic:\n\no using only about 300MB out of a 4gig drive\n\no a >20 *minute* checkpoint\n\nTake a look at some executive summaries in www.tpc.org\n\n\n\nro...@candle.pha.pa.us wrote:\n\n> Let's suppose an order-entry app, with a customer table that has\n\n> row-level locking, and an order table with page-level locking.\n\n>\n\n> Why can't the app do a SELECT FOR UPDATE on the customer table for the\n\n> requested customer, do a non-locking SELECT on the order table, then\n\n> UPDATES on the order table, then release the lock on the customer table?\n\n>\n\n> This would seem to be the best of both worlds, with row-level locking\n\n> overhead only on the table that needs it, and it is kept while the user\n\n> is browsing the order table.\n\n>\n\n> Can't do this without the capability of row-level locking, and the nice\n\n> thing is you can do RLL only on the tables that need it.\n\n>\n\n> How are people locking the rows while people are browsing if they use\n\n> PLL? My guess is they are using the external lock mechanisms mentioned,\n\n> like lock table with lock entries.\n\nYes, any approach you take is possible. How effectively it\n\nworks needs to be measured. I'd been thinking about the\n\nissues raised in this thread over the weekend, and came\n\nup with a new server-side locking model. Basically, it\n\ntakes the idea of the \"soft lock\" to create an \"heirarchical\n\nobject lock\". All elements participating in this lock would\n\nbe defined either thru the table creation statement or an\n\nexplicit statement to identify which column participates\n\n(in other words, how its usually defined). Only one\n\nlock need be generated, that being for the top element\n\nof the heirarchy (in the above example, on the customer).\n\nAll customer-related data with a matching relational\n\nkey automatically participates in the lock. The lock\n\nplacement syntax would be the same, e.g. \"select for update\".\n\nThe lock would need to be explicitly released, however.\n\nThe advantage here is that only one lock is ever required.\n\nThis does away with physical row and page locks, but adds\n\nan overhead in that the server will need to check keys\n\nselect for locking against existing locked keys (in other\n\nwords, about the same overhead as existing lock tests).\n\nThe lock granularity can be enhanced by specifying which\n\nfields are likely to be affect for a table that participates\n\nin this locking model. This means that you could do column\n\nlocking (someone mentioned finer locking than row level in\n\none post in this thread).\n\nWhat does everyone else think? Is this feasable?\n\n-am\n\nPablo Sanchez wrote:\n\n>\n\n>\n\n> I have yet to see you refute any of my points regarding row\n\n> level vs page level locking. For a well written\n\n> application, and isn't that what you strive for?, it simply\n\n> doesn't matter.\n\n>\n\nGee, well, I guess you talked me in to this.\n\nTry writing a hotel reservation system for a major national hotel chain.\n\nRead: Hyatt or something like that. ;-)\n\nTry booking a reservation in a major city like New York.\n\n(Multiple properties, multiple nights and multiple rates.)\n\nOh, and lets not forget the multiple DSRs (Dumb Shit Receptionists) who are\n\ntrying to access this system..... ;-)\n\nNow I am sure that you can do a work around, to COMPENSATE for page\n\nlocking, but why? Row level locking is a much simpler solution. Of course it would be nice to\n\nallow for locking within a nested transaction, and even allow for nesting of transactions.\n\nBut hey that's beyond the immeadiate question.\n\nLets also look at other applications where row level locking is important.\n\nHmmm, OK, how about in the financial industry?\n\nIn a mortgage generation application ?\n\nOr how about in a travel industry application like a flight reservation system?\n\nOr in the telecommunication industry?\n\nOr in a realtime inventory control / POS system?\n\nTrue, you can write these with page level locks, however you won't get the performance,\n\nand you will have to write extra code to compensate.\n\nSorry Pablo, defend Sybase on another point. Surely there are things that Sybase does that\n\nInformix can't right? I mean, take Oracle for instance. They have some neat indexing\n\ntechniques that Informix lacks.\n\n-Just food for thought.\n\n>>>>> \"Michael\" == Michael Segel <Mi...@NOSPAM.King.of.MyDomain.NOSPAM.Segel.com> writes:\n\nMichael>\n\nMichael> [ examples deleted ]\n\nMichael>\n\nMichael> True, you can write these with page level locks,\n\nMichael> however you won't get the performance, and you will\n\nMichael> have to write extra code to compensate.\n\nWhat do you base your assertion that \"you won't get the\n\nperformance\"? The applications you talked about are all\n\napplications that require a highly tuned application in\n\norder to get excellent performance.\n\nIf you look at the TPC-C's (as I've mentioned, before)\n\nyou'll see another highly tuned (OLTP) application. If I\n\ncompare the *currently* submitted numbers for Sybase\n\nvs Informix I see the following:\n\nSybase..... 39,469 tpmC\n\nInformix... 24,309 tpmC\n\nThat's a 62% performance increase by using Sybase. Now I\n\ngrant you that I believe that we'll see Informix\n\nInc. publishing even higher numbers but that's not my\n\npoint. My point is:\n\nFor a finely tuned application, row level locking\n\ndoes *not* matter.\n\nThe numbers don't support it.\n\nI don't see you producing any factual data to prove your\n\npoint. I'd be more than happy to look at any factual and\n\nobjective data you produce.\n\nAs for writing \"extra code to compensate\", this is a\n\nsubjective remark. I think the code difference between the\n\ntwo is minor enough...\n\nMichael> Sorry Pablo, defend Sybase on another point. Surely\n\nMichael> there are things that Sybase does that Informix\n\nMichael> can't right? I mean, take Oracle for instance. They\n\nMichael> have some neat indexing techniques that Informix\n\nMichael> lacks.\n\nHonestly, this has nothing to do with Sybase. It has to do\n\nwith marketing hype as I've said all along. You've\n\nswallowed the row-level is better than page-level pill. It\n\nsorta makes sense but unfortunately the facts don't support\n\nit. It's marketing hype.\n\n* TPC information can be gleaned from www.tpc.org\n\n\n\n>>>>> \"Gary\" == Gary L Burnore <gburnore> writes:\n\nGary>\n\nGary> You DOUBT? Meaning you don't know?\n\nNope, I don't know SABRE nor \"The Other\" application well\n\nenough to say. If the system crashes when I'm booking a\n\nflight, though, I don't lose my seat therefore I believe my\n\nassertion is correct.\n\nGary> Figures.\n\n[ ignored ]\n\nGary> :\n\nGary> :Gary> Row level locking is quite important in some\n\nGary> :Gary> instances.\n\nGary> :\n\nGary> :As I've said, if you look at the TPC-C you can see that for\n\nGary> :a well behaved application there isn't a problem. How do\n\nGary> :you refute that Sybase currently has a higher tpmC value\n\nGary> :than Informix? After all, TPC-C's are OLTP and Informix has\n\nGary> :row level locking. Answer that for me...\n\nGary>\n\nGary> I'm not refuting it. I'm saying it's not based on\n\nGary> Sybases lack of row-level locking.\n\nI can't parse the above point. Would you elaborate?\n\nGary> Look, why not just admit that you like Sybase better\n\nGary> and that's that.\n\nSybase is fine and so is Informix and as a matter of fact, I\n\nlike Oracle's architecture too. They all have problems and\n\ngood points. As a developer it's important to exploit the\n\ngood points rather than the bad one's. But I stray...\n\nGary> It's obvious by your posts that's what's true here.\n\nGary> You're not being unbiased about it at _ALL_.\n\nWhat is obvious is that row level locking doesn't buy you\n\nwant you *think* it's buying you when you have a finely\n\ntuned application. All the examples pointed out to me by\n\nfolks have been cases of finely tuned apps. See my post to\n\nMike Segal on finely tuned app's.\n\nFacts don't show bias. I'm willing to listen to any facts\n\nthat you have to support your claims. As of yet, I've seen\n\nnone.\n\n\n\nPablo Sanchez wrote:\n\n> Nope, I don't know SABRE nor \"The Other\" application well\n\n> enough to say. If the system crashes when I'm booking a\n\n> flight, though, I don't lose my seat therefore I believe my\n\n> assertion is correct.\n\n>\n\nNo, you don't have your seat until you get a confirmation number.Its that simple.\n\n(Confirmation numbers occur after the transaction is completed.\n\nIts obvious you haven't written a hotel reservation system.\n\nMy whole point is that this thread is a waste of breathe.\n\nConceputaly the finer the granularity of locks acheived, the better the application\n\nwill\n\nbehave and the easier it is to implement an OLTP application.\n\nNow, as to TPC benchmarks, why don't you print the configurations used. :-)\n\n(Yes Virginia, I have done benchmarking and I know that everyone cheats:-)\n\n> Gary> I'm not refuting it. I'm saying it's not based on\n\n> Gary> Sybases lack of row-level locking.\n\n>\n\n> I can't parse the above point. Would you elaborate?\n\n>\n\nHe's saying that there are other things that Sybase does well, inspite of not\n\nhavingrow level locking. Would you care to elaborate. It was the same point I was\n\ntrying to\n\nmake. Only you thought to say SNIP! :-)\n\n> Sybase is fine and so is Informix and as a matter of fact, I\n\n> like Oracle's architecture too. They all have problems and\n\n> good points. As a developer it's important to exploit the\n\n> good points rather than the bad one's. But I stray...\n\n>\n\nNo, this whole thread is a stray. That's the point I was trying to make since\n\nitssilly to say that page level locking is better than row level locking.\n\n> What is obvious is that row level locking doesn't buy you\n\n> want you *think* it's buying you when you have a finely\n\n> tuned application. All the examples pointed out to me by\n\n> folks have been cases of finely tuned apps. See my post to\n\n> Mike Segal on finely tuned app's.\n\n>\n\nUhmm, well no. Scale your application up. Increase the number of users.Then lets\n\ntalk about performance. Please understand that IMHO, the best place to tune a\n\nsystem is at the app level, not the db engine. Of course, a well tuned engine is\n\nimportant.\n\n> Facts don't show bias. I'm willing to listen to any facts\n\n> that you have to support your claims. As of yet, I've seen\n\n> none.\n\nWell, how many retail customers use Sybase? Reservation Systems?(SABRE is still\n\nmainframe AFAIK)\n\nThat's the real test.\n\n-Mikey\n\n>>>>> \"Michael\" == Michael Segel <Mi...@NOSPAM.King.of.MyDomain.NOSPAM.Segel.com> writes:\n\nMichael>\n\nMichael> Conceputaly the finer the granularity of locks\n\nMichael> acheived, the better the application will behave\n\nMichael> and the easier it is to implement an OLTP\n\nMichael> application.\n\nand you ignore the fact that there's added overhead with row\n\nlevel locking. When you consider the *whole* picture, you\n\nsoon see that it doesn't make a difference.\n\nMichael> Now, as to TPC benchmarks, why don't you print the configurations used. :-)\n\nThey're lengthy... but I've told people where to look for\n\nthem (and I'll do it again: www.tpc.org). But if you\n\ninisist on the other number, for the Sybase number that\n\nbeats Informix, we have $94.18/tpmC vs $139.04/tpmC for\n\nInformix. It's cheaper to use Sybase and you get 60+%\n\nbetter performance.\n\nMichael> (Yes Virginia, I have done benchmarking and I know\n\nMichael> that everyone cheats:-)\n\nThere are FDR's for the TPC-C's. Tell me on these two\n\nbenches where people \"cheated\".\n\nI grant you that TPC-C's aren't true real world but it's the\n\nbest that we have for a normalized application. Not\n\nsomething silly like \"well my hotel reservation system ran\n\ngreat using product X and sucked on product Y\" All that\n\nproves is that someone may not have known how to write an\n\napplication. Big deal.\n\nMichael> He's saying that there are other things that Sybase\n\nMichael> does well, inspite of not havingrow level\n\nMichael> locking. Would you care to elaborate. It was the\n\nMichael> same point I was trying to make. Only you thought\n\nMichael> to say SNIP! :-)\n\nThe issue has never been whether Sybase does row level or\n\npage level locking. I'm just talking about the issue\n\nitself on row level vs page level locking. You and he keep\n\nwanting to try and drag Sybase into this whole thread. I\n\ncould care less about Sybase at this point. I only bring in\n\nSybase because it's the only RDBMS at this point in time\n\ndoing page level locking. And it's proven with the -C's\n\nthat it's not an issue. But you seem to conveniently ignore\n\nthe fact that Sybase currently beats the pants off of\n\nInformix.\n\nAssuming that there was some cheating, are you saying that\n\nthere was sufficient cheating to warrant a 60+% performance\n\nincrease? I don't think so.\n\nMichael> No, this whole thread is a stray. That's the point I was trying to make since\n\nMichael> itssilly to say that page level locking is better than row level locking.\n\nNo it's not silly and you have yet to refute why it is so.\n\nYou have \"said\" that it is so, but you don't have any\n\n*facts* to support your assertion. You can keep saying it\n\nbut until you can provide some facts to support your\n\nassertion it's hard to give any credibility to your statement.\n\nI have provided you with TPC-C's that prove that it's not an\n\nissue. That's my point that it's not an issue. You have\n\ndone nothing to show contrary. As you say, show me.\n\nMichael> Uhmm, well no. Scale your application up. Increase\n\nMichael> the number of users.\n\nOkay, the TPC-C has for Sybase has 32,000+ users. How many\n\ndo you want? Of course they're mux'd using Tuxedo but\n\nnonetheless the engine is supporting 32,000 users.\n\nMichael> Then lets talk about performance.\n\nOkay, 39,469tpmC's. Is that good enough for you? 60+%\n\ngreater than Informix's current number. Yup, let's talk\n\nabout performance now.\n\nMichael> Please understand that IMHO, the best place to tune a\n\nMichael> system is at the app level, not the db engine. Of course, a well tuned engine is\n\nMichael> important.\n\nI disagree. The best place to tune a system is in its\n\nentirety. You have to consider:\n\no The application\n\no The RDBMS\n\no The hardware\n\nWhat good is it to tune your application when you are CPU\n\nbound, when you are disk bound, when you haven't set\n\nPDQPRIORITY... you have to look at *everything* not just a\n\nsingle component. It's a waste of time otherwise.\n\nMichael> Well, how many retail customers use Sybase?\n\nFEDEX, United Airlines, ....\n\nMichael> Reservation Systems?(SABRE is still\n\nMichael> mainframe AFAIK)\n\nI don't believe it's so. I think that they are using\n\nOracle. United Airline's ticketing uses a mainframe and\n\nthey are looking at getting off of it. NDA prevents me from\n\nfurther discussion on this topic.\n\n\n\nIn article <yutra7x...@mew.corp.sgi.com>, Pablo Sanchez\n\n<pa...@sgi.com> writes\n\n>>>>>> \"Michael\" == Michael Segel <Mi...@NOSPAM.King.of.MyDomain.NOSPAM.Segel.com\n\n>> writes:\n\n>Michael>\n\n>Michael> [ examples deleted ]\n\n>Michael>\n\n>Michael> True, you can write these with page level locks,\n\n>Michael> however you won't get the performance, and you will\n\n>Michael> have to write extra code to compensate.\n\n>\n\n>What do you base your assertion that \"you won't get the\n\n>performance\"? The applications you talked about are all\n\n>applications that require a highly tuned application in\n\n>order to get excellent performance.\n\n>\n\nImagine 1 page with 2 rows one it.\n\n1. Page level locking\n\nUser A updates row 1\n\nAt the same time user B updates row 2. User B has to wait for\n\nUser B to commit.\n\n2. With row level locking\n\nUser A updates row 1\n\nUser B updates row 2 (with no waiting).\n\nHow can 1 be faster than 2 if user B has to wait?\n\n>If you look at the TPC-C's (as I've mentioned, before)\n\n>you'll see another highly tuned (OLTP) application. If I\n\n>compare the *currently* submitted numbers for Sybase\n\n>vs Informix I see the following:\n\n>\n\n> Sybase..... 39,469 tpmC\n\n> Informix... 24,309 tpmC\n\n>\n\n>That's a 62% performance increase by using Sybase. Now I\n\n>grant you that I believe that we'll see Informix\n\n>Inc. publishing even higher numbers but that's not my\n\n>point. My point is:\n\n>\n\nI checked the results, these figure come from different machines.\n\nSo Sybase runs their TPC benchmarks on larger hardware..so?\n\n> For a finely tuned application, row level locking\n\n> does *not* matter.\n\nLock granularity is still a problem. Why do UNIX kernels lock\n\nindividual files and data structures rather than having one large\n\nkernel lock? Try reading\n\nUNIX Systems for Modern Architectures\n\nSysmmetric Multiprocessing and Caching for Kernel Programmers\n\nby Curt Schimmel\n\nAddison-Wesley\n\nISBN 0-201-63338-8\n\n\"If the processes in the application job mix use seperate kernel\n\nresources, each of whose data structures are protected by separate\n\nlocks, then these processes will not contend for the same locks and\n\nwill be able to run simultanueously on different CPUs, whether they\n\nare in user or kernel mode\"\n\nTranslate to databases and internal data structures.\n\n>\n\n>The numbers don't support it.\n\n>\n\n>I don't see you producing any factual data to prove your\n\n>point. I'd be more than happy to look at any factual and\n\n>objective data you produce.\n\n>\n\n>As for writing \"extra code to compensate\", this is a\n\n>subjective remark. I think the code difference between the\n\n>two is minor enough...\n\n>\n\n>Michael> Sorry Pablo, defend Sybase on another point. Surely\n\n>Michael> there are things that Sybase does that Informix\n\n>Michael> can't right? I mean, take Oracle for instance. They\n\n>Michael> have some neat indexing techniques that Informix\n\n>Michael> lacks.\n\n>\n\n>Honestly, this has nothing to do with Sybase. It has to do\n\n>with marketing hype as I've said all along. You've\n\n>swallowed the row-level is better than page-level pill. It\n\n>sorta makes sense but unfortunately the facts don't support\n\n>it. It's marketing hype.\n\n>\n\n>* TPC information can be gleaned from www.tpc.org\n\n--\n\nDavid Williams"
    }
}