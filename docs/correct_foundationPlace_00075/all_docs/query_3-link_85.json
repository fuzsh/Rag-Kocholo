{
    "id": "correct_foundationPlace_00075_3",
    "rank": 85,
    "data": {
        "url": "https://dsf.berkeley.edu/cs262/2005/lecs/systemr.html",
        "read_more_link": "",
        "language": "en",
        "title": "CS262a: System R & DBMS Overview",
        "top_image": "",
        "meta_img": "",
        "images": [],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Joseph M. Hellerstein"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Advanced Topics in Computer Systems\n\nLecture 3\n\nJoe Hellerstein & Timothy Roscoe\n\nSystem R & DBMS Overview\n\nDBMS History\n\nlate 60's: network (CODASYL) & hierarchical (IMS) DBMS. Charles Bachman: father of CODASYL predecessor IDS (at GE in early 1960's). Turing award #8 (1973, between Dijkstra and Knuth.)\n\nIMS Example: Suppliers record type and Parts record type. One is parent, one is child. Each instance identified by a Hierarchical Sequence Key (HSK). Problems include redundancy and requirement of having a parent (deletion anomalies.)\n\nLow-level ``record-at-a-time'' DML, i.e. physical data structures reflected in DML (no data independence).\n\n1970: Codd's paper. The most influential paper in DB research. Set-at-a-time DML. Data independence. Allows for schema and physical storage structures to change under the covers. Papadimitriou: \"as clear a paradigm shift as we can hope to find in computer science\"). Edgar F. Codd: Turing award #18 (1981, between Hoare and Cook).\n\nFocus on separation into 3 levels: physical storage, logical schema, and multiple views.\n\nResults in two kinds of independence: physical data independence, and logical data independence\n\nPhysical allows you change the storage layout without affecting apps. \"DBMS makes right\", hence totally invisible to everyone except in terms of performance.\n\nLogical encapsulates apps from changes in logical schema. \"DBA makes right\" (except in simple cases, when DBMS makes right). Additional flaws with this (can't update views in general). Hence visible to everyone.\n\nData independence CRITICAL for database evolution -- and note that databases live and evolve for a LONG time!\n\nGeneralizing the lesson of data independence:\n\nNeed data indendence when dapp/dt << denvironment/dt, where environment is things like physical storage, machine speed, machine workload, etc.\n\nOther scenarios where this holds?\n\nThis is an early, powerful instance of two themes: levels of indirection (this is a biggie) and adaptivity (done in DBMS on a coarse grain til recent research.)\n\nmid 70's: wholesale adoption of Codd's vision in 2 full-function (sort of) prototypes. Ancestors of essentially all today's commercial systems\n\nIngres : UCB 1974-77\n\na ``pickup team'', including Stonebraker & Wong. early and pioneering. begat Ingres Corp (CA), CA-Universe, Britton-Lee, Sybase, MS SQL Server, Wang's PACE, Tandem Non-Stop SQL.\n\nSystem R : IBM San Jose (now Almaden)\n\n15 PhDs. begat IBM's SQL/DS & DB2, Oracle, HP's Allbase, Tandem Non-Stop SQL. System R arguably got more stuff ``right'', though there was lots of information passing between both groups\n\nJim Gray: Turing Award #22 (1998, between Englebart and Brooks)\n\nLots of Berkeley folks on the System R team, including Gray (1st CS PhD @ Berkeley), Bruce Lindsay, Irv Traiger, Paul McJones, Mike Blasgen, Mario Schkolnick, Bob Selinger , Bob Yost. See\n\nhttp://www.mcjones.org/System_R/SQL_Reunion_95/sqlr95-Prehisto.html#Index71.\n\nBoth were viable starting points, proved practicality of relational approach. Direct example of theory -> practice!\n\nACM Software Systems award #6 shared by both\n\nStated goal of both systems was to take Codd's theory and turn it into a workable system as fast as CODASYL but much easier to use and maintain\n\nInterestingly, Stonebraker received ACM SIGMOD Innovations Award #1 (1991), Gray #2 (1992), whereas Gray got the Turing first.\n\nearly 80's: commercialization of relational systems\n\nEllison's Oracle beats IBM to market by reading white papers.\n\nIBM releases multiple RDBMSs, settles down to DB2. Gray (System R), Jerry Held (Ingres) and others join Tandem (Non-Stop SQL), Kapali Eswaran starts EsVal, which begets HP Allbase and Cullinet\n\nRelational Technology Inc (Ingres Corp), Britton-Lee/Sybase, Wang PACE grow out of Ingres group\n\nCA releases CA-Universe, a commercialization of Ingres\n\nInformix started by Cal alum Roger Sippl (no pedigree to research).\n\nTeradata started by some Cal Tech alums, based on proprietary networking technology (no pedigree to software research, though see parallel DBMS discussion next semester!)\n\nmid 80's: SQL becomes \"intergalactic standard''.\n\nDB2 becomes IBM's flagship product.\n\nIMS \"sunseted''\n\ntoday: network & hierarchical are legacy systems (though commonly in use!)\n\nrelational commoditized -- Microsoft, Oracle and IBM fighting over much of the market. IBM bought Informix, to become solid competitor for #1 with Oracle. MS a strong #3. NCR Teradata is distant #4, and a few others (e.g. Sybase) vying to survive on the fringes. OpenSource coming of age, with MySQL doing well at the low end, and PostgreSQL maturing at the more functional end. BerkeleyDB is an embedded transactional store that is widely used as well\n\nComputer Associates bought Ingres and largely killed it\n\nOracle bought DEC Rdb and largely killed it\n\nInformix bought Illustra (commercial Postgres), incorporated it.\n\nIBM bought Informix, will mostly sunset it.\n\nMicrosoft bootstrapped by buying code to Sybase SQL Server (hence Ingres pedigree)\n\n\"object-relational\" is mainstream (courtesy Postgres)\n\nextension of relational we may talk about as time permits\n\nthink relational + extensible types and downloadable code + rule systems + non-normalized data\n\nInformix, IBM, Oracle, Sybase all claim to sell it today. Microsoft in \"the next version\".\n\nXML has pervaded the relational products as both an interface and a data type, further complicating the \"purity\" of Codd's vision.\n\nRelational System Architecture\n\nDatabases are BIG pieces of software. Typically somewhat hard to modularize. Lots of system design decisions at the macro and micro scale. We will focus mostly on micro decisions -- and hence ideas reusable outside DBMSs -- in subsequent lectures. Here we focus on macro design.\n\nDisk management choices:\n\nfile per relation\n\nbig file in file system\n\nraw device\n\nProcess Model:\n\nprocess per user\n\nserver\n\nmulti-server\n\nBasic modules:\n\nparser\n\nquery rewrite\n\noptimizer\n\nquery executor\n\naccess methods\n\nbuffer manager\n\nlock manager\n\nlog/recovery manager\n\nQuery Rewriter\n\nFlattens views (why?)\n\nmay change query semantics (constraints, protection, etc.)\n\nOptimizer\n\nlarge space of equivalent relational plans\n\npick one that's going to be \"optimal\" (?)\n\nproduces either an interpretable plan tree, or compiled code\n\nExecutor\n\nmodules to perform relation operations like joins, sorts, aggregations, etc.\n\ncalls Access Methods for operations on base and temporary relations\n\nAccess Methods\n\nuniform relational interface (open, get next), a la INGRES AMI, System R's RSS\n\nmultiple implementations: heap, B-tree, extensible hashing\n\nBuffer Manager\n\nIntelligent user-level disk cache\n\nmust interact with transaction manager & lock manager\n\nVirtual memory does not cut it! (we'll discuss this at length)\n\nLock Manager\n\nmust efficiently support lock table\n\nSystem R architecture influential:\n\nphysical and logical locks treated uniformly\n\nmultiple granularity of locks\n\nset intent locks at high levels\n\nwe will study this in more detail later (Gray)\n\ndeadlock handling: detection\n\nLog/Recovery Manager\n\n\"before/after\" log on values\n\ncheckpoint/restore facility for quick recovery\n\nRedo/Undo on restore\n\nSupport soft crashes off disk, hard crashes off tape.\n\nSystem R?s shadowing is too slow. Use Write-Ahead Logging! (WAL) More on this to come.\n\nHard to get right!\n\nNotes on System R\n\nSee the System R reunion notes for fun background and gossip.\n\nSome \"systems chestnuts\" seen in this paper:\n\nExpect to throw out the 1st version of the system\n\nExpose internals via standard external interfaces whenever possible (e.g. catalogs as tables, the /proc filesystem, etc.)\n\nOptimize the fast path\n\nInterpretation vs. compilation vs. intermediate \"opcode\" representations\n\nComponent failure as a common case to consider\n\nProblems arising from interactions between replicated functionality (in this case, scheduling)\n\nSome important points of discussion\n\nFlexibility of storage mechanisms: domains/inversions vs. heap-files/indexes. Use of TID-lists common in modern DBMS. Why be doctrinaire? What about Data Independence? One answer: you have to get transactions right each time.\n\nSystem R was often CPU bound (though that's a coarse-grained assertion -- really means NOT disk-bound). This is common today in well-provisioned DBMSs as well. Why?\n\nDBMSs are not monolithic designs, really. The RSS stuff does intertwine locking and logging into disk access, indexing and buffer management. But RDS/RSS boundary is clean, and RDS is decomposable.\n\nAccess control via views: a deep application of data independence?!\n\nTransactional contribution of System R (both conceptual and implementation) as important as relational model, and in fact should be decoupled from relational model.\n\nThe \"Convoy Problem\":\n\nA classic cross-level scheduling interaction. We will see this again!\n\nPoorly explained in the paper.\n\nI have always found this presentation confusing. A number of issues are going on. The first two have to do with interactions between OS and DB scheduling:\n\nthe OS can preempt a database \"process\" even when that process is holding a high-traffic DB lock\n\nDB processes sitting in DB lock queues use up their OS scheduling quanta while waiting (this is poorly explained in the text). Once they use up all their quanta, they get removed from the \"multiprogramming set\" and go to \"sleep\" -- and an expensive OS dispatch is required to run them again.\n\nThe last issue is that\n\nthe DBMS uses a FCFS wait queue for the lock.\n\nFor a high-traffic DB lock, DB processes will request it on average every T timesteps. If the OS preempts a DB process holding that high-traffic DB lock, the queue behind the lock grows to include almost all DB processes. Moreover, the queue is too long to be drained in T timesteps, so it's \"stable\" -- every DB process queues back up before the queue drains, and they burn up their quanta pointlessly waiting in line, after which they are sent to sleep. Hence each DB process is awake for only one grant of the lock and the subsequent T timesteps of useful work, after which they queue for the lock again, waste their quanta in the queue, and are put back to sleep. The result is that the useful work per OS waking period is about T timesteps, which is shorter than the overhead of scheduling -- hence the system is thrashing.\n\nNote that the solution attacks the only issue in the previous comment that can be handled without interating with the OS: (c) the FCFS DB lock queue. The explanation here is confusing, I think. The point is to always allow any one of the DB processes currently in the \"multiprogramming set\" to immediately get the lock without burning a quantum waiting on the lock -- hence no quanta are wasted on waiting, so each process spends almost all of its alloted quanta on \"real work\". Note that the proposed policy achieves this without needing to know which processes are in the OS' multiprogramming set.\n\nSystem R and INGRES are the prototypes that all current systems are based on. Basic architecture is the same, and many of the ideas remain in today's systems:\n\noptimizer remains, largely unchanged\n\nRSS/RDS divide remains in many systems\n\nSQL, cursors, duplicates, NULLs, etc.\n\nthe pros and cons of duplicates. Alternatives?\n\npros and cons of NULLs. Alternatives?\n\ngrouping and aggregation\n\nupdatable single-table views\n\nbegin/end xact at user level\n\nsavepoints and restore\n\ncatalogs as relations\n\nflexible security (GRANT/REVOKE)\n\nintegrity constraints\n\ntriggers (!!)\n\nclustering\n\ncompiled queries\n\nB-trees\n\nNest-loop & sort-merge join, all joins 2-way\n\ndual logs to support log failure\n\nStuff they got wrong:\n\nshadow paging\n\npredicate locking\n\nSQL language\n\nduplicate semantics\n\nsubqueries vs. joins\n\nouter join\n\nrejected hashing\n\nDatabase View of Applications\n\nBig, complex record-keeping applications like SAP and PeopleSoft, which run over a DBMS. \"Enterprise applications\" to keep businesses humming. A smattering:\n\nERP: Enterprise Resource Planning (SAP, Baan, PeopleSoft, Oracle, IBM, etc.)\n\nCRM: Customer Relationship Management (E.phiphany, Siebel, Oracle, IBM, etc.)\n\nSCM: Supply Chain Management (Trilogy, i2, Oracle, IBM, etc.)\n\nHuman Resources, Direct Marketing, Call Center, Sales Force Automation, Help Desk, Catalog Management, etc.\n\nMany e-business versions of order-entry/procurement and the above (i.e. web serving packages for this)\n\nIntegrated B2B versions of all this rolling as fast as possible\n\nA main job of DBMS is to make these kinds of apps easy to write\n\nOS and DBMS: Philosophical Similarities & Differences\n\nUNIX paper: \"The most important job of UNIX is to provide a file system\".\n\nUNIX and System R are both \"information management\" systems!\n\nboth also provide programming APIs for code\n\nDifference in focus: Bottom-Up (elegance of system) vs. Top-Down (elegance of semantics)\n\nmain goal of UNIX was to provide a small elegant set of mechanisms, and have programmers (i.e. C programmers) build on top of it. As an example, they are proud that \"No large 'access method' routines are required to insulate the programmer from system calls\". After all, OS viewed its role as presenting hardware to computer programmers.\n\nmain goal of System R and Ingres was to provide a complete system that insulated programmers (i.e. SQL + scripting) from the system, while guaranteeing clearly defined semantics of data and queries. After all, DBMS views its role as managing data for application programmers.\n\nAffects where the complexity goes!\n\nto the system, or the end-programmer?\n\nquestion: which is better? in what environments?\n\nfollow-on question: are internet systems more like enterprise apps (traditionally built on DBMSs) or scientific/end-user apps (traditionally built over OSes and files)? Why?\n\nAchilles' heel of RDBMSs: a closed box\n\nCannot leverage technology without going through the full SQL stack\n\nOne solution: make the system extensible, convince the world to download code into the DBMS\n\nAnother solution: componentize the system (hard? RSS is hard to bust up, due to transaction semantics)\n\nAchilles' heel of OSes: hard to decide on the \"right\" level of abstraction\n\nAs we'll read, many UNIX abstractions (e.g. virtual memory) hide *too* much detail, messing up semantics. On the other hand, too low a level can cause too much programmer burden, and messes up the elegance of the system\n\nOne solution: make the system extensible, convince the fancy apps to download code into the OS\n\nAnother solution: componentize the system (hard, due to protection issues)\n\nTraditionally separate communities, despite subsequently clear need to integrate\n\nUNIX paper: \"We take the view that locks are neither necessary nor sufficient, in our environment, to prevent interference between users of the same file. They are unnecessary because we are not faced with large, single-file data bases maintained by independent processes.\"\n\nSystem R: \"has illustrated the feasibility of compiling a very high-level data sublanguage, SQL, into machine-level code\".\n\nSo, a main goal of this class is to work from both of these directions, cull the lessons from each, and ask how to use these lessons today both within and OUTSIDE the context of these historically separate systems."
    }
}