{
    "id": "dbpedia_6614_1",
    "rank": 25,
    "data": {
        "url": "https://contentmarketinginstitute.com/articles/score-content-success/",
        "read_more_link": "",
        "language": "en",
        "title": "Content Assets: Score for Long",
        "top_image": "https://contentmarketinginstitute.com/wp-content/uploads/2022/01/how-set-up-content-scoring-process-better-decisions.png",
        "meta_img": "https://contentmarketinginstitute.com/wp-content/uploads/2022/01/how-set-up-content-scoring-process-better-decisions.png",
        "images": [
            "https://contentmarketinginstitute.com/wp-content/uploads/2023/08/CMI-Logo-1-2023.png",
            "https://contentmarketinginstitute.com/wp-content/uploads/2024/07/logo_pma_menu_20.png",
            "https://contentmarketinginstitute.com/wp-content/uploads/2023/08/CMI_Salary_Landing_Download.png",
            "https://contentmarketinginstitute.com/wp-content/uploads/2024/01/CMWorld_SD_1200.png",
            "https://contentmarketinginstitute.com/wp-content/uploads/2022/01/how-set-up-content-scoring-process-better-decisions.png",
            "https://secure.gravatar.com/avatar/3e7482c503143a215a11dcd2cb47eb74?s=300&r=pg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Lindy Roux"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Learn how to create a scorecard to see how your content is performing qualitatively and quantitatively – Content Marketing Institute",
        "meta_lang": "en",
        "meta_favicon": "https://contentmarketinginstitute.com/wp-content/uploads/2023/08/cropped-cropped-cmi-favicon-large-1-32x32.png",
        "meta_site_name": "Content Marketing Institute",
        "canonical_link": "https://contentmarketinginstitute.com/articles/score-content-success/",
        "text": "Updated January 11, 2022\n\nWant a balanced and actionable way to know whether your content is doing what it’s supposed to do?\n\nCreate a content scorecard.\n\nA content scorecard allows for normalized scoring based on benchmarks determined by the performance of similar content in your industry or your company’s content standards.\n\nIt marries both qualitative and quantitative assessments. Quantitative scores are based on performance metrics such as views, engagement, SEO rank, etc. Qualitative scores are derived from predetermined criteria, such as readability, accuracy, and voice consistency (more on that in a bit).\n\nA #content scorecard marries qualitative and quantitative assessments, says @lindroux via @CMIContent. Share on X\n\nLet’s get to work to create a content scorecard template you can adapt for your situation.\n\nEstablish your quantitative success indicators\n\nFirst, you must measure what matters. What is the job for that piece of content?\n\nFor example, an index or landing page is rarely designed to be the final destination. If a reader spends too long on that kind of page, it’s likely not a good sign. On the other hand, a long time spent on a detailed article or white paper is a positive reflection of user engagement. Be specific with your content goals when deciding what to measure.\n\nWhat should you measure based on the content’s purpose? Here are some ideas:\n\nExposure – content views, impressions, backlinks\n\nEngagement – time spent on page, clicks, rating, comments\n\nConversion – purchase, registration for gated content, return visits, click-throughs\n\nRedistribution – shares, pins\n\nAfter you’ve identified your quantitative criteria, you need to identify the benchmarks. What are you measuring against? Industry standards? Internal standards? A little of both?\n\nA good starting point for researching general user behavior standards is the Nielsen Norman Group. If you seek to focus on your industry, look at your industry marketing groups or even type something like “web metrics for best user experience in [INDUSTRY].”\n\nFind out general web user behavior standards from @NNGroup research, advises @lindroux via @CMIContent. Share on X\n\nBelow is a sample benchmark key. The left column identifies the metric, while the top row indicates the resulting score on a scale of 1 to 5. Each row lists the parameters for the metric to achieve the score in its column.\n\nSample Quantitative Content Score 1-5 *\n\n*Values should be defined based on industry or company benchmarks.\n\nUsing a 1-to-5 scale makes it easier to analyze content that may have different goals and still identify the good, the bad, and the ugly. Your scorecard may look different depending on the benchmarks you select.\n\nHow to document it\n\nYou will create two quantitative worksheets.\n\nLabel the first one as “Quantitative benchmarks.” Create a chart (similar to the one above) tailored to identify your key metrics and the ranges needed to achieve each score. Use this as your reference sheet.\n\nLabel a new worksheet as “Quantitative analysis.” Your first columns should be content URL, topic, and type. Label the next columns based on your quantitative metrics (i.e., page views, return visitors, trend in page views).\n\nAfter adding the details for each piece of content, add the score for each one in the corresponding columns.\n\nRemember, the 1-to-5 rating is based on the objective standards you documented on the quantitative reference worksheet.\n\nDetermine your qualitative analytics\n\nIt’s easy to look at your content’s metrics, shrug, and say, “Let’s get rid of everything that’s not getting eyeballs.” But if you do, you risk throwing out great content whose only fault may be it hasn’t been discovered. Scoring your content qualitatively (using a different five-point scale) helps you identify valuable pieces that might otherwise be buried in the long tail.\n\nIn this content scorecard process, a content strategist or someone equally qualified on your team/agency analyzes the content based on your objectives.\n\nTIP: Have the same person review all the content to avoid any variance in qualitative scoring standards.\n\nHere are some qualitative criteria we’ve used:\n\nConsistency – Is the content consistent with the brand voice and style?\n\nClarity and accuracy – Is the content understandable, accurate, and current?\n\nDiscoverability – Does the layout of the information support key information flows?\n\nEngagement – Does the content use the appropriate techniques to influence or engage visitors?\n\nRelevance – Does the content meet the needs of all intended user types?\n\nTo standardize the assessment, use yes-no questions. One point is earned for every yes. No point is earned for a no. The average qualitative score is then determined by adding up the yes points and dividing the total by the number of questions for the category.\n\nTo standardize a qualitative #content assessment, use yes-no questions, says @lindroux via @CMIContent. Share on X\n\nThe following illustrates how this would be done for the clarity and accuracy category as well as discoverability. Bold indicates a yes answer.\n\nClarity and accuracy: Is the content understandable, accurate, and current?\n\nIs the content understandable to all user types?\n\nDoes it use appropriate language?\n\nIs content labeled clearly?\n\nDo images, video, and audio meet technical standards so they are clear?\n\nScore: 3/4 * 5 = 3.8\n\nDiscoverability: Does the layout of information on the page support key information flows? Is the user pathway to related answers and next steps clear and user-friendly?\n\nIs content concise and scannable?\n\nDoes the information hierarchy reflect key page purpose? (Flow of the page)\n\nDoes content clearly communicate specific and helpful calls to action?\n\nIs content layout/organization consistent?\n\nIs content SEO-friendly?\n\nScore: 1/5 * 5 = 1.0\n\nTIP: Tailor the questions in the relevance category based on the information you can access. For example, if the reviewer knows the audience, the question, “Is it relevant to the interests of the viewers,” is valid. If the reviewer doesn’t know the audience, then don’t ask that question. But almost any reviewer can answer if the content is current. So that would be a valid question to analyze.\n\nHow to document it\n\nCreate two qualitative worksheets.\n\nLabel the first worksheet “Qualitative questions.”\n\nThe first columns are the content URL, topic, and type. Then section the columns for each category and its questions. Add the average formula to the cell under each category label.\n\nLet’s illustrate this following on the example above:\n\nAfter the content details, label the next column “Clarity and accuracy,” and add a column for each of the four corresponding questions.\n\nThen go through each content piece and question, inputting a 1 for yes and a 0 for no.\n\nTo calculate the average rating for clarity and accuracy, input this formula into the cell “=(B5+B6+B7+B8)/4” to determine the average for the first piece of content.\n\nFor simpler viewing, create a new worksheet labeled “Qualitative analysis.” Include only the content information accompanied by the category averages in each subsequent column.\n\nPut it all together\n\nWith your quantitative and qualitative measurements determined, you now can create your scorecard spreadsheet.\n\nHere’s what it would look like based on the earlier example (minus the specific content URLs).\n\nQualitative Scores\n\nArticle A Article B Article C Article D Article E Brand voice/style 5 1 2 3 1 Accuracy/currency? 4 2 3 2 2 Discoverability 3 3 3 3 3 Engagement 4 2 4 2 2 Relevance 3 3 5 3 3 Average Qualitative Score 3.8 2.2 3.4 2.6 2.2\n\nQuantitative Scores\n\nExposure 3 1 3 3 3 Engagement 2 2 2 2 2 Conversion 1 3 3 1 3 Backlinks 4 2 2 4 2 SEO % 2 3 3 2 3 Average Quantitative Score 2.4 2.2 2.6 2.4 2.6 Average Qualitative Score 3.8 2.2 3.4 2.6 2.2 Recommended Action Review and improve Remove and avoid Reconsider distribution plan Reconsider distribution plan Review and improve\n\nOn the scorecard, an “average” column has been added. It is calculated by totaling the numbers for each category and dividing it by the total number of categories.\n\nNow you have a side-by-side comparison of each content URL’s average quantitative and qualitative scores. Here’s how to analyze the numbers and then optimize your content:\n\nQualitative score higher than a quantitative score: Analyze your distribution plan. Consider alternative times, channels, or formats for this otherwise “good” content.\n\nQuantitative score higher than a qualitative score: Review the content to identify ways to improve it. Could its quality be improved with a rewrite? What about the addition of data-backed research?\n\nLow quantitative and qualitative scores: Remove this content from circulation and adapt your content plan to avoid this type of content in the future.\n\nHigh quantitative and qualitative scores: Promote and reuse this content as much as feasible. Update your content plan to replicate this type of content in the future.\n\nOf course, there are times when the discrepancy between quantitative and qualitative scores may indicate that the qualitative assessment is off. Use your judgment, but at least consider the alternatives.\n\nGet going\n\nWhen should you create a content scorecard? While it may seem like a daunting task, don’t let that stop you. Don’t wait until the next big migration. Take bite-size chunks and make it an ongoing process. Start now and optimize every quarter, then the process won’t feel quite so Herculean.\n\nSelecting how much and what content should be evaluated depends largely on the variety of content types and the consistency of content within the same type. You need to select a sufficient number of content pieces to see patterns in topic, content type, traffic, etc.\n\nThough there is no hard and fast science to sample size, in our experience 100 to 200 content assets were sufficient. Your number will depend on:\n\nTotal inventory size​\n\nConsistency within a content type\n\nFrequency of audits​\n\nReview in batches so you don’t get overwhelmed. Set evaluation cycles and look at batches quarterly, revising, retiring, or repurposing your content based on the audit results every time. And remember to select content across the performance spectrum. If you only focus on high-performing content, you won’t identify the hidden gems.\n\nRaise your qualitative and quantitative content marketing initiatives with helpful insight from experts in the field. Subscribe to the free CMI weekday newsletter.\n\nCover image by Joseph Kalinowski/Content Marketing Institute"
    }
}