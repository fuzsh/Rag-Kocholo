{
    "id": "dbpedia_1048_2",
    "rank": 86,
    "data": {
        "url": "https://community.databricks.com/t5/machine-learning/fix-hanging-task-in-databricks/td-p/3242",
        "read_more_link": "",
        "language": "en",
        "title": "Solved: Fix Hanging Task in Databricks",
        "top_image": "https://community.databricks.com/t5/machine-learning/fix-hanging-task-in-databricks/td-p/3242",
        "meta_img": "https://community.databricks.com/t5/machine-learning/fix-hanging-task-in-databricks/td-p/3242",
        "images": [
            "https://d032007s.searchunify.com/resources/Asset-Library/613a96b41d6c3403091612708684b83c/databricks-search-icon.svg",
            "https://community.databricks.com/t5/image/serverpage/avatar-name/fastfood/avatar-theme/candy/avatar-collection/food/avatar-display-size/profile/version/2?xdesc=1.0",
            "https://community.databricks.com/t5/image/serverpage/image-id/93iB584354657383C31/image-size/large?v=v2&px=999",
            "https://community.databricks.com/t5/image/serverpage/image-id/89i81F3A37E084A9A9E/image-size/large?v=v2&px=999",
            "https://community.databricks.com/t5/image/serverpage/image-id/84i8AF905AAD3A6C423/image-size/large?v=v2&px=999",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/skins/images/2C2E4A35911E991B89B48A017EE1FA80/responsive_peak/images/icon_anonymous_profile.svg",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/t5/image/serverpage/avatar-name/avatar-9/avatar-theme/candy/avatar-collection/Hermes_Default/avatar-display-size/profile/version/2?xdesc=1.0",
            "https://community.databricks.com/html/@EF197089B97C1146DF2F526E82589A92/assets/favicon.ico",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/t5/image/serverpage/avatar-name/fastfood/avatar-theme/candy/avatar-collection/food/avatar-display-size/profile/version/2?xdesc=1.0",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/skins/images/2C2E4A35911E991B89B48A017EE1FA80/responsive_peak/images/icon_anonymous_profile.svg",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/skins/images/2C2E4A35911E991B89B48A017EE1FA80/responsive_peak/images/icon_anonymous_profile.svg",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/t5/image/serverpage/avatar-name/fastfood/avatar-theme/candy/avatar-collection/food/avatar-display-size/profile/version/2?xdesc=1.0",
            "https://community.databricks.com/html/@701D0A7DC0D2A53954E673F594836946/assets/db-linkedin.svg",
            "https://community.databricks.com/html/@7381E27767DD219B64408D8A789A1FCF/assets/twitter.svg",
            "https://community.databricks.com/html/@F913DB83FDA72F33E17FE7E8B3F4285D/assets/db-copy-url-icon.png",
            "https://community.databricks.com/skins/images/2192CDDD860CDEE078D333035EA37A31/responsive_peak/images/icon_anonymous_message.png",
            "https://community.databricks.com/skins/images/2192CDDD860CDEE078D333035EA37A31/responsive_peak/images/icon_anonymous_message.png",
            "https://community.databricks.com/t5/image/serverpage/image-id/10218i7C79CDF94F63C985/image-size/large?v=v2&px=999",
            "https://community.databricks.com/t5/image/serverpage/image-id/7773iF4DA9EC28A2DF88C/image-size/large?v=v2&px=999",
            "https://community.databricks.com/t5/image/serverpage/image-id/10181iDED31F53BAE695D8/image-size/large?v=v2&px=999",
            "https://community.databricks.com/t5/image/serverpage/image-id/10097i7CC577FDB4653F48/image-size/large?v=v2&px=999",
            "https://community.databricks.com/t5/image/serverpage/image-id/10051i20B8807737E02FF6/image-size/large?v=v2&px=999",
            "https://community.databricks.com/html/@873023D73C24D0061A34E56D7D2325A6/assets/footer-simple-administration.png",
            "https://community.databricks.com/html/@F41BA112D54C9102C824A9B0EB17C993/assets/footer-databricks-logo.png",
            "https://community.databricks.com/html/@7CD4C8931B702AF20B6FAE671C7E8A64/assets/footer-linkedin.svg",
            "https://community.databricks.com/html/@559D627A6B068528189A734B9AD36931/assets/footer-facebook.svg",
            "https://community.databricks.com/html/@B604AD9C4900479435F1914D061B48A5/assets/footer-twitter.svg",
            "https://community.databricks.com/html/@AE44C84AC692543A782C21C954257EFE/assets/footer-feed.svg",
            "https://community.databricks.com/html/@198ACA0725652029704DE0358D9E681E/assets/footer-glassdoor.svg",
            "https://community.databricks.com/html/@2A5ED4B1C4DD0BAC2ECD2974AC87F605/assets/footer-youtube.svg",
            "https://community.databricks.com/html/@2F0EF50E78F730546440D60491D47BA1/assets/footer-gpcicon_small.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "community.databricks.com",
            "user-id"
        ],
        "publish_date": "2023-06-12T18:44:30+00:00",
        "summary": "",
        "meta_description": "Solved: I am applying a pandas UDF to a grouped dataframe in databricks. When I do this, a couple tasks hang forever, while the rest complete - 3242",
        "meta_lang": "en",
        "meta_favicon": "https://community.databricks.com/html/@EF197089B97C1146DF2F526E82589A92/assets/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://community.databricks.com/t5/machine-learning/fix-hanging-task-in-databricks/td-p/3242",
        "text": "I am applying a pandas UDF to a grouped dataframe in databricks. When I do this, a couple tasks hang forever, while the rest complete quickly.\n\nI start by repartitioning my dataset so that each group is in one partition:\n\ngroup_factors = ['a','b','c'] #masked for anonymity model_df = ( df .repartition( num_cores, #partition into max number of cores on this compute group_factors #partition by group so a group is always in same partition ) )\n\nI then group my dataset and apply the udf:\n\nresults = ( model_df #use repartitioned data .groupBy(group_factors) #build groups .applyInPandas(udf_tune, schema=result_schema) #apply in parallel ) #write results table to store parameters results.write.mode('overwrite').saveAsTable(table_name)\n\nSpark then splits this into tasks equal to the number of partitions. It runs successfully for all but two tasks. Those two tasks do not throw errors, but instead hang until the timeout threshold on the job.\n\nWhat is strange is that these groups/tasks do not appear to have any irregularities. The record size is similar to the other 58 completed tasks. The code does not throw any errors, so we don't have incorrectly typed or formatted data. Further, this command actually completes successfully about 20% of the time. But most days, we get caught on one or two hanging tasks that cause the job to fail.\n\nThe stderr simply notes that the task is hanging:\n\nThe stdout notes an allocation error (although all completed tasks contain the same allocation failure in their stdout files):\n\nAny suggestions for how to avoid the hanging task issue?\n\nP.S. When I reduce my data size (for example, splitting model_df into 4 smaller subsets, grouping and applying on each subset, and appending results) I do not run into this issue."
    }
}