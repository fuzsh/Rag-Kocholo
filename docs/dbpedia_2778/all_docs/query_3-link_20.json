{
    "id": "dbpedia_2778_3",
    "rank": 20,
    "data": {
        "url": "https://www.oreilly.com/library/view/python-data-science/9781491912126/ch04.html",
        "read_more_link": "",
        "language": "en",
        "title": "Python Data Science Handbook [Book]",
        "top_image": "https://www.oreilly.com/library/cover/9781491912126/1200w630h/",
        "meta_img": "https://www.oreilly.com/library/cover/9781491912126/1200w630h/",
        "images": [
            "https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red.svg",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in01.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in02.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in03.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in04.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in05.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in06.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in07.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in08.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in09.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in10.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in11.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in12.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in13.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in14.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in15.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in16.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in17.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in18.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in19.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in20.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in21.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in22.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in23.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in24.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in25.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in26.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in27.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in28.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in29.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in30.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in31.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in32.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in33.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in34.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in35.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in36.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in37.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in38.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in39.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in40.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in41.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in42.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in43.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in44.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in45.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in46.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in47.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in48.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in49.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in50.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in51.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in52.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in53.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in54.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in55.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in56.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in57.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in58.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in59.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in60.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in61.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in62.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in63.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in64.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in65.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in66.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in67.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in68.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in69.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in70.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in71.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in72.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in73.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in74.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in75.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in76.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in77.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in78.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in79.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in80.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in81.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in82.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in83.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in84.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in85.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in86.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in87.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in88.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in89.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in90.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in91.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in92.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in93.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in94.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in95.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in96.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in97.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in98.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in99.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in100.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in101.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in102.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in103.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in104.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in105.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in106.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in107.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in108.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in109.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in110.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in111.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in112.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in113.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in114.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in115.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in116.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in117.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in118.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in119.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in120.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in121.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in122.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in123.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in124.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in125.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in126.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in127.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in128.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in129.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in130.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in131.png",
            "https://www.oreilly.com/api/v2/epubs/9781491912126/files/assets/pyds_04in132.png",
            "https://cdn.oreillystatic.com/oreilly/images/app-store-logo.png",
            "https://cdn.oreillystatic.com/oreilly/images/google-play-logo.png",
            "https://cdn.oreillystatic.com/oreilly/images/roku-tv-logo.png",
            "https://cdn.oreillystatic.com/oreilly/images/amazon-appstore-logo.png",
            "https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red.svg",
            "https://cdn.oreillystatic.com/oreilly/images/report-software-architecture-patterns-553x420.jpg",
            "https://cdn.oreillystatic.com/oreilly/images/laptop-flat-topics-ml-1124x638.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jake VanderPlas"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Chapter 4. Visualization with Matplotlib We’ll now take an in-depth look at the Matplotlib tool for visualization in Python. Matplotlib is a multiplatform data visualization library built on NumPy arrays, …  - Selection from Python Data Science Handbook [Book]",
        "meta_lang": "en",
        "meta_favicon": "//www.oreilly.com/favicon.ico",
        "meta_site_name": "O’Reilly Online Learning",
        "canonical_link": "https://www.oreilly.com/library/view/python-data-science/9781491912126/ch04.html",
        "text": "Continuous Errors\n\nIn some situations it is desirable to show errorbars on continuous quantities. Though Matplotlib does not have a built-in convenience routine for this type of application, it’s relatively easy to combine primitives like plt.plot and plt.fill_between for a useful result.\n\nHere we’ll perform a simple Gaussian process regression (GPR), using the Scikit-Learn API (see “Introducing Scikit-Learn” for details). This is a method of fitting a very flexible nonparametric function to data with a continuous measure of the uncertainty. We won’t delve into the details of Gaussian process regression at this point, but will focus instead on how you might visualize such a continuous error measurement:\n\nIn[4]: from sklearn.gaussian_process import GaussianProcess # define the model and draw some data model = lambda x: x * np.sin(x) xdata = np.array([1, 3, 5, 6, 8]) ydata = model(xdata) # Compute the Gaussian process fit gp = GaussianProcess(corr='cubic', theta0=1e-2, thetaL=1e-4, thetaU=1E-1, random_start=100) gp.fit(xdata[:, np.newaxis], ydata) xfit = np.linspace(0, 10, 1000) yfit, MSE = gp.predict(xfit[:, np.newaxis], eval_MSE=True) dyfit = 2 * np.sqrt(MSE) # 2*sigma ~ 95% confidence region\n\nWe now have xfit, yfit, and dyfit, which sample the continuous fit to our data. We could pass these to the plt.errorbar function as above, but we don’t really want to plot 1,000 points with 1,000 errorbars. Instead, we can use the plt.fill_between function with a light color to visualize this continuous error (Figure 4-29):\n\nIn[5]: # Visualize the result plt.plot(xdata, ydata, 'or') plt.plot(xfit, yfit, '-', color='gray') plt.fill_between(xfit, yfit - dyfit, yfit + dyfit, color='gray', alpha=0.2) plt.xlim(0, 10);\n\nNote what we’ve done here with the fill_between function: we pass an x value, then the lower y-bound, then the upper y-bound, and the result is that the area between these regions is filled.\n\nThe resulting figure gives a very intuitive view into what the Gaussian process regression algorithm is doing: in regions near a measured data point, the model is strongly constrained and this is reflected in the small model errors. In regions far from a measured data point, the model is not strongly constrained, and the model errors increase.\n\nFor more information on the options available in plt.fill_between() (and the closely related plt.fill() function), see the function docstring or the Matplotlib documentation.\n\nFinally, if this seems a bit too low level for your taste, refer to “Visualization with Seaborn”, where we discuss the Seaborn package, which has a more streamlined API for visualizing this type of continuous errorbar.\n\nVisualizing a Three-Dimensional Function\n\nWe’ll start by demonstrating a contour plot using a function z = f ( x , y ) , using the following particular choice for f (we’ve seen this before in “Computation on Arrays: Broadcasting”, when we used it as a motivating example for array broadcasting):\n\nIn[2]: def f(x, y): return np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n\nA contour plot can be created with the plt.contour function. It takes three arguments: a grid of x values, a grid of y values, and a grid of z values. The x and y values represent positions on the plot, and the z values will be represented by the contour levels. Perhaps the most straightforward way to prepare such data is to use the np.meshgrid function, which builds two-dimensional grids from one-dimensional arrays:\n\nIn[3]: x = np.linspace(0, 5, 50) y = np.linspace(0, 5, 40) X, Y = np.meshgrid(x, y) Z = f(X, Y)\n\nNow let’s look at this with a standard line-only contour plot (Figure 4-30):\n\nIn[4]: plt.contour(X, Y, Z, colors='black');\n\nNotice that by default when a single color is used, negative values are represented by dashed lines, and positive values by solid lines. Alternatively, you can color-code the lines by specifying a colormap with the cmap argument. Here, we’ll also specify that we want more lines to be drawn—20 equally spaced intervals within the data range (Figure 4-31):\n\nIn[5]: plt.contour(X, Y, Z, 20, cmap='RdGy');\n\nHere we chose the RdGy (short for Red-Gray) colormap, which is a good choice for centered data. Matplotlib has a wide range of colormaps available, which you can easily browse in IPython by doing a tab completion on the plt.cm module:\n\nplt.cm.<TAB>\n\nOur plot is looking nicer, but the spaces between the lines may be a bit distracting. We can change this by switching to a filled contour plot using the plt.contourf() function (notice the f at the end), which uses largely the same syntax as plt.contour().\n\nAdditionally, we’ll add a plt.colorbar() command, which automatically creates an additional axis with labeled color information for the plot (Figure 4-32):\n\nIn[6]: plt.contourf(X, Y, Z, 20, cmap='RdGy') plt.colorbar();\n\nThe colorbar makes it clear that the black regions are “peaks,” while the red regions are “valleys.”\n\nOne potential issue with this plot is that it is a bit “splotchy.” That is, the color steps are discrete rather than continuous, which is not always what is desired. You could remedy this by setting the number of contours to a very high number, but this results in a rather inefficient plot: Matplotlib must render a new polygon for each step in the level. A better way to handle this is to use the plt.imshow() function, which interprets a two-dimensional grid of data as an image.\n\nFigure 4-33 shows the result of the following code:\n\nIn[7]: plt.imshow(Z, extent=[0, 5, 0, 5], origin='lower', cmap='RdGy') plt.colorbar() plt.axis(aspect='image');\n\nThere are a few potential gotchas with imshow(), however:\n\nplt.imshow() doesn’t accept an x and y grid, so you must manually specify the extent [xmin, xmax, ymin, ymax] of the image on the plot.\n\nplt.imshow() by default follows the standard image array definition where the origin is in the upper left, not in the lower left as in most contour plots. This must be changed when showing gridded data.\n\nplt.imshow() will automatically adjust the axis aspect ratio to match the input data; you can change this by setting, for example, plt.axis(aspect='image') to make x and y units match.\n\nFinally, it can sometimes be useful to combine contour plots and image plots. For example, to create the effect shown in Figure 4-34, we’ll use a partially transparent background image (with transparency set via the alpha parameter) and over-plot contours with labels on the contours themselves (using the plt.clabel() function):\n\nIn[8]: contours = plt.contour(X, Y, Z, 3, colors='black') plt.clabel(contours, inline=True, fontsize=8) plt.imshow(Z, extent=[0, 5, 0, 5], origin='lower', cmap='RdGy', alpha=0.5) plt.colorbar();\n\nThe combination of these three functions—plt.contour, plt.contourf, and plt.imshow—gives nearly limitless possibilities for displaying this sort of three-dimensional data within a two-dimensional plot . For more information on the options available in these functions, refer to their docstrings. If you are interested in three-dimensional visualizations of this type of data, see “Three-Dimensional Plotting in Matplotlib”.\n\nExample: Handwritten Digits\n\nFor an example of where this might be useful, let’s look at an interesting visualization of some handwritten digits data. This data is included in Scikit-Learn, and consists of nearly 2,000 8×8 thumbnails showing various handwritten digits.\n\nFor now, let’s start by downloading the digits data and visualizing several of the example images with plt.imshow() (Figure 4-57):\n\nIn[12]: # load images of the digits 0 through 5 and visualize several of them from sklearn.datasets import load_digits digits = load_digits(n_class=6) fig, ax = plt.subplots(8, 8, figsize=(6, 6)) for i, axi in enumerate(ax.flat): axi.imshow(digits.images[i], cmap='binary') axi.set(xticks=[], yticks=[])\n\nBecause each digit is defined by the hue of its 64 pixels, we can consider each digit to be a point lying in 64-dimensional space: each dimension represents the brightness of one pixel. But visualizing relationships in such high-dimensional spaces can be extremely difficult. One way to approach this is to use a dimensionality reduction technique such as manifold learning to reduce the dimensionality of the data while maintaining the relationships of interest. Dimensionality reduction is an example of unsupervised machine learning, and we will discuss it in more detail in “What Is Machine Learning?”.\n\nDeferring the discussion of these details, let’s take a look at a two-dimensional manifold learning projection of this digits data (see “In-Depth: Manifold Learning” for details):\n\nIn[13]: # project the digits into 2 dimensions using IsoMap from sklearn.manifold import Isomap iso = Isomap(n_components=2) projection = iso.fit_transform(digits.data)\n\nWe’ll use our discrete colormap to view the results, setting the ticks and clim to improve the aesthetics of the resulting colorbar (Figure 4-58):\n\nIn[14]: # plot the results plt.scatter(projection[:, 0], projection[:, 1], lw=0.1, c=digits.target, cmap=plt.cm.get_cmap('cubehelix', 6)) plt.colorbar(ticks=range(6), label='digit value') plt.clim(-0.5, 5.5)\n\nThe projection also gives us some interesting insights on the relationships within the dataset: for example, the ranges of 5 and 3 nearly overlap in this projection, indicating that some handwritten fives and threes are difficult to distinguish, and therefore more likely to be confused by an automated classification algorithm. Other values, like 0 and 1, are more distantly separated, and therefore much less likely to be confused. This observation agrees with our intuition, because 5 and 3 look much more similar than do 0 and 1.\n\nWe’ll return to manifold learning and digit classification in Chapter 5.\n\nTransforms and Text Position\n\nIn the previous example, we anchored our text annotations to data locations. Sometimes it’s preferable to anchor the text to a position on the axes or figure, independent of the data. In Matplotlib, we do this by modifying the transform.\n\nAny graphics display framework needs some scheme for translating between coordinate systems. For example, a data point at ( x , y ) = ( 1 , 1 ) needs to somehow be represented at a certain location on the figure, which in turn needs to be represented in pixels on the screen. Mathematically, such coordinate transformations are relatively straightforward, and Matplotlib has a well-developed set of tools that it uses internally to perform them (the tools can be explored in the matplotlib.transforms submodule).\n\nThe average user rarely needs to worry about the details of these transforms, but it is helpful knowledge to have when considering the placement of text on a figure. There are three predefined transforms that can be useful in this situation:\n\nax.transData\n\nTransform associated with data coordinates\n\nax.transAxes\n\nTransform associated with the axes (in units of axes dimensions)\n\nfig.transFigure\n\nTransform associated with the figure (in units of figure dimensions)\n\nHere let’s look at an example of drawing text at various locations using these transforms (Figure 4-69):\n\nIn[5]: fig, ax = plt.subplots(facecolor='lightgray') ax.axis([0, 10, 0, 10]) # transform=ax.transData is the default, but we'll specify it anyway ax.text(1, 5, \". Data: (1, 5)\", transform=ax.transData) ax.text(0.5, 0.1, \". Axes: (0.5, 0.1)\", transform=ax.transAxes) ax.text(0.2, 0.2, \". Figure: (0.2, 0.2)\", transform=fig.transFigure);\n\nNote that by default, the text is aligned above and to the left of the specified coordinates; here the “.” at the beginning of each string will approximately mark the given coordinate location.\n\nThe transData coordinates give the usual data coordinates associated with the x- and y-axis labels. The transAxes coordinates give the location from the bottom-left corner of the axes (here the white box) as a fraction of the axes size. The transFigure coordinates are similar, but specify the position from the bottom left of the figure (here the gray box) as a fraction of the figure size.\n\nNotice now that if we change the axes limits, it is only the transData coordinates that will be affected, while the others remain stationary (Figure 4-70):\n\nIn[6]: ax.set_xlim(0, 2) ax.set_ylim(-6, 6) fig\n\nYou can see this behavior more clearly by changing the axes limits interactively; if you are executing this code in a notebook, you can make that happen by changing %matplotlib inline to %matplotlib notebook and using each plot’s menu to interact with the plot.\n\nArrows and Annotation\n\nAlong with tick marks and text, another useful annotation mark is the simple arrow.\n\nDrawing arrows in Matplotlib is often much harder than you might hope. While there is a plt.arrow() function available, I wouldn’t suggest using it; the arrows it creates are SVG objects that will be subject to the varying aspect ratio of your plots, and the result is rarely what the user intended. Instead, I’d suggest using the plt.annotate() function. This function creates some text and an arrow, and the arrows can be very flexibly specified.\n\nHere we’ll use annotate with several of its options (Figure 4-71):\n\nIn[7]: %matplotlib inline fig, ax = plt.subplots() x = np.linspace(0, 20, 1000) ax.plot(x, np.cos(x)) ax.axis('equal') ax.annotate('local maximum', xy=(6.28, 1), xytext=(10, 4), arrowprops=dict(facecolor='black', shrink=0.05)) ax.annotate('local minimum', xy=(5 * np.pi, -1), xytext=(2, -6), arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=-90\"));\n\nThe arrow style is controlled through the arrowprops dictionary, which has numerous options available. These options are fairly well documented in Matplotlib’s online documentation, so rather than repeating them here I’ll quickly show some of the possibilities. Let’s demonstrate several of the possible options using the birthrate plot from before (Figure 4-72):\n\nIn[8]: fig, ax = plt.subplots(figsize=(12, 4)) births_by_date.plot(ax=ax) # Add labels to the plot ax.annotate(\"New Year's Day\", xy=('2012-1-1', 4100), xycoords='data', xytext=(50, -30), textcoords='offset points', arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=-0.2\")) ax.annotate(\"Independence Day\", xy=('2012-7-4', 4250), xycoords='data', bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\"), xytext=(10, -40), textcoords='offset points', ha='center', arrowprops=dict(arrowstyle=\"->\")) ax.annotate('Labor Day', xy=('2012-9-4', 4850), xycoords='data', ha='center', xytext=(0, -20), textcoords='offset points') ax.annotate('', xy=('2012-9-1', 4850), xytext=('2012-9-7', 4850), xycoords='data', textcoords='data', arrowprops={'arrowstyle': '|-|,widthA=0.2,widthB=0.2', }) ax.annotate('Halloween', xy=('2012-10-31', 4600), xycoords='data', xytext=(-80, -40), textcoords='offset points', arrowprops=dict(arrowstyle=\"fancy\", fc=\"0.6\", ec=\"none\", connectionstyle=\"angle3,angleA=0,angleB=-90\")) ax.annotate('Thanksgiving', xy=('2012-11-25', 4500), xycoords='data', xytext=(-120, -60), textcoords='offset points', bbox=dict(boxstyle=\"round4,pad=.5\", fc=\"0.9\"), arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle,angleA=0,angleB=80,rad=20\")) ax.annotate('Christmas', xy=('2012-12-25', 3850), xycoords='data', xytext=(-30, 0), textcoords='offset points', size=13, ha='right', va=\"center\", bbox=dict(boxstyle=\"round\", alpha=0.1), arrowprops=dict(arrowstyle=\"wedge,tail_width=0.5\", alpha=0.1)); # Label the axes ax.set(title='USA births by day of year (1969-1988)', ylabel='average daily births') # Format the x axis with centered month labels ax.xaxis.set_major_locator(mpl.dates.MonthLocator()) ax.xaxis.set_minor_locator(mpl.dates.MonthLocator(bymonthday=15)) ax.xaxis.set_major_formatter(plt.NullFormatter()) ax.xaxis.set_minor_formatter(mpl.dates.DateFormatter('%h')); ax.set_ylim(3600, 5400);\n\nYou’ll notice that the specifications of the arrows and text boxes are very detailed: this gives you the power to create nearly any arrow style you wish. Unfortunately, it also means that these sorts of features often must be manually tweaked, a process that can be very time-consuming when one is producing publication-quality graphics! Finally, I’ll note that the preceding mix of styles is by no means best practice for presenting data, but rather included as a demonstration of some of the available options.\n\nMore discussion and examples of available arrow and annotation styles can be found in the Matplotlib gallery , in particular http://matplotlib.org/examples/pylab_examples/annotation_demo2.html.\n\nFancy Tick Formats\n\nMatplotlib’s default tick formatting can leave a lot to be desired; it works well as a broad default, but sometimes you’d like to do something more. Consider the plot shown in Figure 4-78, a sine and a cosine:\n\nIn[9]: # Plot a sine and cosine curve fig, ax = plt.subplots() x = np.linspace(0, 3 * np.pi, 1000) ax.plot(x, np.sin(x), lw=3, label='Sine') ax.plot(x, np.cos(x), lw=3, label='Cosine') # Set up grid, legend, and limits ax.grid(True) ax.legend(frameon=False) ax.axis('equal') ax.set_xlim(0, 3 * np.pi);\n\nThere are a couple changes we might like to make. First, it’s more natural for this data to space the ticks and grid lines in multiples of π . We can do this by setting a MultipleLocator, which locates ticks at a multiple of the number you provide. For good measure, we’ll add both major and minor ticks in multiples of π / 4 (Figure 4-79):\n\nIn[10]: ax.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2)) ax.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 4)) fig\n\nBut now these tick labels look a little bit silly: we can see that they are multiples of π , but the decimal representation does not immediately convey this. To fix this, we can change the tick formatter. There’s no built-in formatter for what we want to do, so we’ll instead use plt.FuncFormatter, which accepts a user-defined function giving fine-grained control over the tick outputs (Figure 4-80):\n\nIn[11]: def format_func(value, tick_number): # find number of multiples of pi/2 N = int(np.round(2 * value / np.pi)) if N == 0: return \"0\" elif N == 1: return r\"$\\pi/2$\" elif N == 2: return r\"$\\pi$\" elif N % 2 > 0: return r\"${0}\\pi/2$\".format(N) else: return r\"${0}\\pi$\".format(N // 2) ax.xaxis.set_major_formatter(plt.FuncFormatter(format_func)) fig\n\nThis is much better! Notice that we’ve made use of Matplotlib’s LaTeX support, specified by enclosing the string within dollar signs. This is very convenient for display of mathematical symbols and formulae; in this case, \"$\\pi$\" is rendered as the Greek character π .\n\nThe plt.FuncFormatter() offers extremely fine-grained control over the appearance of your plot ticks, and comes in very handy when you’re preparing plots for presentation or publication.\n\nExample: Surface Temperature Data\n\nAs an example of visualizing some more continuous geographic data, let’s consider the “polar vortex” that hit the eastern half of the United States in January 2014. A great source for any sort of climatic data is NASA’s Goddard Institute for Space Studies. Here we’ll use the GIS 250 temperature data, which we can download using shell commands (these commands may have to be modified on Windows machines). The data used here was downloaded on 6/12/2016, and the file size is approximately 9 MB:\n\nIn[12]: # !curl -O http://data.giss.nasa.gov/pub/gistemp/gistemp250.nc.gz # !gunzip gistemp250.nc.gz\n\nThe data comes in NetCDF format, which can be read in Python by the netCDF4 library. You can install this library as shown here:\n\n$ conda install netcdf4\n\nWe read the data as follows:\n\nIn[13]: from netCDF4 import Dataset data = Dataset('gistemp250.nc')\n\nThe file contains many global temperature readings on a variety of dates; we need to select the index of the date we’re interested in—in this case, January 15, 2014:\n\nIn[14]: from netCDF4 import date2index from datetime import datetime timeindex = date2index(datetime(2014, 1, 15), data.variables['time'])\n\nNow we can load the latitude and longitude data, as well as the temperature anomaly for this index:\n\nIn[15]: lat = data.variables['lat'][:] lon = data.variables['lon'][:] lon, lat = np.meshgrid(lon, lat) temp_anomaly = data.variables['tempanomaly'][timeindex]\n\nFinally, we’ll use the pcolormesh() method to draw a color mesh of the data. We’ll look at North America, and use a shaded relief map in the background. Note that for this data we specifically chose a divergent colormap, which has a neutral color at zero and two contrasting colors at negative and positive values (Figure 4-110). We’ll also lightly draw the coastlines over the colors for reference:\n\nIn[16]: fig = plt.figure(figsize=(10, 8)) m = Basemap(projection='lcc', resolution='c', width=8E6, height=8E6, lat_0=45, lon_0=-100,) m.shadedrelief(scale=0.5) m.pcolormesh(lon, lat, temp_anomaly, latlon=True, cmap='RdBu_r') plt.clim(-8, 8) m.drawcoastlines(color='lightgray') plt.title('January 2014 Temperature Anomaly') plt.colorbar(label='temperature anomaly (°C)');\n\nThe data paints a picture of the localized, extreme temperature anomalies that happened during that month. The eastern half of the United States was much colder than normal, while the western half and Alaska were much warmer. Regions with no recorded temperature show the map background.\n\nExample: Exploring Marathon Finishing Times\n\nHere we’ll look at using Seaborn to help visualize and understand finishing results from a marathon. I’ve scraped the data from sources on the Web, aggregated it and removed any identifying information, and put it on GitHub where it can be downloaded (if you are interested in using Python for web scraping, I would recommend Web Scraping with Python by Ryan Mitchell). We will start by downloading the data from the Web, and loading it into Pandas:\n\nIn[22]: # !curl -O https://raw.githubusercontent.com/jakevdp/marathon-data/ # master/marathon-data.csv\n\nIn[23]: data = pd.read_csv('marathon-data.csv') data.head()\n\nOut[23]: age gender split final 0 33 M 01:05:38 02:08:51 1 32 M 01:06:26 02:09:28 2 31 M 01:06:49 02:10:42 3 38 M 01:06:16 02:13:45 4 31 M 01:06:32 02:13:59\n\nBy default, Pandas loaded the time columns as Python strings (type object); we can see this by looking at the dtypes attribute of the DataFrame:\n\nIn[24]: data.dtypes\n\nOut[24]: age int64 gender object split object final object dtype: object\n\nLet’s fix this by providing a converter for the times:\n\nIn[25]: def convert_time(s): h, m, s = map(int, s.split(':')) return pd.datetools.timedelta(hours=h, minutes=m, seconds=s) data = pd.read_csv('marathon-data.csv', converters={'split':convert_time, 'final':convert_time}) data.head()\n\nOut[25]: age gender split final 0 33 M 01:05:38 02:08:51 1 32 M 01:06:26 02:09:28 2 31 M 01:06:49 02:10:42 3 38 M 01:06:16 02:13:45 4 31 M 01:06:32 02:13:59\n\nIn[26]: data.dtypes\n\nOut[26]: age int64 gender object split timedelta64[ns] final timedelta64[ns] dtype: object\n\nThat looks much better. For the purpose of our Seaborn plotting utilities, let’s next add columns that give the times in seconds:\n\nIn[27]: data['split_sec'] = data['split'].astype(int) / 1E9 data['final_sec'] = data['final'].astype(int) / 1E9 data.head()\n\nOut[27]: age gender split final split_sec final_sec 0 33 M 01:05:38 02:08:51 3938.0 7731.0 1 32 M 01:06:26 02:09:28 3986.0 7768.0 2 31 M 01:06:49 02:10:42 4009.0 7842.0 3 38 M 01:06:16 02:13:45 3976.0 8025.0 4 31 M 01:06:32 02:13:59 3992.0 8039.0\n\nTo get an idea of what the data looks like, we can plot a jointplot over the data (Figure 4-126):\n\nIn[28]: with sns.axes_style('white'): g = sns.jointplot(\"split_sec\", \"final_sec\", data, kind='hex') g.ax_joint.plot(np.linspace(4000, 16000), np.linspace(8000, 32000), ':k')\n\nThe dotted line shows where someone’s time would lie if they ran the marathon at a perfectly steady pace. The fact that the distribution lies above this indicates (as you might expect) that most people slow down over the course of the marathon. If you have run competitively, you’ll know that those who do the opposite—run faster during the second half of the race—are said to have “negative-split” the race.\n\nLet’s create another column in the data, the split fraction, which measures the degree to which each runner negative-splits or positive-splits the race:\n\nIn[29]: data['split_frac'] = 1 - 2 * data['split_sec'] / data['final_sec'] data.head()\n\nOut[29]: age gender split final split_sec final_sec split_frac 0 33 M 01:05:38 02:08:51 3938.0 7731.0 -0.018756 1 32 M 01:06:26 02:09:28 3986.0 7768.0 -0.026262 2 31 M 01:06:49 02:10:42 4009.0 7842.0 -0.022443 3 38 M 01:06:16 02:13:45 3976.0 8025.0 0.009097 4 31 M 01:06:32 02:13:59 3992.0 8039.0 0.006842\n\nWhere this split difference is less than zero, the person negative-split the race by that fraction. Let’s do a distribution plot of this split fraction (Figure 4-127):\n\nIn[30]: sns.distplot(data['split_frac'], kde=False); plt.axvline(0, color=\"k\", linestyle=\"--\");\n\nIn[31]: sum(data.split_frac < 0)\n\nOut[31]: 251\n\nOut of nearly 40,000 participants, there were only 250 people who negative-split their marathon.\n\nLet’s see whether there is any correlation between this split fraction and other variables. We’ll do this using a pairgrid, which draws plots of all these correlations (Figure 4-128):\n\nIn[32]: g = sns.PairGrid(data, vars=['age', 'split_sec', 'final_sec', 'split_frac'], hue='gender', palette='RdBu_r') g.map(plt.scatter, alpha=0.8) g.add_legend();\n\nIt looks like the split fraction does not correlate particularly with age, but does correlate with the final time: faster runners tend to have closer to even splits on their marathon time. (We see here that Seaborn is no panacea for Matplotlib’s ills when it comes to plot styles: in particular, the x-axis labels overlap. Because the output is a simple Matplotlib plot, however, the methods in “Customizing Ticks” can be used to adjust such things if desired.)\n\nThe difference between men and women here is interesting. Let’s look at the histogram of split fractions for these two groups (Figure 4-129):\n\nIn[33]: sns.kdeplot(data.split_frac[data.gender=='M'], label='men', shade=True) sns.kdeplot(data.split_frac[data.gender=='W'], label='women', shade=True) plt.xlabel('split_frac');\n\nThe interesting thing here is that there are many more men than women who are running close to an even split! This almost looks like some kind of bimodal distribution among the men and women. Let’s see if we can suss out what’s going on by looking at the distributions as a function of age.\n\nA nice way to compare distributions is to use a violin plot (Figure 4-130):\n\nIn[34]: sns.violinplot(\"gender\", \"split_frac\", data=data, palette=[\"lightblue\", \"lightpink\"]);\n\nThis is yet another way to compare the distributions between men and women.\n\nLet’s look a little deeper, and compare these violin plots as a function of age. We’ll start by creating a new column in the array that specifies the decade of age that each person is in (Figure 4-131):\n\nIn[35]: data['age_dec'] = data.age.map(lambda age: 10 * (age // 10)) data.head()\n\nOut[35]: age gender split final split_sec final_sec split_frac age_dec 0 33 M 01:05:38 02:08:51 3938.0 7731.0 -0.018756 30 1 32 M 01:06:26 02:09:28 3986.0 7768.0 -0.026262 30 2 31 M 01:06:49 02:10:42 4009.0 7842.0 -0.022443 30 3 38 M 01:06:16 02:13:45 3976.0 8025.0 0.009097 30 4 31 M 01:06:32 02:13:59 3992.0 8039.0 0.006842 30\n\nIn[36]: men = (data.gender == 'M') women = (data.gender == 'W') with sns.axes_style(style=None): sns.violinplot(\"age_dec\", \"split_frac\", hue=\"gender\", data=data, split=True, inner=\"quartile\", palette=[\"lightblue\", \"lightpink\"]);\n\nLooking at this, we can see where the distributions of men and women differ: the split distributions of men in their 20s to 50s show a pronounced over-density toward lower splits when compared to women of the same age (or of any age, for that matter).\n\nAlso surprisingly, the 80-year-old women seem to outperform everyone in terms of their split time. This is probably due to the fact that we’re estimating the distribution from small numbers, as there are only a handful of runners in that range:\n\nIn[38]: (data.age > 80).sum()\n\nOut[38]: 7\n\nBack to the men with negative splits: who are these runners? Does this split fraction correlate with finishing quickly? We can plot this very easily. We’ll use regplot, which will automatically fit a linear regression to the data (Figure 4-132):\n\nIn[37]: g = sns.lmplot('final_sec', 'split_frac', col='gender', data=data, markers=\".\", scatter_kws=dict(color='c')) g.map(plt.axhline, y=0.1, color=\"k\", ls=\":\");\n\nApparently the people with fast splits are the elite runners who are finishing within ~15,000 seconds, or about 4 hours. People slower than that are much less likely to have a fast second split ."
    }
}