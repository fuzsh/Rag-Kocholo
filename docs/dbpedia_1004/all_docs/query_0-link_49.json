{
    "id": "dbpedia_1004_0",
    "rank": 49,
    "data": {
        "url": "http://www.mikelrodriguez.com/",
        "read_more_link": "",
        "language": "en",
        "title": "Mikel Rodriguez",
        "top_image": "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382297571163-JNGMAWEIPAGEJLDVR4IB/favicon.ico?format=100w",
        "meta_img": "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382297571163-JNGMAWEIPAGEJLDVR4IB/favicon.ico?format=100w",
        "images": [
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/e2462b00-af10-4622-be2e-31656de6e205/Mikel+D+Rodriguez.jpeg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/784fed09-c3c8-4b4d-8d43-9a827cc5eda0/Responsible+Reporting+for+Frontier+AI+Development.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/b38fcda4-deca-4853-8644-cdc92586f60f/Screenshot+2024-04-22+at+2.24.02%E2%80%AFPM.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/242a6529-c6b1-4508-86a9-8fd3f19d79ab/social_harms_red_teaming.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/0fb2e080-4b83-4a67-95d5-df3970ec773d/gemini.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/55c9452e-d309-419a-9e3c-5dfcc640a1a5/Screenshot+2023-11-14+at+12.32.05%E2%80%AFPM.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/7898e9f9-5e55-418e-8105-fa95c0eb4b17/AI+and+cyber.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/0e6a844d-248f-4d4f-a06d-c5491be05042/ATLAS_logo.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/7c4085fc-92e8-4ac4-a520-7a96444cc300/MITRE_ATLAS.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1506544037248-KUIS0EDNRWDASR902E2I/machine+deception.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382113973723-MYO63H1QUYM85YWBSE6H/9642280154_d1eb90341c_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382113973723-MYO63H1QUYM85YWBSE6H/9642280154_d1eb90341c_o.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114000500-TTQXN1B1NIYKO3QF2YOS/6514046823_5dd37ecd8a_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114000500-TTQXN1B1NIYKO3QF2YOS/6514046823_5dd37ecd8a_o.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114005378-4EXMMC594KSSRSGDRYPU/6113684168_1439473816_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114005378-4EXMMC594KSSRSGDRYPU/6113684168_1439473816_o.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114018387-Z2UF6SUMLYYCA3JZXHT3/6109950262_35531773df_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114018387-Z2UF6SUMLYYCA3JZXHT3/6109950262_35531773df_o.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114027676-GFXXIORBYTYP0Z5342RS/6109402157_228cd2560c_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114027676-GFXXIORBYTYP0Z5342RS/6109402157_228cd2560c_o.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114031039-MP25YNZQ11VCHYDG506J/5447022621_ebaef25400_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114031039-MP25YNZQ11VCHYDG506J/5447022621_ebaef25400_o.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114040674-FAN3SU9XY3HD3LFKGTKS/5150862406_083e3ce776_o.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382114040674-FAN3SU9XY3HD3LFKGTKS/5150862406_083e3ce776_o.png?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382112149916-9W1QRH3N1XH0MH4CXRY4/crowd_tracking.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382112149916-9W1QRH3N1XH0MH4CXRY4/crowd_tracking.png?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382109868078-QSVIZUZ9JD5B1M3M7LF9/moviesActions.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382109868078-QSVIZUZ9JD5B1M3M7LF9/moviesActions.png?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382110732959-Y9RAKAJDYGT9XRHYKP6P/videoSummary.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382110732959-Y9RAKAJDYGT9XRHYKP6P/videoSummary.png?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382111416175-SGMZUKWLAGVKJKGX6MVX/fmv3.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382111416175-SGMZUKWLAGVKJKGX6MVX/fmv3.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382111605773-GR4HZ61OCMOWGBHLQC5G/Screen+Shot+2013-10-18+at+11.52.45+AM.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382111605773-GR4HZ61OCMOWGBHLQC5G/Screen+Shot+2013-10-18+at+11.52.45+AM.png?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382111687990-CT3844Q9U9H9LPXSEVQG/vasc.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382111687990-CT3844Q9U9H9LPXSEVQG/vasc.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382112037167-RHW7ABC4GWDLLJTHTL4P/teach2.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382112037167-RHW7ABC4GWDLLJTHTL4P/teach2.jpg?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382476161566-SV3CD1BBYMD8F1C3YTOA/Screen+Shot+2013-10-22+at+5.08.52+PM.png",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382476161566-SV3CD1BBYMD8F1C3YTOA/Screen+Shot+2013-10-22+at+5.08.52+PM.png?format=500w",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382113973723-MYO63H1QUYM85YWBSE6H/9642280154_d1eb90341c_o.jpg",
            "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382113973723-MYO63H1QUYM85YWBSE6H/9642280154_d1eb90341c_o.jpg?format=500w"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Mikel Rodriguez, computer vision research, crowd tracking matlab source code, action recognition source code",
        "meta_lang": "en",
        "meta_favicon": "https://images.squarespace-cdn.com/content/v1/526150c2e4b0e2c92732b619/1382297571163-JNGMAWEIPAGEJLDVR4IB/favicon.ico?format=100w",
        "meta_site_name": "Mikel Rodriguez",
        "canonical_link": "http://www.mikelrodriguez.com",
        "text": "For the past twenty years I’ve had the opportunity to be in the frontlines witnessing first-hand the unique challenges and opportunities that we face when deploying AI in high-stakes consequential environments.\n\nRecently we’ve seen an incredible acceleration in our progress towards more capable AI. While this opens new exciting possibilities for AI to benefit humanity, the potential scale of this impact also forces us to think deeply about how to do so responsibly.\n\nAt Google DeepMind, I help define and lead AI Security research as part of the Red and Blue “ReBl” team to ensure that foundational models are battle-tested with the rigor and scrutiny of real-world adversaries, and help drive research and tooling that will make this red-blue mindset scalable in preparation for AGI.\n\nIn my role as the Managing Director at MITRE Labs, I built and led the AI Red Team for the Department of Defense that focused on deployed AI systems that can be susceptible to attacks involving evasion, data poisoning, model replication; and the exploitation of software flaws to deceive, manipulate, compromise, and render them ineffective. My team worked on developing methods to mitigate bias and defend against emerging ML attacks, securing the AI supply chain, and generally ensuring the trustworthiness of AI systems so they perform as intended in mission-critical environments. While at MITRE, in collaboration with many industry partners, we published ATLAS (Adversarial Threat Landscape for AI Systems) - a knowledge base of adversary tactics, techniques, and case studies for machine learning (ML) systems based on real-world observations, demonstrations from ML red teams and security groups, and the state of the possible from academic research. l firmly believe that AI’s potential will only be realized through collaborations that help produce reliable, resilient, fair, interpretable, privacy preserving, and secure technologies.\n\nI received my Ph.D. in 2010 while working at UCF's computer vision lab with professor Mubarak Shah. I then moved to Paris where I worked as a post-doctoral research fellow at WILLOW, an INRIA/ENS project. During my time at INRIA I worked with Ivan Laptev and Josef Sivic.\n\nHolistic Safety and Responsibility Evaluations of Advanced AI Models\n\nSafety and responsibility evaluations of advanced AI models are a critical but developing field of research and practice. In the development of Google DeepMind’s advanced AI models, we innovated on and applied a broad set of approaches to safety evaluation. In this report, we summarise and share elements of our evolving approach as well as lessons learned for a broad audience. Key lessons learned include: First, theoretical underpinnings and frameworks are invaluable to organise the breadth of risk domains, modalities, forms, metrics, and goals. Second, theory and practice of safety evaluation development each benefit from collaboration to clarify goals, methods and challenges, and facilitate the transfer of insights between different stakeholders and disciplines. Third, similar key methods, lessons, and institutions apply across the range of concerns in responsibility and safety – including established and emerging harms. For this reason it is important that a wide range of actors working on safety evaluation and safety research communities work together to develop, refine and implement novel evaluation approaches and best practices, rather than operating in silos. The report concludes with outlining the clear need to rapidly advance the science of evaluations, to integrate new evaluations into the development and governance of AI, to establish scientifically-grounded norms and standards, and to promote a robust evaluation ecosystem.\n\nWhile advanced AI assistants have the potential to enhance cybersecurity, for example, by analysing large quantities of cyber-threat data to improve threat intelligence capabilities and engaging in automated incident-response, they also have the potential to benefit attackers, for example, through identification of system vulnerabilities and malicious code generation.\n\nThis chapter examines whether and in what respects advanced AI assistants are uniquely positioned to enable certain kinds of misuse and what mitigation strategies are available to address the emerging threats. We argue that AI assistants have the potential to empower malicious actors to achieve bad outcomes across three dimensions: first, offensive cyber operations, including malicious code generation and software vulnerability discovery; second, via adversarial attacks to exploit vulnerabilities in AI assistants, such as jailbreaking and prompt injection attacks; and third, via high-quality and potentially highly personalised content generation at scale. We conclude with a number of recommendations for mitigating these risks, including red teaming, post-deployment monitoring and responsible disclosure processes."
    }
}