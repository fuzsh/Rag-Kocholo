{
    "id": "dbpedia_1004_3",
    "rank": 62,
    "data": {
        "url": "http://modern-rstats.eu/descriptive-statistics-and-data-manipulation.html",
        "read_more_link": "",
        "language": "en",
        "title": "Chapter 4 Descriptive statistics and data manipulation",
        "top_image": "",
        "meta_img": "",
        "images": [
            "http://modern-rstats.eu/assets/pas_une_pipe.png",
            "http://modern-rstats.eu/modern_R_files/figure-html/unnamed-chunk-328-1.png",
            "http://modern-rstats.eu/modern_R_files/figure-html/unnamed-chunk-329-1.png",
            "http://modern-rstats.eu/assets/zoom_list_columns.png",
            "http://modern-rstats.eu/assets/rowwise.png",
            "http://modern-rstats.eu/modern_R_files/figure-html/unnamed-chunk-414-1.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Bruno Rodrigues"
        ],
        "publish_date": "2022-10-24T00:00:00",
        "summary": "",
        "meta_description": "This book will teach you how to use R to solve your statistical, data science and machine learning problems. Importing data, computing descriptive statistics, running regressions (or more complex machine learning models) and generating reports are some of the topics covered. No previous experience with R is needed.",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "4.4.1 pivot_wider() and pivot_longer()\n\nLet’s first create a fake dataset:\n\nlibrary(tidyr)\n\nsurvey_data <- tribble( ~id, ~variable, ~value, 1, \"var1\", 1, 1, \"var2\", 0.2, NA, \"var3\", 0.3, 2, \"var1\", 1.4, 2, \"var2\", 1.9, 2, \"var3\", 4.1, 3, \"var1\", 0.1, 3, \"var2\", 2.8, 3, \"var3\", 8.9, 4, \"var1\", 1.7, NA, \"var2\", 1.9, 4, \"var3\", 7.6 ) head(survey_data)\n\n## # A tibble: 6 × 3 ## id variable value ## <dbl> <chr> <dbl> ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1 1.4 ## 5 2 var2 1.9 ## 6 2 var3 4.1\n\nI used the tribble() function from the {tibble} package to create this fake dataset. I’ll discuss this package later, for now, let’s focus on {tidyr}.\n\nLet’s suppose that we need the data to be in the wide format which means var1, var2 and var3 need to be their own columns. To do this, we need to use the pivot_wider() function. Why wide? Because the data set will be wide, meaning, having more columns than rows.\n\nsurvey_data %>% pivot_wider(id_cols = id, names_from = variable, values_from = value)\n\n## # A tibble: 5 × 4 ## id var1 var2 var3 ## <dbl> <dbl> <dbl> <dbl> ## 1 1 1 0.2 NA ## 2 NA NA 1.9 0.3 ## 3 2 1.4 1.9 4.1 ## 4 3 0.1 2.8 8.9 ## 5 4 1.7 NA 7.6\n\nLet’s go through pivot_wider()’s arguments: the first is id_cols = which requires the variable that uniquely identifies the rows to be supplied. names_from = is where you input the variable that will generate the names of the new columns. In our case, the variable colmuns has three values; var1, var2 and var3, and these are now the names of the new columns. Finally, values_from = is where you can specify the column containing the values that will fill the data frame. I find the argument names names_from = and values_from = quite explicit.\n\nAs you can see, there are some missing values. Let’s suppose that we know that these missing values are true 0’s. pivot_wider() has an argument called values_fill = that makes it easy to replace the missing values:\n\nsurvey_data %>% pivot_wider(id_cols = id, names_from = variable, values_from = value, values_fill = list(value = 0))\n\n## # A tibble: 5 × 4 ## id var1 var2 var3 ## <dbl> <dbl> <dbl> <dbl> ## 1 1 1 0.2 0 ## 2 NA 0 1.9 0.3 ## 3 2 1.4 1.9 4.1 ## 4 3 0.1 2.8 8.9 ## 5 4 1.7 0 7.6\n\nA list of variables and their respective values to replace NA’s with must be supplied to values_fill.\n\nLet’s now use another dataset, which you can get from here (downloaded from: http://www.statistiques.public.lu/stat/TableViewer/tableView.aspx?ReportId=12950&IF_Language=eng&MainTheme=2&FldrName=3&RFPath=91). This data set gives the unemployment rate for each Luxembourguish canton from 2001 to 2015. We will come back to this data later on to learn how to plot it. For now, let’s use it to learn more about {tidyr}.\n\nunemp_lux_data <- rio::import( \"https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/all/unemployment_lux_all.csv\" ) head(unemp_lux_data)\n\n## division year active_population of_which_non_wage_earners ## 1 Beaufort 2001 688 85 ## 2 Beaufort 2002 742 85 ## 3 Beaufort 2003 773 85 ## 4 Beaufort 2004 828 80 ## 5 Beaufort 2005 866 96 ## 6 Beaufort 2006 893 87 ## of_which_wage_earners total_employed_population unemployed ## 1 568 653 35 ## 2 631 716 26 ## 3 648 733 40 ## 4 706 786 42 ## 5 719 815 51 ## 6 746 833 60 ## unemployment_rate_in_percent ## 1 5.09 ## 2 3.50 ## 3 5.17 ## 4 5.07 ## 5 5.89 ## 6 6.72\n\nNow, let’s suppose that for our purposes, it would make more sense to have the data in a wide format, where columns are “divison times year” and the value is the unemployment rate. This can be easily done with providing more columns to names_from =.\n\nunemp_lux_data2 <- unemp_lux_data %>% filter(year %in% seq(2013, 2017), str_detect(division, \".*ange$\"), !str_detect(division, \".*Canton.*\")) %>% select(division, year, unemployment_rate_in_percent) %>% rowid_to_column() unemp_lux_data2 %>% pivot_wider(names_from = c(division, year), values_from = unemployment_rate_in_percent)\n\n## # A tibble: 48 × 49 ## rowid Bertr…¹ Bertr…² Bertr…³ Diffe…⁴ Diffe…⁵ Diffe…⁶ Dudel…⁷ Dudel…⁸ Dudel…⁹ ## <int> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 5.69 NA NA NA NA NA NA NA NA ## 2 2 NA 5.65 NA NA NA NA NA NA NA ## 3 3 NA NA 5.35 NA NA NA NA NA NA ## 4 4 NA NA NA 13.2 NA NA NA NA NA ## 5 5 NA NA NA NA 12.6 NA NA NA NA ## 6 6 NA NA NA NA NA 11.4 NA NA NA ## 7 7 NA NA NA NA NA NA 9.35 NA NA ## 8 8 NA NA NA NA NA NA NA 9.37 NA ## 9 9 NA NA NA NA NA NA NA NA 8.53 ## 10 10 NA NA NA NA NA NA NA NA NA ## # … with 38 more rows, 39 more variables: Frisange_2013 <dbl>, ## # Frisange_2014 <dbl>, Frisange_2015 <dbl>, Hesperange_2013 <dbl>, ## # Hesperange_2014 <dbl>, Hesperange_2015 <dbl>, Leudelange_2013 <dbl>, ## # Leudelange_2014 <dbl>, Leudelange_2015 <dbl>, Mondercange_2013 <dbl>, ## # Mondercange_2014 <dbl>, Mondercange_2015 <dbl>, Pétange_2013 <dbl>, ## # Pétange_2014 <dbl>, Pétange_2015 <dbl>, Rumelange_2013 <dbl>, ## # Rumelange_2014 <dbl>, Rumelange_2015 <dbl>, Schifflange_2013 <dbl>, …\n\nIn the filter() statement, I only kept data from 2013 to 2017, “division”s ending with the string “ange” (“division” can be a canton or a commune, for example “Canton Redange”, a canton, or “Hesperange” a commune), and removed the cantons as I’m only interested in communes. If you don’t understand this filter() statement, don’t fret; this is not important for what follows. I then only kept the columns I’m interested in and pivoted the data to a wide format. Also, I needed to add a unique identifier to the data frame. For this, I used rowid_to_column() function, from the {tibble} package, which adds a new column to the data frame with an id, going from 1 to the number of rows in the data frame. If I did not add this identifier, the statement would work still:\n\nunemp_lux_data3 <- unemp_lux_data %>% filter(year %in% seq(2013, 2017), str_detect(division, \".*ange$\"), !str_detect(division, \".*Canton.*\")) %>% select(division, year, unemployment_rate_in_percent) unemp_lux_data3 %>% pivot_wider(names_from = c(division, year), values_from = unemployment_rate_in_percent)\n\n## # A tibble: 1 × 48 ## Bertrange_2013 Bertr…¹ Bertr…² Diffe…³ Diffe…⁴ Diffe…⁵ Dudel…⁶ Dudel…⁷ Dudel…⁸ ## <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 5.69 5.65 5.35 13.2 12.6 11.4 9.35 9.37 8.53 ## # … with 39 more variables: Frisange_2013 <dbl>, Frisange_2014 <dbl>, ## # Frisange_2015 <dbl>, Hesperange_2013 <dbl>, Hesperange_2014 <dbl>, ## # Hesperange_2015 <dbl>, Leudelange_2013 <dbl>, Leudelange_2014 <dbl>, ## # Leudelange_2015 <dbl>, Mondercange_2013 <dbl>, Mondercange_2014 <dbl>, ## # Mondercange_2015 <dbl>, Pétange_2013 <dbl>, Pétange_2014 <dbl>, ## # Pétange_2015 <dbl>, Rumelange_2013 <dbl>, Rumelange_2014 <dbl>, ## # Rumelange_2015 <dbl>, Schifflange_2013 <dbl>, Schifflange_2014 <dbl>, …\n\nand actually look even better, but only because there are no repeated values; there is only one unemployment rate for each “commune times year”. I will come back to this later on, with another example that might be clearer. These last two code blocks are intense; make sure you go through each lien step by step and understand what is going on.\n\nYou might have noticed that because there is no data for the years 2016 and 2017, these columns do not appear in the data. But suppose that we need to have these columns, so that a colleague from another department can fill in the values. This is possible by providing a data frame with the detailed specifications of the result data frame. This optional data frame must have at least two columns, .name, which are the column names you want, and .value which contains the values. Also, the function that uses this spec is a pivot_wider_spec(), and not pivot_wider().\n\nunemp_spec <- unemp_lux_data %>% tidyr::expand(division, year = c(year, 2016, 2017), .value = \"unemployment_rate_in_percent\") %>% unite(\".name\", division, year, remove = FALSE) unemp_spec\n\nHere, I use another function, tidyr::expand(), which returns every combinations (cartesian product) of every variable from a dataset.\n\nTo make it work, we still need to create a column that uniquely identifies each row in the data:\n\nunemp_lux_data4 <- unemp_lux_data %>% select(division, year, unemployment_rate_in_percent) %>% rowid_to_column() %>% pivot_wider_spec(spec = unemp_spec) unemp_lux_data4\n\n## # A tibble: 1,770 × 2,007 ## rowid Beauf…¹ Beauf…² Beauf…³ Beauf…⁴ Beauf…⁵ Beauf…⁶ Beauf…⁷ Beauf…⁸ Beauf…⁹ ## <int> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 5.09 NA NA NA NA NA NA NA NA ## 2 2 NA 3.5 NA NA NA NA NA NA NA ## 3 3 NA NA 5.17 NA NA NA NA NA NA ## 4 4 NA NA NA 5.07 NA NA NA NA NA ## 5 5 NA NA NA NA 5.89 NA NA NA NA ## 6 6 NA NA NA NA NA 6.72 NA NA NA ## 7 7 NA NA NA NA NA NA 4.3 NA NA ## 8 8 NA NA NA NA NA NA NA 7.08 NA ## 9 9 NA NA NA NA NA NA NA NA 8.52 ## 10 10 NA NA NA NA NA NA NA NA NA ## # … with 1,760 more rows, 1,997 more variables: Beaufort_2010 <dbl>, ## # Beaufort_2011 <dbl>, Beaufort_2012 <dbl>, Beaufort_2013 <dbl>, ## # Beaufort_2014 <dbl>, Beaufort_2015 <dbl>, Beaufort_2016 <dbl>, ## # Beaufort_2017 <dbl>, Bech_2001 <dbl>, Bech_2002 <dbl>, Bech_2003 <dbl>, ## # Bech_2004 <dbl>, Bech_2005 <dbl>, Bech_2006 <dbl>, Bech_2007 <dbl>, ## # Bech_2008 <dbl>, Bech_2009 <dbl>, Bech_2010 <dbl>, Bech_2011 <dbl>, ## # Bech_2012 <dbl>, Bech_2013 <dbl>, Bech_2014 <dbl>, Bech_2015 <dbl>, …\n\nYou can notice that now we have columns for 2016 and 2017 too. Let’s clean the data a little bit more:\n\nunemp_lux_data4 %>% select(-rowid) %>% fill(matches(\".*\"), .direction = \"down\") %>% slice(n())\n\n## # A tibble: 1 × 2,006 ## Beaufort_2001 Beaufo…¹ Beauf…² Beauf…³ Beauf…⁴ Beauf…⁵ Beauf…⁶ Beauf…⁷ Beauf…⁸ ## <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 5.09 3.5 5.17 5.07 5.89 6.72 4.3 7.08 8.52 ## # … with 1,997 more variables: Beaufort_2010 <dbl>, Beaufort_2011 <dbl>, ## # Beaufort_2012 <dbl>, Beaufort_2013 <dbl>, Beaufort_2014 <dbl>, ## # Beaufort_2015 <dbl>, Beaufort_2016 <dbl>, Beaufort_2017 <dbl>, ## # Bech_2001 <dbl>, Bech_2002 <dbl>, Bech_2003 <dbl>, Bech_2004 <dbl>, ## # Bech_2005 <dbl>, Bech_2006 <dbl>, Bech_2007 <dbl>, Bech_2008 <dbl>, ## # Bech_2009 <dbl>, Bech_2010 <dbl>, Bech_2011 <dbl>, Bech_2012 <dbl>, ## # Bech_2013 <dbl>, Bech_2014 <dbl>, Bech_2015 <dbl>, Bech_2016 <dbl>, …\n\nWe will learn about fill(), anoher {tidyr} function a bit later in this chapter, but its basic purpose is to fill rows with whatever value comes before or after the missing values. slice(n()) then only keeps the last row of the data frame, which is the row that contains all the values (expect for 2016 and 2017, which has missing values, as we wanted).\n\nHere is another example of the importance of having an identifier column when using a spec:\n\ndata(mtcars) mtcars_spec <- mtcars %>% tidyr::expand(am, cyl, .value = \"mpg\") %>% unite(\".name\", am, cyl, remove = FALSE) mtcars_spec\n\nWe can now transform the data:\n\nmtcars %>% pivot_wider_spec(spec = mtcars_spec)\n\n## # A tibble: 32 × 14 ## disp hp drat wt qsec vs gear carb `0_4` `0_6` `0_8` `1_4` `1_6` ## <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 160 110 3.9 2.62 16.5 0 4 4 NA NA NA NA 21 ## 2 160 110 3.9 2.88 17.0 0 4 4 NA NA NA NA 21 ## 3 108 93 3.85 2.32 18.6 1 4 1 NA NA NA 22.8 NA ## 4 258 110 3.08 3.22 19.4 1 3 1 NA 21.4 NA NA NA ## 5 360 175 3.15 3.44 17.0 0 3 2 NA NA 18.7 NA NA ## 6 225 105 2.76 3.46 20.2 1 3 1 NA 18.1 NA NA NA ## 7 360 245 3.21 3.57 15.8 0 3 4 NA NA 14.3 NA NA ## 8 147. 62 3.69 3.19 20 1 4 2 24.4 NA NA NA NA ## 9 141. 95 3.92 3.15 22.9 1 4 2 22.8 NA NA NA NA ## 10 168. 123 3.92 3.44 18.3 1 4 4 NA 19.2 NA NA NA ## # … with 22 more rows, and 1 more variable: `1_8` <dbl>\n\nAs you can see, there are several values of “mpg” for some combinations of “am” times “cyl”. If we remove the other columns, each row will not be uniquely identified anymore. This results in a warning message, and a tibble that contains list-columns:\n\nmtcars %>% select(am, cyl, mpg) %>% pivot_wider_spec(spec = mtcars_spec)\n\n## Warning: Values from `mpg` are not uniquely identified; output will contain list-cols. ## * Use `values_fn = list` to suppress this warning. ## * Use `values_fn = {summary_fun}` to summarise duplicates. ## * Use the following dplyr code to identify duplicates. ## {data} %>% ## dplyr::group_by(am, cyl) %>% ## dplyr::summarise(n = dplyr::n(), .groups = \"drop\") %>% ## dplyr::filter(n > 1L)\n\n## # A tibble: 1 × 6 ## `0_4` `0_6` `0_8` `1_4` `1_6` `1_8` ## <list> <list> <list> <list> <list> <list> ## 1 <dbl [3]> <dbl [4]> <dbl [12]> <dbl [8]> <dbl [3]> <dbl [2]>\n\nWe are going to learn about list-columns in the next section. List-columns are very powerful, and mastering them will be important. But generally speaking, when reshaping data, if you get list-columns back it often means that something went wrong.\n\nSo you have to be careful with this.\n\npivot_longer() is used when you need to go from a wide to a long dataset, meaning, a dataset where there are some columns that should not be columns, but rather, the levels of a factor variable. Let’s suppose that the “am” column is split into two columns, 1 for automatic and 0 for manual transmissions, and that the values filling these colums are miles per gallon, “mpg”:\n\nmtcars_wide_am <- mtcars %>% pivot_wider(names_from = am, values_from = mpg) mtcars_wide_am %>% select(`0`, `1`, everything())\n\n## # A tibble: 32 × 11 ## `0` `1` cyl disp hp drat wt qsec vs gear carb ## <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 NA 21 6 160 110 3.9 2.62 16.5 0 4 4 ## 2 NA 21 6 160 110 3.9 2.88 17.0 0 4 4 ## 3 NA 22.8 4 108 93 3.85 2.32 18.6 1 4 1 ## 4 21.4 NA 6 258 110 3.08 3.22 19.4 1 3 1 ## 5 18.7 NA 8 360 175 3.15 3.44 17.0 0 3 2 ## 6 18.1 NA 6 225 105 2.76 3.46 20.2 1 3 1 ## 7 14.3 NA 8 360 245 3.21 3.57 15.8 0 3 4 ## 8 24.4 NA 4 147. 62 3.69 3.19 20 1 4 2 ## 9 22.8 NA 4 141. 95 3.92 3.15 22.9 1 4 2 ## 10 19.2 NA 6 168. 123 3.92 3.44 18.3 1 4 4 ## # … with 22 more rows\n\nAs you can see, the “0” and “1” columns should not be their own columns, unless there is a very specific and good reason they should… but rather, they should be the levels of another column (in our case, “am”).\n\nWe can go back to a long dataset like so:\n\nmtcars_wide_am %>% pivot_longer(cols = c(`1`, `0`), names_to = \"am\", values_to = \"mpg\") %>% select(am, mpg, everything())\n\n## # A tibble: 64 × 11 ## am mpg cyl disp hp drat wt qsec vs gear carb ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 21 6 160 110 3.9 2.62 16.5 0 4 4 ## 2 0 NA 6 160 110 3.9 2.62 16.5 0 4 4 ## 3 1 21 6 160 110 3.9 2.88 17.0 0 4 4 ## 4 0 NA 6 160 110 3.9 2.88 17.0 0 4 4 ## 5 1 22.8 4 108 93 3.85 2.32 18.6 1 4 1 ## 6 0 NA 4 108 93 3.85 2.32 18.6 1 4 1 ## 7 1 NA 6 258 110 3.08 3.22 19.4 1 3 1 ## 8 0 21.4 6 258 110 3.08 3.22 19.4 1 3 1 ## 9 1 NA 8 360 175 3.15 3.44 17.0 0 3 2 ## 10 0 18.7 8 360 175 3.15 3.44 17.0 0 3 2 ## # … with 54 more rows\n\nIn the cols argument, you need to list all the variables that need to be transformed. Only 1 and 0 must be pivoted, so I list them. Just for illustration purposes, imagine that we would need to pivot 50 columns. It would be faster to list the columns that do not need to be pivoted. This can be achieved by listing the columns that must be excluded with - in front, and maybe using match() with a regular expression:\n\nmtcars_wide_am %>% pivot_longer(cols = -matches(\"^[[:alpha:]]\"), names_to = \"am\", values_to = \"mpg\") %>% select(am, mpg, everything())\n\n## # A tibble: 64 × 11 ## am mpg cyl disp hp drat wt qsec vs gear carb ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 21 6 160 110 3.9 2.62 16.5 0 4 4 ## 2 0 NA 6 160 110 3.9 2.62 16.5 0 4 4 ## 3 1 21 6 160 110 3.9 2.88 17.0 0 4 4 ## 4 0 NA 6 160 110 3.9 2.88 17.0 0 4 4 ## 5 1 22.8 4 108 93 3.85 2.32 18.6 1 4 1 ## 6 0 NA 4 108 93 3.85 2.32 18.6 1 4 1 ## 7 1 NA 6 258 110 3.08 3.22 19.4 1 3 1 ## 8 0 21.4 6 258 110 3.08 3.22 19.4 1 3 1 ## 9 1 NA 8 360 175 3.15 3.44 17.0 0 3 2 ## 10 0 18.7 8 360 175 3.15 3.44 17.0 0 3 2 ## # … with 54 more rows\n\nEvery column that starts with a letter is ok, so there is no need to pivot them. I use the match() function with a regular expression so that I don’t have to type the names of all the columns. select() is used to re-order the columns, only for viewing purposes\n\nnames_to = takes a string as argument, which will be the name of the name column containing the levels 0 and 1, and values_to = also takes a string as argument, which will be the name of the column containing the values. Finally, you can see that there are a lot of NAs in the output. These can be removed easily:\n\nmtcars_wide_am %>% pivot_longer(cols = c(`1`, `0`), names_to = \"am\", values_to = \"mpg\", values_drop_na = TRUE) %>% select(am, mpg, everything())\n\n## # A tibble: 32 × 11 ## am mpg cyl disp hp drat wt qsec vs gear carb ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 21 6 160 110 3.9 2.62 16.5 0 4 4 ## 2 1 21 6 160 110 3.9 2.88 17.0 0 4 4 ## 3 1 22.8 4 108 93 3.85 2.32 18.6 1 4 1 ## 4 0 21.4 6 258 110 3.08 3.22 19.4 1 3 1 ## 5 0 18.7 8 360 175 3.15 3.44 17.0 0 3 2 ## 6 0 18.1 6 225 105 2.76 3.46 20.2 1 3 1 ## 7 0 14.3 8 360 245 3.21 3.57 15.8 0 3 4 ## 8 0 24.4 4 147. 62 3.69 3.19 20 1 4 2 ## 9 0 22.8 4 141. 95 3.92 3.15 22.9 1 4 2 ## 10 0 19.2 6 168. 123 3.92 3.44 18.3 1 4 4 ## # … with 22 more rows\n\nNow for a more advanced example, let’s suppose that we are dealing with the following wide dataset:\n\nmtcars_wide <- mtcars %>% pivot_wider_spec(spec = mtcars_spec) mtcars_wide\n\n## # A tibble: 32 × 14 ## disp hp drat wt qsec vs gear carb `0_4` `0_6` `0_8` `1_4` `1_6` ## <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 160 110 3.9 2.62 16.5 0 4 4 NA NA NA NA 21 ## 2 160 110 3.9 2.88 17.0 0 4 4 NA NA NA NA 21 ## 3 108 93 3.85 2.32 18.6 1 4 1 NA NA NA 22.8 NA ## 4 258 110 3.08 3.22 19.4 1 3 1 NA 21.4 NA NA NA ## 5 360 175 3.15 3.44 17.0 0 3 2 NA NA 18.7 NA NA ## 6 225 105 2.76 3.46 20.2 1 3 1 NA 18.1 NA NA NA ## 7 360 245 3.21 3.57 15.8 0 3 4 NA NA 14.3 NA NA ## 8 147. 62 3.69 3.19 20 1 4 2 24.4 NA NA NA NA ## 9 141. 95 3.92 3.15 22.9 1 4 2 22.8 NA NA NA NA ## 10 168. 123 3.92 3.44 18.3 1 4 4 NA 19.2 NA NA NA ## # … with 22 more rows, and 1 more variable: `1_8` <dbl>\n\nThe difficulty here is that we have columns with two levels of information. For instance, the column “0_4” contains the miles per gallon values for manual cars (0) with 4 cylinders. The first step is to first pivot the columns:\n\nmtcars_wide %>% pivot_longer(cols = matches(\"0|1\"), names_to = \"am_cyl\", values_to = \"mpg\", values_drop_na = TRUE) %>% select(am_cyl, mpg, everything())\n\n## # A tibble: 32 × 10 ## am_cyl mpg disp hp drat wt qsec vs gear carb ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1_6 21 160 110 3.9 2.62 16.5 0 4 4 ## 2 1_6 21 160 110 3.9 2.88 17.0 0 4 4 ## 3 1_4 22.8 108 93 3.85 2.32 18.6 1 4 1 ## 4 0_6 21.4 258 110 3.08 3.22 19.4 1 3 1 ## 5 0_8 18.7 360 175 3.15 3.44 17.0 0 3 2 ## 6 0_6 18.1 225 105 2.76 3.46 20.2 1 3 1 ## 7 0_8 14.3 360 245 3.21 3.57 15.8 0 3 4 ## 8 0_4 24.4 147. 62 3.69 3.19 20 1 4 2 ## 9 0_4 22.8 141. 95 3.92 3.15 22.9 1 4 2 ## 10 0_6 19.2 168. 123 3.92 3.44 18.3 1 4 4 ## # … with 22 more rows\n\nNow we only need to separate the “am_cyl” column into two new columns, “am” and “cyl”:\n\nmtcars_wide %>% pivot_longer(cols = matches(\"0|1\"), names_to = \"am_cyl\", values_to = \"mpg\", values_drop_na = TRUE) %>% separate(am_cyl, into = c(\"am\", \"cyl\"), sep = \"_\") %>% select(am, cyl, mpg, everything())\n\n## # A tibble: 32 × 11 ## am cyl mpg disp hp drat wt qsec vs gear carb ## <chr> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 6 21 160 110 3.9 2.62 16.5 0 4 4 ## 2 1 6 21 160 110 3.9 2.88 17.0 0 4 4 ## 3 1 4 22.8 108 93 3.85 2.32 18.6 1 4 1 ## 4 0 6 21.4 258 110 3.08 3.22 19.4 1 3 1 ## 5 0 8 18.7 360 175 3.15 3.44 17.0 0 3 2 ## 6 0 6 18.1 225 105 2.76 3.46 20.2 1 3 1 ## 7 0 8 14.3 360 245 3.21 3.57 15.8 0 3 4 ## 8 0 4 24.4 147. 62 3.69 3.19 20 1 4 2 ## 9 0 4 22.8 141. 95 3.92 3.15 22.9 1 4 2 ## 10 0 6 19.2 168. 123 3.92 3.44 18.3 1 4 4 ## # … with 22 more rows\n\nIt is also possible to construct a specification data frame, just like for pivot_wider_spec(). This time, I’m using the build_longer_spec() function that makes it easy to build specifications:\n\nmtcars_spec_long <- mtcars_wide %>% build_longer_spec(matches(\"0|1\"), values_to = \"mpg\") %>% separate(name, c(\"am\", \"cyl\"), sep = \"_\") mtcars_spec_long\n\n## # A tibble: 6 × 4 ## .name .value am cyl ## <chr> <chr> <chr> <chr> ## 1 0_4 mpg 0 4 ## 2 0_6 mpg 0 6 ## 3 0_8 mpg 0 8 ## 4 1_4 mpg 1 4 ## 5 1_6 mpg 1 6 ## 6 1_8 mpg 1 8\n\nThis spec can now be specified to pivot_longer():\n\nmtcars_wide %>% pivot_longer_spec(spec = mtcars_spec_long, values_drop_na = TRUE) %>% select(am, cyl, mpg, everything())\n\n## # A tibble: 32 × 11 ## am cyl mpg disp hp drat wt qsec vs gear carb ## <chr> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 1 6 21 160 110 3.9 2.62 16.5 0 4 4 ## 2 1 6 21 160 110 3.9 2.88 17.0 0 4 4 ## 3 1 4 22.8 108 93 3.85 2.32 18.6 1 4 1 ## 4 0 6 21.4 258 110 3.08 3.22 19.4 1 3 1 ## 5 0 8 18.7 360 175 3.15 3.44 17.0 0 3 2 ## 6 0 6 18.1 225 105 2.76 3.46 20.2 1 3 1 ## 7 0 8 14.3 360 245 3.21 3.57 15.8 0 3 4 ## 8 0 4 24.4 147. 62 3.69 3.19 20 1 4 2 ## 9 0 4 22.8 141. 95 3.92 3.15 22.9 1 4 2 ## 10 0 6 19.2 168. 123 3.92 3.44 18.3 1 4 4 ## # … with 22 more rows\n\nDefining specifications give a lot of flexibility and in some complicated cases are the way to go.\n\n4.5.4 summarise() across many columns\n\nSummarising across many columns is really incredibly useful and in my opinion one of the best arguments in favour of switching to a {tidyverse} only workflow:\n\ngasoline %>% group_by(country) %>% summarise(across(starts_with(\"l\"), mean))\n\n## # A tibble: 18 × 5 ## country lgaspcar lincomep lrpmg lcarpcap ## <chr> <dbl> <dbl> <dbl> <dbl> ## 1 austria 4.06 -6.12 -0.486 -8.85 ## 2 belgium 3.92 -5.85 -0.326 -8.63 ## 3 canada 4.86 -5.58 -1.05 -8.08 ## 4 denmark 4.19 -5.76 -0.358 -8.58 ## 5 france 3.82 -5.87 -0.253 -8.45 ## 6 germany 3.89 -5.85 -0.517 -8.51 ## 7 greece 4.88 -6.61 -0.0339 -10.8 ## 8 ireland 4.23 -6.44 -0.348 -9.04 ## 9 italy 3.73 -6.35 -0.152 -8.83 ## 10 japan 4.70 -6.25 -0.287 -9.95 ## 11 netherla 4.08 -5.92 -0.370 -8.82 ## 12 norway 4.11 -5.75 -0.278 -8.77 ## 13 spain 4.06 -5.63 0.739 -9.90 ## 14 sweden 4.01 -7.82 -2.71 -8.25 ## 15 switzerl 4.24 -5.93 -0.902 -8.54 ## 16 turkey 5.77 -7.34 -0.422 -12.5 ## 17 u.k. 3.98 -6.02 -0.459 -8.55 ## 18 u.s.a. 4.82 -5.45 -1.21 -7.78\n\nBut where summarise() and across() really shine is when you want to apply several functions to many columns at once:\n\ngasoline %>% group_by(country) %>% summarise(across(starts_with(\"l\"), tibble::lst(mean, sd, max, min), .names = \"{fn}_{col}\"))\n\n## # A tibble: 18 × 17 ## country mean_lgasp…¹ sd_lg…² max_l…³ min_l…⁴ mean_…⁵ sd_li…⁶ max_l…⁷ min_l…⁸ ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 austria 4.06 0.0693 4.20 3.92 -6.12 0.235 -5.76 -6.47 ## 2 belgium 3.92 0.103 4.16 3.82 -5.85 0.227 -5.53 -6.22 ## 3 canada 4.86 0.0262 4.90 4.81 -5.58 0.193 -5.31 -5.89 ## 4 denmark 4.19 0.158 4.50 4.00 -5.76 0.176 -5.48 -6.06 ## 5 france 3.82 0.0499 3.91 3.75 -5.87 0.241 -5.53 -6.26 ## 6 germany 3.89 0.0239 3.93 3.85 -5.85 0.193 -5.56 -6.16 ## 7 greece 4.88 0.255 5.38 4.48 -6.61 0.331 -6.15 -7.16 ## 8 ireland 4.23 0.0437 4.33 4.16 -6.44 0.162 -6.19 -6.72 ## 9 italy 3.73 0.220 4.05 3.38 -6.35 0.217 -6.08 -6.73 ## 10 japan 4.70 0.684 6.00 3.95 -6.25 0.425 -5.71 -6.99 ## 11 netherla 4.08 0.286 4.65 3.71 -5.92 0.193 -5.66 -6.22 ## 12 norway 4.11 0.123 4.44 3.96 -5.75 0.201 -5.42 -6.09 ## 13 spain 4.06 0.317 4.75 3.62 -5.63 0.278 -5.29 -6.17 ## 14 sweden 4.01 0.0364 4.07 3.91 -7.82 0.126 -7.67 -8.07 ## 15 switzerl 4.24 0.102 4.44 4.05 -5.93 0.124 -5.75 -6.16 ## 16 turkey 5.77 0.329 6.16 5.14 -7.34 0.331 -6.89 -7.84 ## 17 u.k. 3.98 0.0479 4.10 3.91 -6.02 0.107 -5.84 -6.19 ## 18 u.s.a. 4.82 0.0219 4.86 4.79 -5.45 0.148 -5.22 -5.70 ## # … with 8 more variables: mean_lrpmg <dbl>, sd_lrpmg <dbl>, max_lrpmg <dbl>, ## # min_lrpmg <dbl>, mean_lcarpcap <dbl>, sd_lcarpcap <dbl>, ## # max_lcarpcap <dbl>, min_lcarpcap <dbl>, and abbreviated variable names ## # ¹​mean_lgaspcar, ²​sd_lgaspcar, ³​max_lgaspcar, ⁴​min_lgaspcar, ⁵​mean_lincomep, ## # ⁶​sd_lincomep, ⁷​max_lincomep, ⁸​min_lincomep\n\nHere, I first started by grouping by country, then I applied the mean(), sd(), max() and min() functions to every column starting with the character \"l\". tibble::lst() allows you to create a list just like with list() but names its arguments automatically. So the mean() function gets name \"mean\", and so on. Finally, I use the .names = argument to create the template for the new column names. {fn}_{col} creates new column names of the form function name _ column name.\n\nAs mentioned before, across() works with other helper functions:\n\ngasoline %>% group_by(country) %>% summarise(across(contains(\"car\"), tibble::lst(mean, sd, max, min), .names = \"{fn}_{col}\"))\n\n## # A tibble: 18 × 9 ## country mean_lgasp…¹ sd_lg…² max_l…³ min_l…⁴ mean_…⁵ sd_lc…⁶ max_l…⁷ min_l…⁸ ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 austria 4.06 0.0693 4.20 3.92 -8.85 0.473 -8.21 -9.77 ## 2 belgium 3.92 0.103 4.16 3.82 -8.63 0.417 -8.10 -9.41 ## 3 canada 4.86 0.0262 4.90 4.81 -8.08 0.195 -7.77 -8.38 ## 4 denmark 4.19 0.158 4.50 4.00 -8.58 0.349 -8.20 -9.33 ## 5 france 3.82 0.0499 3.91 3.75 -8.45 0.344 -8.01 -9.15 ## 6 germany 3.89 0.0239 3.93 3.85 -8.51 0.406 -7.95 -9.34 ## 7 greece 4.88 0.255 5.38 4.48 -10.8 0.839 -9.57 -12.2 ## 8 ireland 4.23 0.0437 4.33 4.16 -9.04 0.345 -8.55 -9.70 ## 9 italy 3.73 0.220 4.05 3.38 -8.83 0.639 -8.11 -10.1 ## 10 japan 4.70 0.684 6.00 3.95 -9.95 1.20 -8.59 -12.2 ## 11 netherla 4.08 0.286 4.65 3.71 -8.82 0.617 -8.16 -10.0 ## 12 norway 4.11 0.123 4.44 3.96 -8.77 0.438 -8.17 -9.68 ## 13 spain 4.06 0.317 4.75 3.62 -9.90 0.960 -8.63 -11.6 ## 14 sweden 4.01 0.0364 4.07 3.91 -8.25 0.242 -7.96 -8.74 ## 15 switzerl 4.24 0.102 4.44 4.05 -8.54 0.378 -8.03 -9.26 ## 16 turkey 5.77 0.329 6.16 5.14 -12.5 0.751 -11.2 -13.5 ## 17 u.k. 3.98 0.0479 4.10 3.91 -8.55 0.281 -8.26 -9.12 ## 18 u.s.a. 4.82 0.0219 4.86 4.79 -7.78 0.162 -7.54 -8.02 ## # … with abbreviated variable names ¹​mean_lgaspcar, ²​sd_lgaspcar, ## # ³​max_lgaspcar, ⁴​min_lgaspcar, ⁵​mean_lcarpcap, ⁶​sd_lcarpcap, ⁷​max_lcarpcap, ## # ⁸​min_lcarpcap\n\nThis is very likely the quickest, most elegant way to summarise that many columns.\n\nThere’s also a way to summarise where:\n\ngasoline %>% group_by(country) %>% summarise(across(where(is.numeric), tibble::lst(mean, sd, min, max), .names = \"{fn}_{col}\"))\n\n## # A tibble: 18 × 17 ## country mean_lgasp…¹ sd_lg…² min_l…³ max_l…⁴ mean_…⁵ sd_li…⁶ min_l…⁷ max_l…⁸ ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 austria 4.06 0.0693 3.92 4.20 -6.12 0.235 -6.47 -5.76 ## 2 belgium 3.92 0.103 3.82 4.16 -5.85 0.227 -6.22 -5.53 ## 3 canada 4.86 0.0262 4.81 4.90 -5.58 0.193 -5.89 -5.31 ## 4 denmark 4.19 0.158 4.00 4.50 -5.76 0.176 -6.06 -5.48 ## 5 france 3.82 0.0499 3.75 3.91 -5.87 0.241 -6.26 -5.53 ## 6 germany 3.89 0.0239 3.85 3.93 -5.85 0.193 -6.16 -5.56 ## 7 greece 4.88 0.255 4.48 5.38 -6.61 0.331 -7.16 -6.15 ## 8 ireland 4.23 0.0437 4.16 4.33 -6.44 0.162 -6.72 -6.19 ## 9 italy 3.73 0.220 3.38 4.05 -6.35 0.217 -6.73 -6.08 ## 10 japan 4.70 0.684 3.95 6.00 -6.25 0.425 -6.99 -5.71 ## 11 netherla 4.08 0.286 3.71 4.65 -5.92 0.193 -6.22 -5.66 ## 12 norway 4.11 0.123 3.96 4.44 -5.75 0.201 -6.09 -5.42 ## 13 spain 4.06 0.317 3.62 4.75 -5.63 0.278 -6.17 -5.29 ## 14 sweden 4.01 0.0364 3.91 4.07 -7.82 0.126 -8.07 -7.67 ## 15 switzerl 4.24 0.102 4.05 4.44 -5.93 0.124 -6.16 -5.75 ## 16 turkey 5.77 0.329 5.14 6.16 -7.34 0.331 -7.84 -6.89 ## 17 u.k. 3.98 0.0479 3.91 4.10 -6.02 0.107 -6.19 -5.84 ## 18 u.s.a. 4.82 0.0219 4.79 4.86 -5.45 0.148 -5.70 -5.22 ## # … with 8 more variables: mean_lrpmg <dbl>, sd_lrpmg <dbl>, min_lrpmg <dbl>, ## # max_lrpmg <dbl>, mean_lcarpcap <dbl>, sd_lcarpcap <dbl>, ## # min_lcarpcap <dbl>, max_lcarpcap <dbl>, and abbreviated variable names ## # ¹​mean_lgaspcar, ²​sd_lgaspcar, ³​min_lgaspcar, ⁴​max_lgaspcar, ⁵​mean_lincomep, ## # ⁶​sd_lincomep, ⁷​min_lincomep, ⁸​max_lincomep\n\nThis allows you to summarise every column that contains real numbers. The difference between is.double() and is.numeric() is that is.numeric() returns TRUE for integers too, whereas is.double() returns TRUE for real numbers only (integers are real numbers too, but you know what I mean). It is also possible to summarise every column at once:\n\ngasoline %>% select(-year) %>% group_by(country) %>% summarise(across(everything(), tibble::lst(mean, sd, min, max), .names = \"{fn}_{col}\"))\n\n## # A tibble: 18 × 17 ## country mean_lgasp…¹ sd_lg…² min_l…³ max_l…⁴ mean_…⁵ sd_li…⁶ min_l…⁷ max_l…⁸ ## <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 austria 4.06 0.0693 3.92 4.20 -6.12 0.235 -6.47 -5.76 ## 2 belgium 3.92 0.103 3.82 4.16 -5.85 0.227 -6.22 -5.53 ## 3 canada 4.86 0.0262 4.81 4.90 -5.58 0.193 -5.89 -5.31 ## 4 denmark 4.19 0.158 4.00 4.50 -5.76 0.176 -6.06 -5.48 ## 5 france 3.82 0.0499 3.75 3.91 -5.87 0.241 -6.26 -5.53 ## 6 germany 3.89 0.0239 3.85 3.93 -5.85 0.193 -6.16 -5.56 ## 7 greece 4.88 0.255 4.48 5.38 -6.61 0.331 -7.16 -6.15 ## 8 ireland 4.23 0.0437 4.16 4.33 -6.44 0.162 -6.72 -6.19 ## 9 italy 3.73 0.220 3.38 4.05 -6.35 0.217 -6.73 -6.08 ## 10 japan 4.70 0.684 3.95 6.00 -6.25 0.425 -6.99 -5.71 ## 11 netherla 4.08 0.286 3.71 4.65 -5.92 0.193 -6.22 -5.66 ## 12 norway 4.11 0.123 3.96 4.44 -5.75 0.201 -6.09 -5.42 ## 13 spain 4.06 0.317 3.62 4.75 -5.63 0.278 -6.17 -5.29 ## 14 sweden 4.01 0.0364 3.91 4.07 -7.82 0.126 -8.07 -7.67 ## 15 switzerl 4.24 0.102 4.05 4.44 -5.93 0.124 -6.16 -5.75 ## 16 turkey 5.77 0.329 5.14 6.16 -7.34 0.331 -7.84 -6.89 ## 17 u.k. 3.98 0.0479 3.91 4.10 -6.02 0.107 -6.19 -5.84 ## 18 u.s.a. 4.82 0.0219 4.79 4.86 -5.45 0.148 -5.70 -5.22 ## # … with 8 more variables: mean_lrpmg <dbl>, sd_lrpmg <dbl>, min_lrpmg <dbl>, ## # max_lrpmg <dbl>, mean_lcarpcap <dbl>, sd_lcarpcap <dbl>, ## # min_lcarpcap <dbl>, max_lcarpcap <dbl>, and abbreviated variable names ## # ¹​mean_lgaspcar, ²​sd_lgaspcar, ³​min_lgaspcar, ⁴​max_lgaspcar, ⁵​mean_lincomep, ## # ⁶​sd_lincomep, ⁷​min_lincomep, ⁸​max_lincomep\n\nI removed the year variable because it’s not a variable for which we want to have descriptive statistics.\n\n4.7.3 Manipulate strings with {stringr}\n\n{stringr} contains functions to manipulate strings. In Chapter 10, I will teach you about regular expressions, but the functions contained in {stringr} allow you to already do a lot of work on strings, without needing to be a regular expression expert.\n\nI will discuss the most common string operations: detecting, locating, matching, searching and replacing, and exctracting/removing strings.\n\nTo introduce these operations, let us use an ALTO file of an issue of The Winchester News from October 31, 1910, which you can find on this link (to see how the newspaper looked like, click here). I re-hosted the file on a public gist for archiving purposes. While working on the book, the original site went down several times…\n\nALTO is an XML schema for the description of text OCR and layout information of pages for digitzed material, such as newspapers (source: ALTO Wikipedia page). For more details, you can read my blogpost on the matter, but for our current purposes, it is enough to know that the file contains the text of newspaper articles. The file looks like this:\n\n<TextLine HEIGHT=\"138.0\" WIDTH=\"2434.0\" HPOS=\"4056.0\" VPOS=\"5814.0\"> <String STYLEREFS=\"ID7\" HEIGHT=\"108.0\" WIDTH=\"393.0\" HPOS=\"4056.0\" VPOS=\"5838.0\" CONTENT=\"timore\" WC=\"0.82539684\"> <ALTERNATIVE>timole</ALTERNATIVE> <ALTERNATIVE>tlnldre</ALTERNATIVE> <ALTERNATIVE>timor</ALTERNATIVE> <ALTERNATIVE>insole</ALTERNATIVE> <ALTERNATIVE>landed</ALTERNATIVE> </String> <SP WIDTH=\"74.0\" HPOS=\"4449.0\" VPOS=\"5838.0\"/> <String STYLEREFS=\"ID7\" HEIGHT=\"105.0\" WIDTH=\"432.0\" HPOS=\"4524.0\" VPOS=\"5847.0\" CONTENT=\"market\" WC=\"0.95238096\"/> <SP WIDTH=\"116.0\" HPOS=\"4956.0\" VPOS=\"5847.0\"/> <String STYLEREFS=\"ID7\" HEIGHT=\"69.0\" WIDTH=\"138.0\" HPOS=\"5073.0\" VPOS=\"5883.0\" CONTENT=\"as\" WC=\"0.96825397\"/> <SP WIDTH=\"74.0\" HPOS=\"5211.0\" VPOS=\"5883.0\"/> <String STYLEREFS=\"ID7\" HEIGHT=\"69.0\" WIDTH=\"285.0\" HPOS=\"5286.0\" VPOS=\"5877.0\" CONTENT=\"were\" WC=\"1.0\"> <ALTERNATIVE>verc</ALTERNATIVE> <ALTERNATIVE>veer</ALTERNATIVE> </String> <SP WIDTH=\"68.0\" HPOS=\"5571.0\" VPOS=\"5877.0\"/> <String STYLEREFS=\"ID7\" HEIGHT=\"111.0\" WIDTH=\"147.0\" HPOS=\"5640.0\" VPOS=\"5838.0\" CONTENT=\"all\" WC=\"1.0\"/> <SP WIDTH=\"83.0\" HPOS=\"5787.0\" VPOS=\"5838.0\"/> <String STYLEREFS=\"ID7\" HEIGHT=\"111.0\" WIDTH=\"183.0\" HPOS=\"5871.0\" VPOS=\"5835.0\" CONTENT=\"the\" WC=\"0.95238096\"> <ALTERNATIVE>tll</ALTERNATIVE> <ALTERNATIVE>Cu</ALTERNATIVE> <ALTERNATIVE>tall</ALTERNATIVE> </String> <SP WIDTH=\"75.0\" HPOS=\"6054.0\" VPOS=\"5835.0\"/> <String STYLEREFS=\"ID3\" HEIGHT=\"132.0\" WIDTH=\"351.0\" HPOS=\"6129.0\" VPOS=\"5814.0\" CONTENT=\"cattle\" WC=\"0.95238096\"/> </TextLine>\n\nWe are interested in the strings after CONTENT=. We are going to use functions from the {stringr} package to get the strings after CONTENT=. In Chapter 10, we are going to explore this file again, but using complex regular expressions to get all the content in one go.\n\n4.7.3.1 Getting text data into Rstudio\n\nFirst of all, let us read in the file:\n\nwinchester <- read_lines(\"https://gist.githubusercontent.com/b-rodrigues/5139560e7d0f2ecebe5da1df3629e015/raw/e3031d894ffb97217ddbad1ade1b307c9937d2c8/gistfile1.txt\")\n\nEven though the file is an XML file, I still read it in using read_lines() and not read_xml() from the {xml2} package. This is for the purposes of the current exercise, and also because I always have trouble with XML files, and prefer to treat them as simple text files, and use regular expressions to get what I need.\n\nNow that the ALTO file is read in and saved in the winchester variable, you might want to print the whole thing in the console. Before that, take a look at the structure:\n\nstr(winchester)\n\n## chr [1:43] \"\" ...\n\nSo the winchester variable is a character atomic vector with 43 elements. So first, we need to understand what these elements are. Let’s start with the first one:\n\nwinchester[1]\n\n## [1] \"\"\n\nOk, so it seems like the first element is part of the header of the file. What about the second one?\n\nwinchester[2]\n\n## [1] \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=UTF-8\\\"><base href=\\\"https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml\\\"><style>body{margin-left:0;margin-right:0;margin-top:0}#bN015htcoyT__google-cache-hdr{background:#f5f5f5;font:13px arial,sans-serif;text-align:left;color:#202020;border:0;margin:0;border-bottom:1px solid #cecece;line-height:16px;padding:16px 28px 24px 28px}#bN015htcoyT__google-cache-hdr *{display:inline;font:inherit;text-align:inherit;color:inherit;line-height:inherit;background:none;border:0;margin:0;padding:0;letter-spacing:0}#bN015htcoyT__google-cache-hdr a{text-decoration:none;color:#1a0dab}#bN015htcoyT__google-cache-hdr a:hover{text-decoration:underline}#bN015htcoyT__google-cache-hdr a:visited{color:#609}#bN015htcoyT__google-cache-hdr div{display:block;margin-top:4px}#bN015htcoyT__google-cache-hdr b{font-weight:bold;display:inline-block;direction:ltr}</style><div id=\\\"bN015htcoyT__google-cache-hdr\\\"><div><span>This is Google's cache of <a href=\\\"https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml\\\">https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml</a>.</span>&nbsp;<span>It is a snapshot of the page as it appeared on 21 Jan 2019 05:18:18 GMT.</span>&nbsp;<span>The <a href=\\\"https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml\\\">current page</a> could have changed in the meantime.</span>&nbsp;<a href=\\\"http://support.google.com/websearch/bin/answer.py?hl=en&amp;p=cached&amp;answer=1687222\\\"><span>Learn more</span>.</a></div><div><span style=\\\"display:inline-block;margin-top:8px;margin-right:104px;white-space:nowrap\\\"><span style=\\\"margin-right:28px\\\"><span style=\\\"font-weight:bold\\\">Full version</span></span><span style=\\\"margin-right:28px\\\"><a href=\\\"http://webcache.googleusercontent.com/search?q=cache:2BVPV8QGj3oJ:https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml&amp;hl=en&amp;gl=lu&amp;strip=1&amp;vwsrc=0\\\"><span>Text-only version</span></a></span><span style=\\\"margin-right:28px\\\"><a href=\\\"http://webcache.googleusercontent.com/search?q=cache:2BVPV8QGj3oJ:https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml&amp;hl=en&amp;gl=lu&amp;strip=0&amp;vwsrc=1\\\"><span>View source</span></a></span></span></div><span style=\\\"display:inline-block;margin-top:8px;color:#717171\\\"><span>Tip: To quickly find your search term on this page, press <b>Ctrl+F</b> or <b>⌘-F</b> (Mac) and use the find bar.</span></span></div><div style=\\\"position:relative;\\\"><?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\"\n\nSame. So where is the content? The file is very large, so if you print it in the console, it will take quite some time to print, and you will not really be able to make out anything. The best way would be to try to detect the string CONTENT and work from there.\n\n4.7.3.2 Detecting, getting the position and locating strings\n\nWhen confronted to an atomic vector of strings, you might want to know inside which elements you can find certain strings. For example, to know which elements of winchester contain the string CONTENT, use str_detect():\n\nwinchester %>% str_detect(\"CONTENT\")\n\n## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE FALSE FALSE TRUE\n\nThis returns a boolean atomic vector of the same length as winchester. If the string CONTENT is nowhere to be found, the result will equal FALSE, if not it will equal TRUE. Here it is easy to see that the last element contains the string CONTENT. But what if instead of having 43 elements, the vector had 24192 elements? And hundreds would contain the string CONTENT? It would be easier to instead have the indices of the vector where one can find the word CONTENT. This is possible with str_which():\n\nwinchester %>% str_which(\"CONTENT\")\n\n## [1] 43\n\nHere, the result is 43, meaning that the 43rd element of winchester contains the string CONTENT somewhere. If we need more precision, we can use str_locate() and str_locate_all(). To explain how both these functions work, let’s create a very small example:\n\nancient_philosophers <- c(\"aristotle\", \"plato\", \"epictetus\", \"seneca the younger\", \"epicurus\", \"marcus aurelius\")\n\nNow suppose I am interested in philosophers whose name ends in us. Let us use str_locate() first:\n\nancient_philosophers %>% str_locate(\"us\")\n\n## start end ## [1,] NA NA ## [2,] NA NA ## [3,] 8 9 ## [4,] NA NA ## [5,] 7 8 ## [6,] 5 6\n\nYou can interpret the result as follows: in the rows, the index of the vector where the string us is found. So the 3rd, 5th and 6th philosopher have us somewhere in their name. The result also has two columns: start and end. These give the position of the string. So the string us can be found starting at position 8 of the 3rd element of the vector, and ends at position 9. Same goes for the other philisophers. However, consider Marcus Aurelius. He has two names, both ending with us. However, str_locate() only shows the position of the us in Marcus.\n\nTo get both us strings, you need to use str_locate_all():\n\nancient_philosophers %>% str_locate_all(\"us\")\n\n## [[1]] ## start end ## ## [[2]] ## start end ## ## [[3]] ## start end ## [1,] 8 9 ## ## [[4]] ## start end ## ## [[5]] ## start end ## [1,] 7 8 ## ## [[6]] ## start end ## [1,] 5 6 ## [2,] 14 15\n\nNow we get the position of the two us in Marcus Aurelius. Doing this on the winchester vector will give use the position of the CONTENT string, but this is not really important right now. What matters is that you know how str_locate() and str_locate_all() work.\n\nSo now that we know what interests us in the 43nd element of winchester, let’s take a closer look at it:\n\nwinchester[43]\n\nAs you can see, it’s a mess:\n\n<TextLine HEIGHT=\\\"126.0\\\" WIDTH=\\\"1731.0\\\" HPOS=\\\"17160.0\\\" VPOS=\\\"21252.0\\\"><String HEIGHT=\\\"114.0\\\" WIDTH=\\\"354.0\\\" HPOS=\\\"17160.0\\\" VPOS=\\\"21264.0\\\" CONTENT=\\\"0tV\\\" WC=\\\"0.8095238\\\"/><SP WIDTH=\\\"131.0\\\" HPOS=\\\"17514.0\\\" VPOS=\\\"21264.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"111.0\\\" WIDTH=\\\"474.0\\\" HPOS=\\\"17646.0\\\" VPOS=\\\"21258.0\\\" CONTENT=\\\"BATES\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"140.0\\\" HPOS=\\\"18120.0\\\" VPOS=\\\"21258.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"114.0\\\" WIDTH=\\\"630.0\\\" HPOS=\\\"18261.0\\\" VPOS=\\\"21252.0\\\" CONTENT=\\\"President\\\" WC=\\\"1.0\\\"><ALTERNATIVE>Prcideht</ALTERNATIVE><ALTERNATIVE>Pride</ALTERNATIVE></String></TextLine><TextLine HEIGHT=\\\"153.0\\\" WIDTH=\\\"1689.0\\\" HPOS=\\\"17145.0\\\" VPOS=\\\"21417.0\\\"><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"105.0\\\" WIDTH=\\\"258.0\\\" HPOS=\\\"17145.0\\\" VPOS=\\\"21439.0\\\" CONTENT=\\\"WM\\\" WC=\\\"0.82539684\\\"><TextLine HEIGHT=\\\"120.0\\\" WIDTH=\\\"2211.0\\\" HPOS=\\\"16788.0\\\" VPOS=\\\"21870.0\\\"><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"96.0\\\" WIDTH=\\\"102.0\\\" HPOS=\\\"16788.0\\\" VPOS=\\\"21894.0\\\" CONTENT=\\\"It\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"72.0\\\" HPOS=\\\"16890.0\\\" VPOS=\\\"21894.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"96.0\\\" WIDTH=\\\"93.0\\\" HPOS=\\\"16962.0\\\" VPOS=\\\"21885.0\\\" CONTENT=\\\"is\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"80.0\\\" HPOS=\\\"17055.0\\\" VPOS=\\\"21885.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"102.0\\\" WIDTH=\\\"417.0\\\" HPOS=\\\"17136.0\\\" VPOS=\\\"21879.0\\\" CONTENT=\\\"seldom\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"80.0\\\" HPOS=\\\"17553.0\\\" VPOS=\\\"21879.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"96.0\\\" WIDTH=\\\"267.0\\\" HPOS=\\\"17634.0\\\" VPOS=\\\"21873.0\\\" CONTENT=\\\"hard\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"81.0\\\" HPOS=\\\"17901.0\\\" VPOS=\\\"21873.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"87.0\\\" WIDTH=\\\"111.0\\\" HPOS=\\\"17982.0\\\" VPOS=\\\"21879.0\\\" CONTENT=\\\"to\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"81.0\\\" HPOS=\\\"18093.0\\\" VPOS=\\\"21879.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"96.0\\\" WIDTH=\\\"219.0\\\" HPOS=\\\"18174.0\\\" VPOS=\\\"21870.0\\\" CONTENT=\\\"find\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"77.0\\\" HPOS=\\\"18393.0\\\" VPOS=\\\"21870.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"69.0\\\" WIDTH=\\\"66.0\\\" HPOS=\\\"18471.0\\\" VPOS=\\\"21894.0\\\" CONTENT=\\\"a\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"77.0\\\" HPOS=\\\"18537.0\\\" VPOS=\\\"21894.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"78.0\\\" WIDTH=\\\"384.0\\\" HPOS=\\\"18615.0\\\" VPOS=\\\"21888.0\\\" CONTENT=\\\"succes\\\" WC=\\\"0.82539684\\\"><ALTERNATIVE>success</ALTERNATIVE></String></TextLine><TextLine HEIGHT=\\\"126.0\\\" WIDTH=\\\"2316.0\\\" HPOS=\\\"16662.0\\\" VPOS=\\\"22008.0\\\"><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"75.0\\\" WIDTH=\\\"183.0\\\" HPOS=\\\"16662.0\\\" VPOS=\\\"22059.0\\\" CONTENT=\\\"sor\\\" WC=\\\"1.0\\\"><ALTERNATIVE>soar</ALTERNATIVE></String><SP WIDTH=\\\"72.0\\\" HPOS=\\\"16845.0\\\" VPOS=\\\"22059.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"90.0\\\" WIDTH=\\\"168.0\\\" HPOS=\\\"16917.0\\\" VPOS=\\\"22035.0\\\" CONTENT=\\\"for\\\" WC=\\\"1.0\\\"/><SP WIDTH=\\\"72.0\\\" HPOS=\\\"17085.0\\\" VPOS=\\\"22035.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"69.0\\\" WIDTH=\\\"267.0\\\" HPOS=\\\"17157.0\\\" VPOS=\\\"22050.0\\\" CONTENT=\\\"even\\\" WC=\\\"1.0\\\"><ALTERNATIVE>cen</ALTERNATIVE><ALTERNATIVE>cent</ALTERNATIVE></String><SP WIDTH=\\\"77.0\\\" HPOS=\\\"17434.0\\\" VPOS=\\\"22050.0\\\"/><String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"66.0\\\" WIDTH=\\\"63.0\\\" HPOS=\\\"17502.0\\\" VPOS=\\\"22044.0\\\"\n\nThe file was imported without any newlines. So we need to insert them ourselves, by splitting the string in a clever way.\n\n4.7.3.3 Splitting strings\n\nThere are two functions included in {stringr} to split strings, str_split() and str_split_fixed(). Let’s go back to our ancient philosophers. Two of them, Seneca the Younger and Marcus Aurelius have something else in common than both being Roman Stoic philosophers. Their names are composed of several words. If we want to split their names at the space character, we can use str_split() like this:\n\nancient_philosophers %>% str_split(\" \")\n\n## [[1]] ## [1] \"aristotle\" ## ## [[2]] ## [1] \"plato\" ## ## [[3]] ## [1] \"epictetus\" ## ## [[4]] ## [1] \"seneca\" \"the\" \"younger\" ## ## [[5]] ## [1] \"epicurus\" ## ## [[6]] ## [1] \"marcus\" \"aurelius\"\n\nstr_split() also has a simplify = TRUE option:\n\nancient_philosophers %>% str_split(\" \", simplify = TRUE)\n\n## [,1] [,2] [,3] ## [1,] \"aristotle\" \"\" \"\" ## [2,] \"plato\" \"\" \"\" ## [3,] \"epictetus\" \"\" \"\" ## [4,] \"seneca\" \"the\" \"younger\" ## [5,] \"epicurus\" \"\" \"\" ## [6,] \"marcus\" \"aurelius\" \"\"\n\nThis time, the returned object is a matrix.\n\nWhat about str_split_fixed()? The difference is that here you can specify the number of pieces to return. For example, you could consider the name “Aurelius” to be the middle name of Marcus Aurelius, and the “the younger” to be the middle name of Seneca the younger. This means that you would want to split the name only at the first space character, and not at all of them. This is easily achieved with str_split_fixed():\n\nancient_philosophers %>% str_split_fixed(\" \", 2)\n\n## [,1] [,2] ## [1,] \"aristotle\" \"\" ## [2,] \"plato\" \"\" ## [3,] \"epictetus\" \"\" ## [4,] \"seneca\" \"the younger\" ## [5,] \"epicurus\" \"\" ## [6,] \"marcus\" \"aurelius\"\n\nThis gives the expected result.\n\nSo how does this help in our case? Well, if you look at how the ALTO file looks like, at the beginning of this section, you will notice that every line ends with the “>” character. So let’s split at that character!\n\nwinchester_text <- winchester[43] %>% str_split(\">\")\n\nLet’s take a closer look at winchester_text:\n\nstr(winchester_text)\n\n## List of 1 ## $ : chr [1:19706] \"</processingStepSettings\" \"<processingSoftware\" \"<softwareCreator\" \"iArchives</softwareCreator\" ...\n\nSo this is a list of length one, and the first, and only, element of that list is an atomic vector with 19706 elements. Since this is a list of only one element, we can simplify it by saving the atomic vector in a variable:\n\nwinchester_text <- winchester_text[[1]]\n\nLet’s now look at some lines:\n\nwinchester_text[1232:1245]\n\n## [1] \"<SP WIDTH=\\\"66.0\\\" HPOS=\\\"5763.0\\\" VPOS=\\\"9696.0\\\"/\" ## [2] \"<String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"108.0\\\" WIDTH=\\\"612.0\\\" HPOS=\\\"5829.0\\\" VPOS=\\\"9693.0\\\" CONTENT=\\\"Louisville\\\" WC=\\\"1.0\\\"\" ## [3] \"<ALTERNATIVE\" ## [4] \"Loniile</ALTERNATIVE\" ## [5] \"<ALTERNATIVE\" ## [6] \"Lenities</ALTERNATIVE\" ## [7] \"</String\" ## [8] \"</TextLine\" ## [9] \"<TextLine HEIGHT=\\\"150.0\\\" WIDTH=\\\"2520.0\\\" HPOS=\\\"4032.0\\\" VPOS=\\\"9849.0\\\"\" ## [10] \"<String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"108.0\\\" WIDTH=\\\"510.0\\\" HPOS=\\\"4032.0\\\" VPOS=\\\"9861.0\\\" CONTENT=\\\"Tobacco\\\" WC=\\\"1.0\\\"/\" ## [11] \"<SP WIDTH=\\\"113.0\\\" HPOS=\\\"4542.0\\\" VPOS=\\\"9861.0\\\"/\" ## [12] \"<String STYLEREFS=\\\"ID7\\\" HEIGHT=\\\"105.0\\\" WIDTH=\\\"696.0\\\" HPOS=\\\"4656.0\\\" VPOS=\\\"9861.0\\\" CONTENT=\\\"Warehouse\\\" WC=\\\"1.0\\\"\" ## [13] \"<ALTERNATIVE\" ## [14] \"WHrchons</ALTERNATIVE\"\n\nThis now looks easier to handle. We can narrow it down to the lines that only contain the string we are interested in, “CONTENT”. First, let’s get the indices:\n\ncontent_winchester_index <- winchester_text %>% str_which(\"CONTENT\")\n\nHow many lines contain the string “CONTENT”?\n\nlength(content_winchester_index)\n\n## [1] 4462\n\nAs you can see, this reduces the amount of data we have to work with. Let us save this is a new variable:\n\ncontent_winchester <- winchester_text[content_winchester_index]\n\n4.7.3.4 Matching strings\n\nMatching strings is useful, but only in combination with regular expressions. As stated at the beginning of this section, we are going to learn about regular expressions in Chapter 10, but in order to make this section useful, we are going to learn the easiest, but perhaps the most useful regular expression: .*.\n\nLet’s go back to our ancient philosophers, and use str_match() and see what happens. Let’s match the “us” string:\n\nancient_philosophers %>% str_match(\"us\")\n\n## [,1] ## [1,] NA ## [2,] NA ## [3,] \"us\" ## [4,] NA ## [5,] \"us\" ## [6,] \"us\"\n\nNot very useful, but what about the regular expression .*? How could it help?\n\nancient_philosophers %>% str_match(\".*us\")\n\n## [,1] ## [1,] NA ## [2,] NA ## [3,] \"epictetus\" ## [4,] NA ## [5,] \"epicurus\" ## [6,] \"marcus aurelius\"\n\nThat’s already very interesting! So how does .* work? To understand, let’s first start by using . alone:\n\nancient_philosophers %>% str_match(\".us\")\n\n## [,1] ## [1,] NA ## [2,] NA ## [3,] \"tus\" ## [4,] NA ## [5,] \"rus\" ## [6,] \"cus\"\n\nThis also matched whatever symbol comes just before the “u” from “us”. What if we use two . instead?\n\nancient_philosophers %>% str_match(\"..us\")\n\n## [,1] ## [1,] NA ## [2,] NA ## [3,] \"etus\" ## [4,] NA ## [5,] \"urus\" ## [6,] \"rcus\"\n\nThis time, we get the two symbols that immediately precede “us”. Instead of continuing like this we now use the *, which matches zero or more of .. So by combining * and ., we can match any symbol repeatedly, until there is nothing more to match. Note that there is also +, which works similarly to *, but it matches one or more symbols.\n\nThere is also a str_match_all():\n\nancient_philosophers %>% str_match_all(\".*us\")\n\n## [[1]] ## [,1] ## ## [[2]] ## [,1] ## ## [[3]] ## [,1] ## [1,] \"epictetus\" ## ## [[4]] ## [,1] ## ## [[5]] ## [,1] ## [1,] \"epicurus\" ## ## [[6]] ## [,1] ## [1,] \"marcus aurelius\"\n\nIn this particular case it does not change the end result, but keep it in mind for cases like this one:\n\nc(\"haha\", \"huhu\") %>% str_match(\"ha\")\n\n## [,1] ## [1,] \"ha\" ## [2,] NA\n\nand:\n\nc(\"haha\", \"huhu\") %>% str_match_all(\"ha\")\n\n## [[1]] ## [,1] ## [1,] \"ha\" ## [2,] \"ha\" ## ## [[2]] ## [,1]\n\nWhat if we want to match names containing the letter “t”? Easy:\n\nancient_philosophers %>% str_match(\".*t.*\")\n\n## [,1] ## [1,] \"aristotle\" ## [2,] \"plato\" ## [3,] \"epictetus\" ## [4,] \"seneca the younger\" ## [5,] NA ## [6,] NA\n\nSo how does this help us with our historical newspaper? Let’s try to get the strings that come after “CONTENT”:\n\nwinchester_content <- winchester_text %>% str_match(\"CONTENT.*\")\n\nLet’s use our faithful str() function to take a look:\n\nwinchester_content %>% str\n\n## chr [1:19706, 1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ...\n\nHum, there’s a lot of NA values! This is because a lot of the lines from the file did not have the string “CONTENT”, so there is no match possible. Let’s us remove all these NAs. Because the result is a matrix, we cannot use the filter() function from {dplyr}. So we need to convert it to a tibble first:\n\nwinchester_content <- winchester_content %>% as.tibble() %>% filter(!is.na(V1))\n\n## Warning: `as.tibble()` was deprecated in tibble 2.0.0. ## Please use `as_tibble()` instead. ## The signature and semantics have changed, see `?as_tibble`.\n\n## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0. ## Using compatibility `.name_repair`.\n\nBecause matrix columns do not have names, when a matrix gets converted into a tibble, the firt column gets automatically called V1. This is why I filter on this column. Let’s take a look at the data:\n\nhead(winchester_content)\n\n## # A tibble: 6 × 1 ## V1 ## <chr> ## 1 \"CONTENT=\\\"J\\\" WC=\\\"0.8095238\\\"/\" ## 2 \"CONTENT=\\\"a\\\" WC=\\\"0.8095238\\\"/\" ## 3 \"CONTENT=\\\"Ira\\\" WC=\\\"0.95238096\\\"/\" ## 4 \"CONTENT=\\\"mj\\\" WC=\\\"0.8095238\\\"/\" ## 5 \"CONTENT=\\\"iI\\\" WC=\\\"0.8095238\\\"/\" ## 6 \"CONTENT=\\\"tE1r\\\" WC=\\\"0.8095238\\\"/\"\n\n4.7.3.5 Searching and replacing strings\n\nWe are getting close to the final result. We still need to do some cleaning however. Since our data is inside a nice tibble, we might as well stick with it. So let’s first rename the column and change all the strings to lowercase:\n\nwinchester_content <- winchester_content %>% mutate(content = tolower(V1)) %>% select(-V1)\n\nLet’s take a look at the result:\n\nhead(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 \"content=\\\"j\\\" wc=\\\"0.8095238\\\"/\" ## 2 \"content=\\\"a\\\" wc=\\\"0.8095238\\\"/\" ## 3 \"content=\\\"ira\\\" wc=\\\"0.95238096\\\"/\" ## 4 \"content=\\\"mj\\\" wc=\\\"0.8095238\\\"/\" ## 5 \"content=\\\"ii\\\" wc=\\\"0.8095238\\\"/\" ## 6 \"content=\\\"te1r\\\" wc=\\\"0.8095238\\\"/\"\n\nThe second part of the string, “wc=….” is not really interesting. Let’s search and replace this with an empty string, using str_replace():\n\nwinchester_content <- winchester_content %>% mutate(content = str_replace(content, \"wc.*\", \"\")) head(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 \"content=\\\"j\\\" \" ## 2 \"content=\\\"a\\\" \" ## 3 \"content=\\\"ira\\\" \" ## 4 \"content=\\\"mj\\\" \" ## 5 \"content=\\\"ii\\\" \" ## 6 \"content=\\\"te1r\\\" \"\n\nWe need to use the regular expression from before to replace “wc” and every character that follows. The same can be use to remove “content=”:\n\nwinchester_content <- winchester_content %>% mutate(content = str_replace(content, \"content=\", \"\")) head(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 \"\\\"j\\\" \" ## 2 \"\\\"a\\\" \" ## 3 \"\\\"ira\\\" \" ## 4 \"\\\"mj\\\" \" ## 5 \"\\\"ii\\\" \" ## 6 \"\\\"te1r\\\" \"\n\nWe are almost done, but some cleaning is still necessary:\n\n4.7.3.6 Exctracting or removing strings\n\nNow, because I now the ALTO spec, I know how to find words that are split between two sentences:\n\nwinchester_content %>% filter(str_detect(content, \"hyppart\"))\n\n## # A tibble: 64 × 1 ## content ## <chr> ## 1 \"\\\"aver\\\" subs_type=\\\"hyppart1\\\" subs_content=\\\"average\\\" \" ## 2 \"\\\"age\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"average\\\" \" ## 3 \"\\\"considera\\\" subs_type=\\\"hyppart1\\\" subs_content=\\\"consideration\\\" \" ## 4 \"\\\"tion\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"consideration\\\" \" ## 5 \"\\\"re\\\" subs_type=\\\"hyppart1\\\" subs_content=\\\"resigned\\\" \" ## 6 \"\\\"signed\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"resigned\\\" \" ## 7 \"\\\"install\\\" subs_type=\\\"hyppart1\\\" subs_content=\\\"installed\\\" \" ## 8 \"\\\"ed\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"installed\\\" \" ## 9 \"\\\"be\\\" subs_type=\\\"hyppart1\\\" subs_content=\\\"before\\\" \" ## 10 \"\\\"fore\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"before\\\" \" ## # … with 54 more rows\n\nFor instance, the word “average” was split over two lines, the first part of the word, “aver” on the first line, and the second part of the word, “age”, on the second line. We want to keep what comes after “subs_content”. Let’s extract the word “average” using str_extract(). However, because only some words were split between two lines, we first need to detect where the string “hyppart1” is located, and only then can we extract what comes after “subs_content”. Thus, we need to combine str_detect() to first detect the string, and then str_extract() to extract what comes after “subs_content”:\n\nwinchester_content <- winchester_content %>% mutate(content = if_else(str_detect(content, \"hyppart1\"), str_extract_all(content, \"content=.*\", simplify = TRUE), content))\n\nLet’s take a look at the result:\n\nwinchester_content %>% filter(str_detect(content, \"content\"))\n\n## # A tibble: 64 × 1 ## content ## <chr> ## 1 \"content=\\\"average\\\" \" ## 2 \"\\\"age\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"average\\\" \" ## 3 \"content=\\\"consideration\\\" \" ## 4 \"\\\"tion\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"consideration\\\" \" ## 5 \"content=\\\"resigned\\\" \" ## 6 \"\\\"signed\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"resigned\\\" \" ## 7 \"content=\\\"installed\\\" \" ## 8 \"\\\"ed\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"installed\\\" \" ## 9 \"content=\\\"before\\\" \" ## 10 \"\\\"fore\\\" subs_type=\\\"hyppart2\\\" subs_content=\\\"before\\\" \" ## # … with 54 more rows\n\nWe still need to get rid of the string “content=” and then of all the strings that contain “hyppart2”, which are not needed now:\n\nwinchester_content <- winchester_content %>% mutate(content = str_replace(content, \"content=\", \"\")) %>% mutate(content = if_else(str_detect(content, \"hyppart2\"), NA_character_, content)) head(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 \"\\\"j\\\" \" ## 2 \"\\\"a\\\" \" ## 3 \"\\\"ira\\\" \" ## 4 \"\\\"mj\\\" \" ## 5 \"\\\"ii\\\" \" ## 6 \"\\\"te1r\\\" \"\n\nAlmost done! We only need to remove the \" characters:\n\nwinchester_content <- winchester_content %>% mutate(content = str_replace_all(content, \"\\\"\", \"\")) head(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 \"j \" ## 2 \"a \" ## 3 \"ira \" ## 4 \"mj \" ## 5 \"ii \" ## 6 \"te1r \"\n\nLet’s remove space characters with str_trim():\n\nwinchester_content <- winchester_content %>% mutate(content = str_trim(content)) head(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 j ## 2 a ## 3 ira ## 4 mj ## 5 ii ## 6 te1r\n\nTo finish off this section, let’s remove stop words (words that do not add any meaning to a sentence, such as “as”, “and”…) and words that are composed of less than 3 characters. You can find a dataset with stopwords inside the {stopwords} package:\n\nlibrary(stopwords) data(data_stopwords_stopwordsiso) eng_stopwords <- tibble(\"content\" = data_stopwords_stopwordsiso$en) winchester_content <- winchester_content %>% anti_join(eng_stopwords) %>% filter(nchar(content) > 3)\n\n## Joining, by = \"content\"\n\nhead(winchester_content)\n\n## # A tibble: 6 × 1 ## content ## <chr> ## 1 te1r ## 2 jilas ## 3 edition ## 4 winchester ## 5 news ## 6 injuries\n\nThat’s it for this section! You now know how to work with strings, but in Chapter 10 we are going one step further by learning about regular expressions, which offer much more power."
    }
}