{
    "id": "yago_18972_2",
    "rank": 70,
    "data": {
        "url": "https://medium.com/%40simo.vanni/how-i-managed-to-knock-down-chatgpt-49cf908b5fff",
        "read_more_link": "",
        "language": "en",
        "title": "How I managed to knock down ChatGPT",
        "top_image": "https://miro.medium.com/v2/resize:fit:1024/1*jApt9gFVqKCBMmJqf4fqnA.png",
        "meta_img": "https://miro.medium.com/v2/resize:fit:1024/1*jApt9gFVqKCBMmJqf4fqnA.png",
        "images": [
            "https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png",
            "https://miro.medium.com/v2/resize:fill:88:88/1*2MweC-Gh7HoLtc7AjXfIQQ.jpeg",
            "https://miro.medium.com/v2/resize:fill:144:144/1*2MweC-Gh7HoLtc7AjXfIQQ.jpeg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Simo Vanni",
            "medium.com",
            "@simo.vanni"
        ],
        "publish_date": "2022-12-13T09:57:31.756000+00:00",
        "summary": "",
        "meta_description": "I assume everyone in this channel knows what ChatGPT stands for — the recent state of the art language model from OpenAI. Today, I gave it a try and my sentiment went from curiosity to smile for the…",
        "meta_lang": "en",
        "meta_favicon": "https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19",
        "meta_site_name": "Medium",
        "canonical_link": "https://medium.com/@simo.vanni/how-i-managed-to-knock-down-chatgpt-49cf908b5fff",
        "text": "I assume everyone in this channel knows what ChatGPT stands for — the recent state of the art language model from OpenAI.\n\nToday, I gave it a try and my sentiment went from curiosity to smile for the high quality, but eventually to surprise when I managed to topple the bot with a simple task.\n\nI first asked simple questions about my own discipline, primate vision. It was well able to answer simple questions, but more specific ones were not correctly answered. No surprise here.\n\nNext I turned into my own language, Finnish, spoken only by some 5 million people. The Finnish language skill was very good, well beyond comprehensible, but not perfect. No real surprise here, but very impressive!\n\nThen I asked a simple question, a question I ask often as a neurologist from patients who are screened for degenerative brain diseases. I asked it to start from 100 and then subtract 7, and again 7 until it reaches zero.\n\nFirst it subtracted correctly 7 twice, and gave a verbal answer, implicating that this calculation should continue down to zero.\n\nThen I critisized it for not doing the task, and asked it again to continue with the calculation until zero. The ChatGPT started doing the calculations correctly. However, it did not stop to zero, but continued subtracting 7 from ever increasing negative number until it gave an error.\n\nThereafter, I have not been able to access the ChatGPT.\n\nWhat happened, I think, was that it does not have a sense of the concept “zero”, and that the zero divides the numbers into positive and negative numbers. Thus, when it did not come up with zero itself during the subtraction, it did not know when to stop.\n\nFor me, zero houses a spatial position between the positive numbers above, and negative numbers below. I guess people have a diverse set of ideas for zero, but what might be common, is that it is somehow attached to contextual knowledge. This contextual knowledge sediments to our cerebral cortex during lifetime, and somehow the system can superfast access relevant context, when there is need.\n\nHuman cortex has about 180 functional areas in each hemisphere, each at least to some extent specialized for processing distinct signals. The connection strength — the number of axons from one area to the nex t—spans 5 log units, with some interareal connections having just a few fibers and others millions. Moreover, connections travel not only directly from one area to the next but also via thalamic nuclei, thus forming a triangle of connections. Finally, most connections are reciprocal, with feedback as well as feedforward triangle. Apparently, it is the feedback from or processing in the functionally higher order areas, which provides the contextual knowledge.\n\nIntriguinly, the feedback systematically lands in different cortical layers and even different parts on neurons compared to the feedforwards signals. In mice primary visual cortex, single cells have been shown to simultaneously recieve signals from all orientations in the single cell’s receptive field, while the spiking output of the neuron was highly tuned for orientation. Apparently the single cell works together with the multiple cortical areas, and provides the necessary contextual data.\n\nObviously, there is still some catching up to do for the engineers constructing the AI models."
    }
}