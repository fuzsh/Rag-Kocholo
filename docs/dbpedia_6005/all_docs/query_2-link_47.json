{
    "id": "dbpedia_6005_2",
    "rank": 47,
    "data": {
        "url": "https://arxiv.org/html/2406.09001v1",
        "read_more_link": "",
        "language": "en",
        "title": "Evaluation of Sparse Acoustic Array Geometries for the Application in Indoor Localization",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/x2.png",
            "https://arxiv.org/html/x3.png",
            "https://arxiv.org/html/x4.png",
            "https://arxiv.org/html/x5.png",
            "https://arxiv.org/html/extracted/5663861/figures/system-implementation/array-on-rotation-table.jpg",
            "https://arxiv.org/html/extracted/5663861/figures/simulation/composite-Npoints-50.png",
            "https://arxiv.org/html/extracted/5663861/figures/calibration/frequency-calib-composite-plot-ieee.png",
            "https://arxiv.org/html/extracted/5663861/figures/experiments/narrowband-angle-legacy-algorithms-comparison.png",
            "https://arxiv.org/html/extracted/5663861/figures/experiments/narrowband-angle-legacy-geometries-spherical.png",
            "https://arxiv.org/html/extracted/5663861/figures/experiments/chamber-mulitple-sources.jpg",
            "https://arxiv.org/html/extracted/5663861/figures/experiments/multiple-sources-calc-composite.png",
            "https://arxiv.org/html/x6.png",
            "https://arxiv.org/html/x7.png",
            "https://arxiv.org/html/x8.png",
            "https://arxiv.org/html/x9.png",
            "https://arxiv.org/html/x10.png",
            "https://arxiv.org/html/x11.png",
            "https://arxiv.org/html/x12.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Georg K.J. Fischer\\orcidlink0000-0003-1460-1061 Niklas Thiedecke\\orcidlink0009-0005-9432-320X Thomas Schaechtle\\orcidlink0000-0002-5304-4213 Andrea Gabbrielli\\orcidlink0000-0002-3167-760X Fabian Höflinger\\orcidlink0000-0001-5877-1439 Alexander Stolz\\orcidlink0000-0003-4730-8830 and Stefan J. Rupitsch\\orcidlink0000-0002-4806-9838 \\IEEEmembershipMember, IEEE This work was partially supported by the German Ministry of Education and Research (BMBF) under the grant FKZ: 16ME0028 Verbundprojekt ISA4.0, as well as by the German Ministry of Economic Affairs and Climate Action (BMWK) under grant FKZ: 03EE3066D Verbundvorhaben LoCA.Georg K.J. Fischer, Thomas Schaechtle, Fabian Höflinger and Alexander Stolz are with the Fraunhofer Institute for Highspeed Dynamics, Ernst-Mach-Institute (EMI), Freiburg, Germany, E-Mail: georg.fischer@emi.fraunhofer.de.Niklas Thiedecke is with Bosch Sensortec GmbH, Reutlingen, Germany.Andrea Gabbrielli, Thomas Schaechtle, Fabian Höflinger and Stefan J. Rupitsch are with the Department of Microsystems Engineering (IMTEK), University of Freiburg, Germany.\n\nAbstract\n\nAngle-of-Arrival (AoA) estimation technology, with its potential advantages, emerges as an intriguing choice for indoor localization. Notably, it holds the promise of reducing installation costs. In contrast to Time-of-Flight (ToF)/ Time-Difference-of-Arrival (TDoA) based systems, AoA-based approaches require a reduced number of nodes for effective localization. This characteristic establishes a trade-off between installation costs and the complexity of hardware and software. Moreover, the appeal of acoustic localization is further heightened by its capacity to provide cost-effective hardware solutions while maintaining a high degree of accuracy. Consequently, acoustic AoA estimation technology stands out as a feasible and compelling option in the field of indoor localization. Sparse arrays additionally have the ability to estimate the Direction-of-Arrival (DoA) of more sources than available sensors by placing sensors in a specific geometry. In this contribution, we introduce a measurement platform designed to evaluate various sparse array geometries experimentally. The acoustic microphone array comprises 64 microphones arranged in an 8x8 grid, following an Uniform Rectangular Array (URA) configuration, with a grid spacing of 8.255 mm. This configuration achieves a spatial Nyquist frequency of approximately 20.8 kHz in the acoustic domain at room temperature. Notably, the array exhibits a mean spherical error of 1.26° when excluding higher elevation angles. The platform allows for masking sensors to simulate sparse array configurations. We assess four array geometries through simulations and experimental data, identifying the Open-Box and Nested array geometries as robust candidates. Additionally, we demonstrate the array’s capability to concurrently estimate the directions of three emitting sources using experimental data, employing waveforms consisting of orthogonal codes.\n\n{IEEEkeywords}\n\nArray signal processing, Direction of Arrival, DoA estimation, Acoustic Localization, Indoor Localization, Sparse Arrays, Indoor positioning systems.\n\nDoA\n\nDirection-of-Arrival\n\nToF\n\nTime-of-Flight\n\nDoF\n\nDegrees-of-Freedom\n\nSBL\n\nSparse Bayesian learning\n\nRF\n\nRadio Frequency\n\nMRA\n\nMinimum Redundancy Array\n\nCRLB\n\nCramér-Rao Lower Bound\n\nGDoP\n\nGeometric Dilution of Precision\n\nUWB\n\nUltra-Wideband\n\nAoA\n\nAngle-of-Arrival\n\nTDoA\n\nTime-Difference-of-Arrival\n\nULA\n\nUniform Linear Array\n\nURA\n\nUniform Rectangular Array\n\nUCA\n\nUniform Circular Array\n\nSNR\n\nSignal-to-Noise Ratio\n\nGCC\n\nGeneralized Cross-Correlation\n\nESPRIT\n\nEstimation of Signal Parameters via Rotational Invariance Techniques\n\nMUSIC\n\nMultiple Signal Classification\n\nLS\n\nLeast Squares\n\nTLS\n\nTotal Least Squares\n\nPCB\n\nPrinted Circuit Board\n\nPSD\n\nPower Density Spectrum\n\nCDF\n\nCumulative Distribution Function\n\nMEMS\n\nMicro-Electro-Mechanical Systems\n\nTDM\n\nTime-Division Multiplexing\n\nFPGA\n\nField Programmable Gate Array\n\nHPS\n\nHard Processor System\n\nRAM\n\nRandom Access Memory\n\nRMSE\n\nRoot Mean Square Error\n\nN-RMSE\n\nNormalized Root Mean Square Error\n\nGUI\n\nGraphical User Interface\n\nCPA\n\nCoprime Planar Array\n\nZC\n\nZadoff-Chu\n\nMLM\n\nMainlobe Magnitude\n\nMLW\n\nMainlobe Width\n\nMSLR\n\nMainlobe / Sidelobe Ratio\n\nMSLS\n\nMainlobe / Sidelobe Separation\n\nIQ\n\nIn-Phase Quadrature\n\nSPL\n\nSound Pressure Level\n\nMSE\n\nMean Squared Error\n\nGT\n\nGround Truth\n\nFoV\n\nField of View\n\nBPF\n\nBandpass Filter\n\nCI\n\nConfidence Interval\n\n1 Introduction\n\n\\IEEEPARstart\n\nDirection-of-Arrival (DoA) estimation proves to be a common challenge within the domain of indoor localization. By strategically navigating the trade-off between hardware and software complexity, it becomes feasible to minimize the requisite number of anchor nodes for localization tasks. Fundamentally, only two nodes are necessary to intersect lines in 3-D space, thereby facilitating position estimation and reducing installation costs. In contrast, ToF systems demand a minimum of four nodes for 3-D localization. DoA-based systems entail a more intricate hardware setup, incorporating multiple arranged sensors such as antennas or microphones. This necessitates sophisticated hardware design, particularly in areas like Radio Frequency (RF) design, tuning, and data acquisition and processing, leading to larger devices. Furthermore, the interdependence of algorithms and hardware development is crucial, as data models heavily rely on parameters like array geometries, sampling specifications, and data handling limits. Despite the hardware complexity, the reduction in required nodes significantly diminishes installation costs. Additionally, receiver synchronization is unnecessary since only angles are estimated.\n\nThe Geometric Dilution of Precision (GDoP) in DoA-based systems exhibits a distinct structure compared to ToF/TDoA-based systems. While ToF/TDoA systems dilute precision outside the polygon of receivers, DoA systems experience precision dilution in the line of receivers and with distance to the receivers (forming a cone shape) [1, 2, 3]. This characteristic makes it an intriguing design choice for engineers to explore and implement.\n\nThe selection of technology spans from RF-based devices, such as WiFi, Bluetooth, 5G, mmWave, or even Ultra-Wideband (UWB), to optical and acoustic systems and combinations thereof [4, 5, 6]. A key distinguishing factor among these technologies is primarily the propagation speed of waves in the medium, which significantly influences the achievable performance bounds [7, 8, 9]. Another critical characteristic is the maturity of the technologies. For instance, technologies like Bluetooth have specific sections in their standards dedicated to AoA estimation [10], while others may lack such provisions. Compatibility is also a noteworthy concern. Given that nearly all smartphones support technologies like Bluetooth, incorporating acoustic localization, despite having the required hardware, necessitates the installation of custom software on the device [11].\n\nAcoustic localization technology, despite not yet being widely deployed, possesses the advantage of achieving high accuracy with straightforward and cost-effective hardware. Its positive traits, including resilience to Radio Frequency (RF) interference, make it a rational choice for deployment in mid-sized areas where both high accuracy and cost-effectiveness are crucial considerations. Acoustic AoA estimation has been subject to exploration in prior research. Conventional algorithms for DoA estimation, particularly when dealing with multiple tags, often necessitate time-synchronized signal emissions. However, this requirement increases tag complexity. Alternatively, accepting a certain degree of message collisions is another approach, albeit making location updates less predictable [12]. Classical subspace estimators offer the capability to simultaneously estimate the DoA of multiple signals. However, the number of locatable sources using these methods is strictly limited by the number of available sensors [13, 14].\n\nIn this study, our primary focus is to explore the potential for increasing the number of concurrently locatable tags by leveraging sparse arrays. To facilitate this investigation, we introduce an evaluation platform comprising 64 microphones arranged in an Uniform Rectangular Array (URA) configuration. This platform enables us to analyze and evaluate the performance of various sparse array geometries.\n\nIt is noteworthy that this paper extends our previously published work in [15]. In addition to the previously published material, we have expanded the literature review and related work section to provide a broader overview. New data has been collected, including more azimuth and elevation angle pairs. With the complete angle space sampled, a full characterization of the evaluated geometries is now possible, revealing the characteristics of each. Furthermore, the multiple sources experiment has been extended to include another source, now encompassing three sources in total.\n\n2 Related Work\n\nThe related work section is divided into two main components. First, we consider the field of acoustic AoA indoor localization, exploring prior research and advancements. The second part provides a concise review of sparse arrays, elucidating their applications and contributions in diverse contexts.\n\n2.1 Acoustic AoA for Indoor Localization\n\nVarious acoustic localization systems grounded in AoA localization have been proposed, featuring array geometries encompassing microphone pairs, triangular configurations, Uniform Linear Arrays, and Uniform Circular Arrays. Saadet al.[16] integrate the AoA methodology with ToF measurements, achieving a 95th percentile localization error of less than 10cmtimes10centimeter10\\text{\\,}\\mathrm{cm}start_ARG 10 end_ARG start_ARG times end_ARG start_ARG roman_cm end_ARG through their triangular array configuration. In another endeavor [17], the authors leverage a uniform linear array with four microphones, yielding a 95-th percentile localization error under 65cmtimes65centimeter65\\text{\\,}\\mathrm{cm}start_ARG 65 end_ARG start_ARG times end_ARG start_ARG roman_cm end_ARG. The work in [18] explores self-positioning through a microphone pair and strategically deployed acoustic beacons. Gabbrielliet al.[19, 12, 20] propose a five-microphone UCA configuration, achieving a 95% error rate of under 17cmtimes17centimeter17\\text{\\,}\\mathrm{cm}start_ARG 17 end_ARG start_ARG times end_ARG start_ARG roman_cm end_ARG in 3-D absolute localization accuracy. Generally, a limited number (<<<10) of microphones is employed to facilitate AoA estimation on embedded devices. However, the development of an indoor localization system capable of concurrently performing AoA estimation for multiple emitting sound sources (tags) remains a pending objective in the current state of research.\n\n2.2 Sparse Arrays and their Applications\n\nSparse arrays have been a subject of research for several decades [21]. Various geometries have been explored, including Nested arrays [22, 23, 24, 25], Coprime arrays [26, 27, 28], Hourglass arrays [29], and Thermos arrays [30]. In the RF domain, sparse arrays offer the potential to mitigate mutual coupling between antennas [30]. Theoretical performance bounds, such as the Cramér-Rao Lower Bound (CRLB), have been established for various geometries, including Coprime arrays, Nested arrays, and Minimum Redundancy Arrays [31]. Furthermore, sparse arrays have found application in other domains, such as medical ultrasound [32], showcasing the potential to reduce costs, albeit with a trade-off involving diminished image quality.\n\nWithin the field of acoustic beamforming applications, sparse arrays have gained prominence, demonstrating adaptability across diverse scenarios. In the domain of speech localization, the work in [33] reports the observation that Semi-Coprime microphone arrays exhibit superior beam patterns and reduced side lobe levels compared to coprime arrays. Bushet al.[34] conducted an assessment and validation of simulation results for Coprime linear microphone arrays with wideband sources. In a related investigation [35], source enumeration utilizing a Bayesian approach is explored, employing Coprime linear microphone arrays. A technique utilizing sparse linear arrays for uncorrelated wideband sources is introduced in [36]. This approach integrates data from different frequency bins into a unified matrix, employing atomic norm minimization for precise DoA estimation. The assessment of this technique involved the utilization of a two-level Nested array. In the experimental domain, the work in [37, 25] conducted a thorough evaluation of planar sparse arrays employing the Sparse Bayesian learning (SBL) approach. This array, consisting of 63 microphones, operated in the lower frequency range (under 3kHztimes3kilohertz3\\text{\\,}\\mathrm{kHz}start_ARG 3 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG). The authors could show, that the SBL algorithm is able to resolve an equal number of sources as available sensors in the 2-D case.\n\nTwo-Dimensional DoA estimation is a consequential extension to the 1-D arrays. In light of this, Aboumahmoud et al.[21] offer a comprehensive review specifically focused on various sparse geometries for 2-D estimation. Within their work, the authors conduct a comparative evaluation considering critical factors such as the number of sensors, their maximum Degrees-of-Freedoms, and aperture sizes. Notably, the predominant nature of these investigations is analytical and performed in silico. Consequently, the existing body of research is characterized by a limited number of experimental validations and demonstrated applications.\n\nThe principal contributions of this work encompass:\n\n•\n\nThe conceptualization of a compact 64-microphone array system tailored for indoor localization applications in the inaudible frequency range.\n\n•\n\nInvestigation into the system’s performance, conducted through a comprehensive analysis involving both simulation and experimentation.\n\n•\n\nEvaluation of various sparse array geometries utilizing empirical data.\n\n•\n\nA practical demonstration showcasing the system’s proficiency in estimating the DoA for multiple concurrently emitting sound sources.\n\n3 Signal Model\n\nThe central idea behind sparse microphone arrays lies in exploiting redundancy within data recorded using non-sparse arrays, e.g. URAs, by reconstructing the information of missing microphones using a combination of two or more other microphones.\n\nDifference co-array\n\nSparse signal processing uses a difference co-array to reconstruct this information, which is defined as the set of differences in microphone positions [21]:\n\n𝔻={m|m=κi−κj,∀κi,κj∈𝕊},𝔻conditional-set𝑚formulae-sequence𝑚subscript𝜅𝑖subscript𝜅𝑗for-allsubscript𝜅𝑖subscript𝜅𝑗𝕊\\displaystyle\\mathbb{D}=\\{m\\ |\\ m=\\kappa_{i}-\\kappa_{j},\\quad\\forall\\ \\kappa_{% i},\\kappa_{j}\\in\\mathbb{S}\\},blackboard_D = { italic_m | italic_m = italic_κ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_κ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , ∀ italic_κ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_κ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ blackboard_S } , (1)\n\nwhere 𝕊𝕊\\mathbb{S}blackboard_S is the set of sensor positions in the array. The set of resulting positions 𝔻𝔻\\mathbb{D}blackboard_D describes the position of all virtual sensors in the difference co-array. Fig. 1 shows an example of a 1-D nested array and its difference co-array.\n\nIn order to calculate the virtual sensor data of the difference co-array of a given physical microphone array, the sample auto correlation matrix of the array’s sensor data has to be vectorized:\n\n𝐳=vec⁢(𝐑^y)𝐳vecsubscript^𝐑𝑦\\displaystyle\\mathbf{z}=\\mathrm{vec}(\\mathbf{\\hat{R}}_{y})bold_z = roman_vec ( over^ start_ARG bold_R end_ARG start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ) =(𝐀∗⊙𝐀)⁢𝐩+σn2⁢𝟏nabsentdirect-productsuperscript𝐀𝐀𝐩superscriptsubscript𝜎𝑛2subscript1𝑛\\displaystyle=(\\mathbf{A}^{*}\\odot\\mathbf{A})\\mathbf{p}+\\sigma_{n}^{2}\\mathbf{% 1}_{n}= ( bold_A start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ⊙ bold_A ) bold_p + italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT (2) with 𝐑^ysubscript^𝐑𝑦\\displaystyle\\mathbf{\\hat{R}}_{y}over^ start_ARG bold_R end_ARG start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT =1K⁢∑k=1K𝐲⁢[k]⁢𝐲⁢[k]H,absent1𝐾superscriptsubscript𝑘1𝐾𝐲delimited-[]𝑘𝐲superscriptdelimited-[]𝑘H\\displaystyle=\\frac{1}{K}\\sum_{k=1}^{K}\\mathbf{y}[k]\\mathbf{y}[k]^{\\mathrm{H}},= divide start_ARG 1 end_ARG start_ARG italic_K end_ARG ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT bold_y [ italic_k ] bold_y [ italic_k ] start_POSTSUPERSCRIPT roman_H end_POSTSUPERSCRIPT , (3) 𝐩𝐩\\displaystyle\\mathbf{p}bold_p =[σ12σ22⋯σM2]T.absentsuperscriptdelimited-[]superscriptsubscript𝜎12superscriptsubscript𝜎22⋯superscriptsubscript𝜎𝑀2T\\displaystyle=\\left[\\begin{array}[]{cccc}\\sigma_{1}^{2}&\\sigma_{2}^{2}&\\cdots&% \\sigma_{M}^{2}\\end{array}\\right]^{\\mathrm{T}}.= [ start_ARRAY start_ROW start_CELL italic_σ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_CELL start_CELL italic_σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_CELL start_CELL ⋯ end_CELL start_CELL italic_σ start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_CELL end_ROW end_ARRAY ] start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT . (5)\n\nHere, 𝐲⁢[k]𝐲delimited-[]𝑘\\mathbf{y}[k]bold_y [ italic_k ] denotes the vector of microphone samples of the k𝑘kitalic_k-th microphone and 𝐩𝐩\\mathbf{p}bold_p holds the powers of the M𝑀Mitalic_M source signals, which are the diagonal entries of the source auto correlation matrix 𝐑ssubscript𝐑𝑠\\mathbf{R}_{s}bold_R start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT. The noise term is represented by σn2⁢𝟏nsuperscriptsubscript𝜎𝑛2subscript1𝑛\\sigma_{n}^{2}{\\mathbf{1}}_{n}italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and the Hermitian transpose of 𝐲𝐲\\mathbf{y}bold_y is denoted by 𝐲Hsuperscript𝐲H\\mathbf{y}^{\\mathrm{H}}bold_y start_POSTSUPERSCRIPT roman_H end_POSTSUPERSCRIPT. The effective array manifold matrix 𝐀eff=𝐀∗⊙𝐀subscript𝐀effdirect-productsuperscript𝐀𝐀\\mathbf{A}_{\\mathrm{eff}}=\\mathbf{A}^{*}\\odot\\mathbf{A}bold_A start_POSTSUBSCRIPT roman_eff end_POSTSUBSCRIPT = bold_A start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ⊙ bold_A can be interpreted as the steering matrix corresponding to the whole difference co-array and is therefore able to exploit all DoF of the physical array [38]. The ⊙direct-product\\odot⊙-operator denotes the Khatri-Rao product.\n\nSpatial Smoothing\n\nThe virtual sensor data vector 𝐳𝐳\\mathbf{z}bold_z cannot be used for DoA-estimation directly because it behaves like fully coherent sources, which violates the assumptions required by the subspace methods. This problem can be taken care of in different ways, one of them being the spatial smoothing technique as discussed by Pal and Vaidyanathan [38], which can be applied without modification for any difference co-array that has a coherent ULA segment in the 1-D case or a coherent URA segment in the 2-D case.\n\nIn order to be able to perform spatial smoothing, the data corresponding to repeating virtual sensors in the difference co-array has to be removed and afterwards the data is re-ordered. This is equivalent to only keeping unique entries of the observation vector 𝐳𝐳\\mathbf{z}bold_z and sorting them, which leads to a new vector 𝐳1subscript𝐳1\\mathbf{z}_{1}bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. The sorting is done such, that the data in 𝐳1jsubscriptsubscript𝐳1𝑗{\\mathbf{z}_{1}}_{j}bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT corresponds to the j𝑗jitalic_j-th element in the center ULA-segment of the difference co-array.\n\nFig. 2 shows entries of the auto correlation matrix in the example of a 1-D Nested array with physical positions 0⁢d0𝑑0d0 italic_d, 1⁢d1𝑑1d1 italic_d, 2⁢d2𝑑2d2 italic_d, 3⁢d3𝑑3d3 italic_d, 7⁢d7𝑑7d7 italic_d, 11⁢d11𝑑11d11 italic_d. In this example, red boxes denote repeated (redundant) virtual sensor positions in the difference co-array. Here, vec⁢(𝔻′)vecsuperscript𝔻′\\mathrm{vec}(\\mathbb{D}^{\\prime})roman_vec ( blackboard_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) denotes the vector containing all elements of the set 𝔻𝔻\\mathbb{D}blackboard_D in increasing order regarding virtual sensor positions. The entries of the auto correlation matrix 𝐑^ysubscript^𝐑𝑦\\mathbf{\\hat{R}}_{y}over^ start_ARG bold_R end_ARG start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT, which correspond to redundant virtual sensor positions, are removed.\n\nIn the 2-D case, the ordering is performed such that the center URA-segment ordering is matched [38].\n\nThe spatial smoothing step now divides the co-array into overlapping sub-arrays, and calculates an auto correlation matrix on the corresponding segment of the virtual sensor observation vector 𝐳1subscript𝐳1\\mathbf{z}_{1}bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Each individual auto correlation matrix is computed as\n\n𝐑i=𝐳1i⁢𝐳1iHsubscript𝐑𝑖subscript𝐳subscript1𝑖superscriptsubscript𝐳subscript1𝑖H\\displaystyle\\mathbf{R}_{i}=\\mathbf{z}_{1_{i}}\\mathbf{z}_{1_{i}}^{\\mathrm{H}}bold_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = bold_z start_POSTSUBSCRIPT 1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT 1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_H end_POSTSUPERSCRIPT (6)\n\nThe selection of sub-arrays and the corresponding segments of 𝐳1subscript𝐳1\\mathbf{z}_{1}bold_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is visualized in Fig. 3. Finally, the spatial smoothing output auto correlation matrix 𝐑s⁢ssubscript𝐑𝑠𝑠\\mathbf{R}_{ss}bold_R start_POSTSUBSCRIPT italic_s italic_s end_POSTSUBSCRIPT is computed by averaging over all 𝐑lsubscript𝐑𝑙\\mathbf{R}_{l}bold_R start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT with\n\n𝐑s⁢s=1L⁢∑l=1L𝐑lsubscript𝐑𝑠𝑠1𝐿superscriptsubscript𝑙1𝐿subscript𝐑𝑙\\displaystyle\\mathbf{R}_{ss}=\\frac{1}{L}\\sum_{l=1}^{L}\\mathbf{R}_{l}bold_R start_POSTSUBSCRIPT italic_s italic_s end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_L end_ARG ∑ start_POSTSUBSCRIPT italic_l = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT bold_R start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT (7)\n\nwhere L𝐿Litalic_L is the number of sub-arrays of the difference co-array, which is a design parameter depending on the array structure and size.\n\n2-D DoA estimation on sparse arrays\n\nWhen spatial smoothing was performed, Multiple Signal Classification (MUSIC) and Estimation of Signal Parameters via Rotational Invariance Techniques (ESPRIT)[13, 14] can be used on the new auto correlation matrix 𝐑s⁢ssubscript𝐑𝑠𝑠\\mathbf{R}_{ss}bold_R start_POSTSUBSCRIPT italic_s italic_s end_POSTSUBSCRIPT (see Eq. 7), as long as the sparse array is designed such, that the difference co-array has a coherent URA center piece.\n\nMUSIC has to be used with the steering matrix 𝐀𝐀\\mathbf{A}bold_A corresponding to a URA with the size of the segment that was used for the spatial smoothing step in the previous section. If MUSIC is then performed on the spatially smoothed auto correlation matrix 𝐑s⁢ssubscript𝐑𝑠𝑠\\mathbf{R}_{ss}bold_R start_POSTSUBSCRIPT italic_s italic_s end_POSTSUBSCRIPT, the DoA of the signal impinging on the original physical array can be estimated.\n\n4 Hardware\n\nOne key property, which most sparse arrays have in common, is that all sensors are placed on an equidistantly spaced grid, where each node has a distance d𝑑ditalic_d to its neighboring nodes. Exploiting this property, each node can be filled out by actual sensors, such, that multiple sparse geometries can be mapped onto this grid by not using the data of specific nodes for estimation, given these nodes are not part of the sparse array currently examined.\n\nFig. 4 illustrates this concept. It can be seen, that the only parameters limiting the number of depictable geometries are the apertures (i.e., the number of nodes) in x- and y-direction, respectively. Thus, these parameters were chosen as large as possible, while still being able to sample with more than double the frequency of the target sound source frequency band of around 20kHztimes20kilohertz20\\text{\\,}\\mathrm{kHz}start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG. The resulting array design is built as an 8x8 grid, which results in a total of 64 microphones.\n\nThe main challenges of designing such a system for the acoustical use-case include:\n\n•\n\nSynchronization of exact analog sampling times\n\n•\n\nData integrity with several high frequency signals in the MHz range close to each other\n\n•\n\nAbility to process and store data of all 64 microphones concurrently\n\nIn this contribution, the Micro-Electro-Mechanical Systems (MEMS) microphone ICS52000 was chosen, as it is specifically designed for array applications. The microphone uses a digital Time-Division Multiplexing (TDM) interface, which enables having up to 16 microphones use a single data line and synchronize with each other by sharing one clock line and daisy-chaining a handshake signal through the whole chain of sensors.\n\nIn order to communicate to all microphones at once and store all the data in parallel at sufficient speed, the communication unit for the system was chosen to be a Field Programmable Gate Array (FPGA), since the TDM interface, as well as an on-chip Random Access Memory (RAM) can be implemented in a parallelized fashion.\n\nThe complete system concept is depicted in Fig. 5. For acquiring data, the DE0-Nano-SoC evaluation board was chosen, which contains both a programmable Cyclone V FPGA and a software programmable Hard Processor System (HPS), facilitating low-level implementation of the TDM interface, data storage and transfer to a computer.\n\n4.1 System Implementation\n\nBecause the maximum number of interconnectable ICS52000 microphones is 16, the whole eight by eight array is split into four sub-arrays, each taking up a quarter of the full array. Each sub-array receives a copy of the system clock, which is provided by a clock-buffer to ensure clean edges. In order to synchronize the four sub-arrays among each other, the first microphone in each of them obtains a global word select signal, which is directly connected to the FPGA. To avoid timing differences induced by length differences of PCB traces, all clock lines leading to a single microphone are matched to the same length. The geometric distance d𝑑ditalic_d between each neighboring microphone is set to 8.255mmtimes8.255millimeter8.255\\text{\\,}\\mathrm{mm}start_ARG 8.255 end_ARG start_ARG times end_ARG start_ARG roman_mm end_ARG. This distance corresponds to half the smallest wavelength λm⁢i⁢nsubscript𝜆𝑚𝑖𝑛\\lambda_{min}italic_λ start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT of a signal, which can still be sampled in the half space. In other words, the largest allowed frequency of sound sources is determined as fmax=c⁢λmin−1=c⁢(2⁢d)−1≈20.788kHzsubscript𝑓max𝑐superscriptsubscript𝜆min1𝑐superscript2𝑑1times20.788kilohertzf_{\\mathrm{max}}=c\\lambda_{\\mathrm{min}}^{-1}=c(2d)^{-1}\\approx$20.788\\text{\\,% }\\mathrm{kHz}$italic_f start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT = italic_c italic_λ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT = italic_c ( 2 italic_d ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≈ start_ARG 20.788 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG in free air at room temperature. If the frequency band of a sound source is larger than this limit, robust estimation of its location will not be possible. footnote 2 displays a picture of the developed array.\n\n4.2 Signal Processing\n\nThe signal processing chain is structured as follows (cf. Fig. 7): First, the K×N𝐾𝑁K\\times Nitalic_K × italic_N sample matrix, denoted as S→→𝑆\\vec{S}over→ start_ARG italic_S end_ARG, is obtained by the array, where K𝐾Kitalic_K represents the number of channels and N𝑁Nitalic_N represents the number of samples. Next, each channel undergoes individual Bandpass Filter (BPF) to a specific frequency using a 10th order Butterworth filter with a bandwidth B𝐵Bitalic_B. Subsequently, we apply a Hilbert transform to each channel to derive complex In-Phase Quadrature (IQ) samples. Following this, a calibration matrix C→→𝐶\\vec{C}over→ start_ARG italic_C end_ARG, similar in size to the complex sample matrix, is applied to ensure accuracy and consistency in the measurements, where ∘\\circ∘ denotes the Hadamard product. Finally, the calibrated, complex sample matrix is passed through to be further processed by the specific DoA estimators, yielding pairs of azimuth and elevation angles, as detailed in Sec. 3.\n\n5 Simulation\n\nIn this section, we introduce various array geometries and simulatively assess their performance. Each geometry’s beampattern is evaluated along with quantitative metrics. The simulations are conducted using the intended design parameters of the array, including dimensions and sampling frequency. The probing signal employed is a complex sinusoid at 20kHztimes20kilohertz20\\text{\\,}\\mathrm{kHz}start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG. In addition to specific design rules such as Billboard or co-prime, a randomly selected set of sensors is included as a last geometry, comprising approximately the same number of sensors as the other sparse geometries.\n\nFig. 8 illustrates these geometries alongside their directional response to an impinging wavefront in the broadside direction. The response is calculated using a traditional delay-and-sum beamformer, providing insights into each geometry’s performance, such as potential angle confusions due to large sidelobes.\n\nTable 1 provides quantitative metrics for evaluating the beampatterns of various array geometries. Asymmetric geometries, such as the Open-box array, naturally result in asymmetric beampatterns. The URA demonstrates the highest Mainlobe Magnitude (MLM), outperforming the Nested array which shows a reduction of approximately −8dBtimes-8decibel-8\\text{\\,}\\mathrm{dB}start_ARG - 8 end_ARG start_ARG times end_ARG start_ARG roman_dB end_ARG. The Open-Box array is distinguished by having the narrowest Mainlobe Width (MLW), as defined by the −3dBtimes-3decibel-3\\text{\\,}\\mathrm{dB}start_ARG - 3 end_ARG start_ARG times end_ARG start_ARG roman_dB end_ARG attenuation threshold. Furthermore, the URA secures the highest Mainlobe / Sidelobe Ratio (MSLR), with the Billboard array following directly behind. The Coprime array is noted for achieving the greatest Mainlobe / Sidelobe Separation (MSLS). The correlation between an array’s symmetry and its beampattern’s symmetry is evident when contrasting the URA with the Open-Box array in Fig. 8.\n\nThe overall angular error e𝑒eitalic_e is assessed using the spherical angular distance between the unit vectors of the estimated point p^i→→subscript^𝑝𝑖\\vec{\\hat{p}_{i}}over→ start_ARG over^ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG and the ground truth value pi→→subscript𝑝𝑖\\vec{p_{i}}over→ start_ARG italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG defined as\n\ne=cos−1⁡(p^i→T⁢pi→).𝑒superscript1superscript→subscript^𝑝𝑖T→subscript𝑝𝑖e=\\cos^{-1}\\left(\\vec{\\hat{p}_{i}}^{\\mathrm{T}}\\vec{p_{i}}\\right).italic_e = roman_cos start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( over→ start_ARG over^ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT over→ start_ARG italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG ) . (8)\n\nThis metric effectively addresses situations where uncertainties in the azimuth angle may not lead to significant deviations, particularly noticeable in low elevation angle regimes. Fig. 9 illustrates the achievable Mean Angular Error under additive Gaussian noise with a specific modeled Signal-to-Noise Ratio (SNR). In this simulation, the ordering is solely correlated with the number of available sensors, with the URA configuration performing the best. A similar outcome can be attained by assessing the CRLB[39, 40], which defines the achievable Mean Squared Error (MSE) for both azimuth and elevation angles separately. The advantage of this simulation lies in its ability to account for irrelevant errors in fringe regions through a composite metric.\n\n6 Experiments\n\nIn this section, the results of several experiments are presented. The measurement setup is first introduced, followed by a discussion of the calibration results. Next, various algorithms are compared against each other, along with an evaluation of their performance using different sparse geometries. The section concludes with an assessment of the system’s capability to handle multiple concurrently emitting sources, accompanied by a discussion of the obtained results.\n\n6.1 Measurement Setup\n\nThe experiments are conducted within an anechoic chamber from the company Wendt-Noise Control, providing an environment free from sound reflections and external interference. The array is assembled onto a two-axis rotation table, as depicted in footnote 2. This rotation table allows rotation in both azimuth and elevation directions. A speaker is positioned approximately 3.7mtimes3.7meter3.7\\text{\\,}\\mathrm{m}start_ARG 3.7 end_ARG start_ARG times end_ARG start_ARG roman_m end_ARG away from the array to emit sound signals for localization purposes. Additionally, a linear reference microphone is employed to provide a reference for the measured amplitudes.\n\n6.2 Calibration and Analysis\n\nThe calibration process comprises both phase calibration and amplitude adjustment. The amplitude adjustment serves two purposes: firstly, to standardize the microphones within the array relative to each other, and secondly, to align the microphone data with Sound Pressure Levels Lpsubscript𝐿𝑝L_{p}italic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, in decibels (dB) relative to 20µ⁢Patimes20micropascal20\\text{\\,}\\mathrm{\\SIUnitSymbolMicro Pa}start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_µ roman_Pa end_ARG.\n\nTo obtain dB SPL calibration values, a Behringer ECM8000 linear measurement microphone is referenced with a B&K Type-4231 calibrator at 94dB⁢SPLtimes94dBSPL94\\text{\\,}\\mathrm{d}\\mathrm{B}~{}\\mathrm{S}\\mathrm{P}\\mathrm{L}start_ARG 94 end_ARG start_ARG times end_ARG start_ARG roman_dB roman_SPL end_ARG. Subsequently, the frequencies are swept through in the range of 10kHz to 20kHzrangetimes10kilohertztimes20kilohertz10\\text{\\,}\\mathrm{kHz}20\\text{\\,}\\mathrm{kHz}start_ARG start_ARG 10 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG end_ARG to start_ARG start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG end_ARG and measured by both the array and the measurement microphone, as depicted in Fig. 10 (a). The variation in sound pressure level arises due to the characteristics of the employed Beyma T2030 speaker.\n\nIn Fig. 10 (b), both uncalibrated and calibrated phase measurements are displayed, indicating marginal differences at the shown frequency of 20kHztimes20kilohertz20\\text{\\,}\\mathrm{kHz}start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG. The sound pressure in dB is modeled with a Log-normal distribution, with its fit shown in (c). In contrast to the phase calibration, the total variance of the measured levels may be reduced by around 40 percent.\n\nIt is important to note the significance of amplitude calibration in achieving accurate Direction-of-Arrival (DoA) measurements, given the assumption of equal gains across all sensors in the observation matrix A→→𝐴\\vec{A}over→ start_ARG italic_A end_ARG. The entries of the calibration matrix are chosen accordingly\n\nC→i,j=Ai,c⁢e−j⁢Ψi,csubscript→𝐶𝑖𝑗subscript𝐴𝑖𝑐superscriptejsubscriptΨ𝑖𝑐\\vec{C}_{i,j}=A_{i,c}\\mathrm{e}^{-\\mathrm{j}\\Psi_{i,c}}over→ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = italic_A start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT roman_e start_POSTSUPERSCRIPT - roman_j roman_Ψ start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT end_POSTSUPERSCRIPT (9)\n\nwhere Ai,csubscript𝐴𝑖𝑐A_{i,c}italic_A start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT represents the amplitude calibration factor and Ψi,csubscriptΨ𝑖𝑐\\Psi_{i,c}roman_Ψ start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT denotes the measured phase factor. The index variable i∈{1,…,K}𝑖1…𝐾i\\in\\{1,\\dots,K\\}italic_i ∈ { 1 , … , italic_K } corresponds to the channel index and j∈{1,…,N}𝑗1…𝑁j\\in\\{1,\\dots,N\\}italic_j ∈ { 1 , … , italic_N } to the sample index. The calibration process yields slightly more accurate estimations, particularly noticeable in lower elevation angle regimes. For instance, below 70°times70degree70\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 70 end_ARG start_ARG times end_ARG start_ARG ° end_ARG at 20kHztimes20kilohertz20\\text{\\,}\\mathrm{kHz}start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG, the measured mean spherical error can be reduced from 1.24°times1.24degree1.24\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 1.24 end_ARG start_ARG times end_ARG start_ARG ° end_ARG to 1.20°times1.20degree1.20\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 1.20 end_ARG start_ARG times end_ARG start_ARG ° end_ARG .\n\n6.3 DoA-Estimation (Single Source)\n\nIn order to show that the developed sensor system is capable of collecting data which are suitable of estimating the AoA of a sound source, a set spanning the complete range of azimuth and elevation angles is composed. The incident sound pressure Lpsubscript𝐿𝑝L_{p}italic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT at the array is set to 60dB⁢SPLtimes60dBSPL60\\text{\\,}\\mathrm{d}\\mathrm{B}~{}\\mathrm{S}\\mathrm{P}\\mathrm{L}start_ARG 60 end_ARG start_ARG times end_ARG start_ARG roman_dB roman_SPL end_ARG, which results in a SNR of around 30dBtimes30decibel30\\text{\\,}\\mathrm{dB}start_ARG 30 end_ARG start_ARG times end_ARG start_ARG roman_dB end_ARG (inband), in the given anechoic environment. For each angle pair, the microphone array captures audio samples which are then sent to a computer for analysis and ultimately estimating the AoA of each source position. To ensure statistical convergence of the results, each measurement has a duration of T=2s𝑇times2secondT=$2\\text{\\,}\\mathrm{s}$italic_T = start_ARG 2 end_ARG start_ARG times end_ARG start_ARG roman_s end_ARG, resulting in N=96000𝑁96000N=96000italic_N = 96000 samples. With only one source involved in this experiment, inter-source correlations pose no issue. Consequently, a simple sinusoidal signal is broadcast from the source without the need for additional processing or coding. The narrowband requirement of subspace algorithms is met by applying a band-pass filter to the recorded microphone data as detailed in Subsec. 4.2.\n\n6.3.1 Comparison of algorithms\n\nThree algorithms are compared using measured data: SRP-PHAT [41], Unitary ESPRIT [42], and MUSIC [14]. A grid comprising 1036 different azimuth and elevation pairs is sampled with the array. The collected samples are preprocessed with a chunk size of N=4096𝑁4096N=4096italic_N = 4096, after which the different estimators are applied to the processed data. In Fig. 11 (a), the overall resulting cumulative distribution of the measured spherical error, calculated using Eq. 8, is depicted. MUSIC performs the best with 9.3°times9.3degree9.3\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 9.3 end_ARG start_ARG times end_ARG start_ARG ° end_ARG in the 95th percentile, followed by SRP-PHAT with 10.4°times10.4degree10.4\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 10.4 end_ARG start_ARG times end_ARG start_ARG ° end_ARG. Fig. 11 (b) illustrates the distribution of errors, with the elevation angle on the radial axis. The largest spherical error occurs in the high elevation angle regions, primarily due to inaccuracies in the elevation angle estimation. Notably, towards the broadside of the array, the error becomes minimal for all investigated algorithms. Note the different color scale used for the ESPRIT algorithm.\n\n6.3.2 Error Distribution\n\nAs depicted in Fig. 11, it is evident that the largest errors occur in the lower elevation regions. When excluding these points, thereby narrowing the field of view, the attainable error gets minimized. Fig. 12 displays the mean and 95th percentile error alongside the left field of view in steradians when excluding data above a certain elevation angle. The steep negative slope of the 95th percentile curve illustrates this phenomenon. For instance, by excluding all angles above 75 degrees, the attainable 95th percentile error reduces to 2.8°times2.8degree2.8\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 2.8 end_ARG start_ARG times end_ARG start_ARG ° end_ARG (or 1.26°times1.26degree1.26\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 1.26 end_ARG start_ARG times end_ARG start_ARG ° end_ARG mean spherical error) while still retaining around 74%times74percent74\\text{\\,}\\mathrm{\\char 37\\relax}start_ARG 74 end_ARG start_ARG times end_ARG start_ARG % end_ARG of the Field of View (FoV). In a real application, this can be implemented by ensuring overlapping regions of multiple receiver arrays.\n\n6.3.3 Comparison of sparse array geometries\n\nIn order to compare sparse array geometries to each other, we used the same data and parameters as in the previous section. Each sparse array’s data is then constructed by masking only the microphones which are present in the current geometry under evaluation and thus, only the data of those microphones is included. Spatial smoothing is performed, using the apertures in x- and y-direction of the difference co-array of each respective geometry as window sizes. Finally, the 2-D Unitary ESPRIT algorithm is applied on the spatially smoothed sample covariance matrix to estimate the DoA of the sound source. In addition to this, the URA and Random arrays are included as a reference. For the URA, once with spatial smoothing as discussed, and once without spatial smoothing with the estimation algorithm directly working with the standard sample covariance matrix.\n\nTo evaluate geometries capable of estimating more sources than there are sensors, the unitary ESPRIT estimator with spatial smoothing is essential. This methodology is specifically applicable to geometries that feature a coherent URA centerpiece in their difference co-array. This criterion is met by the geometries discussed herein, with the exception of the random array. Given the prior introduction of the random array, it is included in the analysis using the standard MUSIC algorithm, which does not have the capability to estimate more sources than sensors. Interestingly, a comparison of the 95th percentile error, as illustrated in Fig. 12, reveals a mere increase of approximately 1°times1degree1\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 1 end_ARG start_ARG times end_ARG start_ARG ° end_ARG in error compared to the fully populated URA.\n\nFig. 13 illustrates the error distribution for the different array geometries. Consistent with previous observations, errors tend to accumulate in the high elevation angle regions across all geometries. Notably, the Coprime array exhibits a strong azimuth angle dependency in the error distribution, corroborating findings from Fig. 8. Conversely, the other sparse geometries demonstrate comparable performance, as indicated by Fig. 14, which displays the Cumulative Distribution Function (CDF). In this evaluation, the Open-Box array performs best within the category of sparse geometries, followed by the Nested and Billboard arrays (cf. Table 2). As expected, the Coprime array, characterized by the smallest aperture size and fewest number of sensors, demonstrates the poorest performance.\n\n6.4 DoA-Estimation (Multiple Sources)\n\nIn this experiment, three cooperative sources (Tags) are positioned within the anechoic chamber using a laser which is mounted on a two-axis rotation table, as depicted in Fig. 15. The tags are equipped with piezoelectric speakers. The source signals, which are bandlimited (B=200Hz𝐵times200hertzB=$200\\text{\\,}\\mathrm{Hz}$italic_B = start_ARG 200 end_ARG start_ARG times end_ARG start_ARG roman_Hz end_ARG) Walsh-Hadamard sequences mixed to 20kHztimes20kilohertz20\\text{\\,}\\mathrm{kHz}start_ARG 20 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG, ensure good cross-correlation properties. The tags emit signals simultaneously at an incident sound pressure ranging from 50dB⁢SPLtimes50dBSPL50\\text{\\,}\\mathrm{d}\\mathrm{B}~{}\\mathrm{S}\\mathrm{P}\\mathrm{L}start_ARG 50 end_ARG start_ARG times end_ARG start_ARG roman_dB roman_SPL end_ARG (Tag 2) to 55dB⁢SPLtimes55dBSPL55\\text{\\,}\\mathrm{d}\\mathrm{B}~{}\\mathrm{S}\\mathrm{P}\\mathrm{L}start_ARG 55 end_ARG start_ARG times end_ARG start_ARG roman_dB roman_SPL end_ARG (Tag 1). Instead of employing the data-augmented ESPRIT estimator, the MUSIC estimator is applied to the nested array selection of the captured data, as depicted in Figure 4. Fig. 16 presents the MUSIC pseudospectrum of the captured scene along with the mean spherical error for all three sources. The error ranges from 0.4°times0.4degree0.4\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 0.4 end_ARG start_ARG times end_ARG start_ARG ° end_ARG up to 1.6°times1.6degree1.6\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 1.6 end_ARG start_ARG times end_ARG start_ARG ° end_ARG, primarily depending on the elevation angle.\n\n6.5 Discussion\n\nIn the initial experiments, we observed that calibration provided only marginal benefits, particularly in lower elevation angle regions, highlighting the robustness of the hardware concept and the quality of the used microphones. Subsequent analysis of single-source experiments revealed that errors tend to accumulate in higher elevation angle regions. When designing localization systems, it may be advisable to ensure overlapping regions where angle measurements in the higher elevation angle range can be discarded or de-weighted. The URA, while not isotropic, does not exhibit strong, noticeable azimuth angle-dependent behavior. Furthermore, we observed that the general-purpose SRP-PHAT algorithm, widely applied in various applications, performed worse than the specialized MUSIC algorithm, especially for narrowband signals. Comparison of multiple array geometries unveiled their performance on real-world data, with some geometries struggling with azimuth angle dependency, resulting in inferior estimation performance in general. Notably, increasing sensor count and aperture size typically leads to better performance. However, distributing sensors too sparsely in various directions to optimize aperture size can yield azimuthal dependencies. It’s also worth mentioning that estimating multiple concurrent sources is possible by employing orthogonal codes, which may also enable source identification.\n\n7 Conclusions and Outlook\n\nIn this contribution, a measurement platform has been proposed for the evaluation of several sparse array geometries. The platform consists of 64 microphones in URA configuration, tuned to a maximum frequency of around 20.8kHztimes20.8kilohertz20.8\\text{\\,}\\mathrm{kHz}start_ARG 20.8 end_ARG start_ARG times end_ARG start_ARG roman_kHz end_ARG. Through a series of simulations and experiments, we have demonstrated the feasibility and effectiveness of sparse array geometries in accurately estimating the direction of arrival of sound sources in indoor environments. The developed array demonstrates promising performance, achieving a 95-percentile spherical error of 2.8°times2.8degree2.8\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 2.8 end_ARG start_ARG times end_ARG start_ARG ° end_ARG (or a mean error of 1.26°times1.26degree1.26\\text{\\,}\\mathrm{\\SIUnitSymbolDegree}start_ARG 1.26 end_ARG start_ARG times end_ARG start_ARG ° end_ARG) when high-error producing regions are excluded using the MUSIC estimator. Our investigation encompassed various sparse array geometries, revealing notable angle dependencies in some configurations. Among these, geometries like the Open-Box or Nested array exhibited superior performance on applied metrics. Furthermore, an experiment involving three concurrently emitting sources demonstrated the feasibility of resolving multiple sources simultaneously.\n\nReferences\n\n[1] Dong-Ho Shin and Tae-Kyung Sung, “Comparisons of error characteristics between toa and tdoa positioning,” IEEE Transactions on Aerospace and Electronic Systems, vol. 38, no. 1, pp. 307–311, 2002.\n\n[2] Don Torrieri, “Statistical theory of passive location systems,” IEEE Transactions on Aerospace and Electronic Systems, vol. AES-20, no. 2, pp. 183–198, 1984.\n\n[3] Rongyan Zhou, Jianfeng Chen, Weijie Tan, Qingli Yan, and Chang Cai, “Optimal 3d angle of arrival sensor placement with gaussian priors,” Entropy, vol. 23, no. 11, p. 1379, 2021.\n\n[4] G. Fischer, J. Bordoy, D. J. Schott, W. Xiong, A. Gabbrielli, F. Hoflinger, K. Fischer, C. Schindelhauer, and S. J. Rupitsch, “Multimodal indoor localization: Fusion possibilities of ultrasonic and bluetooth low-energy data,” IEEE Sensors Journal, vol. 22, no. 6, pp. 5857–5868, 2022.\n\n[5] M. Girolami, F. Mavilia, F. Furfari, and P. Barsocchi, “An experimental evaluation based on direction finding specification for indoor localization and proximity detection,” IEEE Journal of Indoor and Seamless Positioning and Navigation, vol. 2, pp. 36–50, 2024.\n\n[6] A. Sesyuk, S. Ioannou, and M. Raspopoulos, “Radar-based millimeter-wave sensing for accurate 3-d indoor positioning: Potentials and challenges,” IEEE Journal of Indoor and Seamless Positioning and Navigation, vol. 2, pp. 61–75, 2024.\n\n[7] A. N. Mirkin and L. H. Sibul, “Cramer-rao bounds on angle estimation with a two-dimensional array,” IEEE Transactions on Signal Processing, vol. 39, no. 2, pp. 515–517, 1991.\n\n[8] F. Wen, P. Liu, H. Wei, Y. Zhang, and R. C. Qiu, “Joint azimuth, elevation, and delay estimation for 3-d indoor localization,” IEEE Transactions on Vehicular Technology, vol. 67, no. 5, pp. 4248–4261, 2018.\n\n[9] Z. Zhang, Z. Shi, and Y. Gu, “Ziv-zakai bound for doas estimation,” IEEE Transactions on Signal Processing, vol. 71, pp. 136–149, 2023.\n\n[10] Bluetooth SIG, “Bluetooth core specification 5.1.” [Online]. Available: https://www.bluetooth.com/specifications/specs/core-specification-5-1/\n\n[11] F. Höflinger, R. Zhang, J. Hoppe, A. Bannoura, L. M. Reindl, J. Wendeberg, M. Buhrer, and C. Schindelhauer, “Acoustic self-calibrating system for indoor smartphone tracking (assist),” in 2012 International Conference on Indoor Positioning and Indoor Navigation (IPIN). IEEE, 2012, pp. 1–9.\n\n[12] A. Gabbrielli, G. K. Fischer, T. Schaechtle, W. Xiong, D. J. Schott, J. Bordoy, J. Wendeberg, F. Höflinger, C. Schindelhauer, and S. J. Rupitsch, “Airborne acoustic chirp spread spectrum communication system for user identification in indoor localization,” IEEE Transactions on Instrumentation and Measurement, p. 1, 2023.\n\n[13] R. Roy, A. Paulraj, and T. Kailath, “Esprit–a subspace rotation approach to estimation of parameters of cisoids in noise,” IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 34, no. 5, pp. 1340–1342, 1986.\n\n[14] R. Schmidt, “Multiple emitter location and signal parameter estimation,” IEEE Transactions on Antennas and Propagation, vol. 34, no. 3, pp. 276–280, 1986.\n\n[15] G. K. Fischer, N. Thiedecke, A. Gabbrielli, T. Schaechtle, F. Höflinger, A. Stolz, and S. J. Rupitsch, “A measurement platform for the evaluation of sparse acoustic array geometries,” in 2023 13th International Conference on Indoor Positioning and Indoor Navigation (IPIN). IEEE, 2023, pp. 1–6.\n\n[16] M. M. Saad, C. J. Bleakley, T. Ballal, and S. Dobson, “High-accuracy reference-free ultrasonic location estimation,” IEEE Transactions on Instrumentation and Measurement, vol. 61, no. 6, pp. 1561–1570, 2012.\n\n[17] G. Li, L. Zhang, F. Lin, M. Chen, and Z. Wang, “Sailoc: A novel acoustic single array system for indoor localization,” in 2017 9th International Conference on Wireless Communications and Signal Processing (WCSP). IEEE, 2017, pp. 1–6.\n\n[18] S. Ogiso, K. Mizutani, N. Wakatsuki, and T. Ebihara, “Robust indoor localization in a reverberant environment using microphone pairs and asynchronous acoustic beacons,” IEEE Access, vol. 7, pp. 123 116–123 127, 2019.\n\n[19] A. Gabbrielli, J. Bordoy, W. Xiong, G. K. J. Fischer, T. Schaechtle, J. Wendeberg, F. Hoflinger, C. Schindelhauer, and S. J. Rupitsch, “Rails: 3-d real-time angle of arrival ultrasonic indoor localization system,” IEEE Transactions on Instrumentation and Measurement, vol. 72, pp. 1–15, 2023.\n\n[20] A. Gabbrielli, W. Xiong, D. J. Schott, G. Fischer, J. Wendeberg, F. Hoflinger, L. M. Reindl, C. Schindelhauer, and S. J. Rupitsch, “An echo suppression delay estimator for angle of arrival ultrasonic indoor localization,” IEEE Transactions on Instrumentation and Measurement, p. 1, 2021.\n\n[21] I. Aboumahmoud, A. Muqaibel, M. Alhassoun, and S. Alawsh, “A review of sparse sensor arrays for two-dimensional direction-of-arrival estimation,” IEEE Access, vol. 9, pp. 92 999–93 017, 2021.\n\n[22] P. Pal and P. P. Vaidyanathan, “Nested arrays: A novel approach to array processing with enhanced degrees of freedom,” IEEE Transactions on Signal Processing, vol. 58, no. 8, pp. 4167–4181, 2010.\n\n[23] ——, “Nested arrays in two dimensions, part i: Geometrical considerations,” IEEE Transactions on Signal Processing, vol. 60, no. 9, pp. 4694–4705, 2012.\n\n[24] ——, “Nested arrays in two dimensions, part ii: Application in two dimensional array processing,” IEEE Transactions on Signal Processing, vol. 60, no. 9, pp. 4706–4718, 2012.\n\n[25] S. Nannuru, A. Koochakzadeh, K. L. Gemba, P. Pal, and P. Gerstoft, “Sparse bayesian learning for beamforming using sparse linear arrays,” The Journal of the Acoustical Society of America, vol. 144, no. 5, p. 2719, 2018.\n\n[26] P. P. Vaidyanathan and P. Pal, “Sparse sensing with co-prime samplers and arrays,” IEEE Transactions on Signal Processing, vol. 59, no. 2, pp. 573–586, 2011.\n\n[27] C.-L. Liu and P. P. Vaidyanathan, “Cramér–rao bounds for coprime and other sparse arrays, which find more sources than sensors,” Digital Signal Processing, vol. 61, pp. 43–61, 2017.\n\n[28] Q. Wu, F. Sun, P. Lan, G. Ding, and X. Zhang, “Two-dimensional direction-of-arrival estimation for co-prime planar arrays: A partial spectral search approach,” IEEE Sensors Journal, vol. 16, no. 14, pp. 5660–5670, 2016.\n\n[29] C.-L. Liu and P. P. Vaidyanathan, “Hourglass arrays and other novel 2-d sparse arrays with reduced mutual coupling,” IEEE Transactions on Signal Processing, vol. 65, no. 13, pp. 3369–3383, 2017.\n\n[30] L. Sun, M. Yang, and B. Chen, “Thermos array: Two-dimensional sparse array with reduced mutual coupling,” International Journal of Antennas and Propagation, vol. 2018, pp. 1–8, 2018.\n\n[31] C.-L. Liu and P. P. Vaidyanathan, “Cramér–rao bounds for coprime and other sparse arrays, which find more sources than sensors,” Digital Signal Processing, vol. 61, pp. 43–61, 2017.\n\n[32] A. Ramalli, E. Boni, E. Roux, H. Liebgott, and P. Tortoli, “Design, implementation, and medical applications of 2-d ultrasound sparse arrays,” IEEE transactions on ultrasonics, ferroelectrics, and frequency control, vol. 69, no. 10, pp. 2739–2755, 2022.\n\n[33] J. Zhao and C. Ritz, “Semi-coprime microphone arrays for estimating direction of arrival of speech sources,” in 2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE, 2019, pp. 308–313.\n\n[34] D. Bush and N. Xiang, “Broadband implementation of coprime linear microphone arrays for direction of arrival estimation,” The Journal of the Acoustical Society of America, vol. 138, no. 1, pp. 447–456, 2015.\n\n[35] ——, “A model-based bayesian framework for sound source enumeration and direction of arrival estimation using a coprime microphone array,” The Journal of the Acoustical Society of America, vol. 143, no. 6, pp. 3934–3945, 2018. [Online]. Available: https://asa.scitation.org/doi/full/10.1121/1.5042162\n\n[36] F. Wang, Z. Tian, G. Leus, and J. Fang, “Direction of arrival estimation of wideband sources using sparse linear arrays,” IEEE Transactions on Signal Processing, vol. 69, pp. 4444–4457, 2021.\n\n[37] S. Nannuru, P. Gerstoft, G. Ping, and E. Fernandez-Grande, “Sparse planar arrays for azimuth and elevation using experimental data,” The Journal of the Acoustical Society of America, vol. 149, no. 1, p. 167, 2021.\n\n[38] P. Pal and P. P. Vaidyanathan, “Nested Arrays: A Novel Approach to Array Processing With Enhanced Degrees of Freedom,” IEEE Transactions on Signal Processing, vol. 58, no. 8, pp. 4167–4181, Aug. 2010.\n\n[39] P. Stoica and A. Nehorai, “Performance study of conditional and unconditional direction-of-arrival estimation,” IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 38, no. 10, pp. 1783–1795, 1990.\n\n[40] ——, “Music, maximum likelihood, and cramer-rao bound,” IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 37, no. 5, pp. 720–741, 1989.\n\n[41] J. H. Dibiase, A high-accuracy, low-latency technique for talker localization in reverberant environments using microphone arrays. Brown University Providence, RI, 2000.\n\n[42] M. D. Zoltowski, M. Haardt, and C. P. Mathews, “Closed-form 2-d angle estimation with rectangular arrays in element space or beamspace via unitary esprit,” IEEE Transactions on Signal Processing, vol. 44, no. 2, pp. 316–328, 1996.\n\n{IEEEbiography}\n\n[ ]Georg K.J. Fischer received the B.Sc. degree in electrical engineering from the TU Braunschweig, Germany in 2017 and the M.Sc. degree in electrical engineering and information technology from the Karlsruhe Institute of Technology (KIT), Germany in 2019. He joined the Fraunhofer Ernst-Mach-Institute (EMI) in 2020, as a research assistant in the field of signal processing.\n\n{IEEEbiography}\n\n[ ]Niklas Thiedecke received the B.Sc. degree in electrical engineering and information technology from the TU Kaiserslautern, Germany in 2018 and the M.Sc. degree in embedded systems engineering in 2022 from the University of Freiburg, Germany. He was employed from 2018 to 2019 at Bosch Sensortec GmbH, Germany, where he participated in Bosch’s PreMaster-program, working in the field of smart sensor development. Since August 2022, he’s employed at Bosch Sensortec GmbH, Germany as a system architect for pre-development and development of smart sensors and smart connected sensors.\n\n{IEEEbiography}\n\n[ ]Thomas Schaechtle received his B.Eng. degree in electrical engineering from the Cooperative State University DHBW Lörrach in 2013 with TDK-Micronas, Freiburg, as education partner and the M.Sc. degree in embedded systems engineering in 2018 from the University of Freiburg. In 2018, he started as a Ph.D candidate at the Laboratory of Electrical Instrumentation and Embedded Systems, University of Freiburg. He was employed from 2010 to 2014 at TDK-Micronas, where he worked one year as an application engineer in a gas sensor research group. Since April 2022, he has been also working as research assistant for the Fraunhofer Ernst-Mach-Institute (EMI) in the field of ultrasonic communication.\n\n{IEEEbiography}\n\n[ ]Andrea Gabbrielli received the B.Sc. degree in telecommunications engineering from the Faculty of Engineering of the University of Pisa, Pisa, Italy, in 2014, the M.Sc. degree in computer science and the Ph.D. degree in microsystems engineering from the Faculty of Engineering of the University of Freiburg, Freiburg im Breisgau, Germany, in 2019 and 2024, respectively. He joined the Laboratory for Electrical Instrumentation and Embedded Systems at the Department of Microsystems Engineering (IMTEK), University of Freiburg, Germany, in 2019, as a scientific researcher in the field of signal processing for indoor localization.\n\n{IEEEbiography}\n\n[ ]Fabian Höflinger received the B.Sc. degree in automation engineering from the University of Applied Sciences Ravensburg-Weingarten, Weingarten, Germany, in 2007, the master’s degree in automation and energy systems from the Mannheim University of Applied Sciences, Mannheim, Germany, in 2007, and the Ph.D. degree in microsystems engineering, University of Freiburg, Freiburg im Breisgau, Germany, in 2014, with a focus on localization systems.\n\nHe was with Junghans Feinwerktechnik, Dunningen/Seedorf, Germany, where he developed components for telemetric systems. From 2007 to 2010, he was a Development Engineer. Since 2010, he has been with the Laboratory for Electrical Instrumentation and Embedded Systems, Department of Microsystems Engineering, University of Freiburg, where he has also been a Group Leader since 2014 and has a research group in the field of indoor localization. Since 2019, he has also been working for the Fraunhofer Ernst-Mach-Institute (EMI).\n\n{IEEEbiography}\n\n[ ]Alexander Stolz holds the Professorship for Resilience Engineering of Technical Systems at the Department of Sustainable Systems Engineering at the Faculty of Engineering of the Albert-Ludwigs-University in Freiburg. He studied civil engineering at University of Wuppertal and wrote his doctoral thesis about mobilization of bedding stresses in granular soil at the Professorship for Geotechnique. As head of the department Safety, Security and Resilience of Technical Systems he is specialized in the experimental investigation and numerical modeling of complicated and complex structures and networks under extraordinary disruptive events. Dr. Stolz coordinated the Thematic Group “Resistance of structures to explosion effects” in the ERNCIP (European Reference network for Critical Infrastructure protection) framework from 2012 till 2020 and is since 2017 also appointed international member of the AMR10 Committee on Critical Infrastructure Protection.\n\n{IEEEbiography}\n\n[ ]Stefan J. Rupitsch (Member, IEEE) was born in Kitzbuehel, Austria, in 1978. He received the Diploma and Ph.D. degrees in mechatronics from Johannes Kepler University Linz, Austria, in 2004 and 2008, respectively, and the Habilitation degree from the University of Erlangen–Nuernberg, Germany, in 2018.\n\nIn 2004, he was a Junior Researcher with the Linz Center of Mechatronics, Linz. From 2005 to 2008, he was with the Institute for Measurement Technology, Johannes Kepler University Linz. From 2008 to 2020, he was with the Chair of Sensor Technology, University of Erlangen–Nuernberg, where he held a Deputy Professorship. Since December 2020, he has been a Full Professor for electrical instrumentation and embedded systems with the University of Freiburg.\n\nHis research interests include piezoelectric transducers, energy harvesting, embedded systems, ultrasonic imaging and therapy, simulation-based material characterization, and noncontact measurements. He has authored more than 150 articles in these fields as well as the book Piezoelectric Sensors and Actuators: Fundamentals and Applications.\n\nStefan J. Rupitsch was a recipient of the Austrian Society of Measurement and Automation Technology Award for his Ph.D. dissertation in 2009 and the Outstanding Paper Award of the Information Technology Society in 2016. He is an Associate Editor of the IEEE SENSORS JOURNAL and the TM-Technisches Messen journal. He serves as a Guest Associate Editor for the Journal of Sensors and Sensor Systems (JSSS)."
    }
}