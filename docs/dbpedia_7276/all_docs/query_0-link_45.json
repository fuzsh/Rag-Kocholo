{
    "id": "dbpedia_7276_0",
    "rank": 45,
    "data": {
        "url": "http://planet.malept.com/",
        "read_more_link": "",
        "language": "en",
        "title": "Planet Egocity",
        "top_image": "http://3.bp.blogspot.com/_-LcS-OEM6Fg/SZXNj4HoIcI/AAAAAAAAABw/5ZcE0_LlMmE/s320/Awn-0.3.2-announcement-stats.png",
        "meta_img": "",
        "images": [
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=dFKOFgck2J4:ut_ZmLnP7sc:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/dFKOFgck2J4",
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=pnvTwGfo_ms:gl7IOip8zfs:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/pnvTwGfo_ms",
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=3WG4b8U9AfY:HJ2MyzsiGpE:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/3WG4b8U9AfY",
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=KnVQL3ARLZs:LbvsrNIEFco:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/KnVQL3ARLZs",
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=uwvcrfO8XKo:qUlnegIq5bE:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/uwvcrfO8XKo",
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=DH1d_OAUmLo:eRkh42Jtdoc:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/DH1d_OAUmLo",
            "http://feeds.feedburner.com/~ff/malept-tech?d=yIl2AUoC8zA",
            "http://feeds.feedburner.com/~ff/malept-tech?d=YwkR-u9nhCs",
            "http://feeds.feedburner.com/~ff/malept-tech?i=KklcsTQJ8ik:9EmjFhPlVl8:F7zBnMyn0Lo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/KklcsTQJ8ik",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=cj2HXo1c",
            "http://feeds.feedburner.com/~r/malept-tech/~4/n0SN0uD_dnA",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=aGvXRh8t",
            "http://feeds.feedburner.com/~r/malept-tech/~4/4XpT4haxjVs",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=jJFKziwR",
            "http://feeds.feedburner.com/~r/malept-tech/~4/6fke7InFO9s",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=NmAiY5p9",
            "http://feeds.feedburner.com/~r/malept-tech/~4/3l9YepzkriQ",
            "http://3.bp.blogspot.com/_-LcS-OEM6Fg/SZXNj4HoIcI/AAAAAAAAABw/5ZcE0_LlMmE/s320/Awn-0.3.2-announcement-stats.png",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=h0D1OLnS",
            "http://feeds.feedburner.com/~r/malept-tech/~4/s3NaLNpJ4cc",
            "http://2.bp.blogspot.com/_-LcS-OEM6Fg/SY9uUeNjjKI/AAAAAAAAABQ/XvJjlcCjTdo/s400/Awn-0.3.2-screenshot-01.png",
            "http://img7.imageshack.us/img7/9707/screenshot1pn1.png",
            "http://img140.imageshack.us/img140/3125/schermafdruk1ki6.png",
            "http://img7.imageshack.us/img7/6954/sexyawn032kc8.png",
            "http://img5.imageshack.us/img5/3416/screenshotjq2.png",
            "http://img9.imageshack.us/img9/1479/awnssjauntyvh2.png",
            "http://img3.imageshack.us/img3/3959/schermafdruk4rn5.png",
            "http://bayimg.com/image/manhnaabh.jpg",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=GWobRuvo",
            "http://feeds.feedburner.com/~r/malept-tech/~4/b9N39A4JmS0",
            "http://lh3.ggpht.com/_-LcS-OEM6Fg/SXE3EPJNMPI/AAAAAAAAAAM/bIam-j4BtU0/awn-rewrite-screenshot.png",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=Etu5lFSh",
            "http://feeds.feedburner.com/~r/malept-tech/~4/7V7JuK7WUiE",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=Q7ra8YLx",
            "http://feeds.feedburner.com/~r/malept-tech/~4/-FZxSbMOzXI",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=A9n1Iasn",
            "http://feeds.feedburner.com/~r/malept-tech/~4/NefHnUvoZrA",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=dz7JoymO",
            "http://feeds.feedburner.com/~r/malept-tech/~4/pl3c8QU20v0",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=vQUMAgLc",
            "http://feeds.feedburner.com/~r/malept-tech/~4/bwy-K-b3gmM",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=NDxLVFvh",
            "http://feeds.feedburner.com/~r/malept-tech/~4/UpRni0VCkBA",
            "http://www.pledgie.com/campaigns/613.png?skin_name=chrome",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=rStx2XIG",
            "http://feeds.feedburner.com/~r/malept-tech/~4/NwiH6k8t2Wk",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=rIm7H47I",
            "http://feeds.feedburner.com/~r/malept-tech/~4/CLRAE8B7CjM",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=mTusUIHp",
            "http://feeds.feedburner.com/~r/malept-tech/~4/Vd9FZNY9k5w",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=q0HsuTWM",
            "http://feeds.feedburner.com/~r/malept-tech/~4/7ik-aUQFImU",
            "http://farm3.static.flickr.com/2160/2224941561_f75d8d067e_o.jpg",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=GFonruPF",
            "http://feeds.feedburner.com/~r/malept-tech/~4/olNbSFNwpIw",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=0vlohyGE",
            "http://feeds.feedburner.com/~r/malept-tech/~4/zGjZzEYUBP4",
            "https://blogger.googleusercontent.com/tracker/6932260-5903908673780631275?l=blogger.malept.com",
            "http://feeds.feedburner.com/~f/malept-tech?d=41",
            "http://feeds.feedburner.com/~f/malept-tech?d=45",
            "http://feeds.feedburner.com/~f/malept-tech?i=opF5q9Xm",
            "http://feeds.feedburner.com/~r/malept-tech/~4/MrBFfDiNtY0",
            "http://l-stat.livejournal.com/img/userinfo.gif?v=105.7",
            "http://planet.malept.com/images/logo.png",
            "http://planet.malept.com/images/feed-icon-10x10.png",
            "http://planet.malept.com/images/feed-icon-10x10.png",
            "http://planet.malept.com/images/venus.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "What did I do at DevHub?\n\nI've been relatively quiet about what I've worked on at DevHub. You can see bits and pieces of it via Twitter and LinkedIn (not to mention BitBucket and GitHub), but I wanted to give an overall view of what I did, without violating NDAs or anything like that.\n\nMy primary focus was the application layer. As the DevHub developers page says, it's a Django-based environment. Interestingly enough, when I applied for the job, I didn't know Django at all. I was aware that it existed, and I had tried learning Pylons a few months prior (that ended badly). I did, however, know WSGI fairly well, as my URL shortener uses it. So, dealing with Python and the web wasn't a completely foreign concept to me. I would say that it's a testament to how awesome Django is, that I was able to pick it up and port the simple to-do web application that I was writing in PHP (using Doctrine as the ORM) in under a day. Of course, as soon as I was hired, I was made aware that certain major components of Django (the ORM and template systems) weren't being used, but SQLAlchemy and Jinja2 were. Which is another good thing about Django - it may be heavily opinionated, but it's not necessarily \"my way or the highway\".\n\nThis particular aspect is important, mostly because about ten months later, I was given the task to write a \"macroframework\" around this particular combination of technologies, using all of the best practices that we had accumulated since I was hired. I genuinely hope that it gets open sourced, because it's a fairly complete framework - it ports many popular Django apps, and as a good Django-based package would be, it has a lot of unit tests and documentation. In the process of writing it, I've also contributed fixes to the apps that I've ported, when I've seen areas which need improvement.\n\nThere's one other library that I wrote, which I hope will be open sourced. It's essentially a domain name parser. It can tell you whether a given domain name is syntactically valid, and provide relevant and proper concatenations of the constituent parts, such as the subdomain and the domain. It also handles IDNs just fine. It's a bit domain-specific (no pun intended), but works well, mostly due to the amount of unit/doc/regression tests I've written for it.\n\nIn late January, I was assigned the task of porting the DevHub platform from PHP to Python (as one of the reasons I was hired was because I knew both languages fairly well). And that began a six month journey, along with my co-workers (which included the other, more senior developer and two recently hired designers) where we would be working incredibly long hours, to get the new-and-improved DevHub launched in early July.\n\nI had been doing some experimenting with PyPy, because of its sandboxing capabilities. Unfortunately, due to several factors, it was deemed infeasible to use. Since then, however, I have been keeping tabs on its development to see if any of said factors have been eliminated. Regardless of that setback, by March I had made a reasonable amount of progress on the port, and the unpaid overtime began. (Yay for exempt statusÂ¡)\n\nIn the process of porting the platform, I had to deal with a number of third-party APIs, because one of DevHub's features is that it supports a number of third-party services by default (as opposed to having to add HTML embed code given by the third-party). The quality of these APIs ranged from half-decent to just plain terrible. Mind you, I've worked with other APIs prior to DevHub (in fact, I won a t-shirt in an API contest), but they were at least decently documented and the structure made some sense. It's amazing how little thought that some of these API providers give to their users.\n\nIn May, a few things happened: The platform port was essentially complete, our hosting provider took forever to move our server instances cross-country, and it was decided that the site editor needed to be gamified. I wrote a small prototype to see how that would work. Eventually, it was decided that most of that would be scrapped and that we would be using the BigDoor API. We were already partners, so it seemed like a natural fit.\n\nJune was the aforementioned \"Month of Hellâ¢\". At one point, I was at the office for 14 days straight. At the end, I began my week of sleeping at the office (AKA, \"The Week of Utter Hellâ¢\"). Quite possibly, the one good thing that came out of that experience, on a personal level, was that I was given my current phone, a Motorola Droid, as recognition of how much time I spent at the office. (My boss had gone to Google I/O and had gotten one for \"free\", and was/is an iPhone user and thus on AT&T, so it wasn't much use to him.)\n\nBy the launch in July, I was extremely close to burned out as I ever wanted to be. Fortunately, I had made sure that I got a week of vacation in mid-July (where I would be going to OSCON, independent of the company, and also taking in some of the sights of Portland). By the time I was back to work, some people had noticed that I was a significantly different person (i.e., not ridiculously stressed out). I don't really want to think about what would've happened if I didn't take that trip at that time.\n\nRelative to the previous couple of months, August was pretty calm. We (the company) did play a game of dodgeball with a company that we were going to partner with. For me, that just indicated that I was really out of shape. I immediately began jogging when the CEO insinuated that there may be more of these games. (To date, there hasn't been another one.)\n\nSeptember was pretty awesome, mostly because I was fortunate enough to go to DjangoCon. (The company paid for most of it, as part of an agreement during The Month of Hellâ¢.) I talked to some fellow web developers, plus sat in on some pretty interesting talks. I really wish that I could have stayed for all three days, but alas. One interesting thing came out of the experience. One of the technologies that people were consistently touting as a must-use package was celery, a distributed task queue. About a week after DjangoCon, we had a big problem with a long-running task during the request process. I remembered celery, and in under a week, I experimented with it on the development server, documented the process to install the subsystem (for the benefit of our sysadmin), helped my co-worker patch the task to use celery, tested the patch, and deployed it to the live servers.\n\nOctober was the month where I was both working on a client project and dealing with the decision of whether to change jobs, so I've covered most of that already. One thing that I think is worth mentioning is that I started to use code from the HTML5 Boilerplate project. I liked it so much, I'm using it in my current side project, the recently resurrected to-do app. And I plan on using it in the next job, too.\n\nI've been a bit quiet about Awn in my blog. This is partially because I've been working on two major areas: libdesktop-agnostic and Vala/GObject Introspection (as explained in my previous post, On Bindings).\n\nSince my work on libdesktop-agnostic is directly related to Awn, I'll address it here (even though it may be boring to most of you). I currently have abstractions for configuration, desktop entries, and virtual file systems (e.g., GIO). The area that needs the most work currently is the configuration support. What will ultimately happen is that there will be a class which lets you have per-instance configuration for a given app(let), regardless of the backend that is being used. What this means is that Awn users won't be shackled to using GConf if they want a stable dock. Plus, if a user wants to switch backends for some bizarre reason, they don't have to recompile Awn to do so. Obviously, they'd have to migrate the settings themselves, but that's the price one pays.\n\nAnyway, on to Awn. Here's a screencast I took (CC-BY-SA 3.0 licenced!) of a development version of Awn in an Ubuntu Jaunty virtual machine (hooray for VirtualBox!):\n\n(Direct link to YouTube video)\n\nThe bar colors are kind of ugly, mostly because I was testing some of the color-related code on that VM.\n\nObviously, the features shown in the video (orientation, panel style, and applet loading indicator) aren't the only new features in 0.4. I'll be showing off more shininess in successive videos.\n\nMoonbeam has covered most of the current status of Awn 0.4, which I will repeat here, briefly, for those of you who are scared of clicking on links:\n\nMoonbeam is working on an API that allows applets to have text and graphics overlay the applet icon. Think Awn plugin support for applets.\n\nHe is also rewriting Awn System Monitor so that one can monitor multiple things from the dock, among other things.\n\nCertain panel/task animations still need to be implemented.\n\nPlugin (not applet) support still needs to be implemented.\n\nI'd like to take a moment to talk about the Awn plugin system, particularly to those who actually write the plugins. The D-Bus plugin API that was in 0.2.x and 0.3.x will be deprecated in the 0.4 series, and removed in the 0.6 series. There will be a new API in the 0.4 series.\n\nWith regards to what I'm working on - in addition to libdesktop-agnostic integration, I will most likely be working on implementing the D-Bus plugin API, once Moonbeam is done with the API mentioned above.\n\nOn the Awn Extras front, I have the Garbage applet waiting to be added. This is waiting on Vala support being re-activated (which is dependant upon adding GObject Introspection support to Awn), and porting the applet to the 0.4 API. There is also an rTorrent frontend and a social aggregator applet that I have on the backburner (both written in Vala), which may or may not make it into 0.4.0.\n\nAnd finally, a note for Ubuntu users: we are not making available PPA builds of 0.4 until there are no feature regressions in the rewrite. This release is targeted for the official Karmic Koala repositories, just as 0.3.2 was targeted for the Jaunty Jackalope repositories. We anticipate building packages for Hardy and above.\n\nRemember, the best way to keep track of new developments in Awn/Awn Extras is to subscribe to Planet Awn. Be with us next time for \"Autohide and Seek\", or \"The Incredible Shrinking Dock\"!\n\nOver the past couple of days, I've implemented a private URI shortener service for myself, which I have named \"Rshrtnr\". The derivation of the name is left as an exercise for the reader.\n\nMy main motivation for writing it was a criticism of public URI shortening services that I have been seeing in blogs for a long time: if the service has some downtime or suddenly disappears, all of the links that you have created with it are useless. With my approach, I regain some control of where my shortened links point to, and if the service has downtime and/or disappears, I have more options for restoring it.\n\nThe code itself is written in Python. SLOCCount says that the core module runs at around 100 SLOC. Most of my time, however, was taken up by working around problems relating to my webhost's Python installation. The supported Python version is 2.4.x, which is ridiculously old (for reference, Gentoo was the last major Linux distribution to switch from Python 2.4 to 2.5, around July 2008). Additionally, for some reason, if I attempt to change the sys.path variable (i.e., the \"include path\") to use locally installed modules (I am on a shared host), the entire script breaks with zero logged messages anywhere. It runs fine via the command line, but in FastCGI mode, the strangeness occurs.\n\nThe two third-party modules that I used were Paste and mysql-python. I store the URIs and their associated aliases in a simple SQL table, and I use Paste for various WSGI/HTTP-related utilities. I \"manually\" handle routing via parsing the PATH_INFO environment variable.\n\nThere are two ways to specify an alias: either explicitly send a custom one as a query parameter with the URI, or let the app make a random one for you. With the latter behavior, it hashes the URI to generate an eight character \"unique\" alias. Since there are (in theory) 64^8 possibilities, I don't think I'll run out of aliases any time soon, especially since custom aliases can be anywhere from 1 to 15 characters long.\n\nIn my opinion, the most interesting feature is that adding URIs requires one to send an OpenPGP-encoded query string, which needs a public key recognized by the app for the operation to succeed. To write this, I simply parsed the output from sending the OpenPGP message to the gpg binary.\n\nFinally, mod_rewrite magic is used to prettify the shortened URIs. Nothing too exciting about that part.\n\nI had thought about hosting a version of Rshrtnr on Google App Engine, but a key component is missing - OpenPGP support.\n\nIf anyone wants me to release it, please comment below. There's currently a bunch of webhost-specific things that I would need to abstract out before I release the code to the general public, and unless someone gives me a very good reason, it will be licensed under the AGPL version 3.\n\nOne of the more interesting areas in software development, to me at least, is language bindings. Being able to interface with a library written in one language in another language is kind of satisfying, as it allows me to develop without having to reinvent the wheel. There are two specific projects that I use and work on so that I can enhance the software that I develop: GObject Introspection (G-I) and python-spidermonkey.\n\nGObject Introspection\n\nAs a quick overview, the goal of this project is to give C libraries the tools to provide enough metadata about their API so that bindings can be written with minimal effort. Given the time and effort that I have put into maintaining the Awn bindings, it is not very surprising that I would be willing to help out getting this framework working for Awn. My ultimate goal is to eliminate the bindings/python folder in the Awn source tree. It is basically a mixture of a Scheme definition file plus a very bizarrely formatted \"override\" file for custom definitions, all integrated into autotools to produce a C library that is ready to be dynamically loaded into python via import. To meet this goal, I am contributing to the PyBank project, which is a prototype Python module that interfaces with the GObject Introspection library to read compiled library metadata files (called \"typelibs\") on the fly so that classes, functions, etc. can be loaded and called at runtime. In addition to myself, a Google Summer of Code student and a Sugar Labs developer are also working on the module, with Johan Dahlin overseeing it all. So far, I've contributed a unit test suite, ported from the gjs project (JavaScript bindings for GLib-based libraries based on the Spidermonkey VM) and working type bindings for various simple types (e.g., int64 and float).\n\nI have also put some coding effort toward G-I integration in Vala. Vala supports G-I by both reading GIR files (the XML serialization of G-I metadata) to produce VAPI files (short for Vala API files), and writing GIR files when producing a library written in Vala (e.g., libdesktop-agnostic). I have contributed mostly what amounts to workarounds in the GIR reading code, with regards to Vala/G-I behavioral inconsistencies. Didier 'Ptitjes' has done much, much more solid work than I have on both fronts, which I greatly appreciate.\n\npython-spidermonkey\n\nThis project, as the README states, lets you [execute] arbitrary JavaScript code from Python[, and allows] you to reference arbitrary Python objects and functions in the JavaScript VM. As I've stated in an earlier blog post, I use this in my custom website build system to both validate and pack my JavaScript code, via JSLint and Packer, respectively. Since I published that post almost two years ago, that project was revived twice - once by a Mozilla employee (and co-founder of Humanized, which is quite awesome) named Atul Varma, and the latest incarnation is on github. Since it is based on the original implementation in C, and not the Python-based ctypes version, the Base2 recursion problem does not exist, and so I have happily written modules and scripts which wrap the two JavaScript utilities. Recently, I have made them available in a public project on Launchpad called python-jsutils. I haven't really announced it until now because it currently relies on a change I made to python-spidermonkey which allows one to iterate over a JavaScript array, instead of having to write \"unpythonic\" code like for x in range(0, len(foo)): #.... While it is in my fork, it has not been merged to the \"official\" repository.\n\nI need something to get myself blogging again, so I figured that I should write about how my website is written. I'm going to start with one of the parts written in JavaScript: the Tag module. It's comprised of a simple JavaScript object with static methods and properties, no instances. Its main purpose is to create (X)HTML nodes for use in what used to be known as \"dynamic\" HTML. Incidentally, it's also part of my \"old projects\" series: I originally created it for an Intel-sponsored research project that I was working on during my time in university. (For more details on the project, please see my curriculum vitae.)\n\nIn practice, calls using Tag.create() don't look too horrible. Consider the example of building a minimal HTML5 document:\n\nvar html = Tag.create('html', {children: [ Tag.create('head', {children: Tag.create('title')), Tag.create('body') ]});\n\nOr, a data table:\n\nvar table = Tag.create('table', { attributes: {summary: 'MLS Statistics'}, classes: ['sortable', 'centered'], // uses sorttable styles: {border: '1px red inset'}, // use CSS style names, not JS ones children: [ Tag.create('thead', {children: Tag.create('tr', { // text is automatically converted Tag.create('th', {children: 'Team'}), Tag.create('th', {children: 'Goals For'}), Tag.create('th', {children: 'Goals Against'}) })}), Tag.create('tbody', {children: [ Tag.create('tr', { Tag.create('tbody', {children: [ Tag.create('tr', { classes: ['west-coast', 'usa'], children: [ Tag.create('td', {children: 'Seattle Sounders FC'}), Tag.create('td', {children: '9'}), Tag.create('td', {children: '3'}) ] }), // add more teams here... ]) ] });\n\nI recently modified the function so that it deserializes an object (originally a JSON string) into a DOM node tree. This is particularly useful when you're sending partial HTML documents as JSON strings (which I prefer to sending HTML strings and dealing with that mess). So, the first example would look like this:\n\nvar html = Tag.create({ \"name\": \"html\", \"children\": [ { \"name\": \"head\", \"children\": {\"name\": \"title\"} }, {\"name\": \"body\"} ] });\n\nInterestingly enough, I created this without the knowledge of the existence of JSONML or any of its bretheren, although I suspected that JSON-HTML converters already existed.\n\nThree of the functions in the module are basically wrapper functions. Tag.createWithText() creates an HTML element with a text child node, and Tag.createHeader() creates an HTML header element (e.g., <h1>...</h1>) with a text child node. Tag.text() is shorthand for the DOM's document.createTextNode() method.\n\nIn the current iteration, nearly all of the event-related code is commented out, as there are far more competent JavaScript libraries out there which deal with cross-browser events. The only event-related function left is Tag.dispatchEvent(), which sends a \"synthetic\" event for a given HTML element. If I remember correctly, I coded for both the W3C and Microsoft models, but I don't remember testing it on browsers other than IE6/7 and Firefox 2. At some point, I'll probably reintegrate event support to Tag.create() at minimum, using Base2.\n\nThe remaining function is a utility function. Tag.inXHTML() determines whether the document in question is in XHTML mode, using a variety of heuristics. I'm sure there's a better way of doing it, but I couldn't find one when I was researching it.\n\nThis module has been tested in IE6/7, Firefox 1.5/2/3, Safari 2/3, and Opera 9.5 - although not all in the same time periods. It's licensed under the Apache Licence (version 2.0) and is currently somewhere in my compressed JavaScript file. If there's any interest, I'll put up the non-compressed version somewhere and update this post.\n\nBenjamin Otte recently wrote about desktop-web integration in the GNOME desktop. It's kind of interesting that he calls himself \"not web enabled\", given that he's the main developer of the swfdec library and associated applications. I agree with most of what he wrote, but there are a few comments I would like to make.\n\nBenjamin asks:\n\nWhy does dconf (or GConf) not store my settings in the cloud so it uses the same settings on my university login?\n\nAs I understand it, this is one of the features of Conduit. There's a bug in Awn regarding config synchronization via Conduit. I'm probably going to look into how that works when I resume work on the config interface for libdesktop-agnostic.\n\nThere is an erroneous statement in his post:\n\nWe don't even have a http library that knows cookies.\n\nlibsoup has had (non-persistent) cookie support since 2.23.1, and persistent support will be in 2.26.0.\n\nAnd then there's the main point:\n\n[GNOME is] doing a very bad job at integrating the web into the desktop. Apart from epiphany (and the weather applet), what application does GNOME ship that speak http?\n\nI believe there are two main reasons for this: One is GNOME developers are not \"web-enabled\". [...] The other, related reason is that we don't have the software to do this.\n\nIn Awn-land, we have several web-enabled applets:\n\narss\n\ncomics\n\ndigg\n\nlastfm\n\nmeebo\n\npandora\n\nrtm\n\nweather\n\nwebapplet\n\nIn particular, webapplet is a work in progress framework, which will allow what is essentially an applet version of Mozilla Prism. It currently uses WebKit as the backend, although there is also a Gecko-based backend planned. The rest of the applets listed are written in Python. In particular, the digg, meebo, pandora, and rtm applets use the gtkmozembed Python bindings to view the respective websites. Here lies one of the problems of the web-enabling the GNOME platform. This library is acknowledged to be less than ideal. If you look at the source code of the applets, you'll see that there are some ugly hacks in order to make them work properly on Ubuntu systems. Webapplet is slated to replace that ugliness.\n\nOne of my side projects is a status aggregator applet. It's supposed to aggregate all of these social networking status feeds and also to sync all of your personal statuses. One of said social networking websites returns complex, site-specific HTML that obviously needs to be sanitized/canonicalized. The easiest (but not necessarily most memory-efficient) method of performing that task is to use the DOM. There is not currently a DOM library for the GNOME platform. There is a libgdom3 project (written in Vala) which I believe is being / will be used by the gnome2-globalmenu project, but it is unfinished. There is also an old, unmaintained library called gdome2 based on libxml2. I'm not even sure if anyone actually uses that library anymore (its last release was in 2003). I avoided using gtkmozembed and friends based on the experiences described above. I settled on a promising feature request for WebKit: a GObject/C DOM binding. (As an aside, the WebKit bug linked is a fascinating case study on several levels: conflicting coding standards, conflicting developer personalities, and some interesting coding/reviewing.) It's very nice - I can manipulate document fragments as if I were using JavaScript in a web page, among other things. I eagerly await that feature being committed to WebKit trunk.It is an important stepping stone when it comes to working with the web.\n\nAnother side project that I'm currently working on is a developer dashboard applet. It's kind of like the previous applet, except as applied to software projects. I was originally going to write it in Vala, which meant that I would have to write an interface to (at least) the Launchpad API, which meant implementing at least three specifications in Vala: OAuth, URI templates, and WADL. I finished the first two (I haven't yet decided whether to release my URI templates implementation as a separate library - the implementation plus the test app is 451 source lines of code), and WADL is a very complex specification. So, I decided to postpone working on the WADL library and instead am currently working on a prototype applet using Python and launchpadlib. Implementations for those three specifications and many others (including AtomPub) should be included in the GNOME platform if it wants to be web-enabled.\n\nMike Rooney (Awn Extras developer, among other things) posted an article on this \"webhooks\" idea. As I understand it, it's essentially a customizable, web-based version of the \"Subscribe to future XYZ via email\" features (e.g., blog comments) that are currently around. The key phrase in this sort of thinking is \"push technology\". Mike asks:\n\nSo will webhooks replace the current paradigm that I'm using here, or complement it?\n\nI believe that it will complement the current paradigm. We need to have a transitional period (Ã la the old, rigid deadline for the US digital television transition) between the current \"polling\" techniques and the \"new and shiny\" (and arguably bandwidth-saving) push techniques. Take, for example, Twitter . Let's assume that they didn't shut down their XMPP service, and they built upon it an (XML-based) API so that a client (for the purposes of this thought experiment, let's say my currently-in-vaporware Status Aggregator Awn applet) could connect to a specific JID (AKA user name + domain + \"resource\", or specific client) and listen for any new tweets, responses to my tweets, etc., replacing those messy timeout callbacks with messy async socket callbacks. The main benefit that I see is a savings in bandwidth for both the consumer and the producer. It avoids sending network requests every X minutes, which would add up, given the number of services/feeds that a user subscribes to (including mail). This actually leads me to my answer to Mike's other question:\n\nAre webhooks the next step of this evolution, or something else entirely?\n\nAs evidenced by my thought experiment, I'd like to see XMPP as the next step, or at minimum, the step after webhooks. While I love HTTP, and am a big fan of the whole REST concept, it's hard for me to see it used as a facilitator for pushing data, as opposed to pulling it. In fact, given the way that ETags and the like are designed, HTTP is inherently a pull technology. The Comet model feels like a big kludge to me for that reason. XMPP, on the other hand, is designed to be a push technology, and its supporters are actively marketing it as such. It's also scalable, as servers like ejabberd and services like Google Talk can attest. I suppose the bottleneck here is a catch-22: you need both services and apps to buy into this particular implementation. Maybe when I finish one of the myriad projects I have going at once, I'll take a crack at adding a push-based web service client. Ideally, for configuration, all a user would have to do is set their app-specific JID (e.g. foo@example.com/bar_app) in both the web app and the client app, and it would \"just work\" (well, you would also have to set the JID password somehow as well, but that's beside the point).\n\nUpdate (2009/02/18): It seems that I was subconsciously channelling a presentation on XMPP PubSub that I read over six months ago.\n\n[1]I'm focusing on the one I actually use. Yes, I should be using identi.ca, since I am a supporter of free and open services/protocols. It even has the hallowed XMPP interface to microblogging. One of these days, I'll do what all the cool kidsâ¢ are doing and post to both. It'll probably happen when I (continue) work on the vaporware mentioned above. [2]It's vaporware until I push the source code onto a public server.\n\nFor those of you who don't know what a postmortem is in this context, it's essentially a reflection of what happened in this release: what went right, what went wrong, and what we'll try to do next time.\n\nBefore I begin, a lot of the history is from memory, so the facts may not be 100% correct.\n\nBackground\n\nBack around July 2008 or so, we essentially had two branches: stable/bugfix-only (0.2.7) and trunk (0.3.1). A few developers wanted to release from the bugfix branch for the sake of the distributions, but since work was well on its way in trunk, there were not many volunteers to lead the effort. I volunteered to do so, and began merging bugfixes to the stable branch, with the goal of releasing by around the end of August.\n\nUnfortunately, there were three big roadblocks in my way: the infamous make distcheck, Bug 194018 (an intermittent problem with launching launchers on docks not built with GNOME libraries, and Bug 194431, \"the trash bug\".\n\nFor developers, I would guess that one of the most annoying things about releases is the dreaded make distcheck command. This command makes sure that if you run make dist to generate a tarball, that it compiles correctly out-of-the-box. It took what felt like dozens of iterations to make sure that certain files were in the tarball, ready to be installed by the build system. But the most annoying part of the process was the part dealing with internationalization (i18n). I18n is handled by the intltool/gettext packages in Awn, and they expect files to be \"just so\", or else make distcheck fails with a semi-comprehensible error. With some help from Qball, I managed to more-or-less get the trees into a releasable state.\n\nThe desktop-agnostic launcher bug was a pain to debug, as all it did was spit out a cryptic error message to the console instead of launch the application, and this only occurred with some launchers (varying between machines). Fortunately, moonbeam managed to write a fix for it in early August.\n\nThe trash bug was more complex in its own way. In GNOME 2.22, GNOME switched virtual file system (VFS) libraries from GNOME VFS to the more desktop agnostic GIO (part of GLib). Part of this conversion was that the trash directory changed from $HOME/.Trash to the more complex Freedesktop.org standard of $XDG_DATA_HOME/Trash. In comparison to the old trash directory, which was just an intermediary directory prior to \"permanent\" deletion, the new standard added a trash metadata directory (e.g. for the \"restore this file\" feature). Now, the trash applet did not have a maintainer. As I understand it, Neil ported it from the GNOME applets package as one of the proof-of-concept Awn applets. By this time, Neil was (and still currently is) very busy with his awesome (but unrelated) work at Canonical. Thinking that this was a desktop-agnostic issue, I decided to take the bug. My first attempt, merging in the new trash implementation from GNOME applets, failed badly. My next move was to rewrite the entire thing in Vala. My reasons for doing this were twofold: I wanted to work on my skills in C#-like languages, and I wanted the applet to be a bit more readable/maintainable for the next person who would take up maintainership. Unfortunately, it took way to long to write (through no fault of Vala's). The main problem was that the algorithm to determine the number of files in the trash (an important part of the original applet) is ridiculously complex in non-GIO libraries. This is due to the fact that multiple volumes can have trash cans. By the time I figured out about half of it, it was the end of August. Given the number of people subscribed to the bug and commenting on it, plus the comments I saw on the forum, this was a showstopper bug. I couldn't very well release without it in there, so the deadline came and went, and there was no update to Awn in the fall Linux distribution release.\n\nI should note that there will be a happy ending to this bug - last month, I managed to get trash support into libdesktop-agnostic, and as soon as I convert Awn to use libdesktop-agnostic, I will commit the Garbage applet.\n\nReleasing 0.3.2\n\nFast forward to last month (January). One of the core developers (mhr3) suggested that we do a snapshot release of trunk, since work on the rewrite was well underway. Somewhat surprising to me, more developers agreed to help with this release. This time, mhr3 was release manager (for obvious reasons). For the rest of the month and the first week of February, bugfixes were committed to the trunk branches of Awn and Awn Extras. There were also some features added (I admit that I added at least one of them), but the most notable one was the merging of the AWNLib 2.0 branch. I'll get back to that shortly. People were testing applets and noting their functionality on a wiki page, which helped with finding bugs.\n\nBy around February 6th, preparations were underway for the actual release. mhr3 and gilir were busy making sure that make distcheck worked for both Awn and Awn Extras, and I was working on the release notes. DBO, a developer for GNOME Do/Docky, suggested that we put some effort into doing a little marketing, like they did with their recent 0.8 release. So, I started a wiki page with a list of volunteers who would post to various news/forum websites.\n\nThe day of release was interesting. Throughout, various people (including myself) were in and out of the IRC channel doing stuff In Real Life. I managed to finish the release notes (and get screenshots) with the help of the folks in the channel, and gilir stayed up way past midnight local time to sign and upload both the source tarball and the PPA packages. As soon as mhr3 gave the go-ahead signal, the release announcements were sent to their respective news sites. I filed bugs in Gentoo for version bumps for both packages, to head off any overzealous Gentoo + Awn users. I also notified the Mandriva packager of the release, since I had his contact info handy. A few hours later, I remembered that I had an OSNews account (for commenting on some article which was probably tangentially related to Awn) and decided to submit an article. In the morning, I was informed via IRC (on a non-Awn channel, no less) of its publication, with a surprising addition: a mini-review by one of the site's editors, which was positive.\n\nAs of publication, my blog post announcing Awn/Awn Extras 0.3.2 has received almost 5,500 pageviews (see screenshot). To put numbers on the data points in the graph:\n\nSunday: 312\n\nMonday: 2,783\n\nTuesday: 953\n\nWednesday: 1,008\n\nThursday: 367\n\nWhat Went Wrong\n\nWe should have reverted the AWNLib 2.0 branch merge. It caused more problems than it solved: it was inevitable that applets would break, and that at least one API change would be missed before release, especially given the amount of time between the merge and the release.\n\nCoordinating the news/forum releases went OK, but we ended up having two Digg links, which probably spread out the total number of diggs, thereby lowering the chance that it would hit the Digg front page.\n\nI was naÃ¯ve enough to think that Debian/Ubuntu users wouldn't immediately file version bump bugs as some Gentoo users are prone to do. I was wrong.\n\nAdditionally, too many Ubuntu users did not read that we already provide binaries for Feisty through Jaunty (inclusive) - they seem to want to install from source, which we do not recommend (unless they plan on doing development).\n\nWhat Went Right\n\nThe release coordination in the channel went fairly smoothly, especially given that we were all in different time zones.\n\nPosting to OSNews was definitely a good thing. As you can see from the screenshot, it was the highest referrer to the post.\n\nIt was nice that someone not associated with the project posted to reddit - it was the second highest referrer. It was posted two days after the release, but beggars can't be choosers.\n\nNext Steps\n\nFirst and foremost, prepare for a 0.3.2.1 release for Awn Extras.\n\nWhen we have a target date for 0.4.0, we should immediately branch, and said branch should only contain merges approved by the release manager.\n\nA 250-character summary of the new version (complete with reminders of what the packages are) should be written for news sites, in addition to the summary and the release notes.\n\nMake sure to highlight that Ubuntu users do not have to install from source.\n\nI need to get a Slashdot and a reddit account. I'm doing this under protest.\n\nWe need to make sure that there's only one \"official\" Digg post.\n\nI should look into one of those omni-share-to-social-networks buttons, but only for the big announcements. Those \"share\" buttons make me feel a bit dirty.\n\nWe need to get some contact information for at least the packagers for Fedora and OpenSUSE.\n\nIf I remember and have time, I need to learn how to use the OpenSUSE Build Service.\n\nExplicitly mention in the release notes that there is no need to file version bump bugs in Debian/Ubuntu. Although, given past experience, I doubt that the people filing these bugs would read that. On the other hand, it's due diligence.\n\nObviously, I haven't done one of these in a while. There are a few reasons for this. For one, my workload has gotten a bit larger. Additionally, Super Smash Bros. Brawl came out recently...it's ridiculous how much time that game eats up, and I'm only halfway through \"adventure mode\".\n\nBut seriously...both the forums and the bug tracker have been relatively quiet. It's difficult to figure out exactly why that is. However, there have been a few things that have happened in the past month or so.\n\nMoonbeam has a summary of what happened in the week following my last post. Additionally, he has been working on the framework for an applet that can use either the Gecko engine (used, most notably, in Firefox) or the WebKit engine (used in Safari) to render HTML. Hopefully, this will alleviate some of the problems that people have had trying to get some of the HTML-based applets to run properly. Unfortunately for us, moonbeam has become rather busy in real life lately, and so there may or may not be very much progress on the features/applets that he's been working on.\n\nAndrewsomething, a longtime bug/answer triager for both Awn and Awn Extras, has finally taken the plunge (so to speak) and joined the Awn Extras developer team. His first contribution is the \"Remember the Milk\" applet, and for his next undertaking, he is seeing if there's any interest in a simple note applet.\n\nIt is interesting to note that two new, experimental branches have appeared for Awn recently. One, created by moonbeam, focuses on refactoring the launcher/task/applet effects framework so that it's easier to add new effects, and uses cairo's surfaces instead of Gtk+'s \"pixel buffers\" to manipulate the images. This allows for more complex effects to be used, while keeping the overall effect smooth (and potentially hardware-accelerated).\n\nThe other branch was created by longtime Awn contributor haytjes. He's working on fixing the \"custom icon\" feature. Currently, there are several bugs which prevent that feature from being very usable.\n\nAnd finally, I'd like to give a quick Planet Awn roundup. Moonbeam has a very good post on the architecture of Awn and why it's not possible (currently) to have features such as parabolic zoom. Our fearless leader, Neil, has (finally) written a post about the recent Awn/Awn Extras release, and our upcoming plans for the projects. Hopefully, his presence on Planet Gnome will continue to give Awn more publicity :).\n\nI'm taking a break from both trying to make a <tbody/> scroll vertically without a horizontal scrollbar present and playing \"Link's Crossbow Training\" to write up what's transpired in the past several days in Awn-land.\n\nThe Awn Curves branch was partially merged into awn-core-testing. I say \"partially merged\" because meek is merging it in parts, due to the complexity.\n\nThe big event was when Neil finished reviewing the awn-core-testing and awn-extras-testing branches and merged them into their respective trunks. Among the benefits is that users of reacocard's Ubuntu Gutsy repository can now use the shiny new features that those of us on the (very) bleeding edge have been using for a while now.\n\nI should also point out that Neil has added both moonbeam and myself to awn-core, in recognition of our work on both the testing branches and our respective personal branches. This means we have commit access to Awn's trunk branch and more bug/blueprint triaging privileges.\n\nAs a result of the big merge, we now have a new roadmap. What used to be Neil's big rewrite for 0.3 (code-named fandabbydosy) has been spread out over several releases. See the roadmap link for details. One important item to mention is that we plan to release version 0.2.4 of both Awn and Awn Extras on Monday (02/18).\n\nIn Awn Extras, most of the changes have been bugfixes. A patch was added to the media-control applet for Quod Libet support.\n\nFinally, I'm holding a contest for Awn users/enthusiasts. In the near future, I'd like to have a post with screenshots and videos showing off all of the new features and applets in Awn/Awn Extras. Unfortunately, I suck at doing that sort of thing myself. :) So, I'm giving the Awn community the chance to show off their customized docks.\n\nThe only restriction on the screenshots and videos is that you license them under a Creative Commons license. I will, of course, attribute all media to their proper creators :) Ideally, the screenshots should be as hi-res as possible, but any resolution is welcome. The same goes for videos.\n\nThe deadline is Feb. 21, because I'd like to write the post by the end of next week. I'll choose a set of media that looks the nicest (with the help of the people in #awn) and use that as the basis of my next Awn post.\n\nSo if you wish to participate, please post the URL to the media, the attribution information you wish to use (your name or nick), and which feature/applet you're highlighting on the forum thread or as a comment here."
    }
}