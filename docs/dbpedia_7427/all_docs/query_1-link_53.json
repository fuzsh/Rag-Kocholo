{
    "id": "dbpedia_7427_1",
    "rank": 53,
    "data": {
        "url": "https://columbialawreview.org/content/norms-of-computer-trespass/",
        "read_more_link": "",
        "language": "en",
        "title": "NORMS OF COMPUTER TRESPASS",
        "top_image": "https://live-columbia-law-review.pantheonsite.io/wp-content/uploads/2016/05/kerr1.png",
        "meta_img": "https://live-columbia-law-review.pantheonsite.io/wp-content/uploads/2016/05/kerr1.png",
        "images": [
            "https://live-columbia-law-review.pantheonsite.io/wp-content/uploads/2016/05/kerr1.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Managing Editors",
            "Columbia Law Review"
        ],
        "publish_date": "2016-05-01T14:42:51-04:00",
        "summary": "",
        "meta_description": "Introduction The federal government and all fifty states have enacted criminal laws that prohibit unauthorized access to a computer. At first blush, the meaning of these statutes seems clear. The laws prohibit trespass into a computer network just like traditional laws ban trespass in physical space. Scratch below the surface, however, and the picture quickly […]",
        "meta_lang": "en",
        "meta_favicon": "https://live-columbia-law-review.pantheonsite.io/wp-content/uploads/2016/01/CLR-favicon.png",
        "meta_site_name": "Columbia Law Review",
        "canonical_link": "https://columbialawreview.org/content/norms-of-computer-trespass/",
        "text": "Introduction\n\nThe federal government and all fifty states have enacted criminal laws that prohibit unauthorized access to a computer. At first blush, the meaning of these statutes seems clear. The laws prohibit trespass into a computer network just like traditional laws ban trespass in physical space. Scratch below the surface, however, and the picture quickly turns cloudy. Courts applying computer trespass laws have divided deeply over when access is authorized. Circuit splits have emerged, with judges fre­quently expressing uncertainty and confusion over what computer tres­pass laws criminalize.\n\nConsider the facts of seven recent federal cases involving the federal unauthorized access law, the Computer Fraud and Abuse Act (CFAA). In each case, the line between guilt and innocence hinged on a dispute over authorization:\n\nAn employee used his employer’s computer at work for personal reasons in violation of a workplace rule that the com­puter could only be used for official business.\n\nAn Internet activist logged on to a university’s open net­work using a new guest account after his earlier guest account was blocked.\n\nTwo men used an automated program to collect over 100,000 email addresses from a website that had posted the infor­mation at hard-to-guess addresses based on the assumption that outsiders would not find it.\n\nA man accessed a corporate account on a website using login credentials that he purchased from an employee in a secret side deal.\n\nA company collected information from Craigslist after Craigslist sent the company a cease-and-desist letter and blocked the company’s IP address.\n\nA company used an automated program to purchase tick­ets in bulk from Ticketmaster’s website despite the website’s use of a barrier designed to block bulk purchases by automated programs.\n\nA former employee continued to access his former em­ployer’s computer network using a backdoor account that the for­mer employer had failed to shut down.\n\nOn the surface, there are plausible arguments on both sides of these cases. The prosecution can argue that access was unwanted, at least in some sense, and therefore was unauthorized. The defense can argue that access was allowed, at least in some sense, and therefore was authorized. Liability hinges on what concept of authorization applies. However, courts have not yet identified a consistent approach to authorization. Authoriza­tion is not defined under most computer trespass statutes, and the statu­tory definitions that exist are generally circular. Violating computer trespass laws can lead to severe punishment, often including several years in prison for each violation. And yet several decades after the wide­spread enactment of computer trespass statutes, the meaning of author­ization remains remarkably unclear.\n\nThis Essay offers a framework to distinguish between authorized and unauthorized access to a computer. It argues that concepts of authoriza­tion rest on trespass norms. As used here, trespass norms are broadly shared attitudes about what conduct amounts to an uninvited entry into another person’s private space. Relying on the example of physical-world tres­pass, this Essay contends that the scope of trespass crimes follows from identifying trespass norms in three ways: first, characterizing the nature of the space; second, identifying the means of permitted access; and third, identifying the context of permitted entry. These three steps can be used to identify the norms of computer trespass and to give meaning to crimi­nal laws on unauthorized access.\n\nInterpreting computer trespass laws raises an important new twist. Alt­hough trespass norms in physical space are relatively settled and intuitive, computer trespass norms online are often unsettled and contested. The Internet is new and rapidly changing. No wonder courts have struggled to apply these laws: Doing so requires choosing among unsettled norms in changing technologies that judges may not fully understand. In that context, courts cannot merely identify existing norms. Instead, they must identify the best rules to apply from a policy perspective, given the state of technology and its prevailing uses. Published court decisions can then help establish norms consistent with those rules.\n\nAfter first identifying the conceptual challenges of applying com­puter trespass laws, this Essay argues that the principle of authentication provides the most desirable basis for computer trespass norms. Authenti­cation requires verifying that the user is the person who has access rights to the information accessed. Under this principle, the open norm of the World Wide Web should render access to websites authorized unless it bypasses an authentication gate. This approach leaves Internet users free to access websites even when their owners have put in place virtual speed bumps that can complicate access, such as hidden addresses, cookies-based limits, and IP address blocks. Further, when access requires authentica­tion, whether access is authorized should hinge on whether it falls within the scope of delegated authority the authentication implies. Access to canceled accounts should be unauthorized, and access using new accounts may or may not be authorized depending on the circumstances. Finally, the lawfulness of access using a shared password should depend on whether the user intention­ally acts outside the agency of the account holder.\n\nThe authentication principle advocated in this Essay best captures the competing policy goals of modern Internet use in light of the blunt and severe instrument of criminal law. Norms based on this principle give users wide berth to use the Internet as the technology allows, free from the risk of arrest and prosecution, as long as they do not contravene mechanisms of authentication. On the other hand, the norms give com­puter owners the ability to impose an authentication requirement and then control who accesses private information online. The result estab­lishes both public and private virtual spaces online using a relatively clear and stable technological standard.\n\nThis Essay contains four parts. Part I shows how trespass norms apply in physical space. Part II argues that courts should apply the same approach to computer networks but that they must identify the best trespass norms rather than simply identify existing norms. Part III considers the trespass norms that courts should identify in the many difficult cases involving the Web. Part IV explains how the norms of computer trespass should apply to the complex problems raised by canceled, blocked, and shared accounts.\n\nI. Trespass in Physical Space\n\nImagine a suspicious person is lurking around someone else’s home or office. The police are called, and officers watch the suspect approach the building. Now consider: When has the suspect committed a criminal trespass that could lead to his arrest and prosecution? This section shows how the answer comes from trespass norms in physical space—shared understandings of obligations surrounding access to different physical spaces. The rules are not written down in trespass statutes. Instead, those called on to interpret physical trespass laws make intuitive conclusions based on the nature of that space and the understood purposes of differ­ent means of accessing it. From those intuitions, shared understandings emerge about whether and when access to a physical space is permitted. By unpacking our intuitions that govern physical trespass, we can then appreciate why courts have struggled to interpret computer trespass laws.\n\nA. Authorization and Social Norms\n\nThe concept of trespass implies signals sent by property owners about what uses of that property are permitted. In some cases, the signals are clear and direct. Recall the childhood game “red light, green light.” In the game, the game master barks out orders to the players. Green light, they can run. Red light, they must stop. The control is direct and in realtime, with the game master watching the players in person. In this environment, notions of authorization are obvious. The leader monitors and maintains complete control.\n\nThe more common and interesting problems arise when control of authorization is implicit. In most cases, permission is deduced from the circumstances based on signals that draw on shared understandings about the world. A Martian who landed on Earth for the first time would find the results deeply puzzling. Having never experienced human social interaction, it would miss the signals and see the human understandings as arbitrary. From our perspective, however, the signals are intuitive and usually seem obvious.\n\nImportantly, the text of criminal trespass statutes doesn’t provide these answers. Consider New York’s trespass law, § 140.05. The language is brief: “A person is guilty of trespass when he knowingly enters or re­mains unlawfully in or upon premises.” What does “unlawfully” mean? The statutory definition tries but fails to answer that question. “A person ‘enters or remains unlawfully’ in or upon premises,” the defini­tion says, “when he is not licensed or privileged to do so.” That’s no help. When are you “licensed” to enter? What gives you a “privilege”? The text doesn’t say.\n\nCriminal trespass law can retain this textual ambiguity because the real meaning of trespass law comes from trespass norms that are rela­tively clear in physical space. The written law calls on the norms, and the norms tell us, at an intuitive level, when entry to property is forbid­den and when it is permitted. Although identifying social norms is often difficult generally, the specific nature of trespass norms allows greater clarity. Trespass norms are relatively specific: They are about shared in­tuitions about what is a trespass, not what is appropriate or inappropriate behavior generally. And those norms provide relative clarity about what is a physical trespass.\n\nRelative clarity doesn’t mean absolute clarity, of course. Criminal tres­pass law is rarely litigated. Physical trespass tends to be a low-level of­fense, and it typically extends to those who unlawfully remain in place after being told by the homeowner to leave. As a practical matter, the crime may be used primarily as a way to arrest and remove someone who won’t leave where he is not wanted rather than as a tool for criminal pun­ishment on conviction. As a result, some ambiguities may exist but re­main latent in the statute.\n\nBut even if ambiguities remain, they are substantially narrowed by the three ways that trespass norms inform the meaning of criminal tres­pass laws. First, trespass norms provide a general set of rules that govern entrance based on the nature of the space. Second, they help resolve which means of access are permitted. And third, they explain the context in which the permitted means become authorized.\n\nB. The Nature of the Space\n\nThe first way that trespass norms guide notions of license and privi­lege is by providing informal rules based on the nature of each space. Different spaces trigger different obligations. Private homes trigger one set of rules. Commercial stores would trigger another. A public library might trigger a third. A public park a fourth. Life experience with com­mon social practices creates shared understandings about what kinds of entry are permitted for different kinds of spaces.\n\nStart with the home. The home triggers a robust set of assumptions about privacy and permission. A person’s home is his castle, the com­mon law tells us. And the principle of the common law remains deeply and widely held today. Everyone knows that you stay out of another’s home unless there is an express invitation. If you break those norms, trouble will follow. You can expect a frightened homeowner to call the police, if not to emerge with a twelve gauge pointed in your direction. And trespass case law reflects the strong default presumption of the home: The slightest overstep or intrusion into the home, or even just en­try based on false pretenses, has been held to be a trespass.\n\nBut what is true for the home is not true for other physical spaces. Contrast the home with a commercial store. Imagine it’s a weekday after­noon and you find a flower shop in a suburban strip mall. The norms governing access to the shop are very different from those governing ac­cess to a home. You can approach the store and peer through the win­dow. If you see no one inside, you can try to enter through the front door. If the door is unlocked, you can enter the store and walk around. The shared understanding is that shop owners are normally open to po­tential customers. An unlocked door during work hours ordinarily signals an invitation. That openness is not unlimited, of course. You can’t go into the back of the store, marked “Employees Only,” without an invitation. And if the store owner tells you to leave, you have to comply. But in con­trast to the closed default at a private home, the default at a commercial store is openness absent special circumstances indicating closure.\n\nEven open spaces can have trespass norms, and those norms can dif­fer from the norms governing entry into enclosed structures such as homes or stores. In a recent Fourth Amendment case, Florida v. Jardines, the Supreme Court considered the trespass norms that apply to a front porch. Officers suspected that Jardines might be growing marijuana in his home, so they walked a drug-sniffing dog up to his front porch and had him give the front door a good, hard sniff. The dog alerted to drugs, creating probable cause for a warrant and a search.\n\nThe Justices ruled that walking up to the front door with the dog was a trespass that violated the Fourth Amendment because it exceeded the implied social license governing approach to the home. According to Justice Scalia, some entry onto the front porch was permitted by social custom. Any visitor could “approach the home by the front path, knock promptly, wait briefly to be received, and then (absent invitation to linger longer) leave.” On the other hand, bringing a drug-sniffing dog to the front door violated that customary understanding:\n\nTo find a visitor knocking on the door is routine (even if some­times unwelcome); to spot that same visitor exploring the front path with a metal detector, or marching his bloodhound into the garden before saying hello and asking permission, would in­spire most of us to—well, call the police.\n\nThe lesson is that different spaces have different trespass norms. Some spaces are open, others are closed, and still others are open to some but closed to others. The text of trespass laws is often misleadingly simple—just the simple prohibition against unlicensed entry. Meanwhile, the real work of distinguishing culpable invasions from nonculpable explorations comes from space-specific norms.\n\nC. Means of Access\n\nThe second role of trespass norms is to identify means of permitted access. Permission to enter often is implicitly limited to specific methods of entrance. And we know which means of entry are permitted, and which are forbidden, by relying on widely understood social understandings.\n\nConsider entrance to a commercial store. The trespass norm govern­ing a commercial store might be that entrance is permitted when a ready means of access is available that can be read in context as an open invita­tion. That principle implies limits on which means of access are allowed. An open window isn’t an invitation to jump through the window and go inside. If there’s an open chimney or mail drop, that’s not an invitation to try to enter the store. Barring explicit permission from the store own­er, the only means of permitted access to a commercial store is the front door.\n\nThe source of these principles seems to be a socially shared under­standing of the intended function of walls, windows, chimneys, and doors. Windows are there to let in light, not people. Chimneys exist to let out smoke, not admit guests (Santa excepted). We know from life experience that these ways in are not authorized. In contrast, entry through the un­locked front door is authorized. The front door is intended for customer entrance and exit. That’s why it’s there.\n\nD. Context of Access\n\nTrespass norms play a third role by governing the context in which entrance can occur. Entry through the front door might be authorized, but the front door isn’t for everyone. Doors usually come with locks, and locks are designed to let some people in and keep other people out. Locks are an example of access control by which we recognize a means of access but limit it to specific people with specific rights. To complete the picture of how norms govern authorization to enter a home, we need to consider how those norms apply to locks and keys.\n\nThe starting point is simple enough. The property owner owns the door, lock, and keys, so the owner presumptively is in charge. If the lock breaks, the owner has to buy another one. The owner has the power to decide who gets a key and who is permitted to use it. As a result, authori­zation of entrance by key depends on whether that entrance was within the zone of authority delegated by the owner.\n\nImagine you are walking down the street and you see and pick up a lost house key. Possession of the key doesn’t entitle you to use the key and enter the house. You have the key, but you lack permission to use it. And you lack permission because there’s no chain of authorization coming from the owner. Picking a lock is unauthorized for the same reasons, at least unless you’re a locksmith who the owner hired to open the door after being locked out. If the owner grants you permission but later re­vokes it, your authorization expires with the revocation. If the home­owner gives someone else the key but places limits on access, those limits govern authorization.\n\nThe lesson of these examples is that authorization rests on trespass norms. In a world of indirect communication, familiarity with the social signals of what entry is permitted or forbidden makes the law clear enough that most people don’t fear arrest in their everyday activity. The nature of the space provides one set of messages, norms about the in­tended purpose of different means of access provide even more detailed guidance, and access controls within the zone of permission delegated by property owners provide an additional layer of rules.\n\nII. The Norms of Computer Trespass\n\nThe Internet has its own kind of trespass law that closely resembles its physical-world cousin. In cyberspace, the relevant law is found in com­puter misuse statutes such as the CFAA. The CFAA and its state equiva­lents ban unauthorized access to a computer. At a broad level, the pur­pose of those statutes is easy to describe: Unauthorized access statutes are computer trespass statutes. Applying the new statutes requires translat­ing concepts of trespass from physical space to the new environment of computers and networks. But as courts have found, understanding the concept of authorization to computers ends up being surprisingly hard. The courts are divided, with many courts struggling to apply this simple-seeming concept.\n\nThe norms-driven nature of physical trespass law explains why courts have struggled to interpret computer trespass laws. The trespass norms of physical space are relatively clear because they are based on shared expe­rience over time. The Internet and its technologies are new, however, and the trespass norms surrounding its usage are contested and uncertain. When faced with an authorization question under a computer trespass law, today’s judges bring to mind the Martian from outer space considering how tra­ditional trespass laws might govern trespass into a home. Without estab­lished norms to rely on, the application of a seemingly simple concept like “authorization” becomes surprisingly hard.\n\nThis section develops three lessons for interpreting authorization in computer trespass statutes that follow from the norms-based nature of trespass law. First, the meaning of authorization will inevitably rest on the identification of trespass norms, which will in turn rest on models and analogies. Second, Internet technology is sufficiently new, and the norms of computer trespass sufficiently unsettled, that judges applying com­puter trespass law must not just identify existing trespass norms, but must identify as a policy matter the optimal rules that should govern the Internet. And third, despite these challenges, trespass provides a sensible frame­work for regulating computer misuse and courts have the ability to iden­tify and apply the norms for computer trespass within the framework of existing laws.\n\nA. The Inevitability of Norms in Computer Trespass Law\n\nThe first lesson is that the meaning of authorization in computer trespass laws inevitably rests on the identification of proper trespass norms. Like their physical-world cousins, computer trespass laws feature unilluminating text. They prohibit unauthorized access to computers just like physical trespass laws prohibit unlicensed entry to physical spaces. In both contexts, the meaning of the law must draw from social understand­ings about access rights drawn from different signals within the relevant spaces. Courts must identify the rules of different spaces based on under­standings of the relevant trespass norms.\n\nIt’s no surprise that litigation over computer trespass laws often trig­gers a battle of physical-space analogies. The government, seeking a broad reading of the law, will push analogies to physical facts that trigger strict norms. The defense, seeking a narrow reading of the law, will push analo­gies to physical facts that implicate loose norms. The battle of analogies happens not because it is inevitable that we analogize cyberspace to phys­ical space, but rather because authorization inevitably rests on trespass norms. Litigants will use analogies from physical spaces with the trespass norms that best aid their side.\n\nConsider the recent litigation in United States v. Auernheimer. Auernheimer had been convicted of unauthorized access for using a software program that collected information from an AT&T website at hard-to-guess ad­dresses intended to be kept private. On appeal to the Third Circuit, the government’s brief analogized the website to a home where trespass norms are at their zenith. Use of the program was a computer trespass, the government argued, because a physical trespass occurs “when an un­authorized person enters someone else’s residence, even when the front door is left open or unlocked.” In contrast, the defense analogized the website to a public space where trespass norms are at their nadir. Use of the program was not a trespass, the defense argued, because putting in­formation on a website “ma[d]e the information available to everyone and thereby authorized the general public to view the information.” Each analogy aimed to import a set of physical-world norms.\n\nB. Because Computer Trespass Norms Are Unsettled, Courts Should Identify the Best Norms to Apply\n\nThe conflicting analogies found in computer trespass cases highlight the biggest difference between applying physical trespass and computer trespass laws: Computer trespass norms remain uncertain. Understand­ings of access rights surrounding the home are ancient, while under­standings of access rights in computer networks are not. The statutes came first, and the statutory prohibition on unauthorized access has re­mained fixed while computer network technology has advanced at aston­ishing speed. In this environment, courts cannot merely identify existing norms. Instead, they should make a normative policy decision about what understandings should govern the Internet. Judicial decisions will then shape future computer trespass norms, allowing appropriate norms to emerge with the help of the courts.\n\nTo appreciate the problem, consider the rapid evolution of Internet technologies. The Internet itself is less than fifty years old. The World Wide Web is only about twenty years old. The experience of using the Internet morphs quickly. Fifteen years ago, connecting to the Internet meant logging on from a desktop computer at work or perhaps using a dial-up connection from home. Today, connecting to the Internet is very different. Wireless connections have become the norm, allowing anyone to access the Internet from almost anywhere. And in just the last five years, the rise of the “smart phone” has brought the Internet to a light hand-held device that most adults leave on 24/7 and carry with them in their pockets and purses.\n\nThe programs we use to access the Internet also change rapidly. A ma­jority of Americans now have a Facebook account, and about seventy per­cent of account holders visit Facebook every day. But Facebook wasn’t even invented until 2004, and it already has become passé among teen­agers who have moved on to Instagram (launched in 2010 ) and Snapchat (launched in 2011 ). Or consider the popular Apple iPhone intro­duced in 2007. The iPhone popularized the phrase “there’s an app for that” for the new applications, or “apps,” that the phone can run. Apple’s iTunes App Store has more than 1.5 million apps available already, and about 1,000 new apps are submitted for approval every day. Even the specific programs we use change over time. Regular updates and im­provements are the norm, with new versions often adding features that can substantially change the user experience.\n\nThe problem is not just technological. The lawyers have stepped in, too. Companies often hire counsel to write detailed terms of use that purport to say when access is permitted. These written contractual limi­tations can be extremely restrictive, often creating a clash between what the technology allows a user to do and what the language of the terms says is allowed. In that case, what governs: the technology or the lan­guage? Amidst this rapid technological change, courts cannot merely invoke existing trespass norms to interpret authorization to access a com­puter. It’s not clear any widely shared norms exist yet.\n\nDeferring to jury verdicts is not workable, either. Trial courts have of­ten used jury instructions that either leave authorization undefined or else tell the jury, unhelpfully, that access is unauthorized when it is with­out permission. A study by Matthew Kugler suggests that this leads to verdicts far beyond whatever trespass norms may emerge. Kugler sur­veyed 593 adult Americans by asking them to review short descriptions of the facts of several CFAA cases. Respondents were asked to what extent the computer user had “authorization to use the computer” in the way he did, measured on a scale of one (not at all) to six (very much). The study then asked respondents to assign the proper punishment for the act, with respondents choosing among four options: no punishment at all; punishment akin to a parking ticket, punishment for a minor crime such as petty theft, and punishment for a major crime such as burglary.\n\nKugler’s survey suggests that lay opinion about when use is “author­ized” differs considerably from trespass norms. In most of the scenarios, respondents viewed the computer use as unauthorized. Mean values of authorization ranged from a low of 1.43 (for an employee who used his employer’s computer to sell employer trade secrets) to a high of 2.32 (for an employee who used his employer’s computer to check the weather report for personal reasons). But these evaluations had little connec­tion to the respondents’ evaluations of what should be criminal. For ex­ample, although checking the weather report from work was generally considered unauthorized, sixty percent thought it should not be punisha­ble at all and another thirty-two percent concluded that it should only be punished like a parking ticket. Where clear trespass norms exist, we would expect most to say that violating them should subject the tres­passer to at least some criminal punishment. Kugler’s results suggest that lay judgments of authorization probably do not accurately measure tres­pass norms, at least to the extent such norms now exist.\n\nCourts must instead decide between competing claims for what the trespass norms should be, imposing an answer as a matter of law now ra­ther than allowing them to develop organically. One plausible response from courts could be to refuse to go along. If the law rests on unknown norms, perhaps courts should strike down unauthorized access statutes as unconstitutionally void for vagueness—or at least construe them narrowly in light of the vagueness concerns they present. I have argued that posi­tion before, and it retains significant force. However, the alternative path is for courts to draw lines based on the normatively desirable rules and standards that should govern Internet use. In the interim period be­fore norms emerge, courts can identify the best rules to apply as a matter of policy. Judicial decisions in the near term can influence norms in the long term.\n\nC. Trespass Law Provides the Appropriate Framework to Resolve Computer Misuse, and Courts Can Meet the Challenge\n\nIt is worth asking whether trespass provides the right framework to apply and if judges are up to the task. I think the answer to both ques­tions is yes. Trespass provides an appropriate framework because it implies an essential balance. On one hand, protecting online privacy requires recognizing some boundary that individuals cannot cross. On the other hand, preserving the public value of the Internet requires identifying uses that individuals can enjoy without fear of criminal prosecution. Some cases are easy. Everyone agrees that guessing another person’s pass­word to access his private email without his permission should be consid­ered a criminal invasion of privacy. Similarly, everyone agrees that visiting a public website with no access controls or written restrictions should be legal. The trespass structure is sensible. The real challenge is applying it.\n\nI am optimistic that courts can identify and apply computer trespass norms using existing statutes. The very first federal appellate case on the meaning of authorization in the CFAA, United States v. Morris, shows why. Morris offers an early example of how courts can identify norms of computer trespass using the same three inquiries that govern trespass in the physical world: the nature of the space, the means of entry, and the context of entry.\n\nIn the fall of 1988, Robert Tappan Morris, a computer science gradu­ate student, crafted and released a program often called “the Internet worm.” Morris designed the worm to reveal the weak computer security in place on the Internet. First, the program exploited what the court called a “hole or bug (an error)” in three different software programs. And second, the program guessed passwords, “whereby various combina­tions of letters are tried out in rapid sequence in the hope that one will be an authorized user’s password.” Morris sent the worm from a com­puter at MIT, and it quickly spread around the world. Morris was then charged with and convicted of “intentionally access[ing] a Federal inter­est computer without authorization.”\n\nOn appeal, the Second Circuit affirmed the conviction. Writing for the court, Judge Jon Newman found three reasons why the access was without authorization. First, the evidence at trial demonstrated “that the worm was designed to spread to other computers at which he had no ac­count and no authority, express or implied, to unleash the worm pro­gram.” Second, the worm exploited security flaws in software com­mands. “Morris did not use either of those features in any way related to their intended function.” Instead, Morris “found holes in both pro­grams that permitted him a special and unauthorized access route into other computers.” Finally, the worm also guessed passwords, rendering access to those accounts unauthorized.\n\nJudge Newman’s brief explanation of why the Internet worm had ac­cessed computers without authorization contains all of the ingredients for the proper way to think about computer trespass. First, Morris ad­dressed the nature of the virtual space. Although the computers were connected to each other, access was limited to (and based on) private accounts. A user needed an officially sanctioned account to access that particular machine. Much like houses on a row in a suburban street, the computers were linked to each other but required a key or special per­mission to jump from the inside of one to the inside of another.\n\nSecond, Morris focused on the means of entry. None of the pro­grams, used as intended, were ways of gaining access to a private account. But the Internet worm exploited security flaws by using “holes” and “bugs” in the programs that permitted “special access” in a way that was contrary to the “intended function” of the commands. Instead of gain­ing access through the virtual front door, the worm gained access by ex­ploiting security flaws: It broke in through an open window instead. It gained entrance through a bug, not a feature.\n\nThird, the Morris opinion focused on the context of entry. When the Internet worm accessed a private account with a password, it did so only by guessing that password. Here the analogy to physical entry seems intuitive. Guessing a password is like picking a physical lock. A successful guess provides access, just like a successful lock pick does. But the access is not authorized because it does not come directly or indirectly from the property owner. The trespass norm governing locks is that access is per­mitted only to those who have been granted the key in a delegation of permission beginning with the owner. Password guessing is outside the norm and therefore unauthorized.\n\nMorris provides a helpful model for how courts can adopt sensible and clear computer trespass norms even when faced with new facts. A quarter century later, courts can follow the Morris example. The remain­ing Parts offer more specific guidance on how courts can do that for im­portant cases that arise in the context of the Web, as well as blocked, can­celed, and shared accounts.\n\nIII. Norms of the World Wide Web\n\nMany tricky questions interpreting computer trespass statutes involve use of the World Wide Web. The Web did not exist when Congress en­acted the CFAA. But it has quickly become an important—if not the most important—way people use the Internet. Identifying the trespass norms of the Web is difficult because there are two competing narratives in play. On one hand, the World Wide Web is open: By default, anyone can go to any website. On the other hand, website owners frequently put up speed bumps, barriers, and caveats to access that range from hidden website addresses and terms of use to limiting cookies and banning IP addresses. The hard question is this: When should use of the Web in the face of such efforts render the use unauthorized?\n\nThis Part argues that courts should adopt presumptively open norms for the Web. The nature of the space is inherently open. Courts should match the open technology of the Web by applying an open trespass norm. Limited efforts to regulate access such as terms of use, hidden ad­dresses, cookies, and IP blocks should be construed as merely speed bumps rather than virtual barriers. None of these methods should over­come the basic open nature of the Web. Access that bypasses these regu­lations should still be authorized.\n\nThe authorization line should be deemed crossed only when access is gained by bypassing an authentication requirement. An authentication requirement, such as a password gate, is needed to create the necessary barrier that divides open spaces from closed spaces on the Web. This line achieves an appropriate balance for computer trespass law. It protects privacy when meaningful steps are taken to seal off access from the pub­lic while also creating public rights to use the Internet free from fear of prosecution.\n\nA. The Inherent Openness of the Web\n\nThe first step in applying computer trespass law to the Web is to identify the nature of the space that the Web creates. The Web is a pub­lishing protocol for the Internet. It allows anyone in the world to publish information that can be accessed by anyone else without requiring au­thentication. When a computer owner decides to host a web server, mak­ing files available over the Web, the default is to enable the general pub­lic to access those files. A user who surfs the Web enters an address into the prompt at the top of the browser, directing the browser to send a re­quest for data. If the address entered is correct, the web server will re­spond with data that the user’s browser then reassembles into a webpage.\n\nThis process is open to all. The computer doesn’t care who drops by. By default, all visitors get service. In the language of the computer sci­ence literature, there is no authentication requirement. A visitor might be any one of the billion or so Internet users around the world. For that matter, the visitor doesn’t need to be a person. It could be a “bot,” a com­puter program running automatically. It could even be a dog, as the fa­mous New Yorker cartoon reminds us. Because there is no authentication requirement, the web server welcomes all, and the norm is openness to the world. Access is inherently authorized.\n\nThe open nature of the Web is no accident; it is a fundamental part of the Web’s technological design. From its inception in 1969, the crea­tors of the Internet used “Requests for Comments” (RFCs) to describe the basic workings of different Internet protocols. The Internet Engineering Task Force later took over the task of crafting RFCs, and they stand as the definitive technical discussion of the intended function of different Internet applications. Think of them as computer-geek manuals for how the Internet works. The RFCs for the Web are RFC1945 and RFC2616. They teach how the Web works, or more specifically, they teach how “Hypertext Transfer Protocol” (HTTP) works; HTTP is one of the foundational protocols controlling data transfer between web servers and clients. And a quick re­view of the RFCs for the Web shows its inherently open nature.\n\nRFC1945 and RFC2616 describe the protocol used for the Web as “a generic, stateless, object-oriented protocol” for “distributed, collabora­tive, hypermedia information systems.” The means of operation are general and open. The Web works by allowing anyone to make a request for a webpage. As summarized in the RFCs, “[a] client establishes a con­nection with a server and sends a request to the server in the form of a request method, URI, and protocol version, followed by a MIME-like message containing request modifiers.” In English: Anyone can send a request without any authentication. And then, “the server responds with a status line, including the message’s protocol version and a success or error code, followed by a MIME-like message containing server infor­mation, entity metainformation, and possible body content.” Again, in English, the server responds to anyone who has made the request.\n\nThe protocols of the Web make websites akin to a public forum. To draw an analogy, websites are the cyber-equivalent of an open public square in the physical world. A person who connects a web server to the Internet agrees to let everyone access the computer much like one who sells his wares at a public fair agrees to let everyone see what is for sale. Sellers who want to keep people out, backed by the authority of criminal trespass law, shouldn’t set up shop at a public fair. Similarly, companies that want to keep people from visiting their websites shouldn’t connect a web server to the Internet and configure it so that it responds to every request. By choosing to participate in the open Web, the website owner must accept the open trespass norms of the Web.\n\nB. Authorized Access on the Web\n\nAlthough the Web is open by default, website operators often place limits and restrictions on access to information. The challenge for courts is to distinguish provider-imposed restrictions and limits that are at most speed bumps (that cannot trigger trespass liability) from the real barriers to access (that can). In my view, an authentication requirement draws the proper line. When a limit or restriction does not require authentication, access is still open to all. The limit should be construed as insufficient to overcome the open nature of the Web. On the other hand, access that bypasses an authentication gate should, under proper circumstances, be deemed an unauthorized trespass. An authentication requirement pro­vides a clear and easy-to-apply standard that both protects privacy and carves out public-access rights online.\n\nA decade ago, I argued that unauthorized access should be limited to access that circumvents “code-based restrictions,” which I defined as ways of tricking the computer into “giving the user greater privileges” when “computer code” has been used “to create a barrier designed to block the user from exceeding his privileges on the network.” With the benefit of hindsight, that formulation was vague. Trying to figure out when access circumvented a code-based restriction proved harder than I predicted. I now see that the more precise way to formulate the standard is that unauthorized access requires bypassing authentication. The key point is not that some code was circumvented but rather that the com­puter owner conditioned access on authentication of the user and the access was outside the authentication. This section covers examples of limits and restrictions on access that do not require authentication and should not trigger trespass liability.\n\nBegin with a relatively simple case. Access to a website should be au­thorized even if the webpage address is not published or is not intended to be widely known. This issue arose in United States v. Auernheimer, in which the federal government charged the defendant with violating the CFAA by using a webscraper that queried website addresses that the com­puter owner, AT&T, had not expected people to find. The website ad­dresses queried were very difficult to guess because they ended in a long serial number. The defendant helped design a program to guess the num­bers and collected information from over 100,000 website addresses.\n\nHad the Third Circuit reached the question, it should have held that these website visits were authorized because the website had imposed no authentication requirement. The open norm of the Web still gov­erned. Content published on the Web is open to all. Because the Web allows anyone to visit, a website owner necessarily assumes the risk that information published on the Web will be found. A hard-to-guess URL is still a URL, and the information posted at that address is still posted and accessible to the world. Accessing the URL does not violate a trespass norm because all users are implicitly invited to access a publicly accessi­ble address.\n\nThis conclusion is bolstered by the social value and ubiquitous nature of websurfing together with the severity and chilling effect of criminal punishment. We think, and therefore we Google. Courts should not lightly conclude that visiting an unwelcome URL should subject a person to ar­rest by federal agents and the potential for jail time. That is a particularly sensible approach because what looks like a hard-to-guess URL to a per­son may not seem hard to guess for a computer. To a computer, an ad­dress is an address. Even complicated addresses are easy for computers to find. Consequently, there is no workable line between an “easy” URL that can be accessed and one so hard to guess that access is implicitly forbidden.\n\nThe open understanding of the Web should also control access that violates terms of use. Many websites come with terms of use that may on their face say when users are permitted to access the website. The conditions can be arbitrary. One site might say that users must be eight­een years old to visit; another might say that users must agree to be polite. Such terms should not be understood as controlling authorization. Ac­cess regulated only by written terms is not authenticated access. Everyone is let in, just subject to contractual restrictions. Such written terms should be understood as contractual waivers of liability rather than barriers to access.\n\nThis understanding is backed by the understandings of most website owners and users. Lawyers draft terms of use to minimize liability. Broad terms allow computer owners to take action against abusive users and show good faith efforts to stop harmful practices occurring on the site. True, terms of use may be drafted by lawyers to read like limita­tions on access. But companies do not actually expect the many visitors to otherwise-public websites to comply with the terms by keeping themselves out. And because terms can be arbitrary, violating them implies no cul­pable conduct. If a public website has terms prohibiting access by peo­ple who are left-handed and enjoy opera, a left-handed opera lover who visits the site anyway does not deserve arrest and jail time.\n\nThis understanding is also backed by the experience of most com­puter users. Studies suggest that very few Internet users read terms of use. (For the record, I don’t.) Few users could understand them if they tried. Terms of use are often lengthy and filled with legalese. The terms can be hard to find and difficult to interpret. Such terms don’t re­strict access to a computer any more than a standard waiver of rights on the back of a baseball game ticket could control rights to enter the ball­park. Violating the terms on the ticket might change your legal rights to sue the ballpark if something goes wrong, but it doesn’t make your entry to the ballpark a trespass. Similarly, violating terms of use while accessing a website should not render the access a computer trespass.\n\nThe same rule should apply to the use of cookies to record prior vis­its and prompt paywalls. Cookies are pieces of code that websites can place on a browser to customize the user’s experience. Websites can use cookies to prompt repeat visitors to subscribe rather than visit for free. Consider the popular New York Times website, nytimes.com. When you visit the Times website, it places a cookie on your browser that records the visit. The cookie allows the Times to meter access: If a browser is used to visit more than ten stories on the site in a month, the website brings up a screen blocking the reading of additional articles. The point of the block is to pressure frequent readers to buy a subscription. But what if a reader regularly clears out his browser, which erases the cookie and enables unlimited access? Is accessing the site after clearing out the browser unauthorized?\n\nThe answer should be that access enabled by erasing cookies is still authorized. Browsers are designed to give users control over what cookies are stored on their browsers. Such cookies do not authenticate users: They merely allow users to customize their browsing experience. Users can accept cookies, reject cookies, or clear out the cookies kept in their browsers as often as they like. They can use different browsers or differ­ent computers. As a result, user control of cookies is an expected and common way to use the Internet. They do not really limit access to com­puters; they only complicate access to the text of particular stories. Access limitations based on cookies are at most speed bumps rather than barri­ers. Instead of keeping people out, cookies-based barriers only impose enough of a hassle to encourage some users to buy a subscription. Only the most unsophisticated users will see cookies as a barrier, and it will only be because they don’t yet understand how cookies work.\n\nA more difficult case is raised by IP address blocking, which was the issue in Craigslist v. 3Taps. Every device connected to the Internet has an IP address, which is a number that represents the Internet address of that device. Web servers communicate with users on the Internet by receiving requests and sending data to them at their IP addresses. In 3Taps, the defendant business scraped ads from Craigslist and repub­lished them on its own website. Craigslist responded by sending 3Taps a cease-and-desist letter and by blocking the IP addresses associated with 3Taps’s computers. 3Taps changed its IP addresses to circumvent the IP block. Judge Charles Breyer ruled that 3Taps’s access was an unauthor­ized access under the CFAA because “[a] person of ordinary intelligence would understand Craigslist’s actions to be a revocation of authorization to access the website.” Judge Breyer explained:\n\nIP blocking may be an imperfect barrier to screening out a human being who can change his IP address, but it is a real bar­rier, and a clear signal from the computer owner to the person using the IP address that he is no longer authorized to access the website.\n\nJudge Breyer is wrong. Understood in the context of the open Web, an IP block is not a real barrier. A user’s IP address is not fixed. For many users, the IP addresses of their devices will change periodically during normal use. Using multiple computers often means using multiple IP addresses. A person might surf the Web from his phone (using his cell phone’s IP address), from his laptop at home (using his home connec­tion’s IP address), and from work (using the company’s IP address). Us­ers also can easily change their IP addresses if they wish. For some users, turning on and off their modems at home will lead their IP addresses to change. For more sophisticated users, accessing the Web using Tor or a virtual private network allows them to change their IP addresses with the click of a button. There is nothing untoward or blameworthy about using different IP addresses. It is a routine part of using the Internet.\n\nBecause of these technical realities, bypassing an IP block is no more culpable than bending your neck to see around someone who has tempo­rarily blocked your view. To be sure, an IP block indicates that the com­puter owner does not want at least someone at that IP address to visit the website. But that subjective desire is not enough to establish a criminal trespass in light of the open nature of the Web. A computer owner can­not both publish data to the world and yet keep specific users out just by expressing that intent. It is something like publishing a newspaper but then forbidding someone to read it. Publishing on the Web means pub­lishing to all, and IP blocking cannot keep anyone out. Merely circum­venting an IP block does not violate trespass norms.\n\nA particularly tricky case is access that circumvents a CAPTCHA, an issue that arose in United States v. Lowson. CAPTCHA is an acronym for “Completely Automated Public Turing test to tell Computers and Humans Apart.” You have probably seen CAPTCHAs when buying tick­ets online or posting online comments. The website presents you with an image like this requiring you to type in the words before you can proceed:\n\nFigure 1: CAPTCHA Example\n\nThe purpose of the CAPTCHA, as the full name suggests, is to allow humans in but to block computer “bots” that can make thousands of au­tomated requests at once.\n\nThe interesting question is whether use of an automated program to bypass the CAPTCHA by guessing or reading the words is an unauthor­ized access. The question is difficult because the technology shares some characteristics of a traditional authentication gate but not others. Like a password gate, it requires a code to be entered; but unlike a password gate, it presents the code to the user. Although it’s a close case, I think the better answer is that automated bypassing of a CAPTCHA is not itself an unauthorized access. Although the CAPTCHA looks like a password gate, it does not operate like one. The site tells everyone the password. It invites all to enter.\n\nIt is tempting to think that a CAPTCHA authenticates users as peo­ple instead of bots. But a “bot” request is still ultimately a request from a person. It is merely an automated request, with the person who used the software still responsible. That person could gain access and bypass the CAPTCHA manually by visiting the page and typing in the string of num­bers that appear. As a result, a CAPTCHA is best understood as a way to slows a user’s access rather than as a way to deny authorization to access. The CAPTCHA is a speed bump instead of a real barrier to access. Courts should hold that automated access is not a trespass merely because it bypasses a CAPTCHA.\n\nFinally, it is worth considering the business implications of my pro­posed trespass rules. The examples in this section mostly involve busi­nesses that might try to control customer use of their computers for busi­ness reasons. A ticket seller might use a CAPTCHA to limit scalpers, for example, just like the New York Times might use cookies to encourage readers to purchase subscriptions. That raises a fair question: If courts hold that these methods do not constitute a trespass, would that prevent businesses from using these methods—and if so, is that a policy reason to adopt different trespass norms?\n\nThe answer is that criminal trespass liability is unlikely to impact business strategies. Companies can already use civil contract law, based on terms of use, to set legal limits on how visitors use their websites. Companies may not want to enforce those limits for a range of reasons. But at least as a matter of law, often they can. The scope of computer trespass laws implicates a different question: not just what user conduct is legal but what user acts are criminal. As a practical matter, it’s hard to imagine a company using a business model that depends substantially on the prospect of the police arresting and prosecuting customers who cir­cumvent speed bumps designed to regulate website use. Jailing customers for using a website isn’t likely to be a good business strategy. It is telling that when the government has pursued aggressive criminal charges un­der the CFAA for use of websites, it has often been without the support of the companies claimed as victims.\n\nC. Unauthorized Access on the Web and the Authentication Requirement\n\nIn contrast to the examples above, bypassing an authentication re­quirement should trigger liability for computer trespass. Even open spaces often have closed subspaces. Like a store open to the public in the front but for employees only in the back, the Web can have real barriers through which access violates trespass norms and is unauthorized. This moves the norms question from the first inquiry of the nature of the space to the second inquiry of the types of permitted entry. What counts as a real barrier on the Web, and what ways of overcoming those barriers are authorized? When a user bypasses an authentication requirement, either by using stolen credentials or bypassing security flaws to circumvent authen­tication, access should be considered an unauthorized trespass. This stand­ard harnesses criminal law to protect privacy when network owners use technical means to enable access only to specific authenticated users.\n\nThe basic principle of authentication is probably intuitive to most Internet users. Every Internet user is familiar with the notion of an ac­count that limits access. The requirement of credentials to identify the user is an authentication requirement. When access to a computer re­quires an account, the user must register and obtain login credentials such as a username and password. Before allowing the user to access spe­cific information, the user must establish that he is someone with special rights to access the account. A user who cannot satisfy the authentication requirement is blocked from access. The account structure imposes an access control that separates the insiders with accounts from outsiders without them. Because only the account holder should be able to satisfy the authentication requirement, the world—minus one user—is blocked. An authentication requirement creates a technical barrier to access by others. It carves out a virtual private space within the website or service that requires proper authentication to gain access.\n\nAuthentication requirements should be understood as the basic re­quirement of a trespass-triggering barrier on the Web. By limiting access to a specific person or group, the authentication requirement imposes a barrier that overrides the Web default of open access. The norm shifts from open to closed. At that stage, the emphasis shifts to means of access. Much like with a physical key to a door, access is authorized to the person who was given the password. On the other hand, as the Morris court noted, gaining access by guessing a password is just like picking a lock; both lack authorization.\n\nExploits that circumvent authentication mechanisms or otherwise “break in” to systems are similarly unauthorized. Morris is again instruc­tive. Access enabled by an exploit that uses a command in a way contrary to its intended function is unauthorized, much like entering through a window or a chimney in the physical world. For example, hacking tech­niques such as SQL injection attacks are unauthorized and illegal. A Structural Query Language (SQL) injection attack is executed by attach­ing special extra language to the end of a web request. Some web serv­ers are misconfigured so that this extra language will execute a command on the web server rather than return a webpage. The special command can provide access to the private database on the web server rather than just the pages to be published, providing the attacker with means to re­trieve, alter, or delete the data. Although a hacker using an SQL injec­tion attack executes the injection by entering a command into a web browser—just like one would enter a username or password—the act exploits a security bug or hole just like the SENDMAIL flaw used in Morris. Access using an SQL injection is unauthorized for the same rea­son. An SQL injection attack is contrary to the intended function of the web browser: It violates the trespass norms surrounding the proper means of access to information on the server.\n\nImportantly, the application of trespass norms can be technologi­cally arbitrary even if they are socially meaningful. Consider the role of session cookies and persistent login cookies, which are browser cookies gen­erated on a user’s web browser during a typical login process to a web­site. The website generates a long number associated with that login and passes the information back to the user’s browser, with instructions for the browser to store it as a cookie. When the user subsequently visits the website, the browser passes along the unique session-cookie val­ue back to the website. Websites then use this information to automati­cally log in the user. You have likely benefited from these cookies when using web-based email, Amazon, or Facebook. After not visiting the page for a few minutes or even a few days, you can go back to the website and it will automatically log you in. The website does this by reading your stored login or session cookie and matching it to an ongoing known log­in session.\n\nNow consider how computer trespass principles might apply to ac­cess made by hijacking such information. Imagine a third party inter­cepts a login cookie sent over the Web, loads it into his own browser, and visits the website. Use of the cookie will automatically log the third party into the user’s email or Facebook account without the user’s permission or knowledge. Is the third-party access authorized because it was ob­tained merely by sending on a specific cookie value as part of the brow-ser’s web request? Or is it unauthorized because it does so in a way that bypasses an authentication gate?\n\nUnauthorized use of a persistent login cookie should be considered a violation of trespass norms. The cookie acts as a temporary password, tied to the user’s permanent password, that identifies the account and pro­vides access to it. It circumvents the password gate in exactly the same way that entering the permanent username and password would. The fact that the cookie is sent by the browser, which is normally an environment con­trolled by the user for the user’s benefit, should not lead to a differ­ent re­sult. This kind of cookie is an exception to the usual rule because it is a password; the embedding of the password in the browser does not change its function as a password.\n\nThe lines here are subtle, to be clear. Recall the Auernheimer case, where the information posted on a website was available only at a hard-to-guess website address. The difference between a hard-to-guess website address, which should not act as an authentication gate, and a hard-to-guess session cookie, which should, is a matter of social understanding rather than technology. We can draw plausible lines about what acts as a password, but at some level the differences will boil down to shared un­derstandings that some information is part of a public address while other information is a unique identifier. In close cases the technological arbitrariness is inevitable, as trespass norms are ultimately shared views about what invades another’s private space and what doesn’t. Technology alone cannot provide the answer.\n\nIV. Canceled, Blocked, and Shared Accounts\n\nThe next set of questions asks how computer trespass statutes should apply to canceled, blocked, and shared accounts. These questions impli­cate the third way that norms control trespass, the identification of norms governing the context of permitted access. At this stage, authenti­cation clearly implicates trespass liability. If a stranger guesses a victim’s username and password and enters those credentials to access her ac­count without permission, that access is plainly unauthorized. On the other hand, if the user enters her own credentials to access her own pri­vate account, that access is authorized. The hard cases lie between these two poles.\n\nThe gray area involves three basic problems. First, a computer owner might revoke the user’s right to access an account but not close the ac­count. If the credentials still work, and the user continues to access the account using them, is that access authorized or unauthorized? Second, a computer owner might cancel access to a user’s account, and the user might then respond by creating a new account on the same system unbe­knownst to the owner. Is use of the new account authorized or unauthor­ized? Third, an account holder might share her username and password with a third party who accesses the account. Is the third-party access au­thorized because it was by permission of the account holder, or is it unau­thorized because it was not actually accessed by the account holder? In these cases, the law must grapple with how authorization norms apply when account rights are terminated, modified, or shared with others.\n\nThis Part attempts to answer all three questions using the principle of authentication. As explained in Part III, authentication of a user au­thorizes the user to access the account but makes access by others unau­thorized. The trespass norm should aim to preserve that delegation of authority. Again, the goal is to achieve an optimal balance. Overly restrict­ing delegations would prevent beneficial uses of networks by authenti­cated users. On the other hand, permitting authenticated users to fur­ther delegate authority, or to ignore withdrawals of delegation, would nullify the owner’s power to designate who can access the network. Ap­plying this approach suggests three rules. First, suspending an account withdraws authorization to access the account. Second, a suspension may or may not signal that access to additional accounts is prohibited. Finally, use of shared passwords should be permitted only when the third party access is within the scope of agency of the authenticated user.\n\nThis Part concludes by discussing the role of mental states, or mens rea, on computer trespass liability. When authorization hinges on the context of access, the user often will not know the facts that determine whether access was authorized. In that context, the statutory requirement that unauthorized access must be intentional or knowing plays an im­portant role in narrowing criminal liability.\n\nA. Canceled Accounts\n\nThe first issue is how trespass laws should apply when the authority to use an account has been revoked but the user accesses the account anyway. The answer should come from an understanding of what authen­tication means. By permitting an account that requires authentication, the computer owner should be understood to have delegated access rights to the authenticated user. The authenticated user has permission to access the account so long as the computer owner grants the account. The trespass norm should be to preserve that delegation. Preserving the delegation achieves the same dual goals as the authentication require­ment provided in Part III. It enables use of computers (here, accounts held by authorized users) while affording them appropriate space to use their delegated accounts without fear of criminal prosecution for trespass.\n\nUnder this standard, the owner’s revocation of the right to use an authenticated account revokes authorization. When the computer owner communicates the revocation to the user, the delegated authority ends. Subsequent account access violates trespass norms; it should be under­stood as entering a space where the user is no longer welcome. Because authority to use an authenticated account should exist only inside the zone of delegated power, ending the right to access the account should end the delegated right and end the authorization.\n\nCourts have so far adopted this approach, as the Fourth Circuit’s de­cision in United States v. Steele demonstrates. Robert Steele worked as a backup system administrator at a business named SRA, and for work pur­poses he created a backdoor account that gave him access to SRA’s net­work files. After he resigned, Steele continued to use the account to access SRA’s network. The Fourth Circuit ruled that “the fact that Steele no longer worked for SRA when he accessed its server logically suggests that the authorization he enjoyed during his employment no longer ex­isted.” Having left the company, Steele’s rights to access the account were revoked: “Just because SRA neglected to change a password on Steele’s backdoor account does not mean SRA intended for Steele to have continued access to its information.”\n\nThis approach implies a distinction between the rules that should apply to a user who violates terms of use and a user whose account is sus­pended for violating terms of use. Recall that a user who violates terms of use is not committing an unauthorized access. On the other hand, I argue here that a user whose account is revoked for violating terms of use but uses the banned account anyway is guilty of trespass. The distinction is justified because violating terms of use merely provides legal justifica­tion for revocation if the website owner chooses to do so. When a website owner authorizes an account for a user, the user has access rights unless the account is actually revoked. The authority is delegated by the issuing of the account and withdrawn by its revocation, so the act of revocation is needed to undo the act of granting the account.\n\nB. New Accounts Following the Banning of an Old Account\n\nNext imagine that the computer owner cancels or blocks the ac­count but the user can readily sign up for a new one. Imagine Gmail sus­pended your email account for violating Gmail’s terms of use and you want to open another Gmail account the next day or the next year. Does the company’s blocking the first account deny authorization to set up a second account? Or is the user free to start again after having been blocked once—or twice, or three times, or even hundreds of times?\n\nThis problem arose in the controversial case of United States v. Swartz. The Internet activist Aaron Swartz created a guest account on MIT’s network and used it to download a massive number of academic articles to his laptop. Network administrators canceled the guest ac­count in response; Swartz created a new guest account. When system administrators blocked access through the new guest account, Swartz then figured out a way to circumvent guest-account registration: He found a closet in the basement of one of MIT’s buildings that stored the server, entered it, and hard-wired his computer to the network. He then assigned himself two new IP addresses from which he could con­tinue his access. The question was, did having been blocked with an account once mean that subsequent efforts to obtain access were unau­thorized?\n\nAs before, the legal line should track the delegation of authority im­plied by authentication. The application of that principle is trickier, how­ever, because the revocation of delegated authority is less obvious. When anyone can open an account, there is an implicit delegation to anyone who registers for a new account. In some contexts, a single act of block­ing does not imply a total and permanent revocation. In other contexts, it does. For example, a user who has an account suspended for miscon­duct may be perfectly welcome to start again with a new account on the understanding that no further misconduct continues. On the other hand, users who are repeatedly banned eventually must get the message that they are not welcome.\n\nThe key question should be the objective signal sent by the banning or suspension, which will in some contexts allow the user to create a new account but in other contexts won’t. When the ban would be reasonably interpreted as “don’t do that,” creating a new account and using it properly is authorized. When the ban would be reasonably interpreted as “go away and never come back,” creating another account is unauthor­ized. In the Swartz case, for example, access would have been unauthor­ized by the time Swartz entered the closet to circumvent IP registration. Having had his accounts blocked multiple times by MIT’s system adminis­trators for violating the rules on MIT’s network, Swartz had received clear signals that he was no longer welcome to create another account to con­tinue the same conduct.\n\nThis approach once again ends up drawing a subtle distinction. Re­call my earlier conclusion that an IP block is insufficient to trigger tres­pass liability. Circumventing an IP address ban is permitted and author­ized. At the same time, I am arguing here that if the computer owner requires an account to access a computer and then bans the account, circumventing that ban might not be authorized if the context can be interpreted as a complete ban. Is there really a difference? I think there is. Everyone can visit a public website, while not everyone can have the privilege of an account. By creating the access control of an account re­gime, the computer owner takes control of who can access it by making individualized decisions about specific accounts. A suspended account is not just a speed bump. It’s a block to using that account and a potential signal about opening another one. The rules governing the two cases should be different.\n\nC. Password Sharing\n\nThe last and most difficult issue is identifying trespass norms that should govern shared passwords. Consider the facts of United States v. Rich. A financial-services company, LendingTree, sold valuable access to financial information on its website to customers who paid a fee and received a username and password to access the site. The defendant, Brian Rich, made a side deal with an employee at one of LendingTree’s customers; he agreed to pay the employee to get the company username and password. Rich then used the credentials to access the LendingTree website without paying LendingTree. The question is: Does using a shared password constitute an unauthorized access in violation of trespass norms?\n\nThe starting point should again be that the computer owner’s grant­ing of an authenticated account delegated access rights to the account holder. The account holder is authorized but others are not. To preserve this principle, the trespass norm should be that access by the account holder or his agent is authorized while other access to the account is not. When the account holder gives login credentials to a third party, access by the third party is authorized only when the third party acts as the agent of the account holder.\n\nThis approach mirrors the analogous rule in the physical world. When access is limited by a physical lock and key, whether entry is a phys­ical trespass law depends on whether it falls within the zone of permis­sion granted by the owner. For example, in Douglas v. Humble Oil & Refining Co., a business owner gave an employee the key to his home so the employee could feed his pets when he was away. The employee later used the key to enter the home for a different reason. According to the court, this entry for reasons outside the scope of permission was a trespass.\n\nThis approach allows computer account holders to share usernames and passwords with an agent. If the agent accesses the account on the account holder’s behalf, the agent is acting in the place of the account holder and is authorized. The agent then has the same authorization rights as the account holder. For example, I recently set up a Gmail ac­count for my students to email class assignments. I gave my assistant the account password and asked her go into the email inbox and collect them for me. When she did so, she was acting as my agent. Legally speak­ing, she was me. She was fully authorized to access the account in her capacity as my agent. Her conduct was authorized and legal, much like employee access to an employer’s account for work purposes.\n\nOn the other hand, a third party who uses a password in pursuit of her own ends stands in the same place as a third party who has guessed or stolen the password. Consider the facts of Rich. When Rich accessed the LendingTree website using a password, he was not acting as an agent of a legitimate customer. Rich paid for access to the password, but he did not pay LendingTree. Instead, he paid an employee of a legitimate cus­tomer. Rich accessed the account to help himself get richer, not to help the employee. From the perspective of LendingTree, Rich’s access was no different from access using a guessed or stolen password. Rich was not a legitimate customer or an agent of a legitimate customer. Whether he obtained the password by stealing it from the employee or by paying for it makes no difference to LendingTree. For that reason, Rich’s access was unauthorized.\n\nTwo wrinkles need to be ironed out. First, what is the impact of terms of use to the delegated authority of the computer owner? Recall my use of a Gmail account for class. What if Gmail’s Terms of Use forbid password sharing and my secretary’s access violates those Terms? In my view, terms of use barring shared access should be irrelevant for the same reason they are irrelevant to access more generally. As explained earlier, terms of use create rights for the computer owner rather than the ac­count holder. When terms are violated, the computer owner can sus­pend or restrict the account. But violating the terms does not render ac­cess an unauthorized trespass either in the context of public access web­sites or of specific accounts. By granting a user an account, the computer owner necessarily grants the user authorization to access the account for any reason.\n\nSecond, note that my treatment of the delegation from the com­puter owner to an account holder is different from my treatment of the delegation from the account holder to a third party. When authorized by the computer owner, the account holder has full access rights. When au­thorized by the account holder, on the other hand, the third party has narrower rights only to act as the account holder’s agent. This distinction is justified by the underlying role of an authentication requirement. Set­ting up the authentication gate and granting a user account confers rights on the account holder and her agents. An account holder should have only a narrower power to confer access rights because otherwise that delegation would interfere with the original authentication. If com­puter owner A can confer access rights to account holder B, an unlimited power of B to confer access rights to C, D, and E would nullify A’s judg­ment to confer access rights to only account holder B. The rule should be that third-party access outside the agency relationship is unauthorized access.\n\nD. The Critical Role of Mens Rea\n\nThe problem of canceled, blocked, and shared accounts is not com­plete without understanding the associated mental state, or mens rea, that accompanies computer trespass statutes. The problem here is with the fact-sensitive context of permitted entry. The facts relevant to authori­zation may not be known to the user. In this context, the mental state of authorization plays a critical role. Computer trespass statutes generally require that the user commit an intentional or knowing unauthorized access. The government’s burden to prove that an unauthorized access was intentional or knowing plays a crucial role in establishing a limit on liability when authorization is lacking due to the context of entry.\n\nCourts have not explored the role of mental state in establishing lia­bility for computer trespass, so it is important to understand what a men­tal state or knowledge or intent might mean in this context. Consider the broadest section of the CFAA, which prohibits “intentionally access[ing] a computer without authorization” or intentionally “exceeding author­ized access.” The intent requirement plainly applies to the element that authorization is lacking. But does the requirement of intent with respect to lack of authorization require intent as to the legal conclusion that access is unauthorized, or does it merely mean intent as to the facts that make access legally unauthorized?\n\nCourts have not addressed the question, and it is surprisingly com­plex. The usual rule, however, is that a knowledge or intent require­ment for a criminal element requires knowledge or intent about the facts that are legally relevant to the element rather than to a legal status the element implies. It is not entirely free from doubt that this rule applies to computer trespass statutes, although it is often enough the default rule in federal criminal law that it seems likely to apply at least to the CFAA. Applying the usual rule to computer trespass statutes, proving intentional unauthorized access likely requires the government to show that the defendant knew of or hoped for the facts legally relevant to au­thorization and intentionally accessed the computer anyway. The prose­cution need not prove that the defendant knew or intended his conduct to be legally unauthorized. Instead, the key question is the defendant’s state of mind about the facts that, once the law is understood, made the access unauthorized.\n\nSo construed, the mental state requirement of computer trespass has a significant narrowing effect on liability for using canceled, blocked, and shared accounts. The individual must not only take steps that are con­trary to the delegated authority; he must know or hope that his steps are contrary to that delegated authority. Recall the Steele case, in which the ex-employee used the backdoor account after he had resigned. Steele obviously knew that the authority to access the account had been re­voked: As the Fourth Circuit explained, the company had taken his work laptop, denied him physical access to the building, and made him sign a letter that he would not try to access the employer’s network in the fu­ture. In other cases, however, the revocation might not be so clear. The ex-employee might not know that her access rights to the account had been revoked. In such a case, she would not be guilty of criminal com­puter trespass.\n\nThe mental state requirement is particularly important in cases that involve shared passwords. If B shares a password with C, C’s access is with­out authorization when C is acting outside the agency of B. At the same time, C’s access is intentionally without authorization only if C knows or hopes of facts that would bring C’s access outside the agency of B. In many cases, C may not know how B uses the account, how often, or for what. C’s state of mind about whether C is outside the agency relation­ship element may sharply limit C’s liability.\n\nFor example, imagine Ann gives Bob her Netflix username and pass­word and tells Bob to feel free to use her account. Bob then uses Ann’s account as if it were his own. Whether Bob’s use of Ann’s account is out­side the agency relationship is itself a murky question: General permis­sion to use the account whenever Bob likes implies a broad or even per­haps limitless authorization. But that murkiness aside, Bob can’t be crimi­nally liable for accessing Ann’s account unless he knows or hopes that his acts are outside Ann’s authorization. In the usual case, Bob would lack intent to access the account without authorization.\n\nConclusion\n\nApplying law to the Internet often rests on analogies. In litigation, each side will offer analogies that push the decisionmaker in a particular direction. Courts faced with competing analogies must know how to de­cide between them: How do you know whether Internet facts are more like one set of facts from the physical world or another?\n\nThis Essay can be understood as a conceptual guide to choosing analogies in the interpretation of computer trespass statutes. By appreci­ating the role of norms in the interpretation of physical trespass laws, courts can adopt sensible rules based on technological realities and their social construction. Because computer-network norms remain largely unsettled, the task is normative rather than descriptive. Judicial identifi­cation of the best norms to apply can help bring public acceptance of those norms, or at least provide a temporary set of answers until real norms emerge.\n\nThis approach helps avoid analogies that mislead rather than inform by missing the underlying norms that make analogies fit. Applying physical-world trespass cases to the Internet without first considering the differ­ence between the physical and network worlds risks applying precedents from an environment with one norm to an environment that merits a very different one."
    }
}