{
    "id": "dbpedia_3186_0",
    "rank": 64,
    "data": {
        "url": "https://www.usenix.org/conference/usenixsecurity24/fall-accepted-papers",
        "read_more_link": "",
        "language": "en",
        "title": "USENIX Security '24 Fall Accepted Papers",
        "top_image": "https://www.usenix.org/sites/default/files/sec24_banner_social_share_1200x630.png",
        "meta_img": "https://www.usenix.org/sites/default/files/sec24_banner_social_share_1200x630.png",
        "images": [
            "https://www.usenix.org/sites/default/files/styles/neat_conference_menu_logo/public/sec24_wordmark_stacked_white_400x164.png?itok=iZ1avAhI",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg",
            "https://www.usenix.org/sites/all/themes/custom/neat_conference/images/icons/pdf.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-04-30T13:22:34-07:00",
        "summary": "",
        "meta_description": "USENIX Security brings together researchers, practitioners, system programmers, and others to share and explore the latest advances in the security and privacy of computer systems and networks.",
        "meta_lang": "en",
        "meta_favicon": "https://www.usenix.org/sites/default/files/waves_favicon.ico",
        "meta_site_name": "USENIX",
        "canonical_link": "https://www.usenix.org/conference/usenixsecurity24/fall-accepted-papers",
        "text": "Towards Generic Database Management System Fuzzing\n\nYupeng Yang and Yongheng Chen, Georgia Institute of Technology; Rui Zhong, Palo Alto Networks; Jizhou Chen and Wenke Lee, Georgia Institute of Technology\n\nDatabase Management Systems play an indispensable role in modern cyberspace. While multiple fuzzing frameworks have been proposed in recent years to test relational (SQL) DBMSs to improve their security, non-relational (NoSQL) DBMSs have yet to experience the same scrutiny and lack an effective testing solution in general. In this work, we identify three limitations of existing approaches when extended to fuzz the DBMSs effectively in general: being non-generic, using static constraints, and generating loose data dependencies. Then, we propose effective solutions to address these limitations. We implement our solutions into an end-to-end fuzzing framework, BUZZBEE, which can effectively fuzz both relational and non-relational DBMSs. BUZZBEE successfully discovered 40 vulnerabilities in eight DBMSs of four different data models, of which 25 have been fixed with 4 new CVEs assigned. In our evaluation, BUZZBEE outperforms state-of-the-art generic fuzzers by up to 177% in terms of code coverage and discovers 30x more bugs than the second-best fuzzer for non-relational DBMSs, while achieving comparable results with specialized SQL fuzzers for the relational counterpart.\n\nSpeculative Denial-of-Service Attacks In Ethereum\n\nAviv Yaish, The Hebrew University; Kaihua Qin and Liyi Zhou, Imperial College London, UC Berkeley RDI; Aviv Zohar, The Hebrew University; Arthur Gervais, University College London, UC Berkeley RDI\n\nTransaction fees compensate actors for resources expended on transactions and can only be charged from transactions included in blocks. But, the expressiveness of Turing-complete contracts implies that verifying if transactions can be included requires executing them on the current blockchain state.\n\nIn this work, we show that adversaries can craft malicious transactions that decouple the work imposed on blockchain actors from the compensation offered in return. We introduce three attacks: (i) ConditionalExhaust, a conditional resource-exhaustion attack against blockchain actors. (ii) MemPurge, an attack for evicting transactions from actors' mempools. (iii) GhostTX, an attack on the reputation system used in Ethereum's proposer-builder separation ecosystem.\n\nWe evaluate our attacks on an Ethereum testnet and find that by combining ConditionalExhaust and MemPurge, adversaries can simultaneously burden victims' computational resources and clog their mempools to the point where victims are unable to include transactions in blocks. Thus, victims create empty blocks, thereby hurting the system's liveness. The attack's expected cost is $376, but becomes cheaper if adversaries are validators. For other attackers, costs decrease if censorship is prevalent in the network.\n\nConditionalExhaust and MemPurge are made possible by inherent features of Turing-complete blockchains, and potential mitigations may result in reducing a ledger's scalability.\n\n\"I feel physically safe but not politically safe\": Understanding the Digital Threats and Safety Practices of OnlyFans Creators\n\nAnanta Soneji, Arizona State University; Vaughn Hamilton, Max Planck Institute for Software Systems; Adam Doupé, Arizona State University; Allison McDonald, Boston University; Elissa M. Redmiles, Georgetown University\n\nOnlyFans is a subscription-based social media platform with over 1.5 million content creators and 150 million users worldwide. OnlyFans creators primarily produce intimate content for sale on the platform. As such, they are distinctly positioned as content creators and sex workers. Through a qualitative interview study with OnlyFans creators (n=43), building on an existing framework of online hate and harassment, we shed light on the nuanced threats they face and their safety practices. Additionally, we examine the impact of factors such as stigma, prominence, and platform policies on shaping the threat landscape for OnlyFans creators and detail the preemptive practices they undertake to protect themselves. Leveraging these results, we synthesize opportunities to address the challenges of sexual content creators.\n\nPINE: Efficient Verification of a Euclidean Norm Bound of a Secret-Shared Vector\n\nGuy N. Rothblum, Apple; Eran Omri, Ariel University and Ariel Cyber Innovation Center; Junye Chen and Kunal Talwar, Apple\n\nAvailable Media\n\nSecure aggregation of high-dimensional vectors is a fundamental primitive in federated statistics and learning. A two-server system such as PRIO allows for scalable aggregation of secret-shared vectors. Adversarial clients might try to manipulate the aggregate, so it is important to ensure that each (secret-shared) contribution is well-formed. In this work, we focus on the important and well-studied goal of ensuring that each contribution vector has bounded Euclidean norm. Existing protocols for ensuring bounded-norm contributions either incur a large communication overhead, or only allow for approximate verification of the norm bound. We propose Private Inexpensive Norm Enforcement (PINE): a new protocol that allows exact norm verification with little communication overhead. For high-dimensional vectors, our approach has a communication overhead of a few percent, compared to the 16-32x overhead of previous approaches.\n\nSHiFT: Semi-hosted Fuzz Testing for Embedded Applications\n\nAlejandro Mera and Changming Liu, Northeastern University; Ruimin Sun, Florida International University; Engin Kirda and Long Lu, Northeastern University\n\nAvailable Media\n\nModern microcontrollers (MCU)s are ubiquitous on critical embedded applications in the IoT era. Therefore, securing MCU firmware is fundamental. To analyze MCU firmware security, existing works mostly adopt re-hosting based techniques. These techniques transplant firmware to an engineered platform and require tailored hardware or emulation of different parts of the MCU. As a result, security practitioners have observed low-fidelity, false positives, and reduced compatibility with real and complex hardware. This paper presents SHiFT, a framework that leverages the industry semihosting philosophy to provide a brandnew method that analyzes firmware natively in MCUs. This novel method provides high fidelity, reduces false positives, and grants compatibility with complex peripherals, asynchronous events, real-time operations, and direct memory access (DMA). We verified compatibility of SHiFT with thirteen popular embedded architectures, and fully evaluated prototypes for ARMv7-M, ARMv8-M and Xtensa architectures. Our evaluation shows that SHiFT can detect a wide range of firmware faults with instrumentation running natively in the MCU. In terms of performance, SHiFT is up to two orders of magnitude faster (i.e., ×100) than software-based emulation, and even comparable to fuzz testing native applications in a workstation. Thanks to SHiFT's unique characteristics, we discovered five previously unknown vulnerabilities, including a zero-day on the popular FreeRTOS kernel, with no false positives. Our prototypes and source code are publicly available at https://github.com/RiS3-Lab/SHiFT.\n\nCAMP: Compositional Amplification Attacks against DNS\n\nHuayi Duan, Marco Bearzi, Jodok Vieli, David Basin, Adrian Perrig, and Si Liu, ETH Zürich; Bernhard Tellenbach, Armasuisse\n\nThis paper is currently under embargo. The final paper PDF and abstract will be available on the first day of the conference.\n\nRise of Inspectron: Automated Black-box Auditing of Cross-platform Electron Apps\n\nMir Masood Ali, Mohammad Ghasemisharif, Chris Kanich, and Jason Polakis, University of Illinois Chicago\n\nBrowser-based cross-platform applications have become increasingly popular as they allow software vendors to sidestep two major issues in the app ecosystem. First, web apps can be impacted by the performance deterioration affecting browsers, as the continuous adoption of diverse and complex features has led to bloating. Second, re-developing or porting apps to different operating systems and execution environments is a costly, error-prone process. Instead, frameworks like Electron allow the creation of standalone apps for different platforms using JavaScript code (e.g., reused from an existing web app) and by incorporating a stripped down and configurable browser engine. Despite the aforementioned advantages, these apps face significant security and privacy threats that are either non-applicable to traditional web apps (due to the lack of access to certain system-facing APIs) or ineffective against them (due to countermeasures already baked into browsers). In this paper we present Inspectron, an automated dynamic analysis framework that audits packaged Electron apps for potential security vulnerabilities stemming from developers' deviation from recommended security practices. Our study reveals a multitude of insecure practices and problematic trends in the Electron app ecosystem, highlighting the gap filled by Inspectron as it provides extensive and comprehensive auditing capabilities for developers and researchers.\n\nDVa: Extracting Victims and Abuse Vectors from Android Accessibility Malware\n\nHaichuan Xu, Mingxuan Yao, and Runze Zhang, Georgia Institute of Technology; Mohamed Moustafa Dawoud, German International University; Jeman Park, Kyung Hee University; Brendan Saltaformaggio, Georgia Institute of Technology\n\nThe Android accessibility (a11y) service is widely abused by malware to conduct on-device monetization fraud. Existing mitigation techniques focus on malware detection but overlook providing users evidence of abuses that have already occurred and notifying victims to facilitate defenses. We developed DVa, a malware analysis pipeline based on dynamic victim-guided execution and abuse-vector-guided symbolic analysis, to help investigators uncover a11y malware's targeted victims, victim-specific abuse vectors, and persistence mechanisms. We deployed DVa to investigate Android devices infected with 9,850 a11y malware. From the extractions, DVa uncovered 215 unique victims targeted with an average of 13.9 abuse routines. DVa also extracted six persistence mechanisms empowered by the a11y service.\n\nVoltSchemer: Use Voltage Noise to Manipulate Your Wireless Charger\n\nZihao Zhan and Yirui Yang, University of Florida; Haoqi Shan, University of Florida, CertiK; Hanqiu Wang, Yier Jin, and Shuo Wang, University of Florida\n\nWireless charging is becoming an increasingly popular charging solution in portable electronic products for a more convenient and safer charging experience than conventional wired charging. However, our research identified new vulnerabilities in wireless charging systems, making them susceptible to intentional electromagnetic interference. These vulnerabilities facilitate a set of novel attack vectors, enabling adversaries to manipulate the charger and perform a series of attacks.\n\nIn this paper, we propose VoltSchemer, a set of innovative attacks that grant attackers control over commercial-off-the-shelf wireless chargers merely by modulating the voltage from the power supply. These attacks represent the first of its kind, exploiting voltage noises from the power supply to manipulate wireless chargers without necessitating any malicious modifications to the chargers themselves. The significant threats imposed by VoltSchemer are substantiated by three practical attacks, where a charger can be manipulated to: control voice assistants via inaudible voice commands, damage devices being charged through overcharging or overheating, and bypass Qi-standard specified foreign-object-detection mechanism to damage valuable items exposed to intense magnetic fields.\n\nWe demonstrate the effectiveness and practicality of the VoltSchemer attacks with successful attacks on 9 top-selling COTS wireless chargers. Furthermore, we discuss the security implications of our findings and suggest possible countermeasures to mitigate potential threats.\n\nSoK: State of the Krawlers – Evaluating the Effectiveness of Crawling Algorithms for Web Security Measurements\n\nAleksei Stafeev and Giancarlo Pellegrino, CISPA Helmholtz Center for Information Security\n\nWeb crawlers are tools widely used in web security measurements whose performance and impact have been limitedly studied so far. In this paper, we bridge this gap. Starting from the past 12 years of the top security, web measurement, and software engineering literature, we categorize and decompose in building blocks crawling techniques and methodologic choices. We then reimplement and patch crawling techniques and integrate them into Arachnarium, a framework for comparative evaluations, which we use to run one of the most comprehensive experimental evaluations against nine real and two benchmark web applications and top 10K CrUX websites to assess the performance and adequacy of algorithms across three metrics (code, link, and JavaScript source coverage). Finally, we distill 14 insights and lessons learned. Our results show that despite a lack of clear and homogeneous descriptions hindering reimplementations, proposed and commonly used crawling algorithms offer a lower coverage than randomized ones, indicating room for improvement. Also, our results show a complex relationship between experiment parameters, the study's domain, and the available computing resources, where no single best-performing crawler configuration exists. We hope our results will guide future researchers when setting up their studies.\n\nThat Doesn't Go There: Attacks on Shared State in Multi-User Augmented Reality Applications\n\nCarter Slocum, Yicheng Zhang, Erfan Shayegani, Pedram Zaree, and Nael Abu-Ghazaleh, University of California, Riverside; Jiasi Chen, University of Michigan\n\nAugmented Reality (AR) can enable shared virtual experiences between multiple users. In order to do so, it is crucial for multi-user AR applications to establish a consensus on the \"shared state\" of the virtual world and its augmentations through which users interact. Current methods to create and access shared state collect sensor data from devices (e.g., camera images), process them, and integrate them into the shared state. However, this process introduces new vulnerabilities and opportunities for attacks. Maliciously writing false data to \"poison\" the shared state is a major concern for the security of the downstream victims that depend on it. Another type of vulnerability arises when reading the shared state: by providing false inputs, an attacker can view hologram augmentations at locations they are not allowed to access. In this work, we demonstrate a series of novel attacks on multiple AR frameworks with shared states, focusing on three publicly accessible frameworks. We show that these frameworks, while using different underlying implementations, scopes, and mechanisms to read from and write to the shared state, have shared vulnerability to a unified threat model. Our evaluations of these state-of-the-art AR frameworks demonstrate reliable attacks both on updating and accessing the shared state across different systems. To defend against such threats, we discuss a number of potential mitigation strategies that can help enhance the security of multi-user AR applications and implement an initial prototype.\n\nSDFuzz: Target States Driven Directed Fuzzing\n\nPenghui Li, The Chinese University of Hong Kong and Zhongguancun Laboratory; Wei Meng, The Chinese University of Hong Kong; Chao Zhang, Tsinghua University and Zhongguancun Laboratory\n\nDirected fuzzers often unnecessarily explore program code and paths that cannot trigger the target vulnerabilities. We observe that the major application scenarios of directed fuzzing provide detailed vulnerability descriptions, from which highly-valuable program states (i.e., target states) can be derived, e.g., call traces when a vulnerability gets triggered. By driving to expose such target states, directed fuzzers can exclude massive unnecessary exploration.\n\nInspired by the observation, we present SDFuzz, an efficient directed fuzzing tool driven by target states. SDFuzz first automatically extracts target states in vulnerability reports and static analysis results. SDFuzz employs a selective instrumentation technique to reduce the fuzzing scope to the required code for reaching target states. SDFuzz then early terminates the execution of a test case once SDFuzz probes that the remaining execution cannot reach the target states. It further uses a new target state feedback and refines prior imprecise distance metric into a two-dimensional feedback mechanism to proactively drive the exploration towards the target states.\n\nWe thoroughly evaluated SDFuzz on known vulnerabilities and compared it to related works. The results show that SDFuzz could improve vulnerability exposure capability with more vulnerability triggered and less time used, outperforming the state-of-the-art solutions. SDFuzz could significantly improve the fuzzing throughput. Our application of SDFuzz to automatically validate the static analysis results successfully discovered four new vulnerabilities in well-tested applications. Three of them have been acknowledged by developers.\n\nFEASE: Fast and Expressive Asymmetric Searchable Encryption\n\nLong Meng, Liqun Chen, and Yangguang Tian, University of Surrey; Mark Manulis, Universität der Bundeswehr München; Suhui Liu, Southeast University\n\nAsymmetric Searchable Encryption (ASE) is a promising cryptographic mechanism that enables a semi-trusted cloud server to perform keyword searches over encrypted data for users. To be useful, an ASE scheme must support expressive search queries, which are expressed as conjunction, disjunction, or any Boolean formulas. In this paper, we propose a fast and expressive ASE scheme that is adaptively secure, called FEASE. It requires only 3 pairing operations for searching any conjunctive set of keywords independent of the set size and has linear complexity for encryption and trapdoor algorithms in the number of keywords. FEASE is based on a new fast Anonymous Key-Policy Attribute-Based Encryption (A-KP-ABE) scheme as our first proposal, which is of independent interest. To address optional protection against keyword guessing attacks, we extend FEASE into the first expressive Public-Key Authenticated Encryption with Keyword Search (PAEKS) scheme. We provide implementations and evaluate the performance of all three schemes, while also comparing them with the state of the art. We observe that FEASE outperforms all existing expressive ASE constructions and that our A-KP-ABE scheme offers anonymity with efficiency comparable to the currently fastest yet non-anonymous KP-ABE schemes FAME (ACM CCS 2017) and FABEO (ACM CCS 2022).\n\nCritical Code Guided Directed Greybox Fuzzing for Commits\n\nYi Xiang, Zhejiang University NGICS Platform; Xuhong Zhang, Zhejiang University and Jianghuai Advance Technology Center; Peiyu Liu, Zhejiang University NGICS Platform; Shouling Ji, Xiao Xiao, Hong Liang, and Jiacheng Xu, Zhejiang University; Wenhai Wang, Zhejiang University NGICS Platform\n\nNewly submitted commits are prone to introducing vulnerabilities into programs. As a promising countermeasure, directed greybox fuzzers can be employed to test commit changes by designating the commit change sites as targets. However, existing directed fuzzers primarily focus on reaching a single target and neglect the diverse exploration of the additional affected code. As a result, they may overlook bugs that crash at a distant site from the change site and lack directness in multi-target scenarios, which are both very common in the context of commit testing.\n\nIn this paper, we propose WAFLGO, a direct greybox fuzzer, to effectively discover vulnerabilities introduced by commits. WAFLGO employs a novel critical code guided input generation strategy to thoroughly explore the affected code. Specifically, we identify two types of critical code: pathprefix code and data-suffix code. The critical code first guides the input generation to gradually and incrementally reach the change sites. Then while maintaining the reachability of the critical code, the input generation strategy further encourages the diversity of the generated inputs in exploring the affected code. Additionally, WAFLGO introduces a lightweight multitarget distance metric for directness and thorough examination of all change sites. We implement WAFLGO and evaluate it with 30 real-world bugs introduced by commits. Compared to eight state-of-the-art tools, WAFLGO achieves an average speedup of 10.3×. Furthermore, WAFLGO discovers seven new vulnerabilities including four CVEs while testing the most recent 50 commits of real-world software, including libtiff, fig2dev, and libming, etc.\n\nPage-Oriented Programming: Subverting Control-Flow Integrity of Commodity Operating System Kernels with Non-Writable Code Pages\n\nSeunghun Han, The Affiliated Institute of ETRI, Chungnam National University; Seong-Joong Kim, Wook Shin, and Byung Joon Kim, The Affiliated Institute of ETRI; Jae-Cheol Ryou, Chungnam National University\n\nThis paper presents a novel attack technique called page-oriented programming, which reuses existing code gadgets by remapping physical pages to the virtual address space of a program at runtime. The page remapping vulnerabilities may lead to data breaches or may damage kernel integrity. Therefore, manufacturers have recently released products equipped with hardware-assisted guest kernel integrity enforcement. This paper extends the notion of the page remapping attack to another type of code-reuse attack, which can not only be used for altering or sniffing kernel data but also for building and executing malicious code at runtime. We demonstrate the effectiveness of this attack on state-of-the-art hardware and software, where control-flow integrity policies are enforced, thus highlighting its capability to render most legacy systems vulnerable.\n\nA Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data\n\nMeenatchi Sundaram Muthu Selva Annamalai, University College London; Andrea Gadotti and Luc Rocher, University of Oxford\n\nRecent advances in synthetic data generation (SDG) have been hailed as a solution to the difficult problem of sharing sensitive data while protecting privacy. SDG aims to learn statistical properties of real data in order to generate \"artificial\" data that are structurally and statistically similar to sensitive data. However, prior research suggests that inference attacks on synthetic data can undermine privacy, but only for specific outlier records.\n\nIn this work, we introduce a new attribute inference attack against synthetic data. The attack is based on linear reconstruction methods for aggregate statistics, which target all records in the dataset, not only outliers. We evaluate our attack on state-of-the-art SDG algorithms, including Probabilistic Graphical Models, Generative Adversarial Networks, and recent differentially private SDG mechanisms. By defining a formal privacy game, we show that our attack can be highly accurate even on arbitrary records, and that this is the result of individual information leakage (as opposed to population-level inference).\n\nWe then systematically evaluate the tradeoff between protecting privacy and preserving statistical utility. Our findings suggest that current SDG methods cannot consistently provide sufficient privacy protection against inference attacks while retaining reasonable utility. The best method evaluated, a differentially private SDG mechanism, can provide both protection against inference attacks and reasonable utility, but only in very specific settings. Lastly, we show that releasing a larger number of synthetic records can improve utility but at the cost of making attacks far more effective.\n\nSoK (or SoLK?): On the Quantitative Study of Sociodemographic Factors and Computer Security Behaviors\n\nMiranda Wei, University of Washington; Jaron Mink, University of Illinois at Urbana-Champaign; Yael Eiger and Tadayoshi Kohno, University of Washington; Elissa M. Redmiles, Georgetown University; Franziska Roesner, University of Washington\n\nAvailable Media\n\nResearchers are increasingly exploring how gender, culture, and other sociodemographic factors correlate with user computer security and privacy behaviors. To more holistically understand relationships between these factors and behaviors, we make two contributions. First, we broadly survey existing scholarship on sociodemographics and secure behavior (151 papers) before conducting a focused literature review of 47 papers to synthesize what is currently known and identify open questions for future research. Second, by incorporating contemporary social and critical theories, we establish guidelines for future studies of sociodemographic factors and security behaviors that address how to overcome common pitfalls. We present a case study to demonstrate our guidelines in action, at-scale, that conduct a measurement study of the relationships between sociodemographics and de-identified, aggregated log data of security and privacy behaviors among 16,829 users on Facebook across 16 countries. Through these contributions, we position our work as a systemization of a lack of knowledge (SoLK). Overall, we find contradictory results and vast unknowns about how identity shapes security behavior. Through our guidelines and discussion, we chart new directions to more deeply examine how and why sociodemographic factors affect security behaviors.\n\nOn the Difficulty of Defending Contrastive Learning against Backdoor Attacks\n\nChangjiang Li, Stony Brook University; Ren Pang, Bochuan Cao, Zhaohan Xi, and Jinghui Chen, Pennsylvania State University; Shouling Ji, Zhejiang University; Ting Wang, Stony Brook University\n\nRecent studies have shown that contrastive learning, like supervised learning, is highly vulnerable to backdoor attacks wherein malicious functions are injected into target models, only to be activated by specific triggers. However, thus far it remains under-explored how contrastive backdoor attacks fundamentally differ from their supervised counterparts, which impedes the development of effective defenses against the emerging threat.\n\nThis work represents a solid step toward answering this critical question. Specifically, we define TRL, a unified framework that encompasses both supervised and contrastive backdoor attacks. Through the lens of TRL, we uncover that the two types of attacks operate through distinctive mechanisms: in supervised attacks, the learning of benign and backdoor tasks tends to occur independently, while in contrastive attacks, the two tasks are deeply intertwined both in their representations and throughout their learning processes. This distinction leads to the disparate learning dynamics and feature distributions of supervised and contrastive attacks. More importantly, we reveal that the specificities of contrastive backdoor attacks entail important implications from a defense perspective: existing defenses for supervised attacks are often inadequate and not easily retrofitted to contrastive attacks. We also explore several promising alternative defenses and discuss their potential challenges. Our findings highlight the need for defenses tailored to the specificities of contrastive backdoor attacks, pointing to promising directions for future research.\n\n\"I chose to fight, be brave, and to deal with it\": Threat Experiences and Security Practices of Pakistani Content Creators\n\nLea Gröber, CISPA Helmholtz Center for Information Security and Saarland University; Waleed Arshad and Shanza, Lahore University of Management Sciences; Angelica Goetzen, Max Planck Institute for Software Systems; Elissa M. Redmiles, Georgetown University; Maryam Mustafa, Lahore University of Management Sciences; Katharina Krombholz, CISPA Helmholtz Center for Information Security\n\nContent creators are exposed to elevated risks compared to the general Internet user. This study explores the threat landscape that creators in Pakistan are exposed to, how they protect themselves, and which support structures they rely on. We conducted a semi-structured interview study with 23 creators from diverse backgrounds who create content on various topics. Our data suggests that online threats frequently spill over into the offline world, especially for gender minorities. Creating content on sensitive topics like politics, religion, and human rights is associated with elevated risks. We find that defensive mechanisms and external support structures are non-existent, lacking, or inadequately adjusted to the sociocultural context of Pakistan.\n\nDisclaimer: This paper contains quotes describing harmful experiences relating to sexual and physical assault, eating disorders, and extreme threats of violence.\n\nMore Simplicity for Trainers, More Opportunity for Attackers: Black-Box Attacks on Speaker Recognition Systems by Inferring Feature Extractor\n\nYunjie Ge, Pinji Chen, Qian Wang, Lingchen Zhao, and Ningping Mou, Wuhan University; Peipei Jiang, Wuhan University; City University of Hong Kong; Cong Wang, City University of Hong Kong; Qi Li, Tsinghua University; Chao Shen, Xi'an Jiaotong University\n\nRecent studies have revealed that deep learning-based speaker recognition systems (SRSs) are vulnerable to adversarial examples (AEs). However, the practicality of existing black-box AE attacks is restricted by the requirement for extensive querying of the target system or the limited attack success rates (ASR). In this paper, we introduce VoxCloak, a new targeted AE attack with superior performance in both these aspects. Distinct from existing methods that optimize AEs by querying the target model, VoxCloak initially employs a small number of queries (e.g., a few hundred) to infer the feature extractor used by the target system. It then utilizes this feature extractor to generate any number of AEs locally without the need for further queries. We evaluate VoxCloak on four commercial speaker recognition (SR) APIs and seven voice assistants. On the SR APIs, VoxCloak surpasses the existing transfer-based attacks, improving ASR by 76.25% and signal-to-noise ratio (SNR) by 13.46 dB, as well as the decision-based attacks, requiring 33 times fewer queries and improving SNR by 7.87 dB while achieving comparable ASRs. On the voice assistants, VoxCloak outperforms the existing methods with a 49.40% improvement in ASR and a 15.79 dB improvement in SNR.\n\nEaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection\n\nShigang Liu, CSIRO's Data61 and Swinburne University of Technology; Di Cao, Swinburne University of Technology; Junae Kim, Tamas Abraham, and Paul Montague, DST Group, Australia; Seyit Camtepe, CSIRO's Data61; Jun Zhang and Yang Xiang, Swinburne University of Technology\n\nAvailable Media\n\nRecently, deep learning has demonstrated promising results in enhancing the accuracy of vulnerability detection and identifying vulnerabilities in software. However, these techniques are still vulnerable to attacks. Adversarial examples can exploit vulnerabilities within deep neural networks, posing a significant threat to system security. This study showcases the susceptibility of deep learning models to adversarial attacks, which can achieve 100% attack success rate. The proposed method, EaTVul, encompasses six stages: identification of important adversarial samples using support vector machines, identification of important features using the attention mechanism, generation of adversarial data based on these features, preparation of an adversarial attack pool, selection of seed data using a fuzzy genetic algorithm, and the execution of an evasion attack. Extensive experiments demonstrate the effectiveness of EaTVul, achieving an attack success rate of more than 83% when the snippet size is greater than 2. Furthermore, in most cases with a snippet size of 4, EaTVul achieves a 100% attack success rate. The findings of this research emphasize the necessity of robust defenses against adversarial attacks in software vulnerability detection.\n\nHow Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers\n\nGuangsheng Zhang, Bo Liu, Huan Tian, and Tianqing Zhu, University of Technology Sydney; Ming Ding, Data 61, Australia; Wanlei Zhou, City University of Macau\n\nAvailable Media\n\nAs a booming research area in the past decade, deep learning technologies have been driven by big data collected and processed on an unprecedented scale. However, privacy concerns arise due to the potential leakage of sensitive information from the training data. Recent research has revealed that deep learning models are vulnerable to various privacy attacks, including membership inference attacks, attribute inference attacks, and gradient inversion attacks. Notably, the efficacy of these attacks varies from model to model. In this paper, we answer a fundamental question: Does model architecture affect model privacy? By investigating representative model architectures from convolutional neural networks (CNNs) to Transformers, we demonstrate that Transformers generally exhibit higher vulnerability to privacy attacks than CNNs. Additionally, we identify the micro design of activation layers, stem layers, and LN layers, as major factors contributing to the resilience of CNNs against privacy attacks, while the presence of attention modules is another main factor that exacerbates the privacy vulnerability of Transformers. Our discovery reveals valuable insights for deep learning models to defend against privacy attacks and inspires the research community to develop privacy-friendly model architectures.\n\nFast and Private Inference of Deep Neural Networks by Co-designing Activation Functions\n\nAbdulrahman Diaa, Lucas Fenaux, Thomas Humphries, Marian Dietz, Faezeh Ebrahimianghazani, Bailey Kacsmar, Xinda Li, Nils Lukas, Rasoul Akhavan Mahdavi, and Simon Oya, University of Waterloo; Ehsan Amjadian, University of Waterloo and Royal Bank of Canada; Florian Kerschbaum, University of Waterloo\n\nMachine Learning as a Service (MLaaS) is an increasingly popular design where a company with abundant computing resources trains a deep neural network and offers query access for tasks like image classification. The challenge with this design is that MLaaS requires the client to reveal their potentially sensitive queries to the company hosting the model. Multi-party computation (MPC) protects the client's data by allowing encrypted inferences. However, current approaches suffer from prohibitively large inference times. The inference time bottleneck in MPC is the evaluation of non-linear layers such as ReLU activation functions. Motivated by the success of previous work co-designing machine learning and MPC, we develop an activation function co-design. We replace all ReLUs with a polynomial approximation and evaluate them with single-round MPC protocols, which give state-of-theart inference times in wide-area networks. Furthermore, to address the accuracy issues previously encountered with polynomial activations, we propose a novel training algorithm that gives accuracy competitive with plaintext models. Our evaluation shows between 3 and 110× speedups in inference time on large models with up to 23 million parameters while maintaining competitive inference accuracy.\n\nTransferability of White-box Perturbations: Query-Efficient Adversarial Attacks against Commercial DNN Services\n\nMeng Shen and Changyue Li, School of Cyberspace Science and Technology, Beijing Institute of Technology, China; Qi Li, Institute for Network Sciences and Cyberspace, Tsinghua University, China; Hao Lu, School of Computer Science and Technology, Beijing Institute of Technology, China; Liehuang Zhu, School of Cyberspace Science and Technology, Beijing Institute of Technology, China; Ke Xu, Department of Computer Science, Tsinghua University, China\n\nDeep Neural Networks (DNNs) have been proven to be vulnerable to adversarial attacks. Existing decision-based adversarial attacks require large numbers of queries to find an effective adversarial example, resulting in a heavy query cost and also performance degradation under defenses. In this paper, we propose the Dispersed Sampling Attack (DSA), which is a query-efficient decision-based adversarial attack by exploiting the transferability of white-box perturbations. DSA can generate diverse examples with different locations in the embedding space, which provides more information about the adversarial region of substitute models and allows us to search for transferable perturbations. Specifically, DSA samples in a hypersphere centered on an original image, and progressively constrains the perturbation. Extensive experiments are conducted on public datasets to evaluate the performance of DSA in closed-set and open-set scenarios. DSA outperforms the state-of-the-art attacks in terms of both attack success rate (ASR) and average number of queries (AvgQ). Specifically, DSA achieves an ASR of about 90% with an AvgQ of 200 on 4 well-known commercial DNN services.\n\nQuery Recovery from Easy to Hard: Jigsaw Attack against SSE\n\nHao Nie and Wei Wang, Huazhong University of Science and Technology; Peng Xu, Huazhong University of Science and Technology, Hubei Key Laboratory of Distributed System Security, School of Cyber Science and Engineering, JinYinHu Laboratory, and State Key Laboratory of Cryptology; Xianglong Zhang, Huazhong University of Science and Technology; Laurence T. Yang, Huazhong University of Science and Technology and St. Francis Xavier University; Kaitai Liang, Delft University of Technology\n\nSearchable symmetric encryption schemes often unintentionally disclose certain sensitive information, such as access, volume, and search patterns. Attackers can exploit such leakages and other available knowledge related to the user's database to recover queries. We find that the effectiveness of query recovery attacks depends on the volume/frequency distribution of keywords. Queries containing keywords with high volumes/frequencies are more susceptible to recovery, even when countermeasures are implemented. Attackers can also effectively leverage these \"special\" queries to recover all others.\n\nBy exploiting the above finding, we propose a Jigsaw attack that begins by accurately identifying and recovering those distinctive queries. Leveraging the volume, frequency, and cooccurrence information, our attack achieves 90% accuracy in three tested datasets, which is comparable to previous attacks (Oya et al., USENIX' 22 and Damie et al., USENIX' 21). With the same runtime, our attack demonstrates an advantage over the attack proposed by Oya et al (approximately 15% more accuracy when the keyword universe size is 15k). Furthermore, our proposed attack outperforms existing attacks against widely studied countermeasures, achieving roughly 60% and 85% accuracy against the padding and the obfuscation, respectively. In this context, with a large keyword universe (≥3k), it surpasses current state-of-the-art attacks by more than 20%.\n\nSoK: Security of Programmable Logic Controllers\n\nEfrén López-Morales, Texas A&M University-Corpus Christi; Ulysse Planta, CISPA Helmholtz Center for Information Security; Carlos Rubio-Medrano, Texas A&M University-Corpus Christi; Ali Abbasi, CISPA Helmholtz Center for Information Security; Alvaro A. Cardenas, University of California, Santa Cruz\n\nAvailable Media\n\nBillions of people rely on essential utility and manufacturing infrastructures such as water treatment plants, energy management, and food production. Our dependence on reliable infrastructures makes them valuable targets for cyberattacks. One of the prime targets for adversaries attacking physical infrastructures are Programmable Logic Controllers (PLCs) because they connect the cyber and physical worlds. In this study, we conduct the first comprehensive systematization of knowledge that explores the security of PLCs: We present an in-depth analysis of PLC attacks and defenses and discover trends in the security of PLCs from the last 17 of research. We introduce a novel threat taxonomy for PLCs and Industrial Control Systems (ICS). Finally, we identify and point out research gaps that, if left ignored, could lead to new catastrophic attacks against critical infrastructures.\n\n\"I'm not convinced that they don't collect more than is necessary\": User-Controlled Data Minimization Design in Search Engines\n\nTanusree Sharma, University of Illinois at Urbana-Champaign; Lin Kyi, Max Planck Institute for Security and Privacy; Yang Wang, University of Illinois at Urbana-Champaign; Asia J. Biega, Max Planck Institute for Security and Privacy\n\nData minimization is a legal and privacy-by-design principle mandating that online services collect only data that is necessary for pre-specified purposes. While the principle has thus far mostly been interpreted from a system-centered perspective, there is a lack of understanding about how data minimization could be designed from a user-centered perspective, and in particular, what factors might influence user decision-making with regard to the necessity of data for different processing purposes. To address this gap, in this paper, we gain a deeper understanding of users' design expectations and decision-making processes related to data minimization, focusing on a case study of search engines. We also elicit expert evaluations of the feasibility of user-generated design ideas. We conducted interviews with 25 end users and 10 experts from the EU and UK to provide concrete design recommendations for data minimization that incorporate user needs, concerns, and preferences. Our study (i) surfaces how users reason about the necessity of data in the context of search result quality, and (ii) examines the impact of several factors on user decision-making about data processing, including specific types of search data, or the volume and recency of data. Most participants emphasized the particular importance of data minimization in the context of sensitive searches, such as political, financial, or health-related search queries. In a think-aloud conceptual design session, participants recommended search profile customization as a solution for retaining data they considered necessary, as well as alert systems that would inform users to minimize data in instances of excessive collection. We propose actionable design features that could provide users with greater agency over their data through user-controlled data minimization, combined with relevant implementation insights from experts.\n\nTowards Privacy-Preserving Social-Media SDKs on Android\n\nHaoran Lu, Yichen Liu, Xiaojing Liao, and Luyi Xing, Indiana University Bloomington\n\nIntegration of third-party SDKs are essential in the development of mobile apps. However, the rise of in-app privacy threat against mobile SDKs— called cross-library data harvesting (XLDH), targets social media/platform SDKs (called social SDKs) that handles rich user data. Given the widespread integration of social SDKs in mobile apps, XLDH presents a significant privacy risk, as well as raising pressing concerns regarding legal compliance for app developers, social media/platform stakeholders, and policymakers. The emerging XLDH threat, coupled with the increasing demand for privacy and compliance in line with societal expectations, introduces unique challenges that cannot be addressed by existing protection methods against privacy threats or malicious code on mobile platforms. In response to the XLDH threats, in our study, we generalize and define the concept of privacy-preserving social SDKs and their in-app usage, characterize fundamental challenges for combating the XLDH threat and ensuring privacy in design and utilizaiton of social SDKs. We introduce a practical, clean-slate design and end-to-end systems, called PESP, to facilitate privacy-preserving social SDKs. Our thorough evaluation demonstrates its satisfactory effectiveness, performance overhead and practicability for widespread adoption.\n\nAI Psychiatry: Forensic Investigation of Deep Learning Networks in Memory Images\n\nDavid Oygenblik, Georgia Institute of Technology; Carter Yagemann, Ohio State University; Joseph Zhang, University of Pennsylvania; Arianna Mastali, Georgia Institute of Technology; Jeman Park, Kyung Hee University; Brendan Saltaformaggio, Georgia Institute of Technology\n\nOnline learning is widely used in production to refine model parameters after initial deployment. This opens several vectors for covertly launching attacks against deployed models. To detect these attacks, prior work developed black-box and white-box testing methods. However, this has left prohibitive open challenge: how the investigator is supposed to recover the model (uniquely refined on an in-the-field device) for testing in the first place. We propose a novel memory forensic technique, named AiP, which automatically recovers the unique deployment model and rehosts it in a lab environment for investigation. AiP navigates through both main memory and GPU memory spaces to recover complex ML data structures, using recovered Python objects to guide the recovery of lower-level C objects, ultimately leading to the recovery of the uniquely refined model. AiP then rehosts the model within the investigator's device, where the investigator can apply various white-box testing methodologies. We have evaluated AiP using three versions of TensorFlow and PyTorch with the CIFAR-10, LISA, and IMDB datasets. AiP recovered 30 models from main memory and GPU memory with 100% accuracy and rehosted them into a live process successfully.\n\nA Friend's Eye is A Good Mirror: Synthesizing MCU Peripheral Models from Peripheral Drivers\n\nChongqing Lei and Zhen Ling, Southeast University; Yue Zhang, Drexel University; Yan Yang and Junzhou Luo, Southeast University; Xinwen Fu, University of Massachusetts Lowell\n\nAvailable Media\n\nThe extensive integration of embedded devices within the Internet of Things (IoT) has given rise to significant security concerns. Various initiatives have been undertaken to bolster the security of these devices at the software level, involving the analysis of MCU firmware and the implementation of automatic MCU rehosting methods. However, existing hardware-oriented rehosting techniques often face scalability challenges, while firmware-oriented approaches may have limited universality and fidelity. To address these limitations, we propose Perry, a system that synthesizes faithful and extendable peripheral models for MCUs. By extracting peripheral models from hardware drivers, Perry ensures compatibility and accurate emulation of targeted MCUs. The process involves gathering hardware metadata, analyzing driver code, capturing traces of peripheral accesses, and converting software beliefs into hardware behaviors. Perry is implemented with approximately 19,000 lines of code. A comprehensive evaluation of 75 firmware samples has showcased its effectiveness, consistency, universality, and scalability in generating hardware models for MCUs. Perry can efficiently synthesize hardware models consistent with the actual hardware and achieve a 74.24% unit test passing rate, outperforming the state-of-the-art techniques. The hardware models produced by Perry can faithfully emulate diverse firmware and can be readily expanded with minimal manual intervention. Through case studies, we show that Perry can help reproduce firmware vulnerabilities, discover specification-violation bugs in drivers, and fuzz RTOS for vulnerabilities. These case studies have led to the identification of two specification-violating bugs and the discovery of seven new vulnerabilities, underscoring Perry's potential to enhance various security-focused tasks.\n\nCalcuLatency: Leveraging Cross-Layer Network Latency Measurements to Detect Proxy-Enabled Abuse\n\nReethika Ramesh, University of Michigan; Philipp Winter, Independent; Sam Korman and Roya Ensafi, University of Michigan\n\nEfforts from emerging technology companies aim to democratize the ad delivery ecosystem and build systems that are privacy-centric and even share ad revenue benefits with their users. Other providers offer remuneration for users on their platform for interacting with and making use of services. But these efforts may suffer from coordinated abuse efforts aiming to defraud them. Attackers can use VPNs and proxies to fabricate their geolocation and earn disproportionate rewards. Balancing proxy-enabled abuse-prevention techniques with a privacy-focused business model is a hard challenge. Can service providers use minimal connection features to infer proxy use without jeopardizing user privacy?\n\nIn this paper, we build and evaluate a solution, CalcuLatency, that incorporates various network latency measurement techniques and leverage the application-layer and network-layer differences in roundtrip-times when a user connects to the service using a proxy. We evaluate our four measurement techniques individually, and as an integrated system using a two-pronged evaluation. CalcuLatency is an easy-to-deploy, open-source solution that can serve as an inexpensive first-step to label proxies.\n\nFalse Claims against Model Ownership Resolution\n\nJian Liu and Rui Zhang, Zhejiang University; Sebastian Szyller, Intel Labs & Aalto University; Kui Ren, Zhejiang University; N. Asokan, University of Waterloo & Aalto University\n\nAvailable Media\n\nDeep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.\n\nIn this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our core idea is that a malicious accuser can deviate (without detection) from the specified MOR process by finding (transferable) adversarial examples that successfully serve as evidence against independent suspect models. To this end, we first generalize the procedures of common MOR schemes and show that, under this generalization, defending against false claims is as challenging as preventing (transferable) adversarial examples. Via systematic empirical evaluation we show that our false claim attacks always succeed in MOR schemes that follow our generalization, including in a real-world model: Amazon's Rekognition API.\n\nAE-Morpher: Improve Physical Robustness of Adversarial Objects against LiDAR-based Detectors via Object Reconstruction\n\nShenchen Zhu, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Yue Zhao, Institute of Information Engineering, Chinese Academy of Sciences, China; Kai Chen, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China; Bo Wang, Huawei Technologies Co., Ltd.; Hualong Ma and Cheng'an Wei, Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese Academy of Sciences, China\n\nAvailable Media\n\nLiDAR-based perception is crucial to ensure the safety and reliability of autonomous driving (AD) systems. Though some adversarial attack methods against LiDAR-based detectors perception models have been proposed, deceiving such models in the physical world is still challenging. While existing robustness methods focus on transforming point clouds to embed more robust adversarial information, our research reveals how to reduce the errors during the LiDAR capturing process to improve the robustness of adversarial attacks. In this paper, we present AE-Morpher, a novel approach that minimizes differences between the LiDAR-captured and original adversarial point clouds to improve the robustness of adversarial objects. It reconstructs the adversarial object using surfaces with regular shapes to fit the discrete laser beams. We evaluate AE-Morpher by conducting physical disappearance attacks that use a mounted adversarial ornament to conceal a car from models' detection results in both SVL Simulator environments and real-world LiDAR setups. In the simulated world, we successfully deceive the model up to 91.1% of the time when LiDAR moves towards the target vehicle from 20m away. On average, our method increases the ASR by 38.64% and reduces the adversarial ornament's projection area by 67.59%. For the real world, we achieve an average attack success rate of 71.4% over a 12m motion scenario. Moreover, adversarial objects reconstructed by our method can be easily physically constructed by human hands without the requirement of a 3D printer.\n\nLearning with Semantics: Towards a Semantics-Aware Routing Anomaly Detection System\n\nYihao Chen, Department of Computer Science and Technology & BNRist, Tsinghua University; Qilei Yin, Zhongguancun Laboratory; Qi Li and Zhuotao Liu, Institute for Network Sciences and Cyberspace, Tsinghua University; Zhongguancun Laboratory; Ke Xu, Department of Computer Science and Technology, Tsinghua University; Zhongguancun Laboratory; Yi Xu and Mingwei Xu, Institute for Network Sciences and Cyberspace, Tsinghua University; Zhongguancun Laboratory; Ziqian Liu, China Telecom; Jianping Wu, Department of Computer Science and Technology, Tsinghua University; Zhongguancun Laboratory\n\nAvailable Media\n\nBGP is the de facto inter-domain routing protocol to ensure global connectivity of the Internet. However, various reasons, such as deliberate attacks or misconfigurations, could cause BGP routing anomalies. Traditional methods for BGP routing anomaly detection require significant manual investigation of routes by network operators. Although machine learning has been applied to automate the process, prior arts typically impose significant training overhead (such as large-scale data labeling and feature crafting), and only produce uninterpretable results. To address these limitations, this paper presents a routing anomaly detection system centering around a novel network representation learning model named BEAM. The core design of BEAM is to accurately learn the unique properties (defined as routing role) of each Autonomous System (AS) in the Internet by incorporating BGP semantics. As a result, routing anomaly detection, given BEAM, is reduced to a matter of discovering unexpected routing role churns upon observing new route announcements. We implement a prototype of our routing anomaly detection system and extensively evaluate its performance. The experimental results, based on 18 real-world RouteViews datasets containing over 11 billion route announcement records, demonstrate that our system can detect all previously-confirmed routing anomalies, while only introducing at most five false alarms every 180 million route announcements. We also deploy our system at a large ISP to perform real-world detection for one month. During the course of deployment, our system detects 497 true anomalies in the wild with an average of only 1.65 false alarms per day.\n\nDon't Waste My Efforts: Pruning Redundant Sanitizer Checks by Developer-Implemented Type Checks\n\nYizhuo Zhai, Zhiyun Qian, Chengyu Song, Manu Sridharan, and Trent Jaeger, University of California, Riverside; Paul Yu, U.S. Army Research Laboratory; Srikanth V. Krishnamurthy, University of California, Riverside\n\nType confusion occurs when C or C++ code accesses an object after casting it to an incompatible type. The security impacts of type confusion vulnerabilities are significant, potentially leading to system crashes or even arbitrary code execution. To mitigate these security threats, both static and dynamic approaches have been developed to detect type confusion bugs. However, static approaches can suffer from excessive false positives, while existing dynamic approaches track type information for each object to enable safety checking at each cast, introducing a high runtime overhead.\n\nIn this paper, we present a novel tool T-PRUNIFY to reduce the overhead of dynamic type confusion sanitizers. We observe that in large complex C++ projects, to prevent type confusion bugs, developers often add their own encoding of runtime type information (RTTI) into classes, to enable efficient runtime type checks before casts. T-PRUNIFY works by first identifying these custom RTTI in classes, automatically determining the relationship between field and method return values and the concrete types of corresponding objects. Based on these custom RTTI, T-PRUNIFY can identify cases where a cast is protected by developer-written type checks that guarantee the safety of the cast. Consequently, it can safely remove sanitizer instrumentation for such casts, reducing performance overhead. We evaluate T-PRUNIFY based on HexType, a state-of-the-art type confusion sanitizer that supports extensive C++ projects such as Google Chrome. Our findings demonstrate that our method significantly lowers HexType's average overhead by 25% to 75% in large C++ programs, marking a substantial enhancement in performance.\n\nPenetration Vision through Virtual Reality Headsets: Identifying 360-degree Videos from Head Movements\n\nAnh Nguyen, Xiaokuan Zhang, and Zhisheng Yan, George Mason University\n\nIn this paper, we present the first contactless side-channel attack for identifying 360° videos being viewed in a Virtual Reality (VR) Head Mounted Display (HMD). Although the video content is displayed inside the HMD without any external exposure, we observe that user head movements are driven by the video content, which creates a unique side channel that does not exist in traditional 2D videos. By recording the user whose vision is blocked by the HMD via a malicious camera, an attacker can analyze the correlation between the user's head movements and the victim video to infer the video title.\n\nTo exploit this new vulnerability, we present INTRUDE, a system for identifying 360° videos from recordings of user head movements. INTRUDE is empowered by an HMD-based head movement estimation scheme to extract a head movement trace from the recording and a video saliency-based trace-fingerprint matching framework to infer the video title. Evaluation results show that INTRUDE achieves over 96% of accuracy for video identification and is robust under different recording environments. Moreover, INTRUDE maintains its effectiveness in the open-world identification scenario.\n\nIntellectual Property Exposure: Subverting and Securing Intellectual Property Encapsulation in Texas Instruments Microcontrollers\n\nMarton Bognar, Cas Magnus, Frank Piessens, and Jo Van Bulck, DistriNet, KU Leuven\n\nIn contrast to high-end computing platforms, specialized memory protection features in low-end embedded devices remain relatively unexplored despite the ubiquity of these devices. Hence, we perform an in-depth security evaluation of the state-of-the-art Intellectual Property Encapsulation (IPE) technology found in widely used off-the-shelf, Texas Instruments MSP430 microcontrollers. While we find IPE to be promising, bearing remarkable similarities with trusted execution environments (TEEs) from research and industry, we reveal several fundamental protection shortcomings in current IPE hardware. We show that many software-level attack techniques from the academic TEE literature apply to this platform, and we discover a novel attack primitive, dubbed controlled call corruption, exploiting a vulnerability in the IPE access control mechanism. Our practical, end-to-end attack scenarios demonstrate a complete bypass of confidentiality and integrity guarantees of IPE-protected programs.\n\nInformed by our systematic attack study on IPE and root-cause analysis, also considering related research prototypes, we propose lightweight hardware changes to secure IPE. Furthermore, we develop a prototype framework that transparently implements software responsibilities to reduce information leakage and repurposes the onboard memory protection unit to reinstate IPE security guarantees on currently vulnerable devices with low performance overheads.\n\nStop, Don't Click Here Anymore: Boosting Website Fingerprinting By Considering Sets of Subpages\n\nAsya Mitseva and Andriy Panchenko, Brandenburg University of Technology (BTU Cottbus, Germany)\n\nA type of traffic analysis, website fingerprinting (WFP), aims to reveal the website a user visits over an encrypted and anonymized connection by observing and analyzing data flow patterns. Its efficiency against anonymization networks such as Tor has been widely studied, resulting in methods that have steadily increased in both complexity and power. While modern WFP attacks have proven to be highly accurate in laboratory settings, their real-world feasibility is highly debated. These attacks also exclude valuable information by ignoring typical user browsing behavior: users often visit multiple pages of a single website sequentially, e.g., by following links.\n\nIn this paper, we aim to provide a more realistic assessment of the degree to which Tor users are exposed to WFP. We propose both a novel WFP attack and efficient strategies for adapting existing methods to account for sequential visits of pages within a website. While existing WFP attacks fail to detect almost any website in real-world settings, our novel methods achieve F1-scores of 1.0 for more than half of the target websites. Our attacks remain robust against state-of-the-art WFP defenses, achieving 2.5 to 5 times the accuracy of prior work, and in some cases even rendering the defenses useless. Our methods enable to estimate and to communicate to the user the risk of successive page visits within a website (even in the presence of noise pages) to stop before the WFP attack reaches a critical level of confidence.\n\nSOAP: A Social Authentication Protocol\n\nFelix Linker and David Basin, Department of Computer Science, ETH Zurich\n\nSocial authentication has been suggested as a usable authentication ceremony to replace manual key authentication in messaging applications. Using social authentication, chat partners authenticate their peers using digital identities managed by identity providers. In this paper, we formally define social authentication, present a protocol called SOAP that largely automates social authentication, formally prove SOAP's security, and demonstrate SOAP's practicality in two prototypes. One prototype is web-based, and the other is implemented in the open-source Signal messaging application.\n\nUsing SOAP, users can significantly raise the bar for compromising their messaging accounts. In contrast to the default security provided by messaging applications such as Signal and WhatsApp, attackers must compromise both the messaging account and all identity provider-managed identities to attack a victim. In addition to its security and automation, SOAP is straightforward to adopt as it is built on top of the well-established OpenID Connect protocol.\n\nPointerGuess: Targeted Password Guessing Model Using Pointer Mechanism\n\nKedong Xiu and Ding Wang, Nankai University\n\nAvailable Media\n\nMost existing targeted password guessing models view users' reuse behaviors as sequences of edit operations (e.g., insert and delete) performed on old passwords. These atomic edit operations are limited to modifying one character at a time and cannot fully cover users' complex password modification behaviors (e.g., modifying the password structure). This partially leads to a significant gap between the proportion of users' reused passwords and the success rates that existing targeted password models can achieve. To fill this gap, this paper models users' reuse behaviors by focusing on two key components: (1) What they want to copy/keep; (2) What they want to tweak. More specifically, we introduce the pointer mechanism and propose a new targeted guessing model, namely PointerGuess. By hierarchically redefining password reuse from both personal and population-wide perspectives, we can accurately and comprehensively characterize users' password reuse behaviors. Moreover, we propose MS-PointerGuess, which can employ the victim's multiple leaked passwords.\n\nBy employing 13 large-scale real-world password datasets, we demonstrate that PointerGuess is effective: (1) When the victim's password at site A (namely pwA) is known, within 100 guesses, the average success rate of PointerGuess in guessing her password at site B (namely pwB, pwA ≠ pwB) is 25.21% (for common users) and 12.34% (for security-savvy users), respectively, which is 21.23%~71.54% (38.37% on average) higher than its foremost counterparts; (2) When not excluding identical password pairs (i.e., pwA can equal pwB), within 100 guesses, the average success rate of PointerGuess is 48.30% (for common users) and 28.42% (for security-savvy users), respectively, which is 6.31%~15.92% higher than its foremost counterparts; (3) Within 100 guesses, the MS-PointerGuess further improves the cracking success rate by 31.21% compared to PointerGuess.\n\nMetaSafe: Compiling for Protecting Smart Pointer Metadata to Ensure Safe Rust Integrity\n\nMartin Kayondo and Inyoung Bang, Seoul National University; Yeongjun Kwak and Hyungon Moon, UNIST; Yunheung Paek, Seoul National University\n\nRust is a programming language designed with a focus on memory safety. It introduces new concepts such as ownership and performs static bounds checks at compile time to ensure spatial and temporal memory safety. For memory operations or data types whose safety the compiler cannot prove at compile time, Rust either explicitly excludes such portions of the program, termed unsafe Rust, from static analysis, or it relies on runtime enforcement using smart pointers. Existing studies have shown that potential memory safety bugs in such unsafe Rust can bring down the entire program, proposing in-process isolation or compartmentalization as a remedy. However, in this study, we show that the safe Rust remains susceptible to memory safety bugs even with the proposed isolation applied. The smart pointers upon which safe Rust's memory safety is built rely on metadata often stored alongside program data, possibly within reach of attackers. Manipulating this metadata, an attacker can nullify safe Rust's memory safety checks dependent on it, causing memory access bugs and exploitation. In response to this issue, we propose MetaSafe, a mechanism that safeguards smart pointer metadata from such attacks. MetaSafe stores smart pointer metadata in a gated memory region where only a predefined set of metadata management functions can write, ensuring that each smart pointer update does not cause safe Rust's memory safety violation. We have implemented MetaSafe by extending the official Rust compiler and evaluated it with a variety of micro- and application benchmarks. The overhead of MetaSafe is found to be low; it incurs a 3.5% average overhead on the execution time of a web browser benchmarks.\n\nThe overhead of MetaSafe is found to be low; it incurs a 3.5% average overhead on the execution time of a web browser benchmarks.\n\nFormalizing Soundness Proofs of Linear PCP SNARKs\n\nBolton Bailey and Andrew Miller, University of Illinois at Urbana-Champaign\n\nSuccinct Non-interactive Arguments of Knowledge (SNARKs) have seen interest and development from the cryptographic community over recent years, and there are now constructions with very small proof size designed to work well in practice. A SNARK protocol can only be widely accepted as secure, however, if a rigorous proof of its security properties has been vetted by the community. Even then, it is sometimes the case that these security proofs are flawed, and it is then necessary for further research to identify these flaws and correct the record.\n\nTo increase the rigor of these proofs, we create a formal framework in the Lean theorem prover for representing a widespread subclass of SNARKs based on linear PCPs. We then describe a decision procedure for checking the soundness of SNARKs in this class. We program this procedure and use it to formalize the soundness proof of several different SNARK constructions, including the well-known Groth '16.\n\n\"I just hated it and I want my money back\": Data-driven Understanding of Mobile VPN Service Switching Preferences in The Wild\n\nRohit Raj, Mridul Newar, and Mainack Mondal, Indian Institute of Technology, Kharagpur\n\nAvailable Media\n\nVirtual Private Networks (VPNs) are a crucial PrivacyEnhancing Technology (PET) leveraged by millions of users and catered by multiple VPN providers worldwide; thus, understanding the user preferences for the choice of VPN apps should be of importance and interest to the security community. To that end, prior studies looked into the usage, awareness and adoption of VPN users and the perceptions of providers. However, no study so far has looked into the user preferences and underlying reasons for switching among VPN providers and identified features that presumably enhance users' VPN experience. This work aims to bridge this gap and shed light on the underlying factors that drive existing users when they switch from one VPN to another. In this work, we analyzed over 1.3 million reviews from 20 leading VPN apps, identifying 1,305 explicit mentions and intents to switch. Our NLP-based analysis unveiled distinct clusters of factors motivating users to switch. An examination of 376 blogs from six popular VPN recommendation sites revealed biases in the content, and we found ignorance towards user preferences. We conclude by identifying the key implications of our work for different stakeholders. The data and code for this work is available at https://github.com/Mainack/switch-vpn-datacode-sec24.\n\nVOGUES: Validation of Object Guise using Estimated Components\n\nRaymond Muller, Purdue University; Yanmao Man and Ming Li, University of Arizona; Ryan Gerdes, Virginia Tech; Jonathan Petit, Qualcomm; Z. Berkay Celik, Purdue University\n\nAvailable Media\n\nObject Detection (OD) and Object Tracking (OT) are an important part of autonomous systems (AS), enabling them to perceive and reason about their surroundings. While both OD and OT have been successfully attacked, defenses only exist for OD. In this paper, we introduce VOGUES, which combines perception algorithms in AS with logical reasoning about object components to model human perception. VOGUES leverages pose estimation algorithms to reconstruct the constituent components of objects within a scene, which are then mapped via bipartite matching against OD/OT predictions to detect OT attacks. VOGUES's component reconstruction process is designed such that attacks against OD/OT will not implicitly affect its performance. To prevent adaptive attackers from simultaneously evading OD/OT and component reconstruction, VOGUES integrates an LSTM validator to ensure that the component behavior of objects remains consistent over time. Evaluations in both the physical domain and digital domain yield an average attack detection rate of 96.78% and an FPR of 3.29%. Meanwhile, adaptive attacks against VOGUES require perturbations 30x stronger than previously established in OT attack works, significantly increasing the attack difficulty and reducing their practicality.\n\nLotto: Secure Participant Selection against Adversarial Servers in Federated Learning\n\nZhifeng Jiang and Peng Ye, Hong Kong University of Science and Technology; Shiqi He, University of Michigan; Wei Wang, Hong Kong University of Science and Technology; Ruichuan Chen, Nokia Bell Labs; Bo Li, Hong Kong University of Science and Technology\n\nIn Federated Learning (FL), common privacy-enhancing techniques, such as secure aggregation and distributed differential privacy, rely on the critical assumption of an honest majority among participants to withstand various attacks. In practice, however, servers are not always trusted, and an adversarial server can strategically select compromised clients to create a dishonest majority, thereby undermining the system's security guarantees. In this paper, we present Lotto, an FL system that addresses this fundamental, yet underexplored issue by providing secure participant selection against an adversarial server. Lotto supports two selection algorithms: random and informed. To ensure random selection without a trusted server, Lotto enables each client to autonomously determine their participation using verifiable randomness. For informed selection, which is more vulnerable to manipulation, Lotto approximates the algorithm by employing random selection within a refined client pool. Our theoretical analysis shows that Lotto effectively aligns the proportion of server-selected compromised participants with the base rate of dishonest clients in the population. Large-scale experiments further reveal that Lotto achieves time-to-accuracy performance comparable to that of insecure selection methods, indicating a low computational overhead for secure selection.\n\nTerrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation\n\nFabian Bäumer, Marcus Brinkmann, and Jörg Schwenk, Ruhr University Bochum\n\nAvailable Media\n\nThe SSH protocol provides secure access to network services, particularly remote terminal login and file transfer within organizational networks and to over 15 million servers on the open internet. SSH uses an authenticated key exchange to establish a secure channel between a client and a server, which protects the confidentiality and integrity of messages sent in either direction. The secure channel prevents message manipulation, replay, insertion, deletion, and reordering. At the network level, SSH uses the Binary Packet Protocol over TCP.\n\nIn this paper, we show that as new encryption algorithms and mitigations were added to SSH, the SSH Binary Packet Protocol is no longer a secure channel: SSH channel integrity (INT-PST, aINT-PTXT, and INT-sfCTF) is broken for three widely used encryption modes. This allows prefix truncation attacks where encrypted packets at the beginning of the SSH channel can be deleted without the client or server noticing it. We demonstrate several real-world applications of this attack. We show that we can fully break SSH extension negotiation (RFC 8308), such that an attacker can downgrade the public key algorithms for user authentication or turn off a new countermeasure against keystroke timing attacks introduced in OpenSSH 9.5. Further, we identify an implementation flaw in AsyncSSH that, together with prefix truncation, allows an attacker to redirect the victim's login into a shell controlled by the attacker.\n\nWe also performed an internet-wide scan for affected encryption modes and support for extension negotiation. We find that 71.6% of SSH servers support a vulnerable encryption mode, while 63.2% even list it as their preferred choice.\n\nWe identify two root causes that enable these attacks: First, the SSH handshake supports optional messages that are not authenticated. Second, SSH does not reset message sequence numbers when activating encryption keys. Based on this analysis, we propose effective and backward-compatible changes to SSH that mitigate our attacks.\n\nAn Interview Study on Third-Party Cyber Threat Hunting Processes in the U.S. Department of Homeland Security\n\nWilliam P. Maxam III, US Coast Guard Academy; James C. Davis, Purdue University\n\nCybersecurity is a major challenge for large organizations. Traditional cybersecurity defense is reactive. Cybersecurity operations centers keep out adversaries and incident response teams clean up after break-ins. Recently a proactive stage has been introduced: Cyber Threat Hunting (TH) looks for potential compromises missed by other cyber defenses. TH is mandated for federal executive agencies and government contractors. As threat hunting is a new cybersecurity discipline, most TH teams operate without a defined process. The practices and challenges of TH have not yet been documented.\n\nTo address this gap, this paper describes the first interview study of threat hunt practitioners. We obtained access and interviewed 11 threat hunters associated with the U.S. government's Department of Homeland Security. Hour-long interviews were conducted. We analyzed the transcripts with process and thematic coding. We describe the diversity among their processes, show that their processes differ from the TH processes reported in the literature, and unify our subjects' descriptions into a single TH process. We enumerate common TH challenges and solutions according to the subjects. The two most common challenges were difficulty in assessing a Threat Hunter's expertise, and developing and maintaining automation. We conclude with recommendations for TH teams (improve planning, focus on automation, and apprentice new members) and highlight directions for future work (finding a TH process that balances flexibility and formalism, and identifying assessments for TH team performance).\n\niHunter: Hunting Privacy Violations at Scale in the Software Supply Chain on iOS\n\nDexin Liu, Peking University and Alibaba Group; Yue Xiao and Chaoqi Zhang, Indiana University Bloomington; Kaitao Xie and Xiaolong Bai, Alibaba Group; Shikun Zhang, Peking University; Luyi Xing, Indiana University Bloomington\n\nAvailable Media\n\nPrivacy violations and compliance issues in mobile apps are serious concerns for users, developers, and regulators. With many off-the-shelf tools on Android, prior works extensively studied various privacy issues for Android apps. Privacy risks and compliance issues can be equally expected in iOS apps, but have been little studied. In particular, a prominent recent privacy concern was due to diverse third-party libraries widely integrated into mobile apps whose privacy practices are non-transparent. Such a critical supply chain problem, however, was never systematically studied for iOS apps, at least partially due to the lack of the necessary tools.\n\nThis paper presents the first large-scale study, based on our new taint analysis system named iHunter, to analyze privacy violations in the iOS software supply chain. iHunter performs static taint analysis on iOS SDKs to extract taint traces representing privacy data collection and leakage practices. It is characterized by an innovative iOS-oriented symbolic execution that tackles dynamic features of Objective-C and Swift and an NLP-powered generator for taint sources and taint rules. iHunter identified non-compliance in 2,585 SDKs (accounting for 40.4%) out of 6,401 iOS SDKs, signifying a substantial presence of SDKs that fail to adhere to compliance standards. We further found a high proportion (47.2% in 32,478) of popular iOS apps using these SDKs, with practical non-compliance risks violating Apple policies and major privacy laws. These results shed light on the pervasiveness and severity of privacy violations in iOS apps' supply chain. iHunter is thoroughly evaluated for its high effectiveness and efficiency. We are responsibly reporting the results to relevant stakeholders.\n\nInference of Error Specifications and Bug Detection Using Structural Similarities\n\nNiels Dossche and Bart Coppens, Ghent University\n\nError-handling code is a crucial part of software to ensure stability and security. Failing to handle errors correctly can lead to security vulnerabilities such as DoS, privilege escalation, and data corruption. We propose a novel approach to automatically infer error specifications for system software without a priori domain knowledge, while still achieving a high recall and precision. The key insight behind our approach is that we can identify error-handling paths automatically based on structural similarities between error-handling code. We use the inferred error specification to detect three kinds of bugs: missing error checks, incorrect error checks, and error propagation bugs. Our technique uses a combination of path-sensitive, flow-sensitive and both intra-procedural and inter-procedural data-flow analysis to achieve high accuracy and great scalability. We implemented our technique in a tool called ESSS to demonstrate the effectiveness and efficiency of our approach on 7 well-tested, widely-used open-source software projects: OpenSSL, OpenSSH, PHP, zlib, libpng, freetype2, and libwebp. Our tool reported 827 potential bugs in total for all 7 projects combined. We manually categorised these 827 issues into 279 false positives and 541 true positives. Out of these 541 true positives, we sent bug reports and corresponding patches for 46 of them. All the patches were accepted and applied.\n\n\"There are rabbit holes I want to go down that I'm not allowed to go down\": An Investigation of Security Expert Threat Modeling Practices for Medical Devices\n\nRonald Thompson, Madline McLaughlin, Carson Powers, and Daniel Votipka, Tufts University\n\nAvailable Media\n\nThreat modeling is considered an essential first step for \"secure by design\" development. Significant prior work and industry efforts have created novel methods for this type of threat modeling, and evaluated them in various simulated settings. Because threat modeling is context-specific, we focused on medical device security experts as regulators require it, and \"secure by design\" medical devices are seen as a critical step to securing healthcare. We conducted 12 semi-structured interviews with medical device security experts, having participants brainstorm threats and mitigations for two medical devices. We saw these experts do not sequentially work through a list of threats or mitigations according to the rigorous processes described in existing methods and, instead, regularly switch strategies. Our work consists of three major contributions. The first is a two-part process model that describes how security experts 1) determine threats and mitigations for a particular component and 2) move between components. Second, we observed participants leveraging use cases, a strategy not addressed in prior work for threat modeling. Third, we found that integrating safety into threat modeling is critical, albeit unclear. We also provide recommendations for future work.\n\nCDN Cannon: Exploiting CDN Back-to-Origin Strategies for Amplification Attacks\n\nZiyu Lin, Fuzhou University and Tsinghua University; Zhiwei Lin, Sichuan University and Tsinghua University; Ximeng Liu, Fuzhou University; Jianjun Chen and Run Guo, Tsinghua University; Cheng Chen and Shaodong Xiao, Fuzhou University\n\nAvailable Media\n\nContent Delivery Networks (CDNs) provide high availability, speed up content delivery, and safeguard against DDoS attacks for their hosting websites. To achieve the aforementioned objectives, CDN designs several 'back-to-origin' strategies that proactively pre-pull resources and modify HTTP requests and responses. However, our research reveals that these 'back-to-origin' strategies prioritize performance over security, which can lead to excessive consumption of the website's bandwidth.\n\nWe have proposed a new class of amplification attacks called Back-to-Origin Amplification (BtOAmp) Attacks. These attacks allow malicious attackers to exploit the 'back-to-origin' strategies, triggering the CDN to greedily demand more-than-necessary resources from websites, which finally blows the websites. We evaluated the feasibility and real-world impacts of 'BtOAmp' attacks on fourteen popular CDNs. With real-world threat evaluation, our attack threatens all mainstream websites hosted on CDNs. We responsibly disclosed the details of our attack to the affected CDN vendors and proposed possible mitigation solutions.\n\nArcanum: Detecting and Evaluating the Privacy Risks of Browser Extensions on Web Pages and Web Content\n\nQinge Xie, Manoj Vignesh Kasi Murali, Paul Pearce, and Frank Li, Georgia Institute of Technology\n\nModern web browsers support rich extension ecosystems that provide users with customized and flexible browsing experiences. Unfortunately, the flexibility of extensions also introduces the potential for abuse, as an extension with sufficient permissions can access and surreptitiously leak sensitive and private browsing data to the extension's authors or third parties. Prior work has explored such extension behavior, but has been limited largely to meta-data about browsing rather than the contents of web pages, and is also based on older versions of browsers, web standards, and APIs, precluding its use for analysis in a modern setting.\n\nIn this work, we develop Arcanum, a dynamic taint tracking system for modern Chrome extensions designed to monitor the flow of user content from web pages. Arcanum defines a variety of taint sources and sinks, allowing researchers to taint specific parts of pages at runtime via JavaScript, and works on modern extension APIs, JavaScript APIs, and versions of Chromium. We deploy Arcanum to test all functional extensions currently in the Chrome Web Store for the automated exfiltration of user data across seven sensitive websites: Amazon, Facebook, Gmail, Instagram, LinkedIn, Outlook, and PayPal. We observe significant privacy risks across thousands of extensions, including hundreds of extensions automatically extracting user content from within web pages, impacting millions of users. Our findings demonstrate the importance of user content within web pages, and the need for stricter privacy controls on extensions.\n\nLoopy Hell(ow): Inﬁnite Traffic Loops at the Application Layer\n\nYepeng Pan, Anna Ascheman, and Christian Rossow, CISPA Helmholtz Center for Information Security\n\nDenial-of-Service (DoS) attacks have long been a persistent threat to network infrastructures. Existing attack primitives require attackers to continuously send traffic, such as in SYN floods, amplification attacks, or application-layer DoS. In contrast, we study the threat of application-layer traffic loops, which are an almost cost-free attack primitive alternative. Such loops exist, e.g., if two servers consider messages sent to each other as malformed and respond with errors that again trigger error messages. Attackers can send a single IP-spoofed loop trigger packet to initiate an infinite loop among two servers. But despite the severity of traffic loops, to the best of our knowledge, they have never been studied in greater detail.\n\nIn this paper, we thus investigate the threat of application-layer traffic loops. To this end, we propose a systematic approach to identify loops among real servers. Our core idea is to learn the response functions of all servers of a given application-layer protocol, encode this knowledge into a loop graph, and finally, traverse the graph to spot looping server pairs. Using the proposed method, we examined traffic loops among servers running both popular (DNS, NTP, and TFTP) and legacy (Daytime, Time, Active Users, Chargen, QOTD, and Echo) UDP protocols and confirmed the prevalence of traffic loops. In total, we identified approximately 296k servers in IPv4 vulnerable to traffic loops, providing attackers the opportunity to abuse billions of loop pairs.\n\nSingle Pass Client-Preprocessing Private Information Retrieval\n\nArthur Lazzaretti and Charalampos Papamanthou, Yale University\n\nAvailable Media\n\nRecently, many works have considered Private Information Retrieval (PIR) with client-preprocessing: In this model a client and a server jointly run a preprocessing phase, after which client queries run in time sublinear in the database size. However, the preprocessing phase is expensive—proportional to λ N, where λ is the security parameter (e.g., λ=128).\n\nIn this paper we propose SinglePass, the first PIR protocol that is concretely optimal with respect to client-preprocessing, requiring exactly a single linear pass over the database. Our approach yields a preprocessing speedup ranging from 45× to 100× and a query speedup of up to 20× when compared to previous state-of-the-art schemes (e.g., Checklist, USENIX SECURITY 2021, making preprocessing PIR more attractive for a myriad of use cases that are \"session-based\".\n\nIn addition to practical preprocessing, SinglePass features constant-time updates (additions/edits). Previously, the best known approach for handling updates in client-preprocessing PIR had complexity OlogN, while also adding a logN factor to the bandwidth. We implement our update algorithm and show concrete speedups of about 20× over previous state-of-the-art updatable schemes (e.g., Checklist).\n\nLogic Gone Astray: A Security Analysis Framework for the Control Plane Protocols of 5G Basebands\n\nKai Tu, Abdullah Al Ishtiaq, Syed Md Mukit Rashid, Yilu Dong, Weixuan Wang, Tianwei Wu, and Syed Rafiul Hussain, Pennsylvania State University\n\nWe develop 5GBaseChecker— an efficient, scalable, and dynamic security analysis framework based on differential testing for analyzing 5G basebands' control plane protocol interactions. 5GBaseChecker first captures basebands' protocol behaviors as a finite state machine (FSM) through black-box automata learning. To facilitate efficient learning and improve scalability, 5GBaseChecker introduces novel hybrid and collaborative learning techniques. 5GBaseChecker then identifies input sequences for which the extracted FSMs provide deviating outputs. Finally, 5GBaseChecker leverages these deviations to efficiently identify the security properties from specifications and use those to triage if the deviations found in 5G basebands violate any properties. We evaluated 5GBaseChecker with 17 commercial 5G basebands and 2 open-source UE implementations and uncovered 22 implementation-level issues, including 13 exploitable vulnerabilities and 2 interoperability issues.\n\nDONAPI: Malicious NPM Packages Detector using Behavior Sequence Knowledge Mapping\n\nCheng Huang, Nannan Wang, Ziyan Wang, Siqi Sun, Lingzi Li, Junren Chen, Qianchong Zhao, Jiaxuan Han, and Zhen Yang, Sichuan University; Lei Shi, Huawei Technologies\n\nWith the growing popularity of modularity in software development comes the rise of package managers and language ecosystems. Among them, npm stands out as the most extensive package manager, hosting more than 2 million third-party open-source packages that greatly simplify the process of building code. However, this openness also brings security risks, as evidenced by numerous package poisoning incidents.\n\nIn this paper, we synchronize a local package cache containing more than 3.4 million packages in near real-time to give us access to more package code details. Further, we perform manual inspection and API call sequence analysis on packages collected from public datasets and security reports to build a hierarchical classification framework and behavioral knowledge base covering different sensitive behaviors. In addition, we propose the DONAPI, an automatic malicious npm packages detector that combines static and dynamic analysis. It makes preliminary judgments on the degree of maliciousness of packages by code reconstruction techniques and static analysis, extracts dynamic API call sequences to confirm and identify obfuscated content that static analysis can not handle alone, and finally tags malicious software packages based on the constructed behavior knowledge base. To date, we have identified and manually confirmed 325 malicious samples and discovered 2 unusual API calls and 246 API call sequences that have not appeared in known samples.\n\nVibSpeech: Exploring Practical Wideband Eavesdropping via Bandlimited Signal of Vibration-based Side Channel\n\nChao Wang, Feng Lin, Hao Yan, and Tong Wu, Zhejiang University; Wenyao Xu, University at Buffalo, the State University of New York; Kui Ren, Zhejiang University\n\nVibration-based side channel is an ever-present threat to speech privacy. However, due to the target's frequency response with a rapid decay or limited sampling rate of malicious sensors, the acquired vibration signals are often distorted and narrowband, which fails an intelligible speech recovery. This paper tries to answer that when the side-channel data has only a very limited bandwidth (<500Hz), is it feasible to achieve a wideband eavesdropping based on a practical assumption? Our answer is YES based on the assumption that a short utterance (2s-4s) of the victim is exposed to the attacker. What is most surprising is that the attack can recover speech with a bandwidth of up to 8kHz. This covers almost all phonemes (voiced and unvoiced) in human speech and causes practical threat. The core idea of the attack is using vocal-tract features extracted from the victim's utterance to compensate for the side-channel data. To demonstrate the threat, we proposed a vocal-guided attack scheme called VibSpeech and built a prototype based on a mmWave sensor to penetrate soundproof walls for vibration sensing. We solved challenges of vibration artifact suppression and a generalized scheme free of any target's training data. We evaluated VibSpeech with extensive experiments and validated it on the IMU-based method. The results indicated that VibSpeech can recover intelligible speech with an average MCD/SNR of 3.9/5.4dB.\n\n\"What Keeps People Secure is That They Met The Security Team\": Deconstructing Drivers And Goals of Organizational Security Awareness\n\nJonas Hielscher, Ruhr University Bochum; Simon Parkin, Delft University of Technology\n\nSecurity awareness campaigns in organizations now collectively cost billions of dollars annually. There is increasing focus on ensuring certain security behaviors among employees. On the surface, this would imply a user-centered view of security in organizations. Despite this, the basis of what security awareness managers do and what decides this are unclear. We conducted n=15 semi-structured interviews with full-time security awareness managers, with experience across various national and international companies in European countries, with thousands of employees. Through thematic analysis, we identify that success in awareness management is fragile while having the potential to improve; there are a range of restrictions, and mismatched drivers and goals for security awareness, affecting how it is structured, delivered, measured, and improved. We find that security awareness as a practice is underspecified, and split between messaging around secure behaviors and connecting to employees, with a lack of recognition for the measures that awareness managers regard as important. We discuss ways forward, including alternative indicators of success, and security usability advocacy for employees.\n\nPatchCURE: Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses\n\nChong Xiang, Tong Wu, and Sihui Dai, Princeton University; Jonathan Petit, Qualcomm Technologies, Inc.; Suman Jana, Columbia University; Prateek Mittal, Princeton University\n\nState-of-the-art defenses against adversarial patch attacks can now achieve strong certifiable robustness with a marginal drop in model utility. However, this impressive performance typically comes at the cost of 10-100x more inference-time computation compared to undefended models — the research community has witnessed an intense three-way trade-off between certifiable robustness, model utility, and computation efficiency. In this paper, we propose a defense framework named PatchCURE to approach this trade-off problem. PatchCURE provides sufficient \"knobs\" for tuning defense performance and allows us to build a family of defenses: the most robust PatchCURE instance can match the performance of any existing state-of-the-art defense (without efficiency considerations); the most efficient PatchCURE instance has similar inference efficiency as undefended models. Notably, PatchCURE achieves state-of-the-art robustness and utility performance across all different efficiency levels, e.g., 16-23% absolute clean accuracy and certified robust accuracy advantages over prior defenses when requiring computation efficiency to be close to undefended models. The family of PatchCURE defenses enables us to flexibly choose appropriate defenses to satisfy given computation and/or utility constraints in practice.\n\nTowards More Practical Threat Models in Artificial Intelligence Security\n\nKathrin Grosse, EPFL; Lukas Bieringer, QuantPi; Tarek R. Besold, TU Eindhoven; Alexandre M. Alahi, EPFL\n\nAvailable Media\n\nRecent works have identified a gap between research and practice in artificial intelligence security: threats studied in academia do not always reflect the practical use and security risks of AI. For example, while models are often studied in isolation, they form part of larger ML pipelines in practice. Recent works also brought forward that adversarial manipulations introduced by academic attacks are impractical. We take a first step towards describing the full extent of this disparity. To this end, we revisit the threat models of the six most studied attacks in AI security research and match them to AI usage in practice via a survey with 271 industrial practitioners. On the one hand, we find that all existing threat models are indeed applicable. On the other hand, there are significant mismatches: research is often too generous with the attacker, assuming access to information not frequently available in real-world settings. Our paper is thus a call for action to study more practical threat models in artificial intelligence security.\n\nDNN-GP: Diagnosing and Mitigating Model's Faults Using Latent Concepts\n\nShuo Wang, Shanghai Jiao Tong University; Hongsheng Hu, CSIRO's Data61; Jiamin Chang, University of New South Wales and CSIRO's Data61; Benjamin Zi Hao Zhao, Macquarie University; Qi Alfred Chen, University of California, Irvine; Minhui Xue, CSIRO's Data61\n\nDespite the impressive capabilities of Deep Neural Networks (DNN), these systems remain fault-prone due to unresolved issues of robustness to perturbations and concept drift. Existing approaches to interpreting faults often provide only low-level abstractions, while struggling to extract meaningful concepts to understand the root cause. Furthermore, these prior methods lack integration and generalization across multiple types of faults. To address these limitations, we present a fault diagnosis tool (akin to a General Practitioner) DNN-GP, an integrated interpreter designed to diagnose various types of model faults through the interpretation of latent concepts. DNN-GP incorporates probing samples derived from adversarial attacks, semantic attacks, and samples exhibiting drifting issues to provide a comprehensible interpretation of a model's erroneous decisions. Armed with an awareness of the faults, DNN-GP derives countermeasures from the concept space to bolster the model's resilience. DNN-GP is trained once on a dataset and can be transferred to provide versatile, unsupervised diagnoses for other models, and is sufficiently general to effectively mitigate unseen attacks. DNN-GP is evaluated on three real-world datasets covering both attack and drift scenarios to demonstrate state-to the-art detection accuracy (near 100%) with low false positive ra"
    }
}