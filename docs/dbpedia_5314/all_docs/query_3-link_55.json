{
    "id": "dbpedia_5314_3",
    "rank": 55,
    "data": {
        "url": "https://charity.wtf/2024/08/07/is-it-time-to-version-observability-signs-point-to-yes/",
        "read_more_link": "",
        "language": "en",
        "title": "Is It Time To Version Observability? (Signs Point To Yes)",
        "top_image": "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-51.jpeg?fit=754%2C666&ssl=1",
        "meta_img": "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-51.jpeg?fit=754%2C666&ssl=1",
        "images": [
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-44.jpeg?resize=204%2C189&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-43.jpeg?resize=199%2C200&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-47.jpeg?resize=227%2C141&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-42.jpeg?resize=238%2C138&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-56.jpeg?resize=200%2C201&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-39.jpeg?resize=195%2C200&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-35.jpeg?resize=200%2C200&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-8.jpeg?resize=205%2C179&ssl=1",
            "https://i0.wp.com/charity.wtf/wp-content/uploads/2024/08/newpix-36.jpeg?resize=287%2C121&ssl=1",
            "https://secure.gravatar.com/avatar/1fb2fc4c3c27587d4b8be880affbd6b3?s=50&r=pg",
            "https://secure.gravatar.com/avatar/17349fba9879bad567da61d9f333044f?s=50&r=pg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-08-07T00:00:00",
        "summary": "",
        "meta_description": "Augh! I am so behind on so much writing, I‚Äôm even behind on writing shit that I need to reference in order to write other pieces of writing. Like this one. So we‚Äôre just gonna do this quick and dirty on the personal blog, and not bother bringing it up to the editorial standards of...anyone‚Ä¶",
        "meta_lang": "en",
        "meta_favicon": "https://s0.wp.com/i/webclip.png",
        "meta_site_name": "charity.wtf",
        "canonical_link": "https://charity.wtf/2024/08/07/is-it-time-to-version-observability-signs-point-to-yes/",
        "text": "Augh! I am so behind on so much writing, I‚Äôm even behind on writing shit that I need to reference in order to write other pieces of writing. Like this one. So we‚Äôre just gonna do this quick and dirty on the personal blog, and not bother bringing it up to the editorial standards of‚Ä¶anyone else‚Äôs sites. üò¨\n\nIf you‚Äôd rather consume these ideas in other ways:\n\nI gave a keynote at SRECon in March\n\nHere is a slide deck of my slides from CTO Craft Con London in May\n\nA Screaming In The Cloud podcast with Corey Quinn in April\n\nMy piece earlier in the year on the Cost Crisis in Observability Tooling touched on some of the concepts too\n\nMatt Sanabria wrote a great piece comparing us and a bunch of other observability vendors in 2024.\n\nWhat does observability mean? No one knows\n\nIn 2016, we first borrowed the term ‚Äúobservability‚Äù from the wikipedia entry for control systems observability, where it is a measure of your ability to understand internal system states just by observing its outputs. We (Honeycomb) then spent a couple of years trying to work out how that definition might apply to software systems. Many twitter threads, podcasts, blog posts and lengthy laundry lists of technical criteria emerged from that work, including a whole ass book.\n\nIn 2018, Peter Bourgon wrote a blog post proposing that ‚Äúobservability has three pillars: metrics, logs and traces. Ben Sigelman did a masterful job of unpacking why metrics, logs and traces are just telemetry. However, lots of people latched on to the three pillars language: vendors because they (coincidentally!) had metrics products, logging products, and tracing products to sell, engineers because it described their daily reality.\n\nSince then the industry has been stuck in kind of a weird space, where the language used to describe the problems and solutions has evolved, but the solutions themselves are largely the same ones as five years ago, or ten years ago. They‚Äôve improved, of course ‚Äî massively improved ‚Äî but structurally they‚Äôre variations on the same old pre-aggregated metrics.\n\nIt has gotten harder and harder to speak clearly about different philosophical approaches and technical solutions without wading deep into the weeds, where no one but experts should reasonably have to go.\n\nThis is what semantic versioning was made for\n\nLook, I am not here to be the language police. I stopped correcting people on twitter back in 2019. We all do observability! One big happy family. üëç\n\nI AM here to help engineers think clearly and crisply about the problems in front of them. So here we go. Let‚Äôs call the metrics, logs and traces crowd ‚Äî the ‚Äúthree pillars‚Äù generation of tooling ‚Äî that‚Äôs ‚ÄúObservability 1.0‚Äú. Tools like Honeycomb, which are built based on arbitrarily-wide structured log events, a single source of truth ‚Äî that‚Äôs ‚ÄúObservability 2.0‚Äú.\n\nHere is the twitter thread where I first teased out the differences between these generations of tooling (all the way back in December, yes, that‚Äôs how long I‚Äôve been meaning to write this üòÖ).\n\nThis is literally the problem that semantic versioning was designed to solve, by the way. Major version bumps are reserved for backwards-incompatible, breaking changes, and that‚Äôs what this is. You cannot simultaneously store your data across both multiple pillars and a single source of truth.\n\nIncompatible. Breaking change. O11y 1.0, meet O11y 2.0.\n\nsmall technical changes can unlock waves of powerful sociotechnical transformation\n\nThere are a LOT of ramifications and consequences that flow from this one small change in how your data gets stored. I don‚Äôt have the time or space to go into all of them here, but I will do a quick overview of the most important ones.\n\nThe historical analogue that keeps coming to mind for me is virtualization. VMs are old technology, they‚Äôve been around since the 70s. But it wasn‚Äôt until the late 90s that VMware productized it, unlocking wave after wave of change, from cloud computing and SaaS to the very DevOps movement itself.\n\nI believe the shift to observability 2.0 holds a similarly massive potential for change, based on what I see happening today, with teams who have already made the leap. Why? In a word, precision. O11y 1.0 can only ever give you aggregates and random exemplars. O11y 2.0, on the other hand, can tell you precisely what happened when you flipped a flag, deployed to a canary, or made any other change in production.\n\nWill these waves of sociotechnical transformation ever be realized? Who knows. The changes that get unlocked will depend to some extent on us (Honeycomb), and to an even greater extent on engineers like you. Anyway, I‚Äôll talk about this more some other time. Right now, I just want to establish a baseline for this vocabulary.\n\n1.0 vs 2.0: How does the data get stored?\n\n1.0üíô O11y 1.0 has many sources of truth, in many different formats. Typically, you end up storing your data across metrics, logs, traces, APM, RUM, profiling, and possibly other tools as well. Some folks even find themselves falling back to B.I. (business intelligence) tools like Tableau in a pinch to understand what‚Äôs happening on their systems.\n\nEach of these tools are siloed, with no connective tissue, or only a few, predefined connective links that connect e.g. a specific metric to a specific log line. Aggregation is done at write time, so you have to decide up front which data points to collect and which questions you want to be able to ask. You may find yourself eyeballing graph shapes and assuming they must be the same data, or copy-pasting IDs around from logging to tracing tools and back.\n\n2.0 üíö Data gets stored in arbitrarily-wide structured log events (often called ‚Äúcanonical logs‚Äú), often with trace and span IDs appended. You can visualize the events over time as a\n\ntrace, or slice and dice your data to zoom in to individual events, or zoom out to a birds-eye view. You can interact with your data by group by, break down, etc.\n\nYou aggregate at read time, and preserve raw events for ad hoc querying. Hopefully, you derive your SLO data from the same data you query! Think of it as B.I. for systems/app/business data, all in one place. You can derive metrics, or logs, or traces, but it‚Äôs all the same data.\n\n1.0 vs 2.0: on metrics vs logs\n\n1.0 üíô The workhorse of o11y 1.0 is metrics. RUM tools are built on metrics to understand browser user sessions. APM tools are built using metrics to understand application performance. Long ago, the decision was made to use metrics as the source of truth for telemetry because they are cheap and fast, and hardware used to be incredibly expensive.\n\nThe more complex our systems get, the worse of a tradeoff this becomes. Metrics are a terrible building block for understanding rich data, because you have to discard all that valuable context at write time, and they don‚Äôt support high (or even medium!) cardinality data. All you can do to enrich the data is via tags.\n\nMetrics are a great tool for cheaply summarizing vast quantities of data. They are not equipped to help you introspect or understand complex systems. You will go broke and go mad if you try.\n\n2.0 üíö The building block of o11y 2.0 is wide, structured log events. Logs are infinitely more powerful, useful and cost-effective than metrics are because they preserve context and relationships between data, and data is made valuable by context. Logs also allow you to capture high cardinality data and data relationships/structures, which give you the ability to compute outliers and identify related events.\n\n1.0 vs 2.0: Who uses it, and how?\n\n1.0 üíô Observability 1.0 is predominantly about how you operate your code. It centers around errors, incidents, crashes, bugs, user reports and problems. MTTR, MTTD, and reliability are top concerns.\n\nO11y 1.0 is typically consumed using static dashboards ‚Äî lots and lots of static dashboards. ‚ÄúSingle pane of glass‚Äù is often mentioned as a holy grail. It‚Äôs easy to find something once you know what you‚Äôre looking for, but you need to know to look for it before you can find it.\n\n2.0 üíö If o11y 1.0 is about how you operate your code, o11y 2.0 is about how you develop your code. O11y 2.0 is what underpins the entire software development lifecycle, enabling engineers to connect feedback loops end to end so they get fast feedback on the changes they make, while it‚Äôs still fresh in their heads. This is the foundation of your team‚Äôs ability to move swiftly, with confidence. It isn‚Äôt just about understanding bugs and outages, it‚Äôs about proactively understanding your software and how your users are experiencing it.\n\nThus, o11y 2.0 has a much more exploratory, open-ended interface. Any dashboards should be dynamic, allowing you to drill down into a question or follow a trail of breadcrumbs as part of the debugging/understanding process. The canonical question of o11y 2.0 is ‚Äúhere‚Äôs a thing I care about ‚Ä¶ why do I care about it? What are all of the ways it is different from all the other things I don‚Äôt care for?‚Äù\n\nWhen it comes to understanding your software, it‚Äôs often harder to identify the question than the answer. Once you know what the question is, you probably know the answer too. With o11y 1.0, it‚Äôs very easy to find something once you know what you‚Äôre looking for. With o11y 2.0, that constraint is removed.\n\n1.0 vs 2.0: How do you interact with production?\n\n1.0 üíô You deploy your code and wait to get paged. ü§û Your job is done as a developer when you commit your code and tests pass.\n\n2.0 üíö You practice observability-driven development: as you write your code, you instrument it. You deploy to production, then inspect your code through the lens of the instrumentation you just wrote. Is it behaving the way you expected it to? Does anything else look ‚Ä¶ weird?\n\nYour job as a developer isn‚Äôt done until you know it‚Äôs working in production. Deploying to production is the beginning of gaining confidence in your code, not the denouement.\n\n1.0 vs 2.0: How do you debug?\n\n1.0 üíô You flip from dashboard to dashboard, pattern-matching and looking for similar shapes with your eyeballs.\n\nYou lean heavily on intuition, educated guesses, past experience, and a mental model of the system. This means that the best debuggers are ALWAYS the engineers who have been there the longest and seen the most.\n\nYour debugging sessions are search-first: you start by searching for something you know should exist.\n\n2.0 üíö You check your instrumentation, or you watch your SLOs. If something looks off, you see what all the mysterious events have in common, or you start forming hypotheses, asking a question, considering the result, and forming another one based on the answer. You interrogate your systems, following the trail of breadcrumbs to the answer, every time.\n\nYou don‚Äôt have to guess or rely on elaborate, inevitably out-of-date mental models. The data is right there in front of your eyes. The best debuggers are the people who are the most curious.\n\nYour debugging questions are analysis-first: you start with your user‚Äôs experience.\n\n1.0 vs 2.0: The cost model\n\n1.0 üíô You pay to store your data again and again and again and again, multiplied by all the different formats and tool types you are paying to store it in. Cost goes up at a multiplier of your traffic increase. I wrote a whole piece earlier this year on the cost crisis in observability tooling, so I won‚Äôt go into it in depth here.\n\nAs your costs increase, the value you get out of your tools actually decreases.\n\nIf you are using metrics-based products, your costs go up based on cardinality. ‚ÄúCustom metrics‚Äù is a euphemism for ‚Äúcardinality‚Äù; ‚Äú100 free custom metrics‚Äù actually means ‚Äú100 free cardinality‚Äù, aka unique values.\n\n2.0 üíö You pay to store your data once. As your costs go up, the value you get out goes up too. You have powerful, surgical options for controlling costs via head-based or tail-based dynamic sampling.\n\nYou can have infinite cardinality. You are encouraged to pack hundreds or thousands of dimensions in per event, and any or all of those dimensions can be any data type you want. This luxurious approach to cardinality and data is one of the least well understood aspects of the switch from o11y 1.0 to 2.0.\n\nMany observability engineering teams have spent their entire careers massaging cardinality to control costs. What if you just .. didn‚Äôt have to do that? What would you do with your lives? If you could just store and query on all the crazy strings you want, forever? üåà\n\nMetrics are a bridge to our past\n\nWhy are observability 1.0 tools so unbelievably, eyebleedingly expensive? As anyone who works with data can tell you, this is always what happens when you use the wrong tool for the job. Once again, metrics are a great tool for summarizing vast quantities of data. When it comes to understanding complex systems, they flail.\n\nI wrote a whole whitepaper earlier this year that did a deep dive into exactly why tools built on top of metrics are so unavoidably costly. If you want the gnarly detail, download that.\n\nThe TLDR is this: tools built on metrics ‚Äî whether RUM, APM, dashboards, etc ‚Äî are a bridge to our past. If there‚Äôs one thing I‚Äôm certain of, it‚Äôs that tools built on top of wide, structured logs are the bridge to our future.\n\nWide, structured log events are the bridge to our future\n\nFive years from now, I predict that the center of gravity will have swung dramatically; all modern engineering teams will be powering their telemetry off of tools backed by wide, structured log events, not metrics. It‚Äôs getting harder and harder and harder to try and wring relevant insights out of metrics-based observability tools. The end of the ZIRP era is bringing unprecedented cost pressure to bear, and it‚Äôs simply a matter of time.\n\nThe future belongs to tools built on wide, structured log events ‚Äî a single source of truth that you can trace over time, or zoom in, zoom out, derive SLOs from, etc.\n\nIt‚Äôs the only way to understand our systems in all their skyrocketing complexity. This constant dance with cost vs cardinality consumes entire teams worth of engineers and adds zero value. It adds negative value.\n\nAnd here‚Äôs the weirdest part. The main thing holding most teams back psychologically from embracing o11y 2.0 seems to be the entrenched difficulties they have grappling with o11y 1.0, and their sense that they can‚Äôt adopt 2.0 until they get a handle on 1.0. Which gets things exactly backwards.\n\nBecause observability 2.0 is so much easier, simpler, and more cost effective than 1.0.\n\nobservability 1.0 *is* the hard way\n\nIt‚Äôs so fucking hard. We‚Äôve been doing it so long that we are blind to just how HARD it is. But trying to teach teams of engineers to wrangle metrics, to squeeze the questions they want to ask into multiple abstract formats scattered across many different tools, with no visibility into what they‚Äôre doing until it comes out eventually in form of a giant bill‚Ä¶ it‚Äôs fucking hard.\n\nObservability 2.0 is so much simpler. You want data, you just toss it in. Format? don‚Äôt care. Cardinality? don‚Äôt care.\n\nYou want to ask the question, you just ask it. Format? don‚Äôt care.\n\nTeams are beating themselves up trying to master an archaic, unmasterable set of technical tradeoffs based on data types from the 80s. It‚Äôs an unwinnable war. We can‚Äôt understand today‚Äôs complex systems without context-rich, explorable data.\n\nWe need more options for observability 2.0 tooling\n\nMy hope is that by sketching out these technical differences between o11y 1.0 and 2.0, we can begin to collect and build up a vendor-neutral library of o11y 2.0 options for folks. The world needs more options for understanding complex systems besides just Honeycomb and Baselime.\n\nThe world desperately needs an open source analogue to Honeycomb ‚Äî something built for wide structured events, stored in a columnar store (or even just Clickhouse), with an interactive interface. Even just a written piece on how you solved it at your company would help move the industry forward.\n\nMy other hope is that people will stop building new observability startups built on metrics. Y‚Äôall, Datadog and Prometheus are the last, best metrics-backed tools that will ever be built. You can‚Äôt catch up to them or beat them at that; no one can. Do something different. Build for the next generation of software problems, not the last generation.\n\nIf anyone knows of anything along these lines, please send me links? I will happily collect them and signal boost. Honeycomb is a great, lifechanging tool (and we have a generous free tier, hint hint) but one option does not a movement make.\n\n<3 charity\n\nP.S. Here‚Äôs a great piece written by Ivan Burmistrov on his experience using observability 2.0 type tooling at Facebook ‚Äî namely Scuba, which was the inspiration for Honeycomb. It‚Äôs a terrific piece and you should read it.\n\nP.P.S. And if you‚Äôre curious, here‚Äôs the long twitter thread I wrote in October of 2023 on how we lost the battle to define observability:"
    }
}