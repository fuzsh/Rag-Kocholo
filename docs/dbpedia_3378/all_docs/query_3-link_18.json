{
    "id": "dbpedia_3378_3",
    "rank": 18,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/",
        "read_more_link": "",
        "language": "en",
        "title": "Multiple-instance-learning-based detection of coeliac disease in histological whole-slide images",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-jpathinf.gif",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/ga1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/gr1.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/gr2.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/gr3.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/gr4.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/gr5.jpg",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/bin/gr6.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "J. Denholm",
            "B.A. Schreiber",
            "S.C. Evans",
            "O.M. Crook",
            "A. Sharma",
            "J.L. Watson",
            "H. Bancroft",
            "G. Langman",
            "J.D. Gilbey",
            "C.-B. Schönlieb"
        ],
        "publish_date": "2022-08-27T00:00:00",
        "summary": "",
        "meta_description": "We present a multiple-instance-learning-based scheme for detecting coeliac disease, an autoimmune disorder affecting the intestine, in histological whole-slide images (WSIs) of duodenal biopsies. We train our model to detect 2 distinct classes, normal ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9808019/",
        "text": "J Pathol Inform. 2022; 13: 100151.\n\nPMCID: PMC9808019\n\nPMID: 36605111\n\nMultiple-instance-learning-based detection of coeliac disease in histological whole-slide images\n\n,a,b,c,⁎ ,b,c ,c ,d ,c ,e ,f ,f ,b ,b ,g and a,c\n\nJ. Denholm\n\naLyzeum Ltd, Salisbury House, Station Road, Cambridge CB1 2LA, Cambridgeshire, UK\n\nbDepartment of Applied Maths and Theoretical Physics, University of Cambridge, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WA, Cambridgeshire, UK\n\ncDepartment of Pathology, University of Cambridge, Tennis Court Road, Cambridge CB2 1QP, Cambridgeshire, UK\n\nFind articles by J. Denholm\n\nB.A. Schreiber\n\nbDepartment of Applied Maths and Theoretical Physics, University of Cambridge, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WA, Cambridgeshire, UK\n\ncDepartment of Pathology, University of Cambridge, Tennis Court Road, Cambridge CB2 1QP, Cambridgeshire, UK\n\nFind articles by B.A. Schreiber\n\nS.C. Evans\n\ncDepartment of Pathology, University of Cambridge, Tennis Court Road, Cambridge CB2 1QP, Cambridgeshire, UK\n\nFind articles by S.C. Evans\n\nO.M. Crook\n\ndThe Alan Turing Institute, 96 Euston Rd, London NW1 2DB, UK\n\nFind articles by O.M. Crook\n\nA. Sharma\n\ncDepartment of Pathology, University of Cambridge, Tennis Court Road, Cambridge CB2 1QP, Cambridgeshire, UK\n\nFind articles by A. Sharma\n\nJ.L. Watson\n\neOxford Medical School, University of Oxford, S Parks Road, Oxford OX1 3PL, Oxfordshire, UK\n\nFind articles by J.L. Watson\n\nH. Bancroft\n\nfDepartment of Cellular Pathology, Birmingham Heartlands Hospital, University Hospitals Birmingham, 45 Bordesley Green East, Birmingham B9 5SS, West Midlands, UK\n\nFind articles by H. Bancroft\n\nG. Langman\n\nfDepartment of Cellular Pathology, Birmingham Heartlands Hospital, University Hospitals Birmingham, 45 Bordesley Green East, Birmingham B9 5SS, West Midlands, UK\n\nFind articles by G. Langman\n\nJ.D. Gilbey\n\nbDepartment of Applied Maths and Theoretical Physics, University of Cambridge, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WA, Cambridgeshire, UK\n\nFind articles by J.D. Gilbey\n\nC.-B. Schönlieb\n\nbDepartment of Applied Maths and Theoretical Physics, University of Cambridge, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WA, Cambridgeshire, UK\n\nFind articles by C.-B. Schönlieb\n\nM.J. Arends\n\ngDivision of Pathology, University of Edinburgh, Cancer Research UK Edinburgh Centre, Western General Hospital, Crewe Road South, Edinburgh, EH4 2XR, Lothian, Scotland\n\nFind articles by M.J. Arends\n\nE.J. Soilleux\n\naLyzeum Ltd, Salisbury House, Station Road, Cambridge CB1 2LA, Cambridgeshire, UK\n\ncDepartment of Pathology, University of Cambridge, Tennis Court Road, Cambridge CB2 1QP, Cambridgeshire, UK\n\nFind articles by E.J. Soilleux\n\naLyzeum Ltd, Salisbury House, Station Road, Cambridge CB1 2LA, Cambridgeshire, UK\n\nbDepartment of Applied Maths and Theoretical Physics, University of Cambridge, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WA, Cambridgeshire, UK\n\ncDepartment of Pathology, University of Cambridge, Tennis Court Road, Cambridge CB2 1QP, Cambridgeshire, UK\n\ndThe Alan Turing Institute, 96 Euston Rd, London NW1 2DB, UK\n\neOxford Medical School, University of Oxford, S Parks Road, Oxford OX1 3PL, Oxfordshire, UK\n\nfDepartment of Cellular Pathology, Birmingham Heartlands Hospital, University Hospitals Birmingham, 45 Bordesley Green East, Birmingham B9 5SS, West Midlands, UK\n\ngDivision of Pathology, University of Edinburgh, Cancer Research UK Edinburgh Centre, Western General Hospital, Crewe Road South, Edinburgh, EH4 2XR, Lothian, Scotland\n\n⁎Corresponding author. ku.ca.mac@949dj\n\nCopyright © 2022 The Author(s)\n\nThis is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\nAssociated Data\n\nSupplementary Materials\n\nmmc1.zip (25M)\n\nGUID: 1ED9F744-91F0-437A-894F-3708AADC06D3\n\nmmc2.pdf (1.9M)\n\nGUID: 6F4FB831-AD79-4099-9D26-0FFC5C283331\n\nmmc3.pdf (3.1M)\n\nGUID: BC3C1C0A-6033-44F9-BE15-F36FA8A92201\n\nmmc4.pdf (2.5M)\n\nGUID: 5A8DAEF9-16DE-43DA-98ED-BDA8EFBB8B56\n\nmmc5.pdf (4.5M)\n\nGUID: 1D58695A-102E-4E4C-A791-D571D55D9C89\n\nAbstract\n\nWe present a multiple-instance-learning-based scheme for detecting coeliac disease, an autoimmune disorder affecting the intestine, in histological whole-slide images (WSIs) of duodenal biopsies. We train our model to detect 2 distinct classes, normal tissue and coeliac disease, on the patch-level, and in turn leverage slide-level classifications. Using 5-fold cross-validation in a training set of 1841 (1163 normal; 680 coeliac disease) WSIs, our model classifies slides as normal with accuracy (96.7±0.6)%, precision (98.0±1.7)%, and recall (96.8±2.5)%, and as coeliac disease with accuracy (96.7±0.5)%, precision (94.9±3.7)%, and recall (96.5±2.9)% where the error bars are the cross-validation standard deviation.\n\nWe apply our model to 2 test sets: one containing 191 WSIs (126 normal; 65 coeliac) from the same sources as the training data, and another from a completely independent source, containing 34 WSIs (17 normal; 17 coeliac), obtained with a scanner model not represented in the training data. Using the same-source test data, our model classifies slides as normal with accuracy 96.5%, precision 98.4% and recall 96.1%, and positive for coeliac disease with accuracy 96.5%, precision 93.5%, and recall 97.3%. Using the different-source test data the model classifies slides as normal with accuracy 94.1% (32/34), precision 89.5%, and recall 100%, and as positive for coeliac disease with accuracy 94.1%, precision 100%, and recall 88.2%. We discuss generalising our approach to screen for a range of pathologies.\n\nKeywords: Computational pathology, Deep learning, Weakly supervised learning, Computer vision, Coeliac disease\n\nGraphical Abstract\n\nHighlights\n\n•\n\nAutomated detection of coeliac disease.\n\n•\n\nLocalisation of disease features in histological images.\n\n•\n\nWSI classification.\n\n•\n\nInter-scanner/source generalisation.\n\n1. Introduction\n\nThe rise of digital pathology coupled with recent decades of remarkable progress in computer vision1,2 presents exciting new opportunities for the automated detection of diseases and the creation of decision-support tools. Such tools offer the potential to aid pathologists in reporting slides and mitigate the pitfalls associated with manual diagnoses.2 Furthermore, realisations that advancing approaches can uncover salient diagnostic features, which are difficult for humans to detect,3, 4, 5 render such tools appealing. Moreover, stark observations concerning pathologist shortages6, 7, 8, 9 impress the clear and unmet need for novel tools which can ease the demand on pathologists.\n\nIn the histopathological domain, research in this area has largely focused on the detection of cancer (for examples, see Refs10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20), which, in many cases, is clearly evident in histological images. However, for some diseases, the histological presentation is less apparent and obtaining a clear diagnosis is more challenging: non-specific disease features can overlap with those of other conditions, may not be spatially localised on slides, and therefore require a pathologist to subjectively weigh a collection of subtle features before issuing a diagnosis. One pathology which fits this description is coeliac disease (CD), which is often diagnosed by inspecting biopsies from the duodenum.\n\n1.1. Coeliac disease\n\nCoeliac disease is an autoimmune enteropathy which manifests itself upon the ingestion of gluten—proteins found in wheat, barley, and rye.21, 22, 23, 24 Early studies of coeliac disease (CD) first uncovered the connection with food intake by prescribing various dietary restrictions,23,25 before W.-K. Dicke famously reported the success of a wheat-free regime.26 The direct link with the gluten component of wheat was made in 1952 by Anderson et al.27\n\nApproximately, 1.4% of the global population have CD, however the prevalence varies considerably and is difficult to determine precisely.28,29 Interestingly, CD appears to be especially prevalent in certain countries: in Scotland, CD-related hospital admissions are reportedly twice as high as those in England,30, 31, 32 and there is a notable 40-fold difference in the prevalence between Denmark and Sweden.33,34\n\nThe symptoms of CD include digestive discomfort, bloating, weight loss, stomach pain, dermatitis herpetiformis (skin rash), fatigue, anaemia, and fertility problems.35 In young children, the symptoms include growth retardation, abdominal distension, muscle wasting, and hypotonia.35 CD, and in particular a delayed diagnosis, increases the risk of both duodenal adenocarcinoma and lymphoma.36,37 The symptoms are generally alleviated upon the adoption of a gluten-free diet; there is no known cure.38\n\nDespite our mature understanding of CD, the procedure for diagnosing it in adult cases is largely underpinned by a pathologist’s manual and subjective interpretation of a duodenal biopsy. For example, the NICE guidelines for England and Wales recommend patients with symptoms suggestive of CD undergo serological testing, which should be followed by a biopsy if either the serology is positive, or if the serology is negative and the symptoms persist.39 A comprehensive review from the British Society of Gastroenterology also concludes that biopsies remain essential for adult diagnoses.40\n\nOther recent work has argued that, in certain cases, serological information is sufficient to detect CD in adult populations.41,42 Perhaps in the future, more sophisticated approaches will couple such data with pathologist- or computer-vision-based histological analyses to mitigate the high demand on pathologists.\n\nWhile serological tests are clearly useful as screening tools,43, 44, 45 for the time being, histology-based diagnoses remain the gold-standard.\n\n1.2. Histology-based diagnoses\n\nIn cases of CD, when gluten enters the duodenum, the first part of the digestive tract after the stomach, an autoimmune response effects inflammatory and structural changes which can be used to diagnose the disease (see ). These features (see ) are mainly atrophy of the villi, hyperplasia of the crypts, and an increase in the number of intra-epithelial lymphocytes. Some studies suggest a ratio of intra-epithelial lymphocytes to intra-epithelial enterocytes of 0.25 or more as evidence of CD.46,47\n\nThese features are often assessed using the Marsh–Oberhuber classification scheme,48,49 which provides a scale for assessing the nature and severity of the changes effected by the autoimmune response to gluten (simpler alternatives to the Marsh–Oberhuber scheme also exist46,47).\n\nThe challenging and subjective nature of histology-based diagnoses is reflected by the wide variation in quantitative estimates of the inter-observer agreement in CD diagnoses reported in published studies: generally the level of agreement is measured using Cohen’s kappa coefficient,50 and is reported to depend on both the biopsy classification scheme used46,51,52 and the practise setting (i.e., specialist academic analysis, routine diagnostic reporting, and commercial laboratories) in which cases are diagnosed.53,54 Kappa coefficients reported in CD inter-observer agreement studies, which typically involve the interpretation of single samples from D2, vary widely on 0 ≤ κ ≤ 1 (see citations for study-specific details).46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62\n\nThe poor concordance between observers is understandable when one considers the challenging nature of duodenal biopsies, which contain a panoply of information, including diagnostically important structures that differ in size by orders of magnitude. Moreover, there is a lack of regularity in the preparation of specimens: the samples are prone to damage; the orientation is random; tissue occasionally fails to adhere to the slide; inconsistencies in the staining process give rise to large colour variations across different laboratories—a problem exacerbated by samples cut with non-uniform thickness and (in the case of WSIs) digitisation artefacts imposed by commercial scanners. Furthermore, the observer is restricted to examining two-dimensional slices of inherently three-dimensional structures.\n\nAnother substantive hurdle is the variable extent to which evidence of CD is present in the duodenum. While there are clear-cut cases of villous atrophy and crypt hyperplasia—which strongly suggest CD—there are many cases which are subtle: the distinction between coeliac and normal biopsies is not always clear or sharp. Additionally, diagnosing CD from a duodenal biopsy relies on the patient maintaining a gluten-containing diet (otherwise the characteristic changes can alleviate) while suffering from related symptoms—a requirement which is not always met. The NICE guidelines specifically state patients should be advised that insufficient gluten consumption risks a false-negative duodenal biopsy diagnosis.39\n\n1.3. AI progress\n\nStudies examining the automated detection of CD in a histological setting are relatively scarce. Wei et al. present a scheme which involves dividing WSIs into patches of 224×224 pixels (at 20× magnification), labelling the patches based on the patient’s diagnosis and training a convolutional neural network (CNN) to make patch-level classifications.63 Wei et al. report their model identifies CD, normal tissue, and non-specific duodenitis with accuracies of 95.3%, 91.0%, and 89.2%, respectively.\n\nDespite this good performance, labelling all patches with the slide-level diagnosis has a conceptual limitation: not every patch from a disease-positive biopsy contains evidence of disease, yet every patch is so labelled. Thus, patches containing no evidence of disease, drawn from disease-containing slides, are inadvertently labelled as disease-positive,\n\nAnother interesting approach is that of Sali et al., who attempt to determine, using patches, the Marsh–Oberhuber classification of the patient they originate from.64 While this work is interesting and displays promising results, it only includes 162 slides from 34 patients, and omits class II (including only classes I, IIIa, IIIb, and IIIc) from the Marsh–Oberhuber scale.\n\nKowsari et al. detail an approach using colour balancing and CNNs to detect coeliac disease in a dataset of 3118 WSIs, taken from a small set of 121 biopsies from 102 patients.65 On a test set of 1000 images (from the same underlying dataset), Kowsari et al. classify normal slides, coeliac disease, and environmental enteropathy66 with ROC AUCs of 0.90, 0.96, and 0.89, respectively.\n\nIn this contribution, we apply a weakly supervised multiple instance learning (MIL) method to the problem of diagnosing CD solely from WSIs of duodenal biopsies. Such techniques have shown considerable promise in the detection of tumours in similar contexts15,67 and lend themselves well to situations in which the data have been annotated sparingly: i.e., the realistic setting where only slide- and not pixel-level annotations are available. The overarching idea of our approach is to first predict which regions of a WSI contain evidence of CD disease and to then use these patch-level predictions to map to slide-level classifications.\n\n2. Materials and methods\n\n2.1. Materials\n\nOur dataset contains of 2075 WSIs from a total of 1175 cases, and includes normal duodenal biopsies as well as biopsies determined positive for coeliac disease (see ). All of the samples are stained with haematoxylin and eosin and come from adults.\n\nTable 1\n\nSourceDiagnosisSetCasesScans“tif”“.bif”“.ndpi”“.svs”“.isyntax”HNormalTest2121017170Train18117601701700CoeliacTest2121619190Train208187511881880ANormalTest64000710Train5770006450CoeliacTest800090Train61000660SNormalTest17000017Train000000CoeliacTest17000017Train000000\n\nThe scanned samples originate from 3 sources: Birmingham Heartlands Hospital (University Hospitals Birmingham NHS Foundation Trust, England, UK), Addenbrooke’s Hospital (Cambridge University Hospitals NHS Foundation Trust, England, UK), and Sheba Medical Centre (Tel HaShomer, Israel).\n\nThe diagnoses were made by gastrointestinal pathologists practising at the respective hospitals (see ). The cases from Heartlands Hospital were diagnosed as normal if they had no features of CD, increased intra-epithelial lymphocytes, coeliac autoantibodies, malabsorption, diarrhoea, and no gluten-free diet. The cases from Heartlands Hospital diagnosed as CD-positive had clear features of Marsh 2 and above, generally with positive TTG and EMA.\n\nThe cases from Addenbrooke’s Hospital were selected from a list of “all-comer” duodenal biopsies, taken in 4 different months. We selected all of the cases described as containing no abnormality (normal) and cases described as consistent with ongoing, active CD (CD-positive) in the pathology reports. The slides from Sheba Medical Centre were all described as containing no abnormalities (normal), or as positive for coeliac disease.\n\nIn short, cases listed as normal contained only healthy tissue with no evidence of pathology, and cases listed as CD-positive contained sufficient histological evidence to merit such a diagnosis.\n\nAll scans (and accompanying fully anonymised patient data) were obtained with full ethical approval (IRAS: 162057; PI: Dr E. Soilleux).\n\nOur data from Heartlands Hospital is a special case: these research slides were collected specifically for this work and are not the original diagnostic slides—the samples were cut from known cases. In order to capture a diverse range of scanner-specific digitisation artefacts, these samples were scanned on multiple platforms (specified in ).\n\nIn the case of the slides from Addenbrooke’s Hospital, some cases have multiple scans because the number of tissue sections cut required more than 1 slide.\n\nIn order to access images in Philips’s proprietary “.isyntax” format, we first convert them to RGB “.ome.tiff” files using the tools available from Glencoe Software, Inc: namely “isyntax2raw” and “raw2ometiff”.\n\n2.2. WSI preprocessing\n\nPatch extraction: The large scale of WSIs prohibits their treatment as single entities, and necessitates their division into small, manageable, patches. For example, Campanella et al. observe that 470 WSIs contain roughly the same number of pixels as the entire ImageNet data set, which contains in excess of 1.4×107 images (typically resized to 224×224 pixels).15,68 To generate patches, we use QuPath69: we extract patches of 256×256 pixels at 10× magnification, corresponding to approximately 10 μm per pixel. The patches are generated using a sliding window approach with a stride of 128 pixels. We use this overlap at both training and inference time. To include only patches which contain a materially significant amount of tissue, we separate foreground from background using Otsu’s threshold70 and discard patches containing more than 75% background.\n\nStain normalisation: To mitigate the well-known problem of poor generalisation in computational pathology, we standardise the apparent staining characteristics of inputs to our model using Macenko’s method71 for stain normalisation. We illustrate the stain normalisation preprocessing step with four examples in .\n\n2.3. Multiple instance learning method\n\nMultiple instance learning is becoming increasingly popular in computational pathology (e.g., see Refs15,67). The rationale for choosing a MIL-based approach is that, in the absence of pixel-level annotations, MIL still offers scope for the localisation of predictions (on the patch-level) while only requiring slide-level annotations.15,67\n\nThe basic idea involves recognising that, during training, one may safely label all patches from normal slides as normal, but, in the case of disease-positive slides, it is unclear which patches should be labelled as positive and which should be labelled as negative. To address this, one employs a weakly supervised labelling step which associates disease-positive labels with the “least normal” patches sampled from diseased slides. We give a graphical overview of 1 MIL training step in .\n\nIn a single training epoch, we visit each slide in random order. Upon visiting a slide, we randomly sample a bag of patches (with replacement) and infer on each patch. If the slide’s label is negative (i.e., normal), we assign a negative proxy label to each patch (see ). If the slide’s label is positive (i.e., coeliac disease), we assign positive proxy labels to the α “least normal” patches (see ), negative proxy labels to the β “most normal” patches (see ), and zero all other inferences and labels (thus eliminating any gradient flow from these items). Backpropagation then proceeds in the normal way. Lerousseau et al.67 gives an excellent description of multiple instance learning in the context of histological images. For all of the results presented in this work, we set α=10, β=0 and use a bag size of 100 patches.\n\n2.4. Model and training details\n\nWe implement our model in PyTorch: we choose a ResNet50 classification architecture72 initialised with PyTorch’s ImageNet pre-trained weights (with a randomly initialised classification layer), and train for a period 10 epochs using an Adam optimiser with both the learning rate and weight decay set to 10−4, and the other parameters set to their defaults.73 We use the binary-cross-entropy loss criterion and apply the sigmoid activation function to the classifier’s output.\n\n2.5. Metrics\n\nWe assess our model’s performance using three metrics: accuracy (the frequency with which the model’s predictions match the slides’ labels), precision (the number of true-positive predictions divided by the total number of positive predictions), and recall/sensitivity/true-positive-rate (the number of true-positive predictions divided by the total number of positive instances of a given class).\n\nPrecision and recall are particularly useful when there is a large class imbalance as, unlike accuracy, they account for the number of instances of each class. We present all metrics on the WSI level.\n\n3. Results\n\nOur results are organised as follows: in Section 3.1, we detail the development of our model using cross-validation on the training data specified in ; in Section 3.2, we show an example of patch-level predictions overlaid on their corresponding WSI, thus highlighting the regions our model finds indicative of coeliac disease; in Section 3.3, we apply our model to 2 test sets—one containing unseen data from the same sources as the training data (Addenbrooke’s and Heartlands data in ), and another from a truly independent source (Sheba Medical Centre data in ), where the data originate from a centre (using a scanner model/manufacturer) not represented in the training data.\n\n3.1. Model development\n\nWe develop our model using 5-fold cross-validation with the 1841 training WSIs (1161 normal; 680 CD-positive) specified in . When splitting the data, we (approximately) preserve the training set’s ratio of normal to CD-positive cases in each fold, and impose the condition that scans originating from the same case (patient sample) must always be in the same fold. We treat normal tissue and coeliac disease as 2 distinct classes.\n\nTo summarise the patch-level predictions for a single WSI, we compute their mean. To determine whether WSIs can be classified using the mean of the patch-level predictions, we perform receiver operating characteristic (ROC) ( (a)–(b)) and precision-recall (PR) ( (c)–(d)) analysis on these quantities for each cross-validation fold. In , we see that for both the normal and CD classes, the area under the ROC and PR curves exceeds 0.98 in all cases, which shows the mean of the patch-level predictions is a robust statistic for classifying WSIs.\n\nTo foster as general a model as possible, we choose decision thresholds which minimise the difference between the true- and false-positive rates over each of the cross-validation folds. We classify slides as normal if the mean of the normal component of their patch-wise predictions exceeds 0.905, and as CD-positive if the mean of the coeliac component of their patch-wise predictions exceeds 0.096.\n\nWe give an overview of our model’s performance on each cross-validation fold, using these thresholds, in .\n\nTable 2\n\nClassFoldAccuracyROC AUCPrecisionRecallNormal10.9730.9900.9750.98320.9710.9940.9830.97130.9580.9970.9950.93840.9700.9980.9541.00050.9650.9981.0000.949Mean0.9670.9950.9800.970Coeliac10.9730.9900.9700.95520.9680.9940.9500.96430.9610.9970.9110.99340.9700.9981.0000.92350.9650.9980.9200.992Mean0.9670.9950.9500.965\n\nOur cross-validated model classifies slides as normal with accuracy (96.7±06)%, precision (98.0±1.7)%, and recall (96.8±2.5)%, and slides as CD-positive with accuracy (96.7±05)%, precision (94.9±3.7)%, and recall (96.5±2.9)% (the quoted error is the cross-validation standard deviation). It is worth noting here that the cross-validation performance may well be limited by ground-truth noise (see Section 4 for a discussion).\n\n3.2. Localisation\n\nTo understand what our model finds indicative of coeliac disease, at least on a coarse-grained level, it is informative to overlay the patch-wise predictions on the image as a whole and provide a spatial context to the otherwise disparate patch-wise predictions.\n\nGuided by CD diagnostic criteria,46, 47, 48, 49 we expect to find evidence of coeliac disease in patches which contain villi and crypts (see ). Evidence of CD should appear on both a structural level, in the form of atrophy of the villi and hyperplasia of the crypts, and on a cellular level, where the prevalence of lymphocytes in the epithelium should be considerably higher than in normal cases.\n\nWe show an example of such an overlay from a case determined positive for coeliac disease in . The localisation of the predictions in to regions which pathologists deem diagnostically relevant indicates that our model’s positive patch-level classifications are meaningful, and not spurious. For a larger version of , as well as other normal and CD-positive examples, please see the supplementary material.\n\n3.3. Model testing\n\nAfter developing our model and determining optimal decision thresholds using cross-validation, we train a new instance of the model on all of the training data, again for 10 epochs, and evaluate its performance on 2, small, independent test sets:\n\n1.\n\nSame-source testing—the scans originate from the same sources as the training data, and were scanned on the same scanners, but were never used for the model’s training or development (Heartlands and Addenbrooke’s test data in ).\n\n2.\n\nDifferent-source testing—the scans originate from a different source to those used in the model’s training and development (Sheba Medical centre test data in ), and were scanned on a different platform.\n\nIn order to clearly distinguish between the performance on test data from the same training source and the test data from a truly independent source, we evaluate the model’s performance on each of these sets separately (see ).\n\nTable 3\n\nSourceClassAccuracyROC AUCPrecisionRecallScan countSameN0.9650.9960.9840.961126 N; 74 CDCD0.9650.9960.9350.973DifferentN0.9410.9930.8951.00017 N; 17 CDCD0.9410.9931.0000.882\n\nThe model’s performance on the same-source test set is essentially as good as the cross-validation performance on the training set (96.5% versus 96.7% accuracy), which shows it generalises well to unseen samples from these sources.\n\nIn the case of the different-source test set, the model correctly classifies 32 of the 34 cases (94.1%), which suggests it generalises beyond source- and scanner-specific artefacts, has learnt to detect general features of coeliac disease, and makes meaningful classifications.\n\nThe model only misclassified 2/34 WSIs from the different source test set. In these 2 cases, problems with the scanning procedure have given rise to large regions of blur (out-of-focus image) which obscure 25%–50% of the tissue, thus masking the detail in these areas such that it cannot be resolved. We show an example from a poor quality test WSI in\n\nThese 2 misclassifications are an issue of quality control in the data and not a failure to generalise (see Section 4 for discussion).\n\n4. Discussion and conclusions\n\nWe presented a multiple-instance-learning-based approach for the detection of coeliac disease in histological WSIs of duodenal biopsies. Using cross-validation, our model classified slides as normal with accuracy (96.7±0.6)%, precision (98.0±1.7)%, and recall (96.8±2.5)%, and slides as coeliac with accuracy (96.7±0.5)%, precision (94.9±3.7)%, and recall (96.5±2.9)% (error bars are the cross-validation standard deviation).\n\nGiven the large variation typically found in CD inter-observer agreement studies (where pathologists essentially never achieve a complete consensus), it is reasonable to consider that our model’s cross-validation performance is limited by ground-truth noise.\n\nBy overlaying the patch-level predictions on a WSI determined positive for coeliac disease, we showed that our model, to a large extent, associates disease-positive predictions with regions containing the structures pathologists consider to be of diagnostic utility in standard practise. The connection between the model’s predictions and structures pathologists consider diagnostically relevant offers evidence that the predictions are meaningful, and not spurious.\n\nWe further tested the significance of the model’s predictions, and its ability to generalise, by applying it to 2 unseen test sets: 1 containing data from the same sources as the training data, and 1 from a completely independent source, where the samples originated from a different lab, and were scanned with a scanner model/manufacturer not represented in the training data.\n\nThe model’s performance on the same-source test set was essentially as good as the cross-validation performance on the training set (96.5% versus 96.7% accuracy for both classes), which shows the model generalises well to different biopsies from these (same) sources.\n\nIn the case of the different source test set, the model correctly classified 32/34 (94%) cases. In the case of the 2 WSIs, the model failed to classify correctly, problems with the scanning procedure gave rise to large regions of blur which substantially obscured significant portions of the tissue (see ), which, in future iterations of our analysis pipeline, will be rejected in the patch-extraction regime using known blur detection techniques.74\n\nThese 2 misclassifications highlight the paramount importance of WSI quality control: even though diagnostic slides have, by definition, been determined acceptable for a medical diagnosis, digitisation artefacts present significant quality control challenges which must be overcome—either by introducing manual and or automated post-scanning quality control steps.\n\nAnother limitation of this work is that our dataset only includes instances of normal duodenal mucosa and cases determined positive for coeliac disease. While these 2 classes actually represent the vast majority of cases seen in realistic practise settings, a key step in developing our approach is to enrich our dataset with other duodenal pathologies and train the model in this more realistic setting.\n\nThe opportunity exists to extend our multiple-instance-learning approach to screen for more than one kind of duodenal pathology. Expanding our dataset to incorporate a more diverse range of diseases will allow us to investigate the feasibility of developing an approach which could screen biopsies as “normal”, “CD-positive”, or “other abnormality”. However, the rarity of other duodenal pathologies renders the prospect of building a dataset which contains enough examples for meaningful machine-learning research challenging.\n\nAnother interesting line of enquiry is to investigate using our approach to classify biopsies based on their modified Marsh score (as others have tried using different methodologies64). While a model which provides accurate Marsh grading would be valuable, such an undertaking is challenging due to the issue of poor inter-observer agreement in Marsh gradings (e.g., see Refs46,47) and the time intensive nature of labelling a large diverse dataset.\n\nThere is also further scope to develop our approach by reconsidering the mapping between patch- and slide-level predictions. The method we use in this work, while empirically effective, is simple and there is opportunity to explore other approaches for mapping between patch- and slide-level predictions. Investigating the benefit of such techniques will be made practical with a larger and more diverse dataset.\n\nGiven the majority of duodenal biopsies are determined to be normal, it follows that considerable time savings are possible with a model which simply screens for normal duodenal mucosa and allows pathologists to restrict their focus to abnormal cases requiring further attention.\n\nWe have demonstrated that our model can classify WSIs as normal or positive for coeliac disease with high accuracy, precision, and recall. We have also shown promising evidence that our approach generalises to new tissue samples outwith the training set, as well as samples obtained from a source completely independent from the training source. These are essential requirements for any future diagnostic algorithms (or computational methods) underpinned by this work.\n\nThe following are the supplementary data related to this article.\n\nSupplementary material 1\n\nClick here to view.(25M, zip)Image 1\n\nSupplementary material 2\n\nClick here to view.(1.9M, pdf)Image 2\n\nSupplementary material 3\n\nClick here to view.(3.1M, pdf)Image 3\n\nSupplementary material 4\n\nClick here to view.(2.5M, pdf)Image 4\n\nSupplementary figure 1\n\nClick here to view.(4.5M, pdf)Image 5\n\nAuthors’ contributions\n\nJ.D and B.A.S have contributed equally to the development of the WSI-processing and analysis pipeline. J.D wrote this manuscript, and B.A.S, M.J.A. and E.J.S commented on multiple revisions of it. S.C.E. collated and scanned all of the slides from Addenbrooke’s Hospital. A.S. and O.M.C. contributed to the preliminary processing of the data from Heartlands Hospital and discussions concerning the conception and planning of this project. J.L.W. compiled the metadata for the cases from Heartlands Hospital. G.L. reviewed and confirmed the diagnoses in all of the cases from Heartlands Hospital, which were cut, stained and scanned by H.B. J.D.G. and C.B.S. gave advice in early discussions concerning this work, and C.B.S. kindly facilitated access to computer resources. M.J.A. routinely provided specialist gastrointestinal pathology advice throughout this work. E.J.S. conceptualised, initiated and guided both this project and the creation of the data set.\n\nAll authors have been given the opportunity to review and approve this manuscript.\n\nEthical approval\n\nAll slide scans (and accompanying fully anonymised patient data) were obtained with full ethical approval (IRAS: 162057; PI: Dr E. Soilleux).\n\nDeclaration of interests\n\nThe authors declare the following financial interests/personal relationships which may be considered as potential competing interests:\n\nThe following authors are shareholders in Lyzeum Ltd: Elizabeth Soilleux, Mark Arends, Carola-Bibiane Schönlieb and Julian Gilbey.\n\nAcknowledgements\n\nThis work was supported by a Coeliac UK and Innovate UK grant (INOV03-19) awarded to E.J.S., and a Pump Priming Grant (to E.J.S.) from the Pathological Society of Great Britain and Ireland (Path Soc). B.A.S. gratefully acknowledges financial support from a PhD studentship awarded by Path Soc. O.M.C. was supported by an EPSRC grant EP/N510129/1. J.L.W. and A.S. acknowledge financial support from undergraduate bursaries awarded by Path Soc.\n\nAll authors gratefully acknowledge and thank: Yossef Molchanov (Sheba Medical Centre), Chen Mayer (Department of Pathology, Sheba Medical Centre) and Iris Barshack (Sackler Faculty of Medicine, Tel Aviv University), for facilitating the transfer of a small batch of whole-slide images to test our model on; Rosie Telford Spencer, for a careful proofreading of this manuscript; Graham Snudden for organisational and financial support.\n\nReferences\n\n1. Liu L., Ouyang W., Wang X., et al. Deep learning for generic object detection: a survey. Int J Comput Vision. 2020;128:261–318. doi: 10.1007/s11263-019-01247-4. [CrossRef] [Google Scholar]\n\n2. van der Laak J., Litjens G., Ciompi F. Deep learning in histopathology: the path to the clinic. Nat Med. 2021;27:775–784. doi: 10.1038/s41591-021-01343-4. [PubMed] [CrossRef] [Google Scholar]\n\n3. A. H. Beck, A. R. Sangoi, S. Leung, R. J. Marinelli, T. O. Nielsen, M. J. V. D. Vijver, R. B. West, M. V. D. Rijn, D. Koller, Imaging: systematic analysis of breast cancer morphology uncovers stromal features associated with survival, Sci Translat Med 3. 10.1126/scitranslmed.3002564. [PubMed] [CrossRef]\n\n4. Yu K.H., Zhang C., Berry G.J., et al. Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features. Nat Commun. 2016;7:1–10. doi: 10.1038/ncomms12474. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n5. Yu K.H., Berry G.J., Rubin D.L., Ré C., Altman R.B., Snyder M. Association of omics features with histopathology patterns in lung adenocarcinoma. Cell Syst. 2017;5:620–627.e3. doi: 10.1016/j.cels.2017.10.014. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n6. Egevad L., Delahunt B., Samaratunga H., et al. The international society of urological pathology education web—a web-based system for training and testing of pathologists. Virchows Arch. 2019;474:577–584. doi: 10.1007/s00428-019-02540-w. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n7. Adesina A., Chumba D., Nelson A.M., et al. Improvement of pathology in sub-Saharan Africa. Lancet Oncol. 2013;14:e152–e157. doi: 10.1016/S1470-2045(12)70598-3. [PubMed] [CrossRef] [Google Scholar]\n\n8. Robboy S.J., Weintraub S., Horvath A.E., et al. Pathologist workforce in the United States: I. Development of a predictive model to examine factors influencing supply. Arch Pathol Lab Med. 2013;137:1723–1732. doi: 10.5858/arpa.2013-0200-OA. [PubMed] [CrossRef] [Google Scholar]\n\n9. T. R. C. of Pathologists College report finds UK wide histopathology staff shortages. https://www.rcpath.org/discover-pathology/news/college-report-finds-severe-staff-shortages-across-services-vital-to-cancer-diagnosis.html URL.\n\n10. Litjens G., Sánchez C.I., Timofeeva N., et al. Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis. Scient Rep. 2016;6:1–11. doi: 10.1038/srep26286. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n11. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. JAMA. 2017;318:2199–2210. doi: 10.1001/jama.2017.14585. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n12. Litjens G., Kooi T., Bejnordi B.E., et al. A survey on deep learning in medical image analysis. Med Image Anal. 2017;42:60–88. doi: 10.1016/j.media.2017.07.005. [PubMed] [CrossRef] [Google Scholar]\n\n13. Manak M.S., Varsanik J.S., Hogan B.J., et al. Live-cell phenotypic-biomarker microfluidic assay for the risk stratification of cancer patients via machine learning. Nat Biomed Eng. 2018;2:761–772. doi: 10.1038/s41551-018-0285-z. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n14. van der Laak J., Ciompi F., Litjens G. No pixel-level annotations needed. Nat Biomed Eng. 2019;3:855–856. doi: 10.1038/s41551-019-0472-6. [PubMed] [CrossRef] [Google Scholar]\n\n15. Campanella G., Hanna M.G., Geneslaw L., et al. Clinical-grade computational pathology using weakly supervised deep learning on whole slide images. Nat Med. 2019;25:1301–1309. doi: 10.1038/s41591-019-0508-1. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n16. Ba W., Wang S., Shang M., et al. Assessment of deep learning assistance for the pathological diagnosis of gastric cancer. Mod Pathol. 2022:1–7. doi: 10.1038/s41379-022-01073-z. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n17. Tolkach Y., Dohmgörgen T., Toma M., Kristiansen G. High-accuracy prostate cancer pathology using deep learning. Nat Mach Intel. 2020;2:411–418. doi: 10.1038/s42256-020-0200-7. [CrossRef] [Google Scholar]\n\n18. Gehrung M., Crispin-Ortuzar M., Berman A.G., O’Donovan M., Fitzgerald R.C., Markowetz F. Triage-driven diagnosis of barrett’s esophagus for early detection of esophageal adenocarcinoma using deep learning. Nat Med. 2021;27:833–841. doi: 10.1038/s41591-021-01287-9. [PubMed] [CrossRef] [Google Scholar]\n\n19. Saldanha O.L., Quirke P., West N.P., et al. Swarm learning for decentralized artificial intelligence in cancer histopathology. Nat Med. 2022;28:1232–1239. doi: 10.1038/s41591-022-01768-5. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n20. Zhang Z., Chen P., McGough M., et al. Pathologist-level interpretable whole-slide cancer diagnosis with deep learning. Nat Mach Intel. 2019;1:236–245. doi: 10.1038/s42256-019-0052-1. [CrossRef] [Google Scholar]\n\n21. Adams F. London Sydenham Society; 1856. The extant works of Aretaeus, the Cappadocian. [Google Scholar]\n\n22. Paveley W.F. From aretaeus to crosby: A history of coeliac disease. Br Med J. 1988;297:1646–1649. doi: 10.1136/bmj.297.6664.1646. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n23. Losowsky M.S. A history of coeliac disease. Dig Dis. 2008;26:112–120. doi: 10.1159/000116768. [PubMed] [CrossRef] [Google Scholar]\n\n24. Dowd B., Walker-Smith J. Samuel Gee, Aretaeus, and the coeliac affection. Br Med J. 1974;2:45. doi: 10.1136/bmj.2.5909.45. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n25. Lyons J., Dixon C.W., Bauer D.J. Letter: Samuel Gee, Aretaeus, and the coeliac affection. Br Med J. 1974;2:442. doi: 10.1136/BMJ.2.5916.442-A. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n26. Berge-Henegouwen G.P.V., Mulder C.J. Pioneer in the gluten free diet: Willem-Karel Dicke 1905-1962, over 50 years of gluten free diet. Gut. 1993;34:1473–1475. doi: 10.1136/gut.34.11.1473. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n27. Anderson C.M., Frazer A.C., French J.M., Gerrard J.W., Sammons H.G., Smellie J.M. Coeliac disease: gastro-intestinal studies and the effect of dietary wheat flour. The Lancet. 1952;259:836–842. doi: 10.1016/S0140-6736(52)90795-2. [PubMed] [CrossRef] [Google Scholar]\n\n28. Guandalini S., Assiri A. Celiac disease: a review. JAMA Pediatr. 2014;168:272–278. doi: 10.1001/jamapediatrics.2013.3858. [PubMed] [CrossRef] [Google Scholar]\n\n29. Singh P., Arora A., Strand T.A., et al. Global prevalence of celiac disease: systematic review and meta-analysis. Clin Gastroenterol Hepatol. 2018;16:823–836.e2. doi: 10.1016/j.cgh.2017.06.037. [PubMed] [CrossRef] [Google Scholar]\n\n30. O’reilly D., Murphy J., Mclaughlin J., Bradshaw J., Dean G. The prevalence of coeliac disease and cystic fibrosis in Ireland, Scotland, and England and Wales. Int J Epidemiol. 1974;3:247–251. doi: 10.1093/ije/3.3.247. [PubMed] [CrossRef] [Google Scholar]\n\n31. Johnston S.D., Watson R.G., McMillan S.A., Sloan J., Love A.H. Prevalence of coeliac disease in Northern Ireland. Lancet. 1997;350:1370. doi: 10.1016/S0140-6736(05)65142-2. [PubMed] [CrossRef] [Google Scholar]\n\n32. White L.E., Merrick V.M., Bannerman E., et al. The rising incidence of celiac disease in Scotland. Pediatrics. 2013;132:e924–e931. doi: 10.1542/peds.2013-0932. [PubMed] [CrossRef] [Google Scholar]\n\n33. Bodé S., Gudmand-Hãyer E. Incidence and prevalence of adult coeliac disease within a defined geographic area in Denmark. Scand J Gastroenterol. 1996;31:694–699. doi: 10.3109/00365529609009152. [PubMed] [CrossRef] [Google Scholar]\n\n34. Sjöberg K., Eriksson S. Regional differences in coeliac disease prevalence in Scandinavia? Scand J Gastroenterol. 1999;34:41–45. doi: 10.1080/00365529950172817. [PubMed] [CrossRef] [Google Scholar]\n\n35. Fasano A. Clinical presentation of celiac disease in the pediatric population. Gastroenterology. 2005;128:S68–S73. doi: 10.1053/j.gastro.2005.02.015. [PubMed] [CrossRef] [Google Scholar]\n\n36. Silano M., Volta U., Mecchia A., et al. Delayed diagnosis of coeliac disease increases cancer risk. BMC Gastroenterol. 2007;7:1–5. doi: 10.1186/1471-230X-7-8. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n37. Caio G., Volta U., Sapone A., et al. Celiac disease: a comprehensive current review. BMC Med. 2019;17:1–20. doi: 10.1186/s12916-019-1380-z. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n38. Rashtak S., Murray J.A. Review article: coeliac disease, new approaches to therapy. Aliment Pharmacol Ther. 2012;35:768–781. doi: 10.1111/J.1365-2036.2012.05013.X. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n39. N. I. for Health Care Excellence, Recommendations | coeliac disease: recognition, assessment and management | guidance | nice. 2015. https://www.nice.org.uk/guidance/ng20/chapter/Recommendations#recognition-of-coeliac-disease URL. [PubMed]\n\n40. Ludvigsson J.F., Bai J.C., Biagi F., et al. Diagnosis and management of adult coeliac disease: guidelines from the British Society of Gastroenterology. Gut. 2014;63:1210–1228. doi: 10.1136/GUTJNL-2013-306578. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n41. Beig J., Rostami K., Hayman D.T., Hassan S., Gerred S., Ogra R. Is duodenal biopsy always necessary for the diagnosis of coeliac disease in adult patients with high anti-tissue transglutaminase (ttg) antibody titres? Frontl Gastroenterol. 2022;13:287–294. doi: 10.1136/FLGASTRO-2020-101728. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n42. A. R. Baykan, S. Cerrah, S. Ciftel, M. K. Vural, E. Kasap, A no-biopsy approach for the diagnosis of celiac disease in adults: can it be real?, Cureus 14. 10.7759/CUREUS.26521. [PMC free article] [PubMed] [CrossRef]\n\n43. Christian H., Joseph J.A.M.M., Husby S., Murray J.A. Diagnosing coeliac disease and the potential for serological markers. Nat Rev Gastroenterol Hepatol. 2014;11:655–663. doi: 10.1038/nrgastro.2014.162. [PubMed] [CrossRef] [Google Scholar]\n\n44. Hopper A.D., Hadjivassiliou M., Hurlstone D.P., et al. What is the role of serologic testing in celiac disease? A prospective, biopsy-confirmed study with economic analysis. Clin Gastroenterol Hepatol. 2008;6:314–320. doi: 10.1016/j.cgh.2007.12.008. [PubMed] [CrossRef] [Google Scholar]\n\n45. Penny H.A., Raju S.A., Lau M.S., et al. Accuracy of a no-biopsy approach for the diagnosis of coeliac disease across different adult cohorts. Gut. 2021;70:876–883. doi: 10.1136/gutjnl-2020-320913. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n46. Corazza G.R., Villanacci V., Zambelli C., et al. Comparison of the interobserver reproducibility with different histologic criteria used in celiac disease. Clin Gastroenterol Hepatol. 2007;5:838–843. doi: 10.1016/j.cgh.2007.03.019. [PubMed] [CrossRef] [Google Scholar]\n\n47. Ensari A. Gluten-sensitive enteropathy (celiac disease): controversies in diagnosis and classification. Arch Pathol Lab Med. 2010;134:826–836. doi: 10.5858/134.6.826. [PubMed] [CrossRef] [Google Scholar]\n\n48. Marsh M.N. Gluten, major histocompatibility complex, and the small intestine. a molecular and immunobiologic approach to the spectrum of gluten sensitivity (‘celiac sprue’) Gastroenterology. 1992;102:330–354. doi: 10.1016/0016-5085(92)91819-P. [PubMed] [CrossRef] [Google Scholar]\n\n49. Oberhuber G., Granditsch G., Vogelsang H. The histopathology of coeliac disease: time for a standardized report scheme for pathologists. Eur J Gastroenterol Hepatol. 1999;11:1185. doi: 10.1097/00042737-199910000-00019. [PubMed] [CrossRef] [Google Scholar]\n\n50. Cohen J. A coefficient of agreement for nominal scales. Educ Psychol Meas. 1960;20:37–46. doi: 10.1177/001316446002000104. [CrossRef] [Google Scholar]\n\n51. Villanacci V., Magazzù G., Pellegrino S., et al. Comparison of the Marsh–Oberhuber classification with a new grading system in identifying patients with latent celiac disease. Minerva Gastroenterol Dietol. 2010;56:371–375. [PubMed] [Google Scholar]\n\n52. Ghanghoria S., Sharma S., Jain P. Celiac disease: comparison of Oberhuber classification and Corazza-Villanacci classification. Ann Pathol Lab Med. 2019;6:A135–A140. doi: 10.21276/apalm.2190. [CrossRef] [Google Scholar]\n\n53. Arguelles-Grande C., Tennyson C.A., Lewis S.K., Green P.H., Bhagat G. Variability in small bowel histopathology reporting between different pathology practice settings: impact on the diagnosis of coeliac disease. J Clin Pathol. 2012;65:242–247. doi: 10.1136/jclinpath-2011-200372. [PubMed] [CrossRef] [Google Scholar]\n\n54. Niveloni S.I., Cabanne A.M., Vázquez H., et al. 1042 “experts” assess the accuracy of celiac disease diagnosis performed in the community setting. Gastroenterology. 2012;142:S183. doi: 10.1016/s0016-5085(12)60685-4. [CrossRef] [Google Scholar]\n\n55. Picarelli A., Borghini R., Donato G., et al. Weaknesses of histological analysis in celiac disease diagnosis: New possible scenarios. Scand J Gastroenterol. 2014;49:1318–1324. doi: 10.3109/00365521.2014.948052. [PubMed] [CrossRef] [Google Scholar]\n\n56. Eigner W., Wrba F., Chott A., et al. Early recognition of possible pitfalls in histological diagnosis of celiac disease. Scand J Gastroenterol. 2015;50:1088–1093. doi: 10.3109/00365521.2015.1017835. [PubMed] [CrossRef] [Google Scholar]\n\n57. Weile B., Hansen B.F., Hägerstrand I., Hansen J.P.H., Krasilnikoff P.A. Interobserver variation in diagnosing coeliac disease. a joint study by Danish and Swedish pathologists. APMIS. 2000;108:380–384. doi: 10.1034/j.1600-0463.2000.d01-72.x. [PubMed] [CrossRef] [Google Scholar]\n\n58. Mubarak A., Nikkels P., Houwen R., Kate F.T. Reproducibility of the histological diagnosis of celiac disease. Scand J Gastroenterol. 2011;46:1065–1073. doi: 10.3109/00365521.2011.589471. [PubMed] [CrossRef] [Google Scholar]\n\n59. Bilkhoo H.K., Ducruet T., Marchand V., et al. Revisiting pathological criteria for earlier diagnosis of coeliac disease. J Pediatr Gastroenterol Nutr. 2016;62:734–738. doi: 10.1097/MPG.0000000000001026. [PubMed] [CrossRef] [Google Scholar]\n\n60. van Wanrooij R.L., Müller D.M., Neefjes-Borst E.A., et al. Optimal strategies to identify aberrant intra-epithelial lymphocytes in refractory coeliac disease. J Clin Immunol. 2014;34:828–835. doi: 10.1007/s10875-014-0075-7. [PubMed] [CrossRef] [Google Scholar]\n\n61. Montén C., Bjelkenkrantz K., Gudjonsdottir A.H., et al. Validity of histology for the diagnosis of paediatric coeliac disease: a Swedish multicentre study. Scand J Gastroenterol. 2016;51:427–433. doi: 10.3109/00365521.2015.1101486. [PubMed] [CrossRef] [Google Scholar]\n\n62. Webb C., Halvarsson B., Norström F., et al. Accuracy in celiac disease diagnostics by controlling the small-bowel biopsy process. J Pediatr Gastroenterol Nutr. 2011;52:549–553. doi: 10.1097/MPG.0b013e3181fa434f. [PubMed] [CrossRef] [Google Scholar]\n\n63. Wei J.W., Wei J.W., Jackson C.R., Ren B., Suriawinata A.A., Hassanpour S. Automated detection of celiac disease on duodenal biopsy slides: a deep learning approach. J Pathol Inform. 2019;10:7. doi: 10.4103/JPI.JPI_87_18. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n64. Sali R., Ehsan L., Kowsari K., et al. Celiacnet: celiac disease severity diagnosis on duodenal histopathological images using deep residual networks. Proceedings - 2019 IEEE International Conference on Bioinformatics and Biomedicine, BIBM. 2019;2019:962–967. doi: 10.1109/BIBM47256.2019.8983270. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n65. Kowsari K., Sali R., Khan M.N., et al. Vol. 1069. NIH Public Access; 2020. Diagnosis of celiac disease and environmental enteropathy on biopsy images using color balancing on convolutional neural networks; pp. 750–765. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n66. Korpe P.S., Petri W.A. Environmental enteropathy: critical implications of a poorly understood condition. Trends Mol Med. 2012;18:328–336. doi: 10.1016/j.molmed.2012.04.007. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n67. Lerousseau M., Vakalopoulou M., Classe M., et al. Vol. 12265. LNCS, Springer Science and Business Media Deutschland GmbH; 2020. Weakly supervised multiple instance learning histopathological tumor segmentation; pp. 470–479. [CrossRef] [Google Scholar]\n\n68. Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L. Imagenet: a large-scale hierarchical image database. IEEE. 2010:248–255. doi: 10.1109/cvpr.2009.5206848. [CrossRef] [Google Scholar]\n\n69. Bankhead P., Loughrey M.B., Fernández J.A., et al. Qupath: open source software for digital pathology image analysis. Sci Rep. 2017;7:1–7. doi: 10.1038/s41598-017-17204-5. [PMC free article] [PubMed] [CrossRef] [Google Scholar]\n\n70. Otsu N. Threshold selection method from gray-level histograms. IEEE Trans Syst Man Cybern. 1979;SMC-9:62–66. doi: 10.1109/tsmc.1979.4310076. [CrossRef] [Google Scholar]\n\n71. Macenko M., Niethammer M., Marron J.S., et al. 2009. A method for normalizing histology slides for quantitative analysis; pp. 1107–1110. [CrossRef] [Google Scholar]\n\n72. He K., Zhang X., Ren S., Sun J. 2016-Decem. IEEE Computer Society; 2016. Deep residual learning for image recognition; pp. 770–778. [CrossRef] [Google Scholar]\n\n73. Kingma D.P., Ba J.L. International Conference on Learning Representations, ICLR. 2015. Adam: a method for stochastic optimization. [CrossRef] [Google Scholar]\n\n74. Crete F., Dolmiere T., Ladret P., Nicolas M. Vol. 6492. SPIE; 2007. The blur effect: Perception and estimation with a new no-reference perceptual blur metric; p. 64920I. [CrossRef] [Google Scholar]\n\nArticles from Journal of Pathology Informatics are provided here courtesy of Elsevier"
    }
}