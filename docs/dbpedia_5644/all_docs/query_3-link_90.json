{
    "id": "dbpedia_5644_3",
    "rank": 90,
    "data": {
        "url": "https://arxiv.org/html/2312.11144v1",
        "read_more_link": "",
        "language": "en",
        "title": "LSDvis: Hallucinatory Data Visualisations in Real World Environments",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://arxiv.org/html/x1.png",
            "https://arxiv.org/html/x2.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "License: arXiv.org perpetual non-exclusive license\n\narXiv:2312.11144v1 [cs.HC] 18 Dec 2023\n\n\\onlineid\n\n0 \\vgtccategoryResearch \\vgtcinsertpkg \\teaser\n\nLSDvis: Hallucinatory Data Visualisations in Real World Environments\n\nAri Kouts\n\nVISEO e-mail: ari.kouts@viseo.com Lonni Besançon\n\nLinköping University e-mail: lonni.besancon@gmail.com Michael Sedlmair\n\nUniversity of Stuttgart e-mail: Michael.Sedlmair@visus.uni-stuttgart.de Benjamin Lee\n\nUniversity of Stuttgart e-mail: Benjamin.Lee@visus.uni-stuttgart.de\n\nAbstract\n\nWe propose the concept of “LSDvis”: the (highly exaggerated) visual blending of situated visualisations and the real-world environment to produce data representations that resemble hallucinations. Such hallucinatory visualisations incorporate elements of the physical environment, twisting and morphing their appearance such that they become part of the visualisation itself. We demonstrate LSDvis in a “proof of proof of concept”, where we use Stable Diffusion to modify images of real environments with abstract data visualisations as input. We conclude by discussing considerations of LSDvis. We hope that our work promotes visualisation designs which deprioritise saliency in favour of quirkiness and ambience.\n\nIntroduction\n\nThe conditions which data visualisations are viewed under are generally assumed (and subsequently ignored) by designers. High resolution display, well-lit room, the full attention of the reader, and so on. Of course, not all data is to be viewed in the comfort of one’s own home or office. In numerous scenarios, it is advantageous to view data out in the real, physical places to which said data directly relates to, also known as situated visualisation [40, 41]. Situated visualisations are already ever-present in our day-to-day lives. Stationary 2D displays that show public transport arrival and departure times, waiting times for amusement park rides, and exchange rates at currency exchanges. These are all present-day examples of data being presented in situ to the general public.\n\nWith augmented reality (AR) headsets, researchers have recently begun investigating their use to support situated visualisation and analytics [7, 31]. With AR, immersive visualisations can be directly situated or embedded onto or nearby the physical referents in the environment. This not only removes the need to rely on stationary displays, but also can reduce the level of spatial indirection between the data and the referent [41]. However, existing research has arguably still kept to a very “standard” form of situated visualisation. A form that still uses many of the familiar idioms and techniques seen in so-called “traditional” data visualisation, such as the use of floating 2D panels with scatter plots and line charts (e.g. [24, 8]).\n\nThis approach is, of course, optimised for the viewability and understandability of the data in-situ. While perhaps an unassailable objective from a utilitarian standpoint, we argue that it does not make full use of the capabilities of AR to deliver highly engaging and embodied viewing of the data [17]. In particular, one that leads to a stronger emotional response [39, 14].\n\nSo how can we elicit a stronger emotional response in people? The answer is simple: drugs ; specifically lysergic acid diethylamide or LSD. Ivan Sutherland [36] back in 1965 had envisioned the Ultimate Display: a computing system so powerful that it could control the existence of matter. A system that could surpass Metal Gear, breaking the laws of reality in order to present information and facilitate interactivity in ways not otherwise possible. While obviously not Sutherland’s original intention, the manipulation and distortion of the real world to large extents can, if one stretches far enough, be seen as a form of hallucination.\n\nSo what happens when you combine hallucinations with data visualisation? This is where we propose the concept of LSDvis: the (highly exaggerated) visual blending of situated visualisations and the real world to produce data representations that resemble hallucinations. Unlike regular situated visualisations, LSDvis is intended to be playful, letting people see data in ways which they have never seen before—especially when in the physical environments to which the data relates. Examples of which can be seen in Figure LSDvis: Hallucinatory Data Visualisations in Real World Environments.\n\nWe illustrate the LSDvis concept by showcasing a gallery of AI-generated examples, which were created using a Stable Diffusion 1.5 model. Each example is based on an input 2D data visualisation and background image of some real world environment. We chose images in such a way to explore various conditions and determine in which scenarios our AI approach is successful. As this is a self-proclaimed “proof of proof of concept”, we assume that such AI-generated images can simply be back-projected onto their real-world counterparts using AR, hence achieving a proper hallucinatory experience. Of course, further advancements in AI may soon allow these LSDvis images to be generated in real-time. We conclude by describing future steps for LSDvis, particularly in how it may play into its “LSD” moniker and psychedelics in general.\n\n1 Related Topics\n\nLSDvis is not an entirely new concept. From a visualisation perspective, we see it as an amalgamation of three distinct yet related topics: situated visualisation, data physicalisation, and ambient visualisation. We also discuss a fourth topic where others have presented data in non-conventional ways using AR and virtual reality (VR), and a fifth topic on generative models for visualisation which our work bears similarity to.\n\n1.1 Situated Visualisation\n\nAs hallucinations are experienced by people in the real world, it makes sense to also view LSDvis in the context of the real world—hence, situated visualisation. Situated visualisation was first coined by White and Feiner [40] to mean “a visualisation that is related to and displayed in its environment.” Willett et al. [41] later introduced physical referents, which are “the real-world entities and spaces to which data corresponds.” Since then, situated visualisation is now commonly associated with AR technologies [3].\n\nIn existing work, situated visualisations serve to augment the physical referent through conventional visualisation idioms (e.g. [24, 8, 16]), or otherwise through abstract looking graphics (e.g. [34, 35]). The physical referent itself is visibly left unaltered. As LSDvis visually blends the data and the real world together however, the referent itself effectively becomes part (or the entirety) of the data visualisation—or at least it appears to be from the perspective of the viewer. This is the defining characteristic of LSDvis.\n\n1.2 Data Physicalisation\n\nAs we are representing data with (parts of) real world objects, LSDvis is tangentially related to data physicalisation. Jansen et al. [12] defined data physicalisation as “a physical artifact whose geometry or material properties encode data.” The obvious difference of course is that data physicalisation is inherently tangible, thus allowing people to touch and feel data with their own bodies. Much like hallucinations are not actually tangible and exist only in one’s perception, so too is LSDvis. We don’t see this intangibility as a strict disadvantage however. In some ways it expands our scope of possibilities even further, as physically morphing the real world to display data is, at least with current technology, impossible. Thus, what we can achieve with LSDvis is, at least in theory, limited to our own (sober) imaginations and the technology which we are using.\n\n1.3 Ambient Visualisation\n\nLSDvis also builds on the core ideals of ambient visualisation [33]. Ambient visualisations are those which are visually integrated and blend in with the physical surroundings, such that people may be blissfully unaware of the visualisation’s existence. Such visualisations may encode information that is based on the physical context, similar to situated visualisation. As an example, the Activity Wallpaper by Skog [32] visualises data based on local sound levels to indicate the level of physical activity in a room over a period of time. The visualisation simply looks like a typical wallpaper with stylistic patterns however, and not a traditional data visualisation with axes and labels.\n\nThis defocus on saliency is an intentional design goal, as people are not bombarded by hyper-salient, utility-driven information visualisations. Instead, they are treated to an aesthetically pleasing view of the data which they may have serendipitously noticed, thus sparking curiosity and emotional reactions [27]. LSDvis aims to achieve a similar effect. While the distortion of the real world would inherently draw attention to the visualisation’s existence, the visual blending may still cause the LSDvis to not be immediately noticeable, thus facilitating said serendipitous discovery.\n\n1.4 Alternative Data Representations in AR and VR\n\nMuch like our work aims to represent data visualisations in a non-conventional form, so too has several works using AR or VR technologies—particularly by giving meaning to data through physical context. Lee et al. [14] presented the notion of data visceralisation, which is the presentation of data in its original, physical form to enable the “visceral understanding” of data. Casamayou et al. [4] utilised a similar concept to represent temporal data as a roller coaster track which people can ride along in VR. In a similar vein, Assor et al. [1] explored AR-based visualisations of waste data, such as by encoding the waste generated by a restaurant as virtual trash bags. In contrast, our work focuses on embedding data representations by directly altering the underlying image (and perhaps in the future, video or AR-stream sources). This is in some ways akin to large-scale projection mapping done on large buildings as public displays, but LSDvis instead morphs the structure of the environment rather than simply applying a decal over it [15].\n\n1.5 Generative Models for Creative Visualisation\n\nIn a visual essay at alt.VIS 2022, Wood [42] discussed how AI can be used to make visualisations more expressive at the potential cost of their effectiveness. Our work takes on a similar mindset in that the “walled garden” of design rules and atomic variables need not be what we limit our creativities to—even if with the help of machines.\n\nMore broadly speaking, an increasingly large amount of work has been published on how models can be used to generate more creative visualisations. Many focus solely on the visual substitution of abstract glyphs and marks with more realistic or stylised objects or designs. Zhang et al. [46] showed how visual elements can be extracted from source images (e.g. photos of coffee, sketches of juice boxes) to be then repurposed into custom pictorial visualisations. Xiao et al. [44] also created pictorial visualisations, but instead by using a text-to-image generative model based on text inputs and the data of the inputted charts. Wu et al. [43] took a similar approach by transforming an input 2D visualisation into a stylised form using textual prompts and a diffusion model. Ying et al. [45] instead automatically generate these glyphs through the use of metaphors that are derived from a spreadsheet. Schetinger et al. [30] identified a (non-exhaustive) list of potential usages of generative models for use in visualisation, to which many of the aforementioned works fall under the notions of design prettification or embellishment. These types of work mainly seek to turn an existing 2D visualisation into something that is more visually stylised and appealing, usually by associating this style to the semantic meaning of the data (e.g. data about glacier mass represented as a glacier [44]). However, due to the situated nature of our work, we are constrained by the layout and design of real world environments [15]. Thus, the style is dictated more so by the physical environment itself and not of the underlying data semantics.\n\nThis notion of embedding data using the style and content of an existing, non-chart image can be seen in several other works. Tkachev et al. [37] use a visual style transfer on headshots of researchers to encode similarities in their research interests. The images of authors working on HCI might then be drawn in pencil style, while researchers working on computer graphics could be drawn in mosaic style. Coelho and Mueller [6] introduced the idea of Infomages. Infomages refer to informal visual data representations that incorporate a data chart directly into a thematic image, as commonly done for InfoGraphics. A tool is provided that guides the user in creating such Infomages and that leverages object detection algorithms and style embedding techniques to avoid cumbersome manual image processing. The interactive tool supports the designer in carefully crafting InfoGraphics that merge subject matter images with the designer’s interpretation of the data. In contrast to both these approaches, LSDvis takes a more general approach by blending data visualisations with any real world environment that may or may not be semantically related.\n\n2 Illustrating LSDvis\n\nWe now go into detail illustrating our LSDvis concept. Given our targeted scope of this work, our goal was simply to create representative images of what we believe LSDvis may look like in the future. Thus, we turn to our machine overlords an AI image generation model for our work, thereby exploring AI-based visualisation techniques similar to previous papers (e.g. [42]). We first briefly describe our image generation process, then present the images which we have produced.\n\n2.1 AI Image Generation Process\n\nEach LSDvis was based on a 2D data visualisation and an image of a real world environment. We used a Stable Diffusion 1.5 model [28] with an img2img process. Two ControlNet conditional controls were added to each generation [47]. The first control was used to keep the style of the real world image intact. The second control was used to add the outline of the data visualisation, which could be one of the following: canny, hed, scribble, depth, softedge. These outlines were separate black and white images generated in a preprocessing stage that are machine readable by the ControlNet conditional controls. Each generation was completed with a specific text prompt to create the output (e.g. a detailed picture of a modern building with coloured bars on it), which was manually reworded and refined over multiple trials to improve the image. Outputs which we were satisfied with were then upscaled using the SD upscale script (64 tiles, x4 upscale) using the R-ESRGAN_4x+ upscaler model.\n\nIn the future, the prompt could instead be derived using a CLIP-like model [26] or a multimodel LLM model [23], creating a prompt based on what is in the two input images. This could also be combined with another LLM which can automatically recreate the prompt to integrate the data visualisation with the real world image in a certain way, thus removing the need for manual prompt creation.\n\n2.2 Examples\n\nWe now showcase several examples of LSDvis produced by our aforementioned AI generation process. We created these examples to test a variety of different conditions. First, we tested the effectiveness of additive and blending methods of image generation. Second, we experimented with literal representations of visualisation idioms. Lastly, we tested LSDvis with real world images we considered to be more difficult compared to the others, incorporating a level of situatedness to them.\n\nWe describe each example in the order which they appear in Figure 1. This figure shows all of the inputs and the subsequent output for each example. We include footnotes to the sources of all images used in the generation where appropriate.\n\n2.2.1 Additive LSDvis\n\nScatter plot + Brick wall. Being the first example we tested, this demonstrates how windows can be added to a brick wall in order to mimic a simple scatterplot . Of course, while the number of data points is very small, we can imagine this to easily scale to larger datasets—simply by adding more windows! Note that this is the first of many examples which lose the detail of the axes and labels, which is likely one of the pitfalls of LSDvis.\n\nLine chart + Building facade. Similar to the brick wall, this example adds metal pipes to a building’s facade based on a given line chart3. While the pipes themselves are not perfect, their resemblance is aided by the surrounding context that is the building. Of course, the colours of both lines are lost as a result of the generation, which is the first indication that LSDvis may not be suitable to encode colour. Regardless, we still see this as a success given the positional accuracy of the pipes.\n\n2.2.2 Blending LSDvis\n\nBar chart + Columns. Compared to the previous two examples, this one more dramatically modifies the real world by blending and distorting many of its features. Thus, not only new columns are added to the image based on a given bar chart3, but the existing column is modified to follow the new style. Such a dramatic blending of the real world may not be desirable in practice as it now becomes unrecognisable, but this is likely something which can be reined in with further optimisations to the prompt.\n\nVector field + Grass. This example blends a 2D vector field3 with a top-down image of grass , in hopes of the output resembling a grass field that is being blown with the wind. As we can see, the output LSDvis does ever so slightly resemble the input vector field, but is sometimes difficult to make out due to the texture—particularly on the bottom right.\n\n2.2.3 Literal LSDvis\n\nTree diagram + Field. We experimented whether we could create an actual tree based on an input tree diagram in an open field . While the resulting tree is rather skinny, it does resemble the input diagram remarkably well. LSDvis like this one are in a way similar to mirages, with physical (yet intangible) representations of data being added to the real world.\n\nStream graph + Forest. We also experimented with adding a stream graph as a literal stream inside of a forest . This would be much harder than the tree diagram, as the AI would need to not only add a river stream, but also blend it in with the existing forest to make it look natural. Needless to say it turned out very well. As mentioned above, the colour encoding does get lost as a result of this process. While the colour can potentially be added back in with further processing, seeing a stream with rainbow colours might be distressing to see, but arguably would add to the LSD effect.\n\n2.2.4 Situated LSDvis\n\nBar chart + Federation Square. Federation Square is a popular landmark and venue for public events and festivals in Melbourne, Victoria, Australia. As it can get busy, knowing the number of visitors per hour is important, which can be represented as a bar chart . While the AI does distort the shape of the building, it does a great job at making the bar chart appear as though it is actually part of it. This is, of course, partially aided by Federation Square having a rather abstract looking exterior, thus allowing the LSDvis to blend in much easier.\n\nArea chart + The Twelve Apostles. This example is set in The Twelve Apostles in Victoria, Australia. As it is in a remote area, visitors need to drive to see the natural landmark. Thus, this example shows the number of heavy vehicles which visit The Twelve Apostles, based on an input line chart . This line chart is then converted into an area chart, represented as an additional rock formation in the LSDvis. As one can see, the result is impressive, although several rocks in the background were removed in the final image. With that all said, such an example may call into question the ethics of LSDvis (beyond its questionable name): does adding new elements to famous landmarks, akin to mirages, mislead the viewer as to its actual appearance? This is similar to the notion of visualisation mirages [19], except causing (unintentional) deception of the real world and not of an inference made from the data. Perhaps intentionally having a less realistic LSDvis might avoid this issue entirely.\n\nPie chart + Sydney Opera House. The Sydney Opera House is arguably the most famous and recognisable Australian landmark. Other than being a work of art, it is also an actual business that hosts many shows such as, well, operas, and generates revenue. Therefore, this LSDvis incorporates a pie chart of the relative proportions of each of the Sydney Opera House’s revenue streams . The shells of the building are turned into the entire circle of the pie chart, with each segment roughly being visible. As with the other examples, the colour of the slices are lost in order to preserve the original colours and style of the building. Another potential question worth asking however is whether this distortion of famous landmarks can be seen as insensitive, especially if they have cultural or religious significance. This, however, we summarily decide not to answer.\n\n3 Discussion & Future Work\n\nThis work serves as merely a first step and “proof of proof of concept” to the concept of LSDvis. While it very much is intended to be lighthearted, we also believe that it demonstrates new possibilities and perspectives in how information could be presented to people. We first discuss several important topics that came about from reviews of this work, and then discuss the key considerations and future improvements to LSDvis.\n\n3.1 Leaning into the “LSD” moniker\n\nWhile the initial intention of the name LSDvis was to be catchy whilst referring to the blending of visualisations into the real world, it would seem that the overt reference to LSD elicited particularly insightful reviews and reflections on the concept that we now detail.\n\nHistorical connotations of LSD. Of particular interest, as reviewers had highlighted, the name LSDvis (incidentally) links back to a troubled history only slightly mitigated by the current positive research on the substance. Indeed, the history of LSD is a wild mixture of cultural appropriation of the use of psychoactive substances [38], the devastating impact that the War on Drugs had on indigenous populations and minorities in the US [25], the unregulated and illegal research conducted by the CIA (e.g. the MK Ultra project) [20], and the unprecedented and mostly positively-reported impact the drug had on art production (e.g. music) and culture [38]. Despite this, today LSD represents a promising drug for treating dependence [13], and displays interesting preliminary results on anxiety and depression [11]. Besides, LSD, like many other psychedelics, is considered to be physiologically safe if used within the standard doses. Pharmacologically speaking, LSD is considered to be non-addictive substance [9] and often ranked as one of the least harmful illegal drugs on the market, both for the users or society [21, 22]. All in all, LSD may denote anything from a very troubled history to a promising or recreational experience. We however welcome the feelings that the naming of our concept evokes as it elicited interesting discussion points on the parallel one may do with the use of the drug.\n\nThe hallucinatory metaphor. The most common use of LSD ranges from micro-dosing to standard doses. The first usually elicits no real hallucinatory experience but may improve mood (or artistic) performance, while the second usually triggers a short-lived (six to twelve hours) hallucinatory experience, colloquially called “trip”. Good trips may trigger short- to medium-lasting (weeks long) positive effects on users with respect to mood, sense of belonging, or spiritual enlightenment [18]. In parallel, bad trips may evoke fears, anxiety, or a feeling of hopelessness. We believe that the response to LSD use may also characterise the wide range of responses an AR situated and blending visualization experience can evoke. From small and unrealistic incrustations of data representations that would clearly be identifiable as not belonging to reality (similar to micro-dosing), to particularly well-embedded representations that may evoke strong emotional responses on the user (similar to a trip), LSDvis may have a vastly different impact on users. Beyond even the characterisation of the experience on the “trip spectrum”, one may also consider how good or bad the trip can be for users based on a multitude of parameters: realism, organicity of the visulisation, or even the data represented (e.g. the data may generate climate anxiety [5]).\n\nGuides in LSDvis. The hallucinatory experience is also interesting as it can link back to the idea that a guide may be necessary to maximise the experience. A guide is quite common to help users reflect and cope with the experience and limit the chances of a bad trip—a guide of LSDVis may have a very similar role. We imagine that the guide would be a visualisation-literate person or a domain expert of the visualised data who could answer the questions that the visualisation may elicit (reflect), provide more details on the dataset (reflect), assist the user with any negative feelings they may experience by ending the experience or providing more positive context and explanations (cope). In the case of generated climate anxiety for instance, one could point to positive data about climate change and its mitigation efforts. One may also consider that the guiding experience could be facilitated by an AI agent (based on LLMs for instance) that would manage to detect through simple biological measures (e.g. heart-rate, eye movements) either: an unpleasant experience, and would then offer potential mitigation strategies (cope); or curiosity, which would then answer any user queries. Such an agent could even be made to blend with the hallucinatory experience of LSDvis.\n\n3.2 Considerations of LSDvis\n\nAdding vs blending. As mentioned in Section 2.2, our examples generally used one of two approaches: either adding new elements to the real world image, or distorting existing elements of the real world image. From our own observations, we feel that the additive method does yield more visually impressive results, at least given the method that we used. The blending method does result in more questionable outputs, over-distorting the real world image to the point where it may become unrecognisable. This was made apparent while creating our examples, as these blended images took much greater trial and error to achieve a reasonable output compared to additive images. While the additive method is not foolproof, as some examples had rocks removed or mountains reshaped, this can potentially be minimised via inpainting.\n\nAxes, labels, and colour. Several of our examples had input data visualisations which included axes, labels, colour, text, etc. All of this information was lost during the image generation process, even if they were still present in the processed input. Obviously, such information can still be added with further processing, or in our case using Photoshop. However, it is worth questioning whether including these more abstract elements would ruin the aesthetics and appeal of LSDvis. For example, the multiple columns certainly do follow the same heights as the input bar chart, but without the y𝑦yitalic_y-axis it can be impossible to tell what data they encode (if any). From a utilitarian standpoint, this means LSDvis has no value, especially when viewed in the real world. From a more fun perspective, this means that LSDvis has an element of “if you know you know”. Only those “in the loop” are aware of its meaning, which may make people more willing to engage with data and share their knowledge with others to flaunt this exclusive knowledge (similar to dank memes on the internet).\n\nLevel of realism. With the exception of the Sydney Opera House, all of our LSDvis examples do look fairly realistic even despite being AI-generated. While they may not be entirely practical (e.g. randomly placed windows, irregularly bent pipes), they do still fall into the realm of plausibility. This therefore improves the ambience of LSDvis—the less bizarre it appears, the more it simply blends back into its surrounding environment. On the other hand, should the LSDvis appear to be entirely realistic (as is the case of the Sydney Opera House), it now enters the non-human uncanny valley whereby it very obviously encodes something and might stand out almost too much. These two ends of the realism spectrum are in fact representations of hallucinatory experiences with LSD, from micro-dosing (using small doses) to trips. Therefore, if the goal of LSDvis is to subtly hide data in the real world without the viewer noticing, then aiming for a high level of realism is vital. If the goal is instead to just present data in a wacky and interesting manner, then go nuts—realism be damned.\n\n3.3 Improvements to LSDvis\n\nThere are numerous obvious avenues for improvement to LSDvis. While the name and motivation of LSDvis may not be conducive towards more “traditional” research, all of these research directions are generalisable beyond our concept. Note that we intentionally do not include improvements that focus solely on the AI aspects.\n\nTaxonomisation of physical elements to visualisation components. As was the original intention, many of our examples see physical elements being used to encode data. The same way that data can be mapped to graphics [2], so to can data be mapped to physical elements (akin to data physicalisation [12]). Of course, the scope of physical elements is orders of magnitude greater than simple graphical primitives, so we expect such a taxonomy to vary based on domain and use case.\n\nReal-time AR rendering. While more of a technical limitation, the end goal would be to achieve such a hallucinatory effect in real-time AR. At present, each image takes approximately 20 to 30 seconds to generate, excluding any further iterations and refinement to optimise the prompt. Regardless, this is a real possibility given the current pace of AI research in the next several years.\n\nAnimated transitions in LSDvis. Similar to how animation can be a useful technique in data visualisation [10], it may also be useful in LSDvis. Animations can further add to the hallucinatory effect of the LSDvis, as parts of the physical environment may move, pulsate, and twist. This may be creepy to some people, which depending on the use case might actually be the goal of LSDvis. Animation can also be used to visually transition the viewer between the real world and LSDvis, with them seeing the walls, furniture, and overall environment around them “coming to life” and give them the impression that they are, in a sense, falling down on spheres.\n\n4 Conclusion\n\nIn this workshop paper we presented LSDvis, which is a lighthearted and playful way of visualising data in situated contexts in a manner that more closely resembles hallucinations. While perhaps lacking in its utility, we hope that LSDvis serves to promote visualisation designs which prioritise entertainment and engagement. In particular, we advocate for visualisations to not strongly pursue saliency and visual pop-out. Rather, visualisations—particularly those which are situated using AR—can instead be designed to be subtle, thus not bombarding the viewer with information on visually intrusive bright blue panels. This way, the information is there when the viewer notices it, but is otherwise “invisible”, thus letting them focus on the real world.\n\n5 Conflict of Interest\n\nLonni Besançon is a co-organiser of the 2023 alt.VIS workshop and was an organiser in 2021 and 2022.\n\nAcknowledgements.\n\nWe would like to thank our reviewers for their insightful and thought-provoking feedback. This project was funded by the German Research Foundation (DFG) project 495135767 and the Austria Science Fund (FWF) project I 5912-N (joint Weave project). The project is associated with and further supported by the DFG Excellence Cluster EXC 2120/1 – 390831618.\n\nReferences\n\n[1] A. Assor, A. Prouzeau, P. Dragicevic, and M. Hachet. Exploring Augmented Reality Waste Data Representations for Eco Feedback. In Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems, CHI EA ’23, pp. 1–4. Association for Computing Machinery, New York, NY, USA, Apr. 2023. doi: 10 . 1145/3544549 . 3583905\n\n[2] J. Bertin. Semiology of graphics. University of Wisconsin Press, Madison, Wis, 1983.\n\n[3] N. Bressa, H. Korsgaard, A. Tabard, S. Houben, and J. Vermeulen. What’s the Situation with Situated Visualization? A Survey and Perspectives on Situatedness. IEEE Transactions on Visualization and Computer Graphics, 28(1):107–117, Jan. 2022. doi: 10 . 1109/TVCG . 2021 . 3114835\n\n[4] V. Casamayou, Y. Jansen, P. Dragicevic, and A. Prouzeau. Ride Your Data : Raise your Arms, Scream, and Experience your Data from a Roller Coaster Cart. In alt.VIS 2022. Oklahoma City / Hybrid, United States, Oct. 2022.\n\n[5] S. Clayton and B. T. Karazsia. Development and validation of a measure of climate change anxiety. Journal of Environmental Psychology, 69:101434, 2020. doi: 10 . 1016/j . jenvp . 2020 . 101434\n\n[6] D. Coelho and K. Mueller. Infomages: Embedding Data into Thematic Images. Computer Graphics Forum, 39(3):593–606, 2020. doi: 10 . 1111/cgf . 14004\n\n[7] N. ElSayed, B. Thomas, K. Marriott, J. Piantadosi, and R. Smith. Situated Analytics. In 2015 Big Data Visual Analytics (BDVA), pp. 1–8, Sept. 2015. doi: 10 . 1109/BDVA . 2015 . 7314302\n\n[8] P. Fleck, A. Sousa Calepso, S. Hubenschmid, M. Sedlmair, and D. Schmalstieg. RagRug: A Toolkit for Situated Analytics. IEEE Transactions on Visualization and Computer Graphics, pp. 1–1, 2022. doi: 10 . 1109/TVCG . 2022 . 3157058\n\n[9] J. H. Halpern, J. Suzuki, P. E. Huertas, and T. Passie. Hallucinogen Abuse and Dependence, pp. 1–5. Springer Berlin Heidelberg, Berlin, Heidelberg, 2010. doi: 10 . 1007/978-3-642-27772-6_43-2\n\n[10] J. Heer and G. Robertson. Animated Transitions in Statistical Data Graphics. IEEE Transactions on Visualization and Computer Graphics, 13(6):1240–1247, Nov. 2007. doi: 10 . 1109/TVCG . 2007 . 70539\n\n[11] F. Holze, P. Gasser, F. Müller, P. C. Dolder, and M. E. Liechti. Lysergic acid diethylamide–assisted therapy in patients with anxiety with and without a life-threatening illness: a randomized, double-blind, placebo-controlled phase ii study. Biological Psychiatry, 93(3):215–223, 2023. doi: 10 . 1016/j . biopsych . 2022 . 08 . 025\n\n[12] Y. Jansen, P. Dragicevic, P. Isenberg, J. Alexander, A. Karnik, J. Kildal, S. Subramanian, and K. Hornbæk. Opportunities and challenges for data physicalization. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI ’15, pp. 3227–3236. ACM, New York, NY, USA, 2015. doi: 10 . 1145/2702123 . 2702180\n\n[13] T. S. Krebs and P.-Ø. Johansen. Lysergic acid diethylamide (lsd) for alcoholism: meta-analysis of randomized controlled trials. Journal of Psychopharmacology, 26(7):994–1002, 2012. doi: 10 . 1177/0269881112439253\n\n[14] B. Lee, D. Brown, B. Lee, C. Hurter, S. Drucker, and T. Dwyer. Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality. IEEE Transactions on Visualization and Computer Graphics, 27(2):1095–1105, Feb. 2021. doi: 10 . 1109/TVCG . 2020 . 3030435\n\n[15] B. Lee, M. Sedlmair, and D. Schmalstieg. Design Patterns for Situated Visualization in Augmented Reality. To appear in IEEE VIS 2023, 2023. doi: 10 . 48550/ARXIV . 2307 . 09157\n\n[16] W. Luo, Z. Yu, R. Rzayev, M. Satkowski, S. Gumhold, M. McGinity, and R. Dachselt. Pearl: Physical Environment based Augmented Reality Lenses for In-Situ Human Movement Analysis. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, CHI ’23, pp. 1–15. Association for Computing Machinery, New York, NY, USA, Apr. 2023. doi: 10 . 1145/3544548 . 3580715\n\n[17] K. Marriott, F. Schreiber, T. Dwyer, K. Klein, N. Henry Riche, T. Itoh, W. Stuerzlinger, and B. H. Thomas. Immersive Analytics. Lecture Notes in Computer Science. Springer International Publishing, 2018.\n\n[18] W. McGlothlin, S. Cohen, and M. S. McGlothlin. Long lasting effects of lsd on normals. Archives of General Psychiatry, 17(5):521–532, 1967. doi: 10 . 1001/archpsyc . 1967 . 01730290009002\n\n[19] A. McNutt, G. Kindlmann, and M. Correll. Surfacing Visualization Mirages. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1–16. ACM, Honolulu HI USA, Apr. 2020. doi: 10 . 1145/3313831 . 3376420\n\n[20] J. C. McWilliams. Covert connections: The fbn, the oss, and the cia. The Historian, 53(4):657–678, 1991.\n\n[21] D. Nutt, L. A. King, W. Saulsbury, and C. Blakemore. Development of a rational scale to assess the harm of drugs of potential misuse. the Lancet, 369(9566):1047–1053, 2007. doi: 10 . 1016/S0140-6736(07)60464-4\n\n[22] D. J. Nutt, L. A. King, and L. D. Phillips. Drug harms in the uk: a multicriteria decision analysis. The Lancet, 376(9752):1558–1565, 2010. doi: 10 . 1016/S0140-6736(10)61462-6\n\n[23] OpenAI. GPT-4 Technical Report, Mar. 2023. doi: 10 . 48550/arXiv . 2303 . 08774\n\n[24] A. Prouzeau, Y. Wang, B. Ens, W. Willett, and T. Dwyer. Corsican Twin: Authoring In Situ Augmented Reality Visualisations in Virtual Reality. In Proceedings of the International Conference on Advanced Visual Interfaces, AVI ’20, pp. 1–9. Association for Computing Machinery, New York, NY, USA, Oct. 2020. doi: 10 . 1145/3399715 . 3399743\n\n[25] D. M. Provine. Race and inequality in the war on drugs. Annual Review of Law and Social Science, 7:41–60, 2011. doi: 10 . 1146/annurev-lawsocsci-102510-105445\n\n[26] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever. Learning transferable visual models from natural language supervision. In M. Meila and T. Zhang, eds., Proceedings of the 38th International Conference on Machine Learning, vol. 139 of Proceedings of Machine Learning Research, pp. 8748–8763. PMLR, July 2021.\n\n[27] J. Rodgers and L. Bartram. Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback. IEEE Transactions on Visualization and Computer Graphics, 17(12):2489–2497, Dec. 2011. doi: 10 . 1109/TVCG . 2011 . 196\n\n[28] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-Resolution Image Synthesis with Latent Diffusion Models. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10674–10685, June 2022. doi: 10 . 1109/CVPR52688 . 2022 . 01042\n\n[29] A. Satyanarayan, D. Moritz, K. Wongsuphasawat, and J. Heer. Vega-Lite: A Grammar of Interactive Graphics. IEEE Transactions on Visualization and Computer Graphics, 23(1):341–350, Jan. 2017. doi: 10 . 1109/TVCG . 2016 . 2599030\n\n[30] V. Schetinger, S. Di Bartolomeo, M. El-Assady, A. McNutt, M. Miller, J. P. A. Passos, and J. L. Adams. Doom or Deliciousness: Challenges and Opportunities for Visualization in the Age of Generative Models. Computer Graphics Forum, 42(3):423–435, 2023. doi: 10 . 1111/cgf . 14841\n\n[31] S. Shin, A. Batch, P. W. S. Butcher, P. D. Ritsos, and N. Elmqvist. The Reality of the Situation: A Survey of Situated Analytics. IEEE Transactions on Visualization and Computer Graphics, pp. 1–19, 2023. doi: 10 . 1109/TVCG . 2023 . 3285546\n\n[32] T. Skog. Activity wallpaper: Ambient visualization of activity information. In Proceedings of the 5th Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, DIS ’04, pp. 325–328. Association for Computing Machinery, New York, NY, USA, Aug. 2004. doi: 10 . 1145/1013115 . 1013171\n\n[33] T. Skog, S. Ljungblad, and L. Holmquist. Between aesthetics and utility: Designing ambient information visualizations. In IEEE Symposium on Information Visualization 2003 (IEEE Cat. No.03TH8714), pp. 233–240, Oct. 2003. doi: 10 . 1109/INFVIS . 2003 . 1249031\n\n[34] L. R. Skreinig, A. Stanescu, S. Mori, F. Heyen, P. Mohr, M. Sedlmair, D. Schmalstieg, and D. Kalkofen. AR Hero: Generating Interactive Augmented Reality Guitar Tutorials. In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), pp. 395–401, Mar. 2022. doi: 10 . 1109/VRW55335 . 2022 . 00086\n\n[35] A. Stanescu, P. Mohr, D. Schmalstieg, and D. Kalkofen. Model-Free Authoring by Demonstration of Assembly Instructions in Augmented Reality. IEEE Transactions on Visualization and Computer Graphics, 28(11):3821–3831, Nov. 2022. doi: 10 . 1109/TVCG . 2022 . 3203104\n\n[36] I. E. Sutherland. The Ultimate Display. In Proceedings of the IFIP Congress, vol. 2, pp. 506–508, 1965.\n\n[37] G. Tkachev, R. Cutura, M. Sedlmair, S. Frey, and T. Ertl. Metaphorical Visualization: Mapping Data to Familiar Concepts. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems, CHI EA ’22, pp. 1–10. Association for Computing Machinery, New York, NY, USA, Apr. 2022. doi: 10 . 1145/3491101 . 3516393\n\n[38] G. Wadley. How psychoactive drugs shape human culture: A multi-disciplinary perspective. Brain research bulletin, 126:138–151, 2016. doi: 10 . 1016/j . brainresbull . 2016 . 04 . 008\n\n[39] Y. Wang, A. Segal, R. Klatzky, D. F. Keefe, P. Isenberg, J. Hurtienne, E. Hornecker, T. Dwyer, and S. Barrass. An Emotional Response to the Value of Visualization. IEEE Computer Graphics and Applications, 39(5):8–17, Sept. 2019. doi: 10 . 1109/MCG . 2019 . 2923483\n\n[40] S. White and S. Feiner. SiteLens: Situated visualization techniques for urban site visits. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1117–1120. ACM, Boston MA USA, Apr. 2009. doi: 10 . 1145/1518701 . 1518871\n\n[41] W. Willett, Y. Jansen, and P. Dragicevic. Embedded Data Representations. IEEE Transactions on Visualization and Computer Graphics, 23(1):461–470, Jan. 2017. doi: 10 . 1109/TVCG . 2016 . 2598608\n\n[42] J. Wood. Beyond the Walled Garden: A Visual Essay in Five Chapters. In alt.VIS 2022. Oklahoma City / Hybrid, United States, Oct. 2022.\n\n[43] J. Wu, J. J. Y. Chung, and E. Adar. Viz2viz: Prompt-driven stylized visualization generation using a diffusion model, Apr. 2023. doi: 10 . 48550/arXiv . 2304 . 01919\n\n[44] S. Xiao, S. Huang, Y. Lin, Y. Ye, and W. Zeng. Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model, July 2023. doi: 10 . 48550/arXiv . 2304 . 14630\n\n[45] L. Ying, X. Shu, D. Deng, Y. Yang, T. Tang, L. Yu, and Y. Wu. MetaGlyph: Automatic Generation of Metaphoric Glyph-based Visualization. IEEE Transactions on Visualization and Computer Graphics, 29(01):331–341, Jan. 2023. doi: 10 . 1109/TVCG . 2022 . 3209447\n\n[46] J. E. Zhang, N. Sultanum, A. Bezerianos, and F. Chevalier. DataQuilt: Extracting Visual Elements from Images to Craft Pictorial Visualizations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1–13. ACM, Honolulu HI USA, Apr. 2020. doi: 10 . 1145/3313831 . 3376172\n\n[47] L. Zhang and M. Agrawala. Adding Conditional Control to Text-to-Image Diffusion Models, Feb. 2023. doi: 10 . 48550/arXiv . 2302 . 05543"
    }
}