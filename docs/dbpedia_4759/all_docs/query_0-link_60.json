{
    "id": "dbpedia_4759_0",
    "rank": 60,
    "data": {
        "url": "https://lawreview.uchicago.edu/print-archive/working-themselves-impure-life-cycle-theory-legal-theories",
        "read_more_link": "",
        "language": "en",
        "title": "Working Themselves Impure: A Life Cycle Theory of Legal Theories",
        "top_image": "https://lawreview.uchicago.edu/themes/_custom/sd/favicons/favicon.ico",
        "meta_img": "https://lawreview.uchicago.edu/themes/_custom/sd/favicons/favicon.ico",
        "images": [
            "https://lawreview.uchicago.edu/themes/_custom/sd/logo.svg",
            "https://lawreview.uchicago.edu/themes/_custom/sd/logo.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "I.  The Object of the Life Cycle Theory",
        "meta_lang": "en",
        "meta_favicon": "/themes/_custom/sd/favicons/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://lawreview.uchicago.edu/print-archive/working-themselves-impure-life-cycle-theory-legal-theories",
        "text": "I. The Object of the Life Cycle Theory\n\nThe life cycle outlined in the Introduction is not equally applicable to all legal theories. Rather, it best captures those theories marked by proceduralism and depoliticization: theories that seek to negotiate highly politicized legal conflicts through the introduction of decisionmaking frameworks that abstract away from the central values in contention. This Part proposes to answer why such theories should be privileged objects of analysis, why they are so susceptible to the impurification process, and why it is reasonable to treat each such theory as a unitary phenomenon.\n\nA. Proceduralism and Depoliticization in Contemporary Legal Theory\n\nWe focus on theories that promise depoliticization through proceduralism not only because such theories are especially prone to the life cycle but also because, in our view, this style of theorizing is especially prominent in contemporary legal scholarship. Although nothing critical hangs on the exact chronology, one plausible candidate for dating the (re)emergence of this theoretical style is the 1980s. That decade began with the publication of Professor John Hart Ely’s landmark book, Democracy and Distrust. The book developed a justification for “representation-reinforcing” judicial review that attempted to square the Warren Court’s apparent revival of natural law jurisprudence with the late-stage legal process theory of Ely’s mentor, Professor Alexander Bickel. Within a few years, law review articles were heralding the advent of a “new legal process” or “new public law” program that sought to expand upon Ely’s defense of individual rights protection, while also modernizing process theory’s account of the administrative state in light of increasingly pointed critiques from public choice, law and economics, and critical legal studies (CLS). Even though new legal process failed to coalesce as a coherent movement, it signaled a renewed interest in theories that attempt to vindicate select high-level values by perfecting the means by which government officials reach legal decisions.\n\nLooking back further in time, one could argue that much contemporary legal theory is best understood as a development within the older legal process school of the 1950s and 1960s. Or one might argue that the “[p]uzzling [p]ersistence” of process-based theories reflects a basic tendency within American legal culture, if not within law itself, to seek nominal reconciliation of competing views about the content of public policy; legal theorists are perpetually redescribing these first-order political conflicts as—and rerouting them into—comparatively esoteric debates about the allocation of institutional authority and the rationality of decisionmaking methods. Despite the plausibility of these two longer narratives, we find the 1980s origin story more felicitous because the immediately preceding decades remain the last era in which moralistic argument flowered in American public law. The failure of the legal process synthesis to supply generally accepted standards for legal decisionmaking had become undeniable by the late 1960s, and in the wake of this failure came a series of “[a]ttempts to reinfuse constitutional law with principles of justice [that] persisted into and throughout the 1970s.” Representative of this shift were the many efforts made during this period to ground constitutional law in Rawlsian political philosophy.\n\nBut then the pendulum swung back. The public law theories that have gained the most traction since the 1970s have retreated from the open pursuit of justice in favor of a more formalistic, institutionalist orientation. Rawlsian theories of constitutional law are now a dim memory. So are Marxist and nihilist theories, for that matter. Like their counterparts in the “new legal process” fold, originalism, textualism, popular constitutionalism, and CBA eschew natural law notions and seek to transcend ordinary political divides—including the academic divide between “right-wing” versions of law and economics and “explicitly leftist CLS”—through the establishment of “particular procedures for reaching decisions about the terms of social life.”\n\nToday’s leading public law theories depart from the old legal process in acknowledging the normativity of legal decisionmaking and accepting that “no issues are simply ‘procedural.’” For instance, popular constitutionalism and originalism generally locate their legitimacy in popular sovereignty or popular ratification of the Constitution, while CBA generally privileges the substantive norm of social welfare. Yet in their focus on the manner in which legal authority is exercised, these theories have resurrected the process school’s founding commitment to the autonomous validity of law. Such theories are proceduralist to the extent that they define valid legal decisions as those reached by appropriate procedures or persons. Such theories are depoliticized to the extent that the decisionmaking models they recognize as valid abstract from the politically divisive values at stake in a given legal conflict.\n\nIn short, for all of its internal diversity, mainstream public law theory has operated within a certain template since at least the 1980s. This template seeks to accommodate normative conflict, linguistic indeterminacy, and regulatory complexity by means of proceduralism and depoliticization. The result is a recipe for impurification.\n\nB. Susceptibility to the Life Cycle\n\nEver since the New Deal shifted the center of gravity in American law toward federal regulation, public law conflicts have garnered the lion’s share of political attention. Accordingly, one can expect a large and interested audience for any theory promising resolution of a significant public law controversy. And that is the implied promise of the theories we describe: by reorienting official practice around new methods or criteria for public law decisionmaking, such theories hold out the hope of resolving politically contentious legal conflicts without reference to the primary values in contention.\n\nThese theories are so susceptible to being compromised because of the way in which they seek to forge compromise. On the one hand, these theories inject reformist ideas into debates that are perceived to matter a great deal. Participants are likely to be sensitive to such efforts and to register their discontent if they suspect any given proposal of privileging certain interests at the expense of their own agendas. On the other hand, these theories intervene in an abstract fashion, without speaking directly to the issues that animate participants on either side. Originalism and popular constitutionalism, for example, supply guidance about how the Constitution should be interpreted and by whom, but they have nothing explicit to say about which substantive goods society should prioritize or what the legal rules should be regarding abortion, health care, or any other public policy matter. This abstraction may reduce backlash in the short term, but it also creates conceptual space within the terms of the theory to incorporate competing perspectives on the underlying conflict.\n\nA fundamental tension emerges. The goal of proceduralism and depoliticization is to overcome, or appear to overcome, the divisions within a preexisting legal conflict. To achieve this goal, a theory must build a broad base of support that minimizes partisan taint. And so proceduralist, depoliticized theories must respond to at least some of the criticisms that their initial formulations engender. At the same time that this responsiveness allows the theories to broaden their bases, however, it leads them down the path of adulteration. The theories will become less purely procedural and more obviously charged with politically divisive meanings as newer iterations seek to appease constituencies that insist on the inviolability of various first-order commitments.\n\nGenerally speaking, then, we have reason to predict (and case studies to suggest) that the legal theories most susceptible to the life cycle will be those that seek to negotiate highly politicized legal conflicts by prescribing decisionmaking methods that abstract away from the central values in contention. Theories that do not seek to intervene in such conflicts—ones that address, say, an overlooked body of doctrine—are less likely to face critical audiences that demand adulteration or to feel the same need to appease such critics. For the historically contingent reason given above, this suggests that private law theories may be less likely to experience the life cycle; the balance of highly politicized legal conflicts occur today in public law.\n\nAt least three types of prescriptive legal theories that do intervene in politically contentious legal conflicts may also depart from our paradigm and avoid the life cycle. First, some may endorse decision procedures that are so fluid or underspecified that partisans cannot tell which values or interests their adoption would ultimately favor, disfavor, or displace. Examples here might include theories of experimentalism in public administration and theories of pluralism or multiple modalities in constitutional interpretation. A theory that is highly open-ended at the outset—agnostic on key questions of procedure as well as substance—will have few, if any, foundational goals to be compromised. It is impure by design.\n\nSecond, other theories may engage with a political conflict in a direct and substantive manner, rather than in an abstract, procedural register. In consequence, they may escape the critique that they have ignored the values most salient to the conflict, as well as the obligation to seek consensus validation. Examples here might include Professor Robin West’s theory of progressive constitutionalism and Professor Randy Barnett’s and Professor Richard Epstein’s theories of libertarian constitutionalism, each of which is grounded in contested normative commitments. These openly ideological arguments will face other, potentially severe, challenges in the marketplace of legal ideas, but impurification is less likely to be one of them.\n\nAnd third, a prescriptive legal theory that fails to gain an early base of support will not be perceived as a threat by key participants in any conflict. Its purity will be maintained at the expense of marginalization. Examples here are endless. The vast majority of proposed legal theories never leave the realm of the obscure.\n\nAll that we have said so far concerns prescriptive legal theories; what of their descriptive counterparts? To the extent that any legal theory can be considered purely descriptive, we suspect that it will prove relatively impervious to the life cycle. Because such a theory will not seek to dictate particular legal outcomes, it will have less of a need to expand its constituency and will be less likely to receive pushback from the many parties opposed to those outcomes. In the absence of such wide-ranging resistance, a descriptive theory could avoid significant impurification and still survive (although, like all theories, it might undergo a certain amount of transformation in response to critique). And while a descriptive legal theory, like any theory, needs commentators to affirm its worth, a prescriptive theory will generally need more, and more influential, supporters to bring about a desired change in the law. In pursuit of these supporters, concessions must be made, adulterations admitted.\n\nThat being said, our model is open to the possibility that the descriptive/prescriptive distinction is better conceived of as a spectrum than as a hard-and-fast dichotomy. Many positive theorists have prescriptive motivations. Many descriptive theories entail, or may be seen as entailing, certain sorts of legal outcomes that are subsequently “exposed” and critiqued on moral or policy grounds. Law and economics is perhaps the most significant example of an ostensibly descriptive theory of law (at least as classically formulated) that has been understood by both proponents and opponents to have a normative thrust. In such cases, descriptive theories may experience life cycle effects—as indeed has happened with law and economics. In general, susceptibility to the life cycle turns on whether a given theory is widely perceived as likely to influence, and not just diagnose, official legal practice through the introduction of a depoliticized decision procedure.\n\nC. An Adulterated Theory or Multiple Theories?\n\nThis Article treats as single objects of analysis legal “theories” the contents of which are, at this writing, highly contested. Would it not be more appropriate to treat theoretical terms such as originalism or textualism as names designating sets of legal theories that share a family resemblance, but not necessarily a common life cycle? This question has more than semantic significance, as our own theory contends that the very capaciousness of originalism and textualism is attributable to a process of adulteration rather than elective affinity.\n\nNonetheless, we think that the question has two relatively simple empirical answers. First, theories and theoretical terms have origins. And at its origin, as Part III.A discusses, “originalism” meant something fairly specific to its supporters and critics. To be sure, individual supporters and critics disagreed with each other on numerous levels. But even to have these debates required the existence of some minimal consensus view of the emerging theory: an understanding of its basic assumptions, prescriptions, and goals that few participants would have disputed. This consensus is a social and historical fact about the legal community at a particular moment in time. It is precisely because of the intellectual and political setbacks and successes experienced by this original “originalism” that the term—and the theoretical school that embraced it—gradually became more complex, capacious, and even at times self-contradictory.\n\nSecond, however diverse a given theoretical school may become and however disparate the motivations of those operating within it may be, members of the theoretical school generally remain committed to the theory’s initial decisional formalism. Originalists do not abandon the decisional centrality of the constitutional text; textualists do not abandon the decisional centrality of the statutory text; cost-benefit analysts do not abandon the decisional centrality of a calculus of trade-offs; and popular constitutionalists do not abandon the decisional centrality of “the people,” even as they locate “the people” in more rarified institutional settings. This fixation on a theory’s initial formalism, despite increasingly significant intellectual and political differences among its proponents, belies an account of family resemblance or elective affinity. This fixation strikes us, instead, as strong evidence of the adulteration of a common source—which is to say, strong evidence of life cycle effects.\n\nWe should note that in assessing the development of these theoretical schools, our method is to examine the claims made in a theory’s name not only by law professors but also by government officials, public intellectuals, and movement activists. Such a broad description of a theory’s social base is open to the objection that it stacks the deck in favor of a finding of adulteration. For instance, by sharply distinguishing academic from judicial and popular invocations of a theory, one might be able to redescribe internal diversity and discord as the existence of multiple, relatively harmonious theoretical schools.\n\nThis objection strikes us as misplaced. Even within the confines of the academy, all of the theories under discussion have become highly adulterated. Furthermore, any effort to segregate academic from nonacademic invocations of a given theory would be in considerable tension with the structure of prescriptive legal theorizing. Such theorizing necessarily seeks, at some level, to attract nonacademic adherents: government officials in particular, as well as those who have the power to influence those officials. To restrict the inquiry to any single discursive community would be to miss the interpenetration of scholarly, governmental, and popular discourses that drives the development of these theories.\n\nII. The Structure of the Life Cycle\n\nWe now turn to the life cycle itself. It bears emphasis at the outset that our model is the product of an induction over a limited number of cases: those theories that have achieved widespread popularity in American public law during the past several decades. We do not claim to have identified any precise metric for assessing a theory’s popularity or “impurity,” much less any transcendent truth about law. Nevertheless, given the significance of the examples we have included and the historical trend they appear to represent, we feel reasonably confident that our model has predictive as well as descriptive power. At least for the foreseeable future, any process-oriented public law theory that attracts extensive support can be expected to arrive at a state of impurity. This Part elaborates on the stages of the life cycle, including the drivers and dynamics of the impurification process.\n\nA. Stage One: Theory Birth\n\nAt T1, the theory introduces a decision procedure or criterion for judgment that seeks to resolve a highly politicized legal conflict in terms that are relatively alien to the main points of political contention; in so doing, the theory differentiates itself from preexisting legal theories used to negotiate the conflict.\n\nAs noted above, the theories we see as most prone to the life cycle arise out of specific sociolegal conflicts. These conflicts are about legal questions, such as the best way for judges to interpret the Constitution or for administrators to implement statutes, but they have clear political stakes and identifiable political blocs. When originalism emerged as a theory of constitutional interpretation, for instance, it was widely understood to reflect “conservative frustration with the broad, rights-expansive decisions of the Warren and Burger Courts” in areas such as criminal procedure and reproductive choice. When popular constitutionalism emerged some two decades later, it was widely understood to reflect liberal frustration with the broad, rights-constrictive decisions of the Rehnquist Court in areas such as antidiscrimination law. The market for a new prescriptive legal theory begins to expand as the leading theories of the day come to be seen either as partial to one side of the conflict or as unresponsive to both sides—as doing too much political work or too little. By the time originalism arrived on the scene in the 1970s, “fundamental values” and other explicitly moral theories of constitutional interpretation had become associated with liberal and Democratic projects, whereas prominent alternatives such as structuralism had never aligned closely with any ideological camp.\n\nAgainst this backdrop, the new theory introduces an approach to legal decisionmaking that purports to advance a certain high-level end, such as democracy, judicial constraint, or social welfare, without committing to any of the political blocs that constitute the poles of the conflict. The theory may be inaugurated by one side or the other, as with the conservative push for originalism or the liberal push for popular constitutionalism. But its prescriptions are held out as uniquely attractive and legitimate regardless of which groups or which values end up winning in any given case. While proponents do not necessarily tout the theory’s substantive “neutrality”—conventional CBA, for example, was openly oriented around the pursuit of economic efficiency —they do claim a kind of relative neutrality. They promise an approach that allows official decisionmakers to avoid choosing directly among the competing political blocs and their first-order preferences. People of all stripes, it is claimed, should be willing to accept the theory in principle.\n\nThe precise date of birth for these theories can be difficult to pinpoint. The theory may be introduced (or reintroduced in modern form) in a foundational work or set of works, on which sympathetic commentators seek to build: Judge Robert Bork’s 1971 article Neutral Principles and Some First Amendment Problems and Professor Raoul Berger’s 1977 book Government by Judiciary are often said to have played this role in the case of originalism, which crystallized as a distinctive interpretive approach in the 1980s. Alternatively, the theory may be propounded in a range of contemporaneous works, leaving its pedigree more obscure. Among those who help to launch a prescriptive legal theory, some may be motivated by broad moral goals, some by narrow policy goals, some by professional advancement or personal renown, some by intellectual curiosity, some by the pursuit of truth, and some by a complicated mix of each of these factors and perhaps others as well. It may be the case that legal commentators face especially strong incentives to offer ambitious new theories, which will then have to be scaled back, on account of the preferences of law review editors or the dynamics of legal intellectual influence. But we need not delve too deeply into the determinants of legal theory entrepreneurship, as our focus is on aggregate sociological effects rather than individual behaviors. No matter what accounts for their genesis, all theories with the formal features we identify are susceptible to the life cycle. Once such a theory is born, its parents cannot control its ultimate life path.\n\nB. Stages Two through Five: The Dialectic of Impurification\n\nAt T2, critics of the theory highlight its failure to secure certain values that gave rise to the conflict in the first place.\n\nAt T3, the theory responds to these critiques by internalizing them—supplementing or modifying its approach so as to better serve the initially ignored values. As a result, the theory’s constituency expands, but at the price of normative and conceptual purity.\n\nAt T4, this process of criticism and response recurs.\n\nAt T5, the theory has come to reflect the conflict-ridden political and theoretical field it had promised to transcend. To the extent the theory ever posed a direct threat to particular participants in the underlying conflict, that danger has dwindled.\n\nMost theories that are introduced each year go nowhere. Even if they manage to attract attention, they fail to spark follow-on inquiry, much less develop into a recognizable school of thought. The question of why certain legal theories develop into intellectual and social movements is highly contextual and largely beyond the scope of this study. The one point we wish to raise in this regard is that, in the current legal process–inflected era, those prescriptive theories that lack an abstract, procedural orientation start with a competitive disadvantage. The susceptibility of a theory to the life cycle, that is, may be not only a product of its success in gaining a wide range of adherents but also a condition precedent for achieving such success in the first place.\n\nWhatever propels them forward, some prescriptive theories of the sort we describe do blossom into intellectual movements. And when this happens, impurification follows. Through an iterative process of contestation and reformulation, the theories become increasingly unmoored from the goals that were articulated to justify their adoption, adrift from their raisons d’être. The details of this evolutionary process are also highly contextual, to be sure, but the process itself is not so complex or contingent as to preclude a stylized model. The key development occurs at T3 (and may recur numerous times thereafter), when normative objections to the theory are not simply parried by those speaking in the name of the theory but rather are incorporated into the theory itself, through refinements designed to address the objections. This is the moment, to put it provocatively, when the theory begins to cannibalize itself.\n\nWhy and how do these self-defeating shifts occur? In a typical case, several mechanisms combine to produce the phenomenon. Some of these mechanisms may affect individual theorists who modify their views over time, while others rely on an influx of new commentators who continually criticize and revise the theory. Key impurifying agents include:\n\nPolitical feedback effects. As the new theory encounters criticism about morally relevant information that it excludes or about substantive values and social groups that it disfavors, notwithstanding its ostensibly depoliticized character, proponents may suggest revisions intended to broaden or maintain the theory’s appeal. Early versions of originalism that seemed hard to reconcile with Brown v Board of Education of Topeka, for example, were jettisoned in part to “make originalism safe for Brown” and the principle of racial equality that the canonical case embodies. The theory of originalism thereafter became harder to typecast as radical or right leaning in its methodological demands and policy implications.\n\nProfessional feedback effects. While impurification is partly driven by the need to incorporate discordant political views, it also follows from epistemic and practical weaknesses of the theory that only become apparent over time. As the new theory encounters criticism about such weaknesses, proponents may suggest revisions intended to make the initial idea not just more politically palatable but also more intellectually and institutionally sound or a better fit with prevailing legal norms, in ways that redound to their reputational benefit and attract partisans of alternative theoretical approaches. The theory becomes more sophisticated and less grandiose. Early versions of originalism that relied on idiosyncratic notions of the Framers’ intent, for example, were jettisoned in part to make the theory more coherent, if less constraining. What we are calling a process of impurification can thus be seen as a process of purification from another perspective: the very moves that undermine the theory’s initial normative aspirations may be ones that make it conceptually richer and more refined.\n\nFragmentation and co-optation. As the new theory is elaborated by more and more commentators, differences of opinion may emerge and eventually crystallize into competing versions of the theory, further compromising the objectives of its founders. Some of the second- and third-generation commentators who speak in the theory’s name may not share those objectives at all, and may even wish to subvert them. Originalism, as Professor James Fleming observes, has now experienced both balkanization into rival camps and Balkinization, or “what happens when originalism becomes so inclusive that even Yale law professor Jack Balkin, hitherto a pragmatic living constitutionalist, becomes an originalist.”\n\nChurches can excommunicate those who peddle false versions of their creed. Political parties may be able to withhold endorsements and financial support from those who defy the party line. Intellectual movements have no comparable tools to weed out saboteurs from sympathizers or to ensure internal discipline—perhaps especially if they are led by professors whose compensation derives largely from fixed, school-specific salaries (as in law) rather than competitive, centralized grants. As a prescriptive legal theory becomes increasingly influential, the universe of people who identify with the theory not only expands in size but also changes in composition, becoming more ideologically diverse and representative of the overall population of lawyers. Purists are absorbed into the crowd.\n\nC. Stage Six: Theory Death and Theory Persistence\n\nAt T6, the theory either falls out of favor with mainstream legal actors, at least for the time being, or persists in substantially adulterated form.\n\nThe life cycle reaches its end once a prescriptive legal theory, as expressed by prominent commentators and applied by public officials, becomes incapable of fulfilling the distinctive normative functions—including decisional clarity—it was created to fulfill. But life and law go on. One of two basic fates awaits a theory at T6.\n\nThe first is theory death. Legal thinkers and decisionmakers may gradually set aside an adulterated theory as a needless complication or obfuscation of the initial conflict, until at some point the theory ceases to claim new adherents. Such a slide toward irrelevance seems to be happening at this moment to popular constitutionalism. Although the impurification process we describe may have a dialectical cast, it does not necessarily yield durable syntheses.\n\nImportantly, however, abandonment of a theory may be only temporary. Today’s originalism is the successor to last generation’s “interpretivism.” Today’s CBA is the latest successor to versions of CBA dating back to the New Deal era. Both theories have older intellectual roots. A prescriptive legal theory may fade away at T6 only to be reborn, years later, in a slightly revised and relabeled form. And then the impurification process starts again. Our life cycle theory is thus consonant with a larger epicyclical account of legal theory development.\n\nThe second fate is that of stubborn persistence. Even if it no longer serves its motivating purposes, an adulterated theory may continue to command allegiance because it serves social interests that are unrelated to those purposes. There are many reasons, for instance, why contemporary left liberals may wish to associate themselves with originalism and CBA, as we explore in Part V. But those reasons have little to do with disciplining judges or administrators or with maximizing economic efficiency or fidelity to the constitutional text.\n\nIII. Case Studies\n\nHaving laid out the general framework of our model, we now turn to case studies to help illustrate its workings. This Part reviews the intellectual history of several prominent legal theories through the lens of the life cycle. As suggested above, there is a conventional narrative regarding when theories such as originalism and textualism emerged and what they were “about” during this formative period. We sketch these origin stories, which establish a baseline for understanding what the theories were meant to accomplish, and then trace the theories’ development in the years that followed. These case studies proceed in a necessarily summary fashion; a detailed version of any one of them would be an article unto itself. Nevertheless, we believe that the discussions below (and the more exhaustive historical treatments on which some of them draw) are sufficient to demonstrate that the life cycle model plausibly fits the evidence—that it provides a parsimonious and consilient account not only of why these theories have evolved in the manner that they have, but also of how these seemingly disparate episodes in public law reform are in fact closely connected.\n\nA. From Old Originalism to New Originalism\n\nThe story of originalism’s theoretical evolution has been told numerous times in recent years, so we will aim to be as concise as possible here. As already indicated, contemporary originalist theory arose out of conservative frustration with the “activist” constitutional rulings of the Warren and Burger Courts; received influential articulations in the 1970s from Professor Berger, Judge Bork, and then–Associate Justice William Rehnquist; and rose to public prominence in the mid-1980s following the advocacy of Attorney General Edwin Meese. In these early years, originalists urged a “jurisprudence of original intention,” according to which judges would be required to follow “the specific intentions of the Framers . . . regarding how a specific provision was meant to apply to specific issues.” This methodology was defended on democratic and rule of law grounds. But the “primary commitment” of originalist theory in the 1970s and 1980s, as many have observed, “was to judicial restraint.” Constraining judges through text and history was held out to be the theory’s central virtue and objective. “Originalist methods of constitutional interpretation were understood as a means to that end.”\n\nOriginal intent originalism met with a variety of objections. One line of critique called attention to the difficulties of recovering and applying the Framers’ (possibly quite varied) intentions. Another line of critique claimed that the Framers did not intend for their own subjective intentions to be controlling. A third line of critique emphasized that a jurisprudence of original intent might be at odds with celebrated decisions such as Brown, as some of originalism’s early proponents had openly acknowledged.\n\nIn response to these objections, originalism underwent a series of transformations. The focus of inquiry moved from the intentions of the Framers to the understandings of the ratifiers to the “original public meaning” of the constitutional text, or how the words of the Constitution “would have been understood by an ordinary, reasonably well-informed user of the language, in context, at the time, within the relevant political community that adopted them.” Justice Antonin Scalia helped catalyze this move in a 1986 speech that called on originalists “to change the label from the Doctrine of Original Intent to the Doctrine of Original Meaning.” In addition to the turn to public meaning, originalists generally came to embrace a distinction between “constitutional interpretation” (understood as the effort to discern the text’s communicative content) and “constitutional construction” (understood as the process by which that text is given legal effect). In the many instances in which the communicative content of the constitutional text does not fully determine a legal result, these originalists allow, a judge must engage in the “essentially normative” practice of construction. As a result of these and related shifts, the so-called new originalism that predominates today is conceptually sophisticated, richly elaborated, and substantially immune from the sharpest objections leveled against its predecessors.\n\nIt is also highly impure, in the sense we use that term. As Professor Thomas Colby has explained at length, the theoretical adjustments that have enhanced originalism’s academic credibility and broadened its political appeal have “effectively sacrificed the Old Originalism’s promise of judicial constraint.” The same developments credited with helping originalism “work itself pure” in a scholastic sense, that is, have compromised its foundational (and still often touted ) aim to limit judicial discretion and bring clarity and predictability to constitutional law. A number of internal schisms have opened up along the way, as some self-identified originalists seek to justify and facilitate its convergence with living constitutionalism, some seek to recast the theory in less normative and more positivistic terms, and some seek to fend off the foregoing efforts—and save originalism’s “soul” —through additional methodological modifications or a return to “[o]ld-time” ideas such as intentionalism.\n\nYet while Colby is correct that originalism has “sacrificed” some of its original ideals as it has become increasingly refined, he errs in assuming that this theoretical trajectory (or this trade-off) is peculiar to originalism. On the contrary, the process of adulteration through maturation is endemic to legal theorizing. It is the life cycle. The failure to understand originalism’s development in this broader context, furthermore, distorts Colby’s reading of the evidence that he so sensitively assembles—leading him both to overstate the “inconsistency” and “incoherence” of the originalist movement, and to understate the real-world effects that its adulterated products may be having on the legal system. To make headway on the “bedeviling” phenomenon that Colby has observed, it is necessary to generalize, and theorize, his observations.\n\nB. From New Textualism to New New Textualism\n\nWhen the theory of “new textualism” emerged in the 1980s, it too promised to discipline judicial behavior—in the realm of statutes. New textualism took aim at the broadly purposive approach to statutory interpretation that had come to dominate theory and practice in the wake of the New Deal. Displacing an earlier textualist tradition that sought to locate legislative intent in the “plain meaning” of statutes, mid-century purposivists urged interpreters to “[c]arry [o]ut the [p]urpose” of statutes as best they can, on the assumption “that the legislature was made up of reasonable persons pursuing reasonable purposes reasonably.” The distinguishing features of this purposive approach included the extensive use of legislative history and a “soft plain meaning rule,” according to which “the plainest meaning [could] be trumped by contradictory legislative history.”\n\nBy the 1980s, however, this approach had led courts into a nettle of politically charged debates about the validity of new regulatory schemes. The judges’ “willingness to consider almost anything that was said about or happened to a legislative proposal that becomes a statute” only highlighted the political stakes of their interpretive methods. Drawing on modern public-choice scholarship as well as a classically formalist conception of the separation of powers, new textualists attacked the entire enterprise of “imaginative[ly] reconstruct[ing]” legislative intent. Purposivism, they argued, underestimated the complexity and opacity of the legislative process, overestimated the ability of judges to recover shared aims from biased committee reports and floor debates, and elevated judicial inclinations over the sovereign decisions embodied in legislative enactments. The most prominent new textualists, such as Scalia and Judge Frank Easterbrook, contended that these enactments—the statutory texts themselves—provided the sole legitimate source of law. “To favor a statute’s purposes over its text, they argued, was to ignore the constitutionally prescribed lawmaking procedures and to aggrandize the judiciary’s role in the constitutional design.”\n\nIt followed that exacting attention to a statute’s wording was the sole acceptable method by which judges could determine what the law required. Engagement with the relatively raw, value-laden language surrounding the passage of bills was both unnecessary and improper. By directing judges to focus on the semantic structure of statutory texts rather than the policy debates surrounding their passage, new textualism thus proposed to rescue the legitimacy of courts from the politically contentious chaos of modern lawmaking. Consistent application of interpretive canons to determine statutory meaning, moreover, would bring order to that chaos by spurring Congress to engage in more careful legislative drafting.\n\nThe theory of new textualism was suspected from the start of being a political project aimed at restraining judicial and legislative efforts to create a more liberal administrative state. Although these suspicions helped prompt a rapid scholarly response, critics generally engaged new textualism on its own depoliticized and proceduralist terms, focusing on the nuances of public choice and constitutional design. Professors Daniel Farber and Philip Frickey, for instance, argued that the public-choice analysis so popular with new textualists was “compatible with a more respectful attitude toward legislative intent,” while their four corners approach to statutory interpretation belied their own commitment to being “honest agents of the political branches.” A series of internal critiques soon followed. New textualists, it was alleged, assumed without warrant that courts treat nonstatutory legislative materials as sources of law rather than sources of evidence. New textualists undermined their own program by relying on a range of nonstatutory materials (from dictionaries to canons of construction to past precedents) to say what the law is; they also imputed intentions to Congress when deploying interpretive devices such as the absurdity doctrine. New textualists’ unprecedented refusal to consider legislative history actually aggrandized courts at the expense of Congress, given that legislators write laws against a backdrop of past judicial practice.\n\nNew textualists quickly adapted to these critiques, and gave up a good deal of ground in the process. As early as 1989, Scalia acknowledged that various interpretive canons used by textualists required courts to engage in purposive analysis and to consider public policy. The legitimacy of these canons, he would later explain, rests on a theory of implicit delegation of interpretive authority from Congress to the courts (or to agencies). By 1994, Easterbrook was prepared to concede that “‘[p]lain meaning’ as a way to understand language is silly” and to embrace the importance of contextual evidence. Three years later, leading textualist theorist Professor John Manning proposed that Scalia’s sweeping bicameralism-and-presentment argument against legislative history be replaced with a much narrower proposition: that nonstatutory materials such as committee reports could not authoritatively settle statutory meaning, as this would imply an impermissible “self-delegation” of legislative authority from Congress to an entity under its control. Manning’s argument not only was more esoteric than Scalia’s; it also contemplated and indeed championed recourse to legislative history as a means to “add substantial value to the interpretive process by supplying a well-informed, contemporaneous account of the relevant background to the enactment.” Surveying the theory’s development a decade after Manning wrote those words, Professor Jonathan Molot concluded that textualists “have been so successful . . . [at] distinguishing their new brand of ‘modern textualism’ from the older, more extreme ‘plain meaning’ school, that they no longer can identify, let alone conquer, any remaining territory between textualism’s adherents and nonadherents.” New textualism had worked itself impure.\n\nMolot oversimplifies, however, in attributing this development to the new textualists’ quick and canny responses to criticisms (or graceful concessions of defeat). An additional impetus to impurification came from the other side—from the efforts of the theory’s critics to adapt it to their own normative ends. For even as they rejected new textualism’s rigid conception of the separation of powers and its specific applications by judges like Easterbrook and Scalia, left-leaning skeptics increasingly came to view the theory as a useful corrective to purposivism’s own conservative tendencies. New textualism developed in parallel with a literature challenging overly “archeological” or “static” approaches to statutory interpretation, which assumed that the meaning of a statute was fixed at the time of its passage. On both democratic and hermeneutic grounds, a range of liberal scholars supported a more “dynamic” approach, and some of them argued that new textualism, properly understood, did so as well. Whatever its original political connotations, new textualism helpfully dispelled the fetishism of legislative intent and provided reasons to set aside legislative history, at least when such history was contrary to interpretations that were textually plausible and socially preferable. The vitality of this connection between a liberal commitment to judicial-legislative dynamism and a liberal openness to textualism (in highly adulterated form) can be seen today in scholarship that identifies and endorses new fields of federal common law, along with the proliferation of novel interpretive canons.\n\nTo be sure, one can still find “old” new textualists who, at least some of the time, seek to maintain the purity of the theory’s aversion to purposivism and intentionalism. But if the Roberts Court’s recent jurisprudence is any indication, these efforts represent a rearguard action, and a highly adulterated new textualism reigns supreme. King v Burwell supplies a particularly significant example. In King, Chief Justice John Roberts’s opinion for the Court cites no legislative history in construing the Affordable Care Act (ACA)—apparently basing its interpretation of an “ambiguous” statutory provision on a reading of that provision in the context of the statutory text as a whole and the application of several traditional interpretive canons. As just described, the Court’s approach sounds like a stringent form of textualism. Yet, as Scalia emphasized in dissent, the degree to which the provision was ambiguous was itself unclear. Roberts discerned from the “long history of failed health insurance reform” leading up to the ACA a “legislative plan” to expand access to coverage. In light of this plan, the meaning of the disputed provision became ambiguous, as its most literal interpretation would result in the failure to provide subsidies to millions of people legally obligated to purchase insurance. Roberts then resolved the ambiguity in a manner that was both permitted by the ACA’s text and accorded with its goals.\n\nDistinguishing itself from the old purposivism, the Court’s decision in King goes out of its way to establish that its interpretation “can fairly be read” from the statutory text. Yet the Court’s “key move,” as Professor Richard Re observes, is to integrate purposive considerations into the threshold “identification of textual clarity or ambiguity.” It has been suggested that the remaining divide between textualists and nontextualists generally reduces to disagreements over whether a particular statutory provision is or is not unambiguous. In its highly adulterated form, however, new textualism encompasses both poles of this debate: just compare the majority and dissenting opinions in King. As the King litigation further demonstrates, the original political controversy that new textualism sought to resolve—about how judges should respond to the growth of the administrative state—is now being reprised within the terms of the theory.\n\nC. From Popular Constitutionalism to Democratic Constitutionalism\n\nCompared to originalism and textualism, popular constitutionalism has passed through the stages of the life cycle at an accelerated pace. It burst on the intellectual scene and then was quickly reworked. The story of popular constitutionalism’s impurification is also comparatively straightforward, in our view, so we will tell it quickly.\n\nAlthough its basic themes have been explored many times since the Founding, the emergence of popular constitutionalism as a distinctive contemporary theory is often pegged to the publication of works such as Professor Mark Tushnet’s book Taking the Constitution Away from the Courts and Professor Larry Kramer’s article We the Court around the turn of the millennium. Alarmed by the conservative “activism” of the Rehnquist Court and the ethic of “judicial supremacy” that enabled it, Kramer and Tushnet drew on history to argue for a relocation of authority over constitutional interpretation and enforcement to “the people themselves.” Both their rhetoric and their reform ideas were bracing. Americans should consider “doing away with judicial review.” When the Court becomes “overly assertive,” Congress and the president should stand ready to “slash[ ]” its budget, impeach its members, “strip it of jurisdiction,” and “ignore its mandates.” The occasional rowdy mob might be useful too. Leading popular constitutionalists such as Kramer and Tushnet did not specify any single decision procedure—they differed in this regard from their counterparts in the originalism, textualism, and CBA movements—but their prescriptions likewise concentrated on the manner in which legal questions are resolved, in view of an overriding high-level goal (here, popular sovereignty).\n\nCritics on the political left as well as the right quickly mounted a range of objections. Popular constitutionalism, many worried, would debilitate judicial authority and jeopardize minority rights and individual rights. Its judgments rested on overly pessimistic premises about the aloofness of the Court and overly optimistic premises about the capacities and interests of ordinary citizens. Ironically, popular constitutionalism would prove unpopular in practice, given the American public’s long-standing support for judicial supremacy. If the theory somehow were to take hold, might it not lead to anarchy?\n\nScholarship identified with popular constitutionalism began to splinter. One strain sought to deepen the case against judicial review. A much larger and more conciliatory strain, however, attempted to parry the first wave of objections by softening popular constitutionalism’s conception of the “popular.” Kramer himself led the way. Responding to his critics, Kramer explained in 2006 that he was not calling for “direct action” or the abolition of judicial review, but rather for richer constitutional deliberation and the “mediation” of popular will “through formal institutions of government.” While devices such as “ignoring mandates, budget cutting, jurisdiction stripping, court packing, and the like” may be preferable to “nothing,” Kramer suggested, there are many subtler ways of exerting political pressure on the courts and thereby ensuring popular control over constitutional law.\n\nAs Tom Donnelly has noted, “[i]t is unclear whether this [was] simply a clarification of [Kramer’s] original intended position, a reevaluation based on thoughtful criticisms, or something in between.” Regardless, the message was clear that popular constitutionalism does not necessarily require populism in any recognizable form; rather, it can and should be effectuated through democratically accountable institutions. Sympathetic scholars increasingly began to migrate away from Kramer’s terminology in favor of the more decorous label of “democratic constitutionalism” proposed by Professors Robert Post and Reva Siegel. Foreshadowing this shift, Kramer slipped without explanation from “popular constitutionalism” to “democratic constitutionalism” in the penultimate sentence of a 2006 response piece.\n\nOnce the key adulterating move to “mediating” structures was made, it turned out that popular constitutionalism was everywhere. Scholars began to locate the practice of, or potential for, popular constitutionalism in an ever-growing list of institutions, from the federal Congress and executive branch, to state judicial elections and attorneys general, to the lower federal courts. Even the Supreme Court could be recast as an agent rather than an enemy of popular constitutionalism, given the empirical evidence showing that its opinions tend to stay within the mainstream of public opinion. Indeed, even Supreme Court decisions striking down progressive federal laws for exceeding the scope of Congress’s enumerated powers—the very paradigm of judicial activism that stirred Kramer to such righteous anger—might be recast as victories for popular constitutionalism, given their arguable benefits to democratic deliberation.\n\nPopular constitutionalism has thus crossed the political aisle and become increasingly self-contradictory. The theory has not simply failed to dispel controversy over the Court’s constitutional jurisprudence or to make any appreciable dent in judicial supremacy. It has given proponents of robust judicial review a new language of legitimation—just like originalism.\n\nD. From Quantitative CBA to “Qualitative” CBA\n\nWhile CBA is an expansive term with a long intellectual and political history, CBA as a prescriptive theory of public law emerged as a distinct discourse in the legal academy in the 1980s. It did so in response to the growth of CBA in judicial review of administrative action and, more significantly, the increasing use of CBA by administrators themselves. The latter trend reached its initial, controversial culmination in the Reagan administration’s 1981 executive order directing agencies to implement regulations only when “the potential benefits to society . . . outweigh the potential costs.” This requirement marked a decisive intervention in the long-running—and, by 1981, increasingly politically contentious—debate over the efficacy and legitimacy of the administrative state.\n\nMost participants in this debate agreed that the administrative state was beset by “regulatory failure,” but their diagnoses and proposed solutions differed sharply. Some argued that the central problem was capture of agencies by regulated industries and the consequent harm to regulatory beneficiaries. Others argued that the key problem was agencies’ heedless advocacy on behalf of putative beneficiaries, at the expense of regulated industries and the economic welfare of the nation as a whole. A third camp suggested that forces of bureaucratic entrenchment and self-aggrandizement were leading agencies further and further away from their statutorily imposed missions.\n\nThe Reagan administration’s CBA policy was seen to take sides in this dispute. As Professor Cass Sunstein noted shortly after the publication of the executive order, its implicit diagnosis of regulatory failure was that “regulation has been unduly intrusive on the private sector.” The administration’s solution, moreover, was undergirded by a particular “normative conception” of the administrative state: namely, that “the purpose of regulation—at least as a general rule—is to promote economic ‘efficiency,’ or to increase production, by compensating for free rider effects and transactions cost barriers to bargaining.” The executive order did not define “costs” and “benefits” in explicitly economic terms. Yet, as Sunstein concluded, “the language of the order, as well as the rhetoric used during its implementation, indicate[d] that it [was] intended to ensure that regulatory decisions will promote economic ‘efficiency.’”\n\nInterpreted in this way, as imposing a “wealth maximization” requirement on the administrative state, the 1981 order instantiated a potentially inflammatory prescriptive theory of public law. It ignored the leading alternative accounts of regulatory failure: capture and self-aggrandizement. And it appeared to endorse a rigidly welfarist version of CBA, one that economists and lawyers had spent more than a decade attacking for its theoretical refusal or practical inability to accommodate distributional concerns and other “soft” variables. Nonetheless, Sunstein offered a qualified defense of the executive order’s implicit theory, insisting that “the conception of the regulatory process reflected in the order is peculiarly well-suited to the institutional competence of the executive branch.” Nor was Sunstein alone among progressive legal theorists in supporting the Reagan administration’s initiative. As Professor Susan Rose-Ackerman summarized the state of affairs in the early 1980s:\n\nAt the level of broad substantive principle there was agreement between the Reagan administration and Progressivism on the need for regulatory reform. Both believed that government intervention in the economy should be justified by reference to market failures and that, insofar as possible, cost-benefit tests should be used to set regulatory policy.\n\nOf course, progressives were not blind to the deregulatory potential of CBA. Sunstein’s support was premised on the argument that the Reagan administration’s order contained an internal mechanism for taming the excesses of CBA, in its proviso that CBA be used “to the extent permitted by law.” What this meant, according to Sunstein, was that the CBA directive applied only to a subset of statutes: those whose efficiency-promoting implementation would not frustrate legislative purposes and thus compromise the separation of powers. Given that “the questions faced by Congress . . . are predominantly distributional,” Sunstein reasoned, many statutes would not be subject to efficiency maximization. Other statutes, however, appear to seek efficiency—for example, certain antitrust laws and laws “protecting against an ‘unreasonable risk’ to health or safety”—and so would fit comfortably with the logic of CBA. Still other statutes, including many antipollution laws, “have some effects which maximize wealth, and some that do not.” In these cases, an agency could choose to enforce “only the efficiency-promoting applications” of the law, so long as this “exclusive implementation [did] not fundamentally conflict with legislative purposes.” In addition, CBA could be used by agencies to select the most “cost-effective approaches” to implementation that vindicated Congress’s non-efficiency-maximizing aims, to “identify the costs and benefits of regulatory proposals with a view to statutory reform or ordering priorities,” and to “decline to act in exceptional cases of de minimis benefits and high costs.”\n\nBy imposing a separation-of-powers decision procedure on top of CBA’s own decision procedure, Sunstein effectively delegated the task of resolving many of the traditional critiques of CBA to an idealized model of administrative decisionmaking. For instance, the complaint that CBA fails to consider distributional or deontological values became something of a non sequitur in Sunstein’s scheme. It was simply against the law for administrators to use CBA to implement statutes with solely distributional goals, or to implement a statute’s efficiency-promoting provisions in a manner that “fundamentally conflict[s]” with the statute’s other, non-efficiency-promoting purposes.\n\nOver the course of the 1980s, actual administrative practice would frustrate this idealized model. An “atmosphere of scandal” thickened around the Environmental Protection Agency (EPA) in particular, as rumors swirled that the president’s Office of Management and Budget (OMB)—responsible for oversight of the CBA initiative—had “illegally delayed EPA promulgation of regulations” and “subverted statutory standards.” Mass resignations followed in 1983, and the new administrator, brought in to restore public confidence, fared little better. His “plan to propose a modest acid rain control program was vetoed after OMB Director David Stockman” determined “that it would cost several thousand dollars per pound of fish saved.”\n\nAgainst this political backdrop, academic criticism of public law CBA intensified. Scholars issued new challenges to CBA’s elevation of economic efficiency to the status of a legal norm. No defensible theory of regulation, many argued, could justify the categorical privileging of efficiency over other public values or individual preferences. CBA’s exaltation of efficiency would lead, instead, to a “lack of balance.” The Reagan administration’s CBA program, for example, allegedly “focused almost exclusively on reducing costs to industry.” Critics also questioned the ability of CBA to accurately price goods “not normally bought and sold on markets”—the sorts of goods that regulators so often have to take into account.\n\nBy the 1990s, these criticisms (and the experience of two Republican presidencies) had chastened those politically progressive legal theorists who had been initially supportive of the Reagan administration’s CBA initiative. When the Clinton administration introduced its own “Regulatory Planning and Review” executive order in 1993, Sunstein and his coauthor Professor Richard Pildes characterized it as a “quite surprising step.” President Bill Clinton’s order had retained the Reagan-era “emphasis on cost-benefit analysis as the basic foundation of decision,” they observed, but it also “include[d] a new, complex, and somewhat unruly set of substantive principles,” some of which “qualif[ied] the commitment to cost-benefit analysis, though in ambiguous ways,” and some of which were “of uncertain legality.” In response to this continuation and complication of Reagan-era CBA policy, Pildes and Sunstein offered “a range of proposals designed” to “simultaneously promot[e] economic and democratic goals.” These proposals amounted to a significant impurification of the theory of efficiency-maximizing CBA that Sunstein had defended fourteen years earlier. “Regulations should be evaluated not only in terms of aggregate costs and benefits,” Pildes and Sunstein wrote, “but also in terms that reflect democratic judgments about qualitative differences among qualitatively different risks”—including “an understanding of whether a risk is voluntarily incurred, especially dreaded, equitably distributed, potentially irreversible or catastrophic, faced by future generations, or incurred by discrete groups within the population.”\n\nNo longer could formalistic separation-of-powers principles be relied upon to prevent CBA from suppressing values sounding in distribution, desert, and the like. Indeed, Pildes and Sunstein’s rejection of a “single metric” of analysis and their call for a “disaggregated system for assessing the qualitatively different effects of regulatory impositions” strayed so far from traditional, efficiency-maximizing CBA that Professors Matthew Adler and Eric Posner argued the approach could not be properly characterized as CBA at all. Pildes and Sunstein’s approach resembled, rather, the sort of “procedure that agencies regularly seem to employ in lieu of CBA.”\n\nAdler and Posner sought to ward off such impurification. Writing in 1999, they explained that the deontological, distributional, “desert-based,” and “perfectionist” issues (“such as the purported intrinsic good of preserving endangered species”) that troubled Pildes and Sunstein were “nonwelfarist considerations”—and “CBA does not capture, and is not meant to capture, nonwelfarist considerations.” The political controversy and normative anxiety that welfarist CBA had provoked, in Adler and Posner’s telling, stemmed from a failure to appreciate that “CBA is a decision procedure, not a moral standard.” Adler and Posner allowed that CBA need not be “the exclusive choice procedure for government,” and could be employed “as one part of the overall set of procedures and institutions by which projects are ultimately approved, rejected, or amended.” But they insisted that CBA retain its pure, welfarist form, as only in that form can it reliably “enabl[e] agencies to evaluate projects according to the extent that they contribute to overall well-being.”\n\nBut such is not the fate of process-oriented public law theories. Three decades after Sunstein penned his formalistic defense of the Reagan administration’s imposition of efficiency-maximizing CBA on the executive branch, the Obama administration issued an order on “Improving Regulation and Regulatory Review.” By this time, Sunstein was serving as administrator of the Office of Information and Regulatory Affairs, and Executive Order 13563 reflected the adulterated conception of CBA that Pildes and he had proposed in the wake of the backlash to Reagan-era CBA. The order directs agencies to “select, in choosing among alternative regulatory approaches, those approaches that maximize net benefits (including potential economic, environmental, public health and safety, and other advantages; distributive impacts; and equity).” “Where appropriate and permitted by law,” the opening section continues, “each agency may consider (and discuss qualitatively) values that are difficult or impossible to quantify, including equity, human dignity, fairness, and distributive impacts.” The references to “fairness” and “human dignity” were new to this line of executive orders, and their inclusion led some conservative commentators to ask sarcastically whether “a rule might pass Mr. Obama’s cost-benefit test if it imposes $999 billion in hard costs but supposedly results in a $1 trillion increase in human dignity.” In practice, President Barack Obama has suggested that these “soft” variables have done little to disturb traditional, quantitative modes of analysis. In the law on the books as in the academic literature, however, such variables have become increasingly integrated into the methodology of CBA.\n\nBy the lights of Adler and Posner, this is no longer CBA. It certainly is not the version of CBA that Sunstein endorsed in 1981 as “peculiarly well-suited to the institutional competence of the executive branch.” As reflected in the governing executive orders and in Sunstein’s own writings, mainstream CBA has now internalized the very same “impossible to quantify” values of distribution, fairness, and dignity that hounded the administrative state throughout the 1970s and that the Reagan-era proponents of CBA had hoped to transcend.\n\nIV. Analogues to the Life Cycle Theory\n\nThe claim that prescriptive legal theories such as the ones just discussed tend to become impurified has numerous analogues, both in academic research and in the real-world operation of law and politics. Before we examine the implications of our claim for legal practice, this Part briefly examines parallels to the life cycle model elsewhere in law, political science, and the philosophy of science. Investigating these parallels helps to place our model in a larger conceptual context and further establish its plausibility. A comparison with the work of Professor Thomas Kuhn, in particular, helps to illuminate ways in which the progress of “legal science” does and does not resemble other fields of scientific endeavor.\n\nA. Analogues in Law\n\n1. Rules/standards convergence.\n\nLegal theorists in general, and constitutional theorists in particular, have posited life cycle–like processes before. On the jurisprudential side, scholars such as Professors Pierre Schlag and Frederick Schauer have argued that the putatively fundamental distinction between legal rules and legal standards turns out to be unstable over time, as rules tend “to evolve or degenerate, depending upon our perspective, into standards, and standards to evolve or degenerate into rules.” Rules are designed to be precise, offering clear ex ante guidance to interested parties. Standards are designed to be imprecise, leaving much of their content to be worked out on a case-by-case basis pursuant to an overarching principle or policy. And yet, in practice, these regulatory strategies gradually bleed into one another, as rules become riddled with qualifications and exceptions that reduce their clarity and standards become concretized through interpretations and understandings that reduce their flexibility.\n\nThe literature on rules/standards convergence relates to our own theory in at least two noteworthy ways. First, this literature sheds some light on the drivers of the life cycle. According to Schauer, whenever legal decisionmakers can “permissibly or legitimately or professionally” exercise discretion—and they usually can—they will be tempted to deploy “rule-avoiding strategies” to prevent the seemingly unjust or unreasonable application of a given rule to a given case. At the same time, many decision-makers will be tempted to rein in the “uncomfortable vagueness” of standards through “rulification” techniques: “More choice is not always better than less, and not every decision-maker has the time, energy, or inclination to engage in the ‘from the ground up’ process that unconstrained discretion and unspecified standards require.” The upshot of these paired processes of “adaptive behaviour” is the de facto merger of rules and standards.\n\nWhile the subjects of Schauer’s account are official legal decisionmakers, its behavioral assumptions would seem to apply, at least in part, to the reasoning in which legal scholars engage when they elaborate prescriptive theories. Presented with a certain set of rules or standards that a theory appears to endorse (“Judges should aspire to promote vague principle X,” “Agencies must forswear concrete practice Y”), scholars may similarly seek to recalibrate the degree of discretion that the theory affords by loosening or tightening its initial formulation. And they may take these rule-avoiding or rulifying steps for similar reasons: to arrive at more normatively or empirically satisfying legal frameworks, to prevent undesirable outcomes in specific cases, to ease their analytic burden, to signal restraint, and so on. Such adaptive behavior may also help explain how prescriptive legal theories can experience significant adulteration without departing from their original formalisms. A theory’s core set of rules or standards may remain accepted by all those who hold to it, even if different blocs of theorists would construe those rules or standards in significantly more or less constraining ways.\n\nThe second point of contact between theories of rules/standards convergence and our theory is that some extreme versions of the former could be read to anticipate or even subsume the latter. From Schlag’s point of view, for instance, the life cycle model may simply describe one instance of the “omnipresent” and “irreducible” dialectic between rules and standards that haunts legal discourse. Schlag contends that virtually all legal argumentation embodies this dialectic and thus follows a predictable path toward “refinement or entropy”—but never resolution. We are skeptical about the sweep of Schlag’s claim. But if he were right, then it may seem rather unsurprising to find certain legal theories becoming impurified; what demands explanation is the way in which this dynamic appears to unfold so much more slowly and subtly, if at all, for other sorts of theories. In general, though, the jurisprudential literature’s various accounts of rules/standards convergence complement our account insofar as each suggests a basic instability in efforts to channel legal decisionmaking into a relatively pure framework, as well as a concomitant need to analyze such efforts in dynamic terms. Whether embedded in an authoritative directive or an academic theory, the initial manner in which a legal prescription is formulated matters less than is commonly supposed.\n\n2. Cycles of constitutional theory.\n\nBeyond these abstract theories about the development of rules and standards, we also find analogues (or, at least, adjuncts) to our life cycle model in scholarship that identifies a tendency for constitutional theory, writ large, to experience politically driven cycles. The most sustained argument to this effect appears in Professor Barry Friedman’s article The Cycles of Constitutional Theory. At any given time, according to Friedman, those constitutional scholars who share the Supreme Court’s political orientation will tend to formulate theories that legitimate broad judicial review, while those scholars who disapprove of the Court’s political orientation will tend to promote theories that do the opposite. As a result, a generation of “conservative” or “progressive” constitutional scholars may, over the course of their careers, shift from supporting restrictive to supporting expansive theories of judicial power (or vice versa). Likewise, multiple generations of constitutional scholars with the same political orientation may adopt contradictory theories of judicial review.\n\nFriedman’s account operates on a longer timescale than ours; he is concerned with the oscillations across different theories rather than with the evolution of any given theory. Moreover, what cycles back and forth in Friedman’s narrative is a political bloc’s general attitude toward judicial review: pro or con. The actual content of the operative theories does not necessarily follow suit. Whereas we seek to explain the trajectories of individual legal theories, Friedman seeks to specify the motives that drive theory choice.\n\nFriedman’s account is nonetheless relevant for our purposes, both because it illustrates the degree to which public law theories are bound up with politics and because it helps place the life cycle in epicyclical context. We noted above that some highly adulterated theories that fall into senescence at T6 may reemerge at a later date. Friedman contends that political blocs will find themselves in need of a new legal theory at predictable junctures, when their attitudes toward judicial review change in response to the changing composition of the Court. The churn of the life cycle ensures a reserve of institutionally oriented, ideologically ambiguous theories from which such blocs can draw. Indeed, the sorts of legal theories most likely to undergo the life cycle are just the sorts of theories that Friedman suggests the politics of judicial review favor: theories that purport to transcend politics through “wide-reaching,” “structural” solutions.\n\nIf our life cycle model harmonizes with Friedman’s story in this way, it also gives reason to suspect that he overstates the “dilemma” of constitutional theory. The many constitutional scholars who traffic in structural solutions, Friedman warns, must either abandon their earlier theories of judicial review when the Court turns over or else “betray their own ideological values.” Yet as we have shown, the more wide-reaching and proceduralist a prescriptive theory, the more susceptible it will be to impurification. This dynamic allows for the sort of political responsiveness that Friedman predicts, but without the replacement of one theory by another that he assumes must accompany such responsiveness. A progressive scholar, for instance, may continue to endorse popular constitutionalism even if the Court turns sharply in a progressive direction, because legitimation by “the people themselves”—it will be claimed—can take any number of institutional forms. Similarly, large numbers of conservative originalists managed to adjust to the increasingly conservative composition of the Court without abandoning either originalism or their own ideological values, because legitimation by the constitutional text does not—it came to be claimed—require a commitment to judicial restraint. The impurification process contributes to intergenerational repetition and revisionism in constitutional scholarship, but it reduces the need for any given group of scholars to cycle between different theories in response to shifts in institutional politics.\n\nB. Analogues in Politics and Political Science\n\nFor more than a century, political scientists and sociologists have studied the process of “goal displacement” by which organizations that depend on mass support—political parties and trade unions in particular—tend to attenuate or abandon their initial policy objectives in order to broaden their membership. A related phenomenon is the attenuation or abandonment of policy objectives after political parties have achieved electoral success and entered government; this phenomenon is generally attributed to the domination of party representatives by relatively autonomous state bureaucracies and their private-sector clients. These processes of political moderation were first noted, and have remained especially acute, with respect to European social democracies, but similar dynamics have been identified in the American political system. The advent of an era of party polarization in the United States has not necessarily blunted the tendency toward adulteration of policy agendas that accompanies the pursuit of party growth and the penetration of party representatives into government.\n\nProcesses of party moderation offer an interesting if rather indirect analogue to the life cycle of prescriptive legal theories. On the one hand, the goal displacement experienced by political parties that seek to expand their base or enter government can be seen as the mirror image of the impurification experienced by theories such as originalism or popular constitutionalism. Parties initially hold themselves out as politically radical, but their policy objectives are gradually adulterated by the moderating forces of a mass electorate and an autonomous state bureaucracy. Prescriptive legal theories initially hold themselves out as above the political fray, but their proceduralist prescriptions are gradually adulterated as they accommodate a range of theoretical criticisms from participants in or around the political fray. Whereas adulteration in the first case proceeds through depoliticization, adulteration in the second case proceeds through politicization. On the other hand, processes of party-ideology and legal-theory adulteration can be seen as functionally identical. Both parties and theories adulterate their initial agendas in order to secure the support of broader constituencies (of voters or scholars) and particularly powerful groups of experts (entrenched bureaucrats and private-sector interests in the case of parties, official decisionmakers in the case of theories).\n\nFrom either point of view, the comparison of political parties and legal theories highlights the fundamentally sociological orientation of our life cycle account. This account does not reduce legal theories to the communities of scholars who espouse them, but neither does it treat them as formal sets of propositions divorced from their shifting social bases. Prescriptive legal theories, much like political parties, are continually constituting and being reconstituted by the goals of their supporters.\n\nC. Analogues in the History and Philosophy of Science\n\nThe life cycle model also bears an interesting resemblance to some of the literature on theory change in the history and philosophy of science. We have in mind especially Kuhn’s classic account of theory change in the natural sciences, although the aspect of his account that is most analogous to our model is shared by many other accounts of scientific theory change. This aspect is the claim that experimental falsifications of a given theory do not necessarily lead to the rejection of that theory so much as to the complication of its initial formulation. According to Kuhn, scientific “discovery” is nothing other than the adjustment of a preexisting theory to account for an “anomaly,” or “the recognition that nature has somehow violated the [ ] expectations” of the theory. Confronted with such violations, scientists do not discard their theory but rather “devise numerous articulations and ad hoc modifications of their theory” until “the anomalous has become the expected.”\n\nThis process of scientific discovery through theoretical adjustment can, in the long run, lead to the abandonment of one theory and the adoption of an alternative: that is, a scientific revolution. But first, the incumbent theory must enter a period of “crisis.” During the critical phase of a theory’s life, anomalies—and the theoretical adjustments they require—mount at such a rate and to such an extent that the “complexity” of the theory “increas[es] far more rapidly than its accuracy[,] and [ ] a discrepancy corrected in one place [is] likely to show up in another.” For example, in the decades before Antoine Lavoisier’s oxygen theory of combustion displaced the earlier phlogiston theory, “the net result of [combustion] experiments” had been a chemical typology “so elaborate that the phlogiston theory proved increasingly little able to cope with laboratory experience.” While none of the leading chemists of the day “suggested that the [phlogiston] theory should be replaced, they were unable to apply it consistently.” As a result, by the time Lavoisier came along, “there were almost as many versions of the phlogiston theory as there were pneumatic chemists” conducting combustion experiments.\n\nKuhn notes that this “proliferation of versions of a theory is a very usual symptom of crisis.” Another symptom is the increasing resemblance between the theory in crisis and earlier theories that were thought to have been superseded. Such critical symptoms are not, however, sufficient to lead scientists to abandon the incumbent theory. “[A] scientific theory is declared invalid only if an alternate candidate is available to take its place. . . . The decision to reject one [theory] is always simultaneously the decision to accept another.”\n\nOur life cycle account of legal theories parallels Kuhn’s account of natural scientific theory change in significant ways, but sharply diverges from it in at least one crucial respect. The most striking parallel is the idea that a theory develops through impurification—through the introduction of unexpected provisos and the modification, or even abandonment, of formerly central tenets. This process might tend to be faster or more contentious in law than in natural science on account of factors such as the volume of legal scholarship, the adversarial nature of legal discourse, and the political stakes of public law. But the basic structure of theory change is similar. Furthermore, on both accounts, the process of impurification is occasioned by resistance to the theory as it exists at a given moment in time. In Kuhn’s narrative, resistance comes from “nature” in the form of physical phenomena at odds with the theory’s expectations. In the life cycle, resistance comes from society in the form of legal, political, and moral objections leveled at the theory by other theorists and practitioners.\n\nAlthough there is a logical symmetry between these two kinds of resistance, their ontologically distinct character leads to a sharp divergence between Kuhn’s depiction of theory change and our own. For Kuhn, the boundary between periods of “normal science” and periods of “crisis” is not only sharply drawn but also normatively significant; the validity of natural science depends on it. During periods of “normal science,” the theoretical adjustments occasioned by “anomalous” physical phenomena produce scientific “discoveries” and are thus all to the good. During periods of “crisis,” however, a proliferation of anomalies leads to “pronounced professional insecurity” and an experience of “persistent failure” among scientists, as their theory becomes experimentally unwieldy and internally inconsistent. Although it will not be discarded until a superior alternative emerges, such a “monster” theory is felt to be fundamentally if indescribably at odds with nature and thus an embarrassment to the profession.\n\nThe life cycle of legal theories can admit no such sharp distinction between periods of normal science and crisis, between intrinsically legitimating and delegitimating theoretical modifications. To be sure, the process of impurification may produce legal theories that increasingly fail to influence crucial decisionmakers or that are criticized for incoherence or bad faith. But there is no truly external standard against which a theoretical modification can be deemed to have come up short. There are only other scholars and practitioners who may accept or reject the theory in its currently adulterated form. Normal science in the legal community—as perhaps in all social scientific and humanistic endeavors—is always in a critical phase.\n\nThere are historians and philosophers of science who argue that this reflexivity characterizes the natural sciences as well—that we lack the epistemological resources to draw any fundamental distinction between the natural and social sciences on the basis of the existence of a nonhuman nature. Kuhn is not one of them, though. He denies the falsifiability of natural scientific theories for the reason that no “anomalous” natural phenomenon will invalidate a scientific theory in the absence of a superior, alternative theory offered by human hands. But he also rejects thoroughgoing social constructivism. Nature is out there, Kuhn insists, a source of phenomena that can be described in a variety of different ways but that cannot be persuaded out of existence. It is nature, in the last instance, that dictates a theory’s descent from normal science into crisis and therefore, potentially, supersession through revolution.\n\nIn the absence of such a dictatorial nature, the only force that can cause a highly adulterated legal theory to “go bad”—and be seen to require discarding—is the negative judgment of other legal theorists and practitioners. The next Part considers in further detail some of the reasons theorists and practitioners may have for making, or declining to make, such a negative judgment.\n\nV. Lessons and Implications\n\nWhat does it say about a legal culture that its leading prescriptive theories tend to work themselves impure in the ways we have described? If the life cycle model captures something true about the development of legal movements, then this question warrants sustained investigation and reflection. We focus on two implications here. At a macro level, we suggest, the life cycle plays a generally salutary role in moderating the pace of legal change and maintaining a productive tension between law and politics. At a micro level, the life cycle underscores the need to look beyond the four corners of any given legal theory to understand the work it is doing. As the examples of originalism and CBA demonstrate in particular, adulterated theories may exert powerful disciplinary effects on legal scholarship and practice even after they have abandoned many of their initial assumptions and prescriptions, and even after they have failed to achieve their initial normative goals.\n\nA. The Conservatism of Legal Theory\n\nWhen public law theorists propose to resolve a politically fraught legal conflict by advancing a new decision procedure or decisionmaking ideal, the stakes can seem quite high. The relationship between legal theory and legal practice is uncertain and complex, of course, and theorists may be inclined to overstate their influence. Nonetheless, as the case studies in Part III reflect, the sociological connections between the legal academy, the courts, and the administrative state are close enough to enable a prescriptive theory of public law, under the right conditions, to move quickly from the law reviews and lecture halls to the United States Reports and the Federal Register. Yet as our case studies also reflect, the ultimate impact of such a theory’s adoption is unlikely to prove as normatively significant as one might assume at the outset. Prescriptive legal theories tend to succeed only after running the gauntlet of the life cycle; by the time they achieve widespread acceptance, their leading formulations look very different from their initial formulations. The theories come to recapitulate rather than resolve the underlying conflict in which they intervened.\n\nIt follows that the early proponents and opponents of these theories may not be playing for stakes that are as high as they think. The former can hope to achieve only partial victory. As time goes by, theories such as originalism, textualism, popular constitutionalism, and CBA end up not so much displacing as encompassing rival approaches such as living constitutionalism, purposivism, departmentalism, and qualitative analysis. If proponents of prescriptive legal theories find this observation to be chastening, opponents might find it a source of comfort—and power. Critics of ascendant theoretical movements, we have seen, may be able to “win through losing” by prompting concessions and tempering the perceived excesses of a disfavored theory. While an appreciation of the life cycle may counsel a certain realism about legal reform, it does not justify fatalism or quiescence.\n\nThe life cycle model also helps to illustrate why it is a fallacy of composition to assume that if certain leading theorists or theories seem “radical” at any given time, legal theory as a collective enterprise will be radical as well. The dialectic of impurification tends, instead, to push legal movements in more inclusive and conciliatory directions. To focus solely on a specific group of legal theory entrepreneurs or their specific proposals is to miss the myriad external forces that will inevitably rework their ideas, compromise their objectives, and condition their influence. A dynamic perspective is needed to understand the aggregate effects of such theorizing.\n\nThe life cycle theory itself ought to be considered in a dynamic perspective. We have emphasized that the susceptibility of prescriptive public law theories to impurification is partly a consequence of the form they generally take: process oriented and silent on the values that animate the conflicts they seek to resolve. As discussed in Part I, an especially bullish market for public law theories that purport to offer a depoliticized proceduralism has existed since the 1980s. This market is attributable to a series of contingent historical events: the failure of New Deal–era legal realism to secure the autonomy and primacy of the legal profession within the administrative state; the critique of the legal process school’s assumption of an underlying cultural consensus on the nature of rationality and democracy; and the backlash against the strongly normative legal theorizing of the 1960s and 1970s. If mainstream public law theorizing were to become more openly ideological or outcome oriented, then the life cycle might no longer loom so large. Perhaps the tendency of prescriptive public law theories to work themselves impure will wane in the years ahead.\n\nPerhaps, but we are doubtful. The norm—and the rhetorical utility—of claiming political neutrality has a long pedigree in American public law, and we can detect few signs of a nascent retreat from proceduralism and depoliticization in current scholarship. The life cycle model could lose most of its descriptive and predictive power one day, but it would take a sea change in our legal culture.\n\nAll of this may seem rather dispiriting insofar as it underscores the limits of legal theory and the obstacles to legal change. Those who believe that public law decisionmaking needs fundamental reform may be especially exasperated by the life cycle: one can hear this exasperation in the laments of “old-time” originalists that the theory has “lost its soul,” or in the insistence of economically minded theorists that deontological considerations simply cannot be a part of CBA. Yet while the impurification of any given theory is likely to strike many as suboptimal, the evolutionary pattern that we describe has some significant benefits for the legal system as a whole. The crises that felled legal realism and legal process are conventionally thought to have stemmed from a failure to manage the inextricable yet antagonistic relationship between law and politics; legal realism was insufficiently attentive to law, while legal process was insufficiently attentive to politics. The thoroughgoing politicization of law and the thoroughgoing legalization of politics both left lawyers in a protracted state of bad faith, either denying their own social and economic privilege as a distinctive professional class or denying the political conditions that underwrote that privilege. The contemporary mode of prescriptive legal theorizing, in contrast, allows lawyers to be lawyers even as it ceaselessly exposes them to the vicissitudes of politics. By proposing abstract theories about how legal decisions should be reached, lawyers exercise their core competencies. By having to adulterate these theories in response to politically charged critiques, lawyers are forced to acknowledge the empirical and normative limits of their capacity to solve public problems.\n\nMore importantly, through the life cycles (and epicycles) that legal theories undergo, law regenerates itself. Even if the controversies in which they intervene are ultimately irresolvable by law, legal theories’ tendency to supply process-oriented solutions that then undergo impurification keeps law “in the game.” Law is neither so powerful that it stifles major value conflicts, nor so inflexible that political actors demand an abandonment of it altogether. The dynamism of individual public law theories thus supports an overarching conservatism and stability in public law practice—not because the law itself is purified in a Burkean fashion through durable traditions that generate better and better judgments, but rather because legal innovation is perpetually tempered by political and professional feedback, and political contest is perpetually rerouted through law.\n\nWhile public law may not work itself pure, then, the impurification of influential prescriptive theories both reflects and reinforces its responsiveness to public deliberation and debate. This interpretation of the life cycle as part of a salutary, dialogic process of legal development echoes familiar accounts of the (passably) democratic character of Anglo-American common law. The irony of contemporary prescriptive theories is that, in trying to cabin legal discretion through formalistic, high-level frameworks, these theories end up catalyzing the sort of incremental contestation and transformation celebrated by defenders of discretionary, common-law decisionmaking.\n\nB. The Double Life of Successful Legal Theories\n\nIn light of the life cycle, the persistence of the best-known prescriptive legal theories presents something of a puzzle. These theories manage to secure a broad following only after abandoning, or at least substantially modifying, the normative commitments and practical proposals that recommended the theories in the first place. At their inception, originalism, textualism, and CBA promised to simplify and constrain judicial, executive, and scholarly resolution of public law debates, while partly insulating decisionmakers from the war of first-order values that undergirded those debates. Today, these theories’ decision procedures balloon with exceptions, metaprocedures, and side constraints. Not only do such baroque frameworks fail to simplify or constrain the work of decision; they actually dramatize the value-laden conflicts that the early proponents of these theories had promised to defuse. Such conflicts now take place within the highly adulterated procedural field of our most influential public law theories. The puzzle is why certain theories that fail to achieve their initial goals nonetheless gain and sustain such broad support, and what work this strange form of success accomplishes.\n\nAn exogenous hypothesis for theory persistence.\n\nThese questions suggest the outlines of a program of empirical research, one that we commend but cannot undertake here. We propose, however, that such a program begin with the following hypothesis: highly adulterated legal theories persist to a large degree because of the work they do “off the page”—serving interests and ideals that are exogenous to the theories’ stated norms. However elegant or powerful it might be, the internal logic of a theory like originalism or CBA is unable to provide a satisfying basis for explaining the theory’s persistence, given how compromised and contested that logic eventually becomes. It seems to us more likely that prescriptive legal theories have second-order (and third- and fourth-order) effects on the world that cannot necessarily be gleaned from their academic expositions, and that these effects are in fact what determine their fate at the end of the life cycle.\n\nWhat might this look like in practice? CBA, some have suggested, tends to enhance the power and prestige of economists and their allies within the legal academy and the administrative state. Even when seemingly noneconomic values such as dignity are incorporated within the cost-benefit calculus, the very form of the calculus exerts a disciplinary effect, privileging a certain mode of expertise and a certain vision of the administrative state that marginalizes alternative visions. Similarly, originalism and textualism may tend to enhance the power and prestige of lawyers as a privileged expert class, while raising barriers to entry for nonlegal actors. Originalism may also serve the interests of American elites more generally, at home and abroad, insofar as it implies that American power is constrained by an age-old set of universally appealing principles of good governance.\n\nEven the diversity and discord that frequently characterize highly adulterated legal theories may produce exogenous effects that favor their persistence. Take, for example, the potentially productive tension between byzantine academic defenses of a late-stage theory and the existence in popular discourse of a simpler, idealized version of that theory. Several scholars have posited just such a double life in the case of originalism. On this account, the professional embrace of a theory, in an impure form, lends intellectual legitimacy to its popular variant. In turn, the political appeal of the popular variant stimulates demand for the continuing professional use of the theory, however great the discrepancy between the popular and professional versions may be.\n\nIn a related vein, there may be situations in which two mutually reinforcing versions of a theory, one much “purer” than the other, exist within the professional legal community. We noted in Part III, for example, that while CBA has become endlessly complicated and compromised in law journals and in high-profile legal documents such as Executive Order 13563, federal administrators may continue to deploy a relatively pure, efficiency-maximizing variant of CBA in practice. In this case, the presence of the adulterated form of CBA—which ostensibly incorporates dignity, fairness, and other such “soft” variables into the analysis—may help to legitimate and shield from scrutiny the continuing, controversial primacy of efficiency maximization within certain agencies.\n\nAlternative hypotheses.\n\nOther hypotheses deserve consideration. It is tempting to explain the persistence of highly adulterated legal theories in a much more deflationary manner, as a story of path dependence and transaction costs: once a theory wins sufficient popularity, its opponents feel compelled to engage with the theory on its own terms, which means learning the language. And once the relevant scholars and officials have learned the language, it is simply easier for everyone to go on speaking it, rearticulating their fundamental disagreements through its prism. This deflationary account of theory persistence, however, is insufficient for at least two reasons.\n\nFirst, it has few resources to explain why some highly adulterated legal theories flourish whereas others recede into obscurity. For instance, despite similar initial commitments to judicial restraint and popular sovereignty, and an equally if not more simplistic decisional formalism, popular constitutionalism seems to be waning at this time while originalism reigns supreme. The best the deflationary account can do is demonstrate that originalism arrived on the scene first, and that a transition to popular constitutionalism therefore would have required new learning. Yet this explanation depends on the assumption that only one legal theory is dominant, or widely spoken, at a given time. While that assumption might well be warranted in the natural sciences, it is much less plausible in the social sciences. Our suggested hypothesis, on the other hand, can explain the waning of popular constitutionalism in terms of the poor fit between its decision procedure—which even in its adulterated formulations continues to exalt “the people themselves”—and the interests of legal elites.\n\nThe second problem with the deflationary account is that a focus on path dependence and transaction costs ignores the dynamism of widely accepted prescriptive legal theories. As we have seen, these theories gain acceptance through an iterated process of adaptation and adulteration, which demands a constant openness to challenge and capacity for change. Yet the deflationary account explains the persistence of such theories on the ground that theoretical learning is proh"
    }
}