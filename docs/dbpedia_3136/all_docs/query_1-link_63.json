{
    "id": "dbpedia_3136_1",
    "rank": 63,
    "data": {
        "url": "https://rjlipton.com/2010/03/13/breaking-provably-secure-systems/",
        "read_more_link": "",
        "language": "en",
        "title": "Breaking Provably Secure Systems",
        "top_image": "https://rjlipton.com/wp-content/uploads/2010/03/images3.jpeg",
        "meta_img": "https://rjlipton.com/wp-content/uploads/2010/03/images3.jpeg",
        "images": [
            "https://i0.wp.com/rjlipton.com/wp-content/uploads/2010/03/images3.jpeg?resize=104%2C78&ssl=1",
            "https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++E_%7Ba%7D%3A+x+%5Crightarrow+x%5E%7Ba%7D+%5Cbmod+q&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bq%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Ba%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++E_%7Ba%7D+%28+E_%7Bb%7D+%28x%29+%29+%5Cequiv+E_%7Bb%7D+%28+E_%7Ba%7D+%28x%29+%29+%5Cbmod+q.+&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bf%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bf%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bf%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bf%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bf%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7Bf%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+P%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+H%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+H%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+A%7D%7D&bg=e8e8e8&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+P%7D%7D&bg=e8e8e8&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+H%7D%7D&bg=e8e8e8&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+H%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+H%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+H%7D%7D&bg=ffffff&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&bg=e8e8e8&fg=000000&s=0&c=20201002",
            "https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&bg=e8e8e8&fg=000000&s=0&c=20201002",
            "https://secure.gravatar.com/avatar/2d7bff693baadb9394cef3de688463e0?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/afaa664a052777146630095c596117b2?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/2d7bff693baadb9394cef3de688463e0?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/970091cdfaf365130491cfc43ef1dac4?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/67a9188883318f0dfa4d8e453deb33dd?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/2d7bff693baadb9394cef3de688463e0?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/afaa664a052777146630095c596117b2?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/2d7bff693baadb9394cef3de688463e0?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/8981c1f01f028b7081e914c7b1d1d6ae?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/ec69cee30e0f484433cdd537ec0ce2db?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/afaa664a052777146630095c596117b2?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/c2546888ca27f86e2399ea486cb54ce4?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/357a20e8c56e69d6f9734d23ef9517e8?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/be26bdc1beb58a51b7f69cc173ec322e?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/be26bdc1beb58a51b7f69cc173ec322e?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/afaa664a052777146630095c596117b2?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/ec69cee30e0f484433cdd537ec0ce2db?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/be2692d3028119761c7260f9fc35464b?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/2d7bff693baadb9394cef3de688463e0?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/f3cb0908274c7ca0edb59d99bdbbd202?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/8deacfad4ee425948571d5fe18fb9a2e?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/ba889e55501f7001fde325517cb4a83a?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/9f465d4348610516e72fe40fe4d43342?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/caec9ab33329393086b7a16313821c65?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/e25bd0b21efd3671ede0d3fcd63bc560?s=60&d=identicon&r=g",
            "https://secure.gravatar.com/avatar/0ee47795848c54cf012a8a38aabf06de?s=60&d=identicon&r=g",
            "http://faq.files.wordpress.com/2006/11/a28.png?w=600",
            "https://i0.wp.com/rjlipton.com/wp-content/uploads/2014/12/lrqmitbookcover.jpg?fit=140%2C209&ssl=1",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://secure.gravatar.com/avatar/6e6a8cc1254b1e8a106deb594d1b3974?s=48&d=identicon&r=g",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://secure.gravatar.com/avatar/f7d54f7f006a2310645c5b28e5a1df82?s=48&d=identicon&r=g",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://secure.gravatar.com/avatar/d9779ec67344c3462ef2c75307b201d1?s=48&d=identicon&r=g",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://secure.gravatar.com/avatar/d9779ec67344c3462ef2c75307b201d1?s=48&d=identicon&r=g",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://secure.gravatar.com/avatar/d9779ec67344c3462ef2c75307b201d1?s=48&d=identicon&r=g",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "https://graph.facebook.com/v6.0/10209625708535882/picture?type=large",
            "http://sm6.sitemeter.com/meter.asp?site=sm6godel",
            "https://c.statcounter.com/10549194/0/7a3b68f9/1/"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2010-03-13T00:00:00",
        "summary": "",
        "meta_description": "Provably secure crypto-systems can and have been broken Neal Koblitz is a strong number theorist who is famous, among other things, for inventing elliptic curve cryptography. This was also independently invented by Victor Miller at the same time---1985. Neal, during his career, has also worked on critical reviews of applications of mathematics to other areas.…",
        "meta_lang": "en",
        "meta_favicon": "https://s0.wp.com/i/webclip.png",
        "meta_site_name": "Gödel's Lost Letter and P=NP",
        "canonical_link": "https://rjlipton.com/2010/03/13/breaking-provably-secure-systems/",
        "text": "Provably secure crypto-systems can and have been broken\n\nNeal Koblitz is a strong number theorist who is famous, among other things, for inventing elliptic curve cryptography. This was also independently invented by Victor Miller at the same time—1985. Neal, during his career, has also worked on critical reviews of applications of mathematics to other areas. Mathematics is a perfect fit for the physical sciences, but is less clear how it fits with the social sciences. Neal was, for instance, involved in a potential misuse of mathematical methods to social science—see my discussion earlier about Serge Lang and his book “The File.”\n\nToday I plan on talking about a recent article he wrote with Alfred Menezes for the AMS Notices entitled:\n\nThe Brave New World of Bodacious Assumptions in Cryptography.\n\nNot the usual math title—I have never seen a title like this in an AMS publication, or in any other publication. According to Wikipedia bodacious means:\n\nRemarkable, courageous, audacious, spirited;\n\nIn CB radio jargon, a general-purpose word of praise;\n\nA variety of iris (plant);\n\nVoluptuous, attractive, “hot,” appealing to the eye;\n\nBo-Day-Shus!!!, an album by Mojo Nixon and Skid Roper.\n\nNeal has been critical of theory’s approach to cryptography, and has written some very critical pieces. I do not agree with him, but I do think he raises some important issues.\n\nEarly Days Of Cryptography\n\nI have two background stories I wish to share—hopefully they will help explain my views on security, and why I think Neal has raised some interesting issues. It will also show how stupid I was, but I will get to this in a moment.\n\nCheating At Mental Poker: Adi Shamir, Ronald Rivest and Leonard Adleman (SRA) in 1979 wrote a paper on how to play “mental poker.” They described a protocol for playing two-person poker over a communication channel, without using any trusted party. One player acted as the dealer and handed out the cards, and both then played poker.\n\nWhen I got the actual paper—this is way before Internet and pdf files—I immediately realized there was a problem with their protocol. Their method used a family of maps\n\nwhere is a large prime and was odd. The key to their method was the simple observation:\n\nI sent Rivest a letter outlining an attack based on getting at least one bit of information: I used the observation that their maps preserved whether a number is a quadratic residue or a non residue. This allows the player who is “dealing” the cards to cheat and control who gets, for example, the aces.\n\nRon replied quickly, by return mail, with a fix: this stopped my attack, the dealer no longer could decide who got the aces. However, it still had a problem, the non-dealer could still see a few bits of information about the dealers hand. This is plenty of information to win at poker—in the long run. I should have challenged Ron to actually play for money, but instead wrote a paper on how to cheat at mental poker. The paper was not widely read, even though it was published as part of an AMS workshop. At least one paper cites me as “Ron Lipton”—oh well.\n\nShortly after this Shafi Goldwasser and Silvio Micali wrote a beautiful paper on how to use probabilistic methods to construct a protocol that avoided the problems I had pointed out. I was stupid, since I did not try to find such a provable protocol. At the time, I was working on complexity theory, and did not follow up on my crypto ideas. Too bad.\n\nA few years ago, at a very pleasant lunch in San Francisco with Dick Karp, Shafi and Silvio pointed out to Dick how much they were influenced by my cheating paper. Even though I usually get little—no credit?—for my work, they were quite adamant how important it was to their thinking about semantic security. I thanked them.\n\nIn the SRA paper, they did not realize their protocol leaked at least one bit—more than enough to win at poker. This simple example, in the hands of Shafi and Silvio, led eventually to important new ideas in cryptography. The second story is also about how hard it is define what is security.\n\nProving An OS Kernel is Secure:\n\nIn the summer of 1976, Anita Jones and I were part of a RAND summer study group organized by Stockton Gaines on security. Anita and I eventually wrote a fun paper during the summer: a paper with a long, complex, and crazy story; I will share it with you another day.\n\nDuring the workshop, Gerry Popek visited us one day, and gave a talk on his then current project to prove a certain OS kernel was secure. This was a large project, with lots of funding, lots of programmers, and he said they hoped in two years to have a proof of the OS’s correctness. What struck me during his talk was he could write down on the board, a blackboard, a relatively simple formula from set theory. The formula, he stated, captured the notion of data security: if a certain function had this property, then he would be able to assert his OS could not leak any information. Very neat.\n\nAt the end of his talk I asked him if he wanted a proof now that his function satisfied the formula. He looked at me puzzled, as did everyone else. He pointed out his was defined by his OS, so how could I possibly prove it satisfied his formula—the was thousands of lines of code. He added they were working hard on proving this formula, and hoped to have a full proof in the next 24 months.\n\nI asked again would he like a proof today? Eventually, I explained: the formula he claimed captured the notion of security was a theorem of set theory—any function had the property. Any. He said this was impossible, since his formula meant his system had no leaks. I walked to the board and wrote out a short set theory proof to back up my claim—any had his property. The proof was not trivial, but was not hard either.\n\nThe point of the story is: the formula captured nothing at all about his OS. It was a tautology. What surprised me was his response: I thought he would be shocked. I thought he might be upset, or even embarrassed his formula was meaningless. He was not at all. Gerry just said they would have to find another formula to prove. Oh well.\n\nProvable Security\n\nI hope I do not lose my theory membership card, but I think Neal has made some serious points in his recent paper. But, first let’s look at the foundations of modern cryptography. This is based on turning “lemons” into “lemonade”: turning hardness of certain computations into security of certain crypto-protocols. You probably all know the framework, but here is my view of it:\n\nLet be a protocol between Alice and Bob. This is nothing more than a fancy way of saying Alice and Bob have an algorithm—almost always random—they plan to execute together. The goal of the algorithm is to send a message, to share a secret, to agree on a value, to do a computation together, and in general to do some interesting information processing. Of course, Alice and Bob are using the protocol to avoid others from learning all or even parts of their information.\n\nLet be some computational problem we believe is “hard.” The assumption that requires a great deal of computation can vary greatly: it can mean worst case cost, average cost, and can, today, mean the cost on a quantum computer.\n\nLet be the class of “attacks” allowed against the protocol. Usually these have to be explicitly stated and carefully defined. Sometimes, we allow simple attacks, sometimes we allow more powerful attacks. For example, allowing the attacker to influence Alice or Bob is a much more powerful attack, than an attacker who passively watches their protocol.\n\nFinally, the proof of security is a mathematical theorem of the form:\n\nTheorem: Any efficient attack of type against the protocol , implies the problem is not hard.\n\nOf course, such theorems would have more quantitative bounds, but this is their general form.\n\nProvable Security?\n\nThe framework is very pretty, but can fail in multiple ways—as Neal points out in his papers. Let’s take a look at what can go wrong. It is convenient to do this in reverse order of the parts of the framework: the theorem first, then the attacks, then the hardness assumption, and finally the protocol.\n\nThe Theorem: Any theorem, especially a complex theorem, can have an incorrect proof. I have talked about this is several previous discussions—see here. Even great mathematicians make mistakes, so it should come as no surprise if cryptographers make mistakes.\n\nThere are two reasons errors here are perhaps more likely than in some other areas of mathematics. First, there may be much less intuition about the behavior of a complex protocol. No matter how precise you are in your reasoning in any proof, intuition is a great guide. Sometimes, I have thought I had proved something, but it did not fit with my intuition. Usually, this led, after more careful thought, to the discovery of an error in the proof.\n\nSecond, as Rich DeMillo, Alan Perlis, and I have pointed out in our famous—infamous?—paper on social processes, the social network of mathematicians is a requirement for confidence in proofs. Without others checking your theorem, teaching it in their class, using it in their own work, finding new proofs of your theorem, we would be flooded with errors. The trouble with crypto theorems is they do not always have this social network to back them up. Many crypto papers prove theorems used by others, but many do not.\n\nThe Attacks: This is in, in my opinion, the main issue: do the attacks include all the possible attacks? My examples on mental poker and OS kernels show two simple examples where attacks were not properly defined. There are many attacks on crypto protocols that were not envisioned initially. These include: timing attacks, fault based attacks, composition of protocols, and many others.\n\nThe Hardness Assumption: There are hardness assumptions, and there are hardness assumptions. Clearly, if the problem is not as hard as you thought, then even if the theorem and attacks are correct, the theorem is meaningless.\n\nThe failure of a hardness assumption to really be hard has happened over and over in modern cryptography. Famous examples include:\n\nThe assumption about hardness of knapsack problems;\n\nThe assumption in the original RSA paper on the cost of factoring;\n\nThe assumptions about solving certain Diophantine equations—especially the work of John Pollard and Claus Schnorr on solving binary quadratic forms, and Don Coppersmith on low exponent RSA.\n\nThe Protocol: Finally, the protocol itself is a potential failure point. If the protocol is implemented incorrectly, then all the other parts of the framework are useless.\n\nNeal’s Main Attack\n\nNeal’s main attack is on a paper written by of one of own faculty at Georgia Tech: Sasha Boldyreva. She with Craig Gentry, Adam O’Neil, and Dae Hyun Yum wrote a paper on a certain crypto protocol in 2007. In order to prove their protocol was secure they needed to assume a certain technical problem was intractable. They argued their assumption was reasonable: they even could prove it was hard provided the groups involved were generic.\n\nI will not explain exactly what this means, but in my view it is equivalent to really restricting the attacks allowed. Roughly, if a group is generic, then there are very limited operations an attacker can perform on the group. Neal quotes them as saying: This has become a standard way of building confidence in the hardness of computational problems in groups equipped with bilinear maps.\n\nThe problem is the attacker can use “burning arrows:” the attacker can use the structure of the group in question, and is not limited to treat it as a generic group. The attacker can do what ever they want, as long as the computations they perform are efficient. This is exactly what happened two years later: Jung Hwang, Dong Lee, and Moti Yung showed Sasha’s protocol could be easily broken. Neal—to hammer home his point—gives the attack in full, since it is so simple. Not simple to find, but simple since it involves only solving a few equations over the group.\n\nThe lesson here is a valid one I believe: we must be very careful in making assumptions about what an attacker can do. An equivalent way to look at this situation is: the hardness assumption was not true, if sufficiently general attacks against it are allowed. Neal then adds a comment:\n\nThe 4-page proof is presented in a style that is distressingly common in the provable security literature, with cumbersome notation and turgid formalism\n\nThis is unfair—I always have felt whether a proof is clear is a subjective statement. But, there is a lesson here. Just as SRA did not allow a simple attack that defeated their mental poker protocol, Sasha and her colleagues did not allow non-generic attacks against her protocol.\n\nOpen Problems\n\nRich DeMillo, Alan Perlis, and I, in our social process paper, were most concerned with implementations of complex software. The verification community idea, at the time, was to use mathematics to proof correctness of such systems.\n\nBut, perhaps one way to summarize is this: the whole framework of crypto-provable systems needs the same social processes we outline in our old paper. The exact specification of attacks, and the proof of the security of a protocol are just as vulnerable to problems as the implementation of any large software.\n\nAn open problem is to see more proofs of the completeness of attacks. I am unsure how we can do this, but I think this would be very confidence building for the field."
    }
}