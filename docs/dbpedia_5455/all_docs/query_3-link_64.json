{
    "id": "dbpedia_5455_3",
    "rank": 64,
    "data": {
        "url": "https://www.cambridge.org/core/journals/american-political-science-review/article/how-experiments-help-campaigns-persuade-voters-evidence-from-a-large-archive-of-campaigns-own-experiments/FF5BE6ED1553475F8321F7C4209357F7",
        "read_more_link": "",
        "language": "en",
        "title": "How Experiments Help Campaigns Persuade Voters: Evidence from a Large Archive of Campaigns’ Own Experiments",
        "top_image": "https://static.cambridge.org/covers/PSR_0_0_0/american_political science review.jpg?send-full-size-image=true",
        "meta_img": "https://static.cambridge.org/covers/PSR_0_0_0/american_political science review.jpg?send-full-size-image=true",
        "images": [
            "https://www.cambridge.org/core/cambridge-core/public/images/icn_circle__btn_close_white.svg",
            "https://www.cambridge.org/core/cambridge-core/public/images/logo_core.png",
            "https://www.cambridge.org/core/cambridge-core/public/images/logo_core.svg",
            "https://www.cambridge.org/core/cambridge-core/public/images/logo_core.svg",
            "https://www.cambridge.org/core/cambridge-core/public/images/logo_core.svg",
            "https://static.cambridge.org/covers/PSR_0_0_0/american-political-science-review.jpg",
            "https://www.cambridge.org/core/page-component/img/save-pdf-icon.080470e.svg",
            "https://www.cambridge.org/core/page-component/img/pdf-download-icon.c7fb40c.svg",
            "https://www.cambridge.org/core/page-component/img/pdf-download-icon.c7fb40c.svg",
            "https://www.cambridge.org/core/page-component/img/dropbox-icon.3d57046.svg",
            "https://www.cambridge.org/core/page-component/img/google-drive-icon.a50193b.svg",
            "https://www.cambridge.org/core/page-component/img/close-icon.194b28a.svg",
            "https://www.cambridge.org/core/page-component/img/share-icon.cbcfad8.svg",
            "https://www.cambridge.org/core/page-component/img/close-icon.194b28a.svg",
            "https://www.cambridge.org/core/page-component/img/cite-icon.44eaaa4.svg",
            "https://www.cambridge.org/core/page-component/img/rights-icon.d4a677c.svg",
            "https://www.cambridge.org/core/page-component/img/license-cc-icon.e3a74ed.svg",
            "https://www.cambridge.org/core/page-component/img/license-by-icon.33e212c.svg",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline1.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_tab1.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline2.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline3.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_tab2.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline45.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline46.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_fig1.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline47.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline48.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline49.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline50.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline51.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline52.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_fig2.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline53.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_fig3.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline54.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline55.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline56.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline57.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_tab3.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline58.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline59.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_fig4.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline60.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline61.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline62.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline63.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_inline64.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_tab1.png",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary-alt:20240207104950-93214-mediumThumb-png-S0003055423001387_tab2.jpg",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary-alt:20240207104950-40128-mediumThumb-png-S0003055423001387_fig1.jpg",
            "https://www.cambridge.org/core/journals/american-political-science-review/article/how-experiments-help-campaigns-persuade-voters-evidence-from-a-large-archive-of-campaigns-own-experiments/${staticDomain}/content/id/urn:cambridge.org:id:article:S0003055423001387/resource/name/S0003055423001387_inline47.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_fig2.png",
            "https://www.cambridge.org/core/journals/american-political-science-review/article/how-experiments-help-campaigns-persuade-voters-evidence-from-a-large-archive-of-campaigns-own-experiments/${staticDomain}/content/id/urn:cambridge.org:id:article:S0003055423001387/resource/name/S0003055423001387_inline53.png?pub-status=live",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary-alt:20240207104950-84458-mediumThumb-png-S0003055423001387_fig3.jpg",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240207104916660-0929:S0003055423001387:S0003055423001387_tab3.png",
            "https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary-alt:20240207104950-86595-mediumThumb-png-S0003055423001387_fig4.jpg",
            "https://www.cambridge.org/core/page-component/img/link-icon.edd0163.svg",
            "https://assets.crossref.org/logo/crossref-logo-100.png",
            "https://upload.wikimedia.org/wikipedia/commons/a/a9/Google_Scholar_logo_2015.PNG",
            "https://assets.crossref.org/logo/crossref-logo-100.png",
            "https://www.cambridge.org/core/cambridge-core/public/images/cambridge_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "LUKE HEWITT",
            "DAVID BROOCKMAN",
            "ALEXANDER COPPOCK",
            "BEN M. TAPPIN",
            "JAMES SLEZAK",
            "VALERIE COFFMAN",
            "NATHANIEL LUBIN",
            "MOHAMMAD HAMIDIAN"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "How Experiments Help Campaigns Persuade Voters: Evidence from a Large Archive of Campaigns’ Own Experiments",
        "meta_lang": "en",
        "meta_favicon": "/core/cambridge-core/public/images/favicon.ico",
        "meta_site_name": "Cambridge Core",
        "canonical_link": "https://www.cambridge.org/core/journals/american-political-science-review/article/how-experiments-help-campaigns-persuade-voters-evidence-from-a-large-archive-of-campaigns-own-experiments/FF5BE6ED1553475F8321F7C4209357F7",
        "text": "American political campaigns are among the most expensive in the world, and “television advertising is the cornerstone of many” of these campaigns (Sides, Vavreck, and Warshaw Reference Sides, Vavreck and Warshaw2021, 715). For instance, Jacobson and Carson (Reference Jacobson and Carson2019) find that almost half of a typical congressional campaign’s budget is spent on TV ads. The latest research finds that this advertising has small per-person persuasive effects that, across a large amount of advertising, can accumulate to meaningful effects on competitive election outcomes (Sides, Vavreck, and Warshaw Reference Sides, Vavreck and Warshaw2021).\n\nGiven the enormous sums they spend on television advertising and that the main mechanism by which such advertising affects elections appears to be through persuasion not mobilization (Sides, Vavreck, and Warshaw Reference Sides, Vavreck and Warshaw2021), a central challenge for campaigns is making this advertising maximally persuasive. Both campaign consultants and the academic literature are replete with theories of how to persuade voters in campaigns, especially through paid advertising. Empirically validating those theories is typically quite difficult because doing so requires estimating the causal effects of alternative advertisements. Campaigns and their consultants often use tools such as focus groups or intuition (Thurber and Nelson Reference Thurber and Nelson2001) that, while potentially providing some important insights, may not reliably uncover the causal effects of competing persuasive strategies. Experimental work carried out by academics, too, has its flaws, as it often relies on treatments academics themselves compose or tests advertisements outside of a campaign context, undermining ecological validity.\n\nOver the last decade, though, campaigns have increasingly conducted their own randomized experiments. These campaigns sometimes allow their experimental results to be shared publicly or in academic research (e.g., Kalla and Broockman Reference Kalla and Broockman2018), but the vast majority remain the private information of campaigns or parties (Issenberg Reference Issenberg2012). Moreover, even studies that are shared may be subject to publication bias (Franco, Malhotra, and Simonovits Reference Franco, Malhotra and Simonovits2014). What lessons do these typically proprietary experiments hold for long-standing theories of what persuades voters? And what implications does the rise of campaign experimentation have for American politics?\n\nIn this article, we provide a rare window into these questions based on a unique collection of experiments campaigns themselves conducted in the midst of two election seasons in the United States (US). In 2018 and 2020, dozens of Democratic and other left-leaning campaign organizations contracted with the technology company Swayable to conduct survey experimental tests of their advertisements, intended to be later run on television and digitally. The extent of Swayable use underscores the prevalence of experimentation in modern American elections: Swayable was hired to conduct advertising experiments in support of Democratic candidates in 20 of the 36 (56%) US House races rated by the Cook Political Report as toss-ups prior to the 2022 election, and 100% of the US Senate races rated as toss-ups prior to the 2020 and 2022 elections (seven and four races, respectively).Footnote 1 Swayable’s agreements with campaigns also allowed them to subsequently share the resulting data with academics for research.Footnote 2 The resulting set of experiments is an unprecedented treasure trove of data on the persuasive effects of campaigns’ real ads, as tested in real time, during real campaigns, among voters eligible to vote in those elections, from randomized survey experiments. We executed an agreement with Swayable that allowed us to access the de-identified data from their entire universe of experiments, and that allowed us to publish whatever conclusions we drew from our analyses of those data.\n\nTo understand the implications of campaign experimentation, in this article, we analyze the complete archive of these experiments from the original microdata. We make small adjustments to account for Swayable’s evolving design idiosyncrasies, described below. There are also some limitations to the data, such as incomplete information on attrition in some studies and the fact that these studies were originally conducted by a third party, described in greater detail below. We meta-analyze the resulting effect estimates to characterize average effects, what predicts these effects, and how variable these effects are. With research assistance, we hand-coded theoretically important characteristics of each ad such as primary focus, messenger, emotion, tone, appeals, and use of evidence. We include these measurements as predictors in our meta-regression models of persuasive effects.\n\nAs we analyze the entire archive of these experiments, we can set aside concerns about publication bias; campaigns could not choose to cherry-pick which experiments we analyzed based on the results. By analyzing data from multiple election cycles and at multiple levels of office, we can also offer insights into how these conclusions vary across contexts.\n\nOur investigation points to two main conclusions.\n\nFirst, we find small but politically meaningful variation in ads’ persuasive effects. Across the three contexts we examine (2018 downballot, 2020 downballot, and 2020 presidential), we find that the average ad affected immediately measured vote choice by 2.3 percentage points, 1.2 points, and 0.8 points, respectively. We estimate that the variance of the true treatment effects of the ads relative to these baselines is small but meaningful: our meta-analytic results indicate that the standard deviation of the distribution of true treatment effects were 1.5 points, 0.5 points, and 0.3 points, respectively, or roughly about half the size of the average effect. We characterize this scale of variation as “small” in absolute terms because even the largest of these amounts to just 0.03 standard deviations.Footnote 3 But this variation is nevertheless politically meaningful, since it is common for advertisements to be 50% less or 50% more persuasive than the average advertisement. Although we expect the absolute size of these advertisements’ effects to be much smaller in the field, when campaigns intend to deploy these advertisements to millions of people, we conduct simulations showing that choosing an above average ad over a below average ad could still easily determine the outcome of a close election. Our simulations also show that access to experimentation has profound implications for how campaigns should allocate their budgets.\n\nOur second main conclusion is that the extant theories about what features of advertisements make them more effective have very limited and highly context-dependent explanatory power. We consider a variety of theories in the academic literature as well as those common among campaigns—for example, whether ads work better when they are negative, provide new facts about candidates, attempt to elicit emotions such as anger or enthusiasm, or feature testimonials. These predictions have attracted substantial attention over decades of research, and we offer one of the most comprehensive and systematic explorations of them to date. Assessing these predictions of when ads will be more or less effective across 617 real advertisements, we find at best limited evidence for any of them. Moreover, we find that “what works” changes from election to election. For example, features that predict stronger effects among ads produced for the 2018 downballot elections fail to do so among ads produced for the 2020 downballot elections. Finally, even the theories that receive partial support explain a very small proportion of the overall variation in ads’ persuasive effects. These findings suggest limits on the ability of general theories to predict the persuasiveness of any particular political advertisements across highly heterogeneous electoral contexts.\n\nThese two conclusions in turn have two implications for campaigns and for American politics more generally.\n\nFirst, when it comes to campaign strategy, we conduct simulations that show that spending money on experimentation may be an extremely cost-effective investment. To the extent that ad experimentation does successfully identify more effective ads within an election cycle, modest investments to find the ads that work better would allow campaigns to dramatically increase the impact of their overall advertising spending. Indeed, our simulations find that the returns to ad experimentation may be so large that optimal campaign behavior would be to devote a substantial portion (over 10%) of their media budget to ad experimentation—a whole new category of expenditure that scarcely figures in classic theories of campaigning.\n\nSecond, we also demonstrate that this new behavior of campaigns has implications for American politics: experiments increase the influence of money in elections, because experimentation is a complement to campaign spending. In a world without experimentation, well-financed campaigns can of course “buy” more votes than less-well financed ones through more advertising (Sides, Vavreck, and Warshaw Reference Sides, Vavreck and Warshaw2021). But experimentation may also serve as a multiplier that enhances the importance of financial advantages because it increases the marginal effects of advertising spending by making those ads more persuasive. Our findings thus suggest that scholars should not only view campaigns’ use of experimentation as a way for researchers to generate knowledge about what persuades voters, but also as an object of study in itself with important implications for American elections and democracy.\n\nOur article makes several contributions that advance our understanding of campaigns in an era of experimentation. First, we demonstrate theoretically and illustrate through simulations that the extent of heterogeneity in the effects of different campaign ads conditions the payoff of experimentation for campaigns: the more heterogeneous the effects of ads, the more campaigns gain from experimentation. Second, empirically, we estimate the extent of effect heterogeneity in campaign ads—in other words, how much campaigns have to gain from experimentation—using a unique archive of real ads tested by real campaigns during real elections. Appendix D of the Supplementary Material quantifies the extent of this empirical contribution, showing that without access to the large archive of experiments we analyze, neither scholars nor practitioners would be able to form reasonably precise estimates about how heterogeneous the effects of advertisements are and therefore how beneficial experiments would be. Third, we provide some of the most comprehensive tests available to date of influential theories of campaign persuasion, using real ads to test them in the midst of real campaigns. We show that theories common among scholars or practitioners do not reliably predict ads’ effects, suggesting that there may be no alternative to experimentation to determine which ads are most effective in a given electoral context. Fourth, we show that, given the extent and seeming unpredictability of heterogeneity in ads’ effects, experiments are likely to increase the impact of money in elections, as they allow each dollar of campaign spending to persuade more voters. Finally, in the conclusion, we show how our theoretical analysis and empirical contributions suggest a series of priorities for future research about the promises and pitfalls of experimentation for campaigns."
    }
}