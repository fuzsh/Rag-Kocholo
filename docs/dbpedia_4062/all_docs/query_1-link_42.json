{
    "id": "dbpedia_4062_1",
    "rank": 42,
    "data": {
        "url": "https://www.science.gov/topicpages/r/range%2Bcross-well%2Bseismology",
        "read_more_link": "",
        "language": "en",
        "title": "well seismology: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Glacial seismology\n\nNASA Astrophysics Data System (ADS)\n\nAster, R. C.; Winberry, J. P.\n\n2017-12-01\n\nSeismic source and wave propagation studies contribute to understanding structure, transport, fracture mechanics, mass balance, and other processes within glaciers and surrounding environments. Glaciogenic seismic waves readily couple with the bulk Earth, and can be recorded by seismographs deployed at local to global ranges. Although the fracturing, ablating, melting, and/or highly irregular environment of active glaciers can be highly unstable and hazardous, informative seismic measurements can commonly be made at stable proximal ice or rock sites. Seismology also contributes more broadly to emerging studies of elastic and gravity wave coupling between the atmosphere, oceans, solid Earth, and cryosphere, and recent scientific and technical advances have produced glaciological/seismological collaborations across a broad range of scales and processes. This importantly includes improved insight into the responses of cryospheric systems to changing climate and other environmental conditions. Here, we review relevant fundamental physics and glaciology, and provide a broad review of the current state of glacial seismology and its rapidly evolving future directions.\n\nGlacial seismology.\n\nPubMed\n\nAster, R C; Winberry, J P\n\n2017-12-01\n\nSeismic source and wave propagation studies contribute to understanding structure, transport, fracture mechanics, mass balance, and other processes within glaciers and surrounding environments. Glaciogenic seismic waves readily couple with the bulk Earth, and can be recorded by seismographs deployed at local to global ranges. Although the fracturing, ablating, melting, and/or highly irregular environment of active glaciers can be highly unstable and hazardous, informative seismic measurements can commonly be made at stable proximal ice or rock sites. Seismology also contributes more broadly to emerging studies of elastic and gravity wave coupling between the atmosphere, oceans, solid Earth, and cryosphere, and recent scientific and technical advances have produced glaciological/seismological collaborations across a broad range of scales and processes. This importantly includes improved insight into the responses of cryospheric systems to changing climate and other environmental conditions. Here, we review relevant fundamental physics and glaciology, and provide a broad review of the current state of glacial seismology and its rapidly evolving future directions.\n\nSeismology in Chile\n\nUSGS Publications Warehouse\n\nKausel, E.\n\n1983-01-01\n\nThe Department of Geology and Geophysics, which is under the faculties of Mathematics and Physical Sciences of the University of Chile, is the organization that is responsible for the Seismological Service of Chile and for installing,operating, and maintaining the seismological stations as well as all the strong-motion stations in Chile.\n\nAlbuquerque Seismological Laboratory--50 years of global seismology\n\nUSGS Publications Warehouse\n\nHutt, C.R.; Peterson, Jon; Gee, Lind; Derr, John; Ringler, Adam; Wilson, David\n\n2011-01-01\n\nThe U.S. Geological Survey Albuquerque Seismological Laboratory is about 15 miles southeast of Albuquerque on the Pueblo of Isleta, adjacent to Kirtland Air Force Base. The Albuquerque Seismological Laboratory supports the Global Seismographic Network Program and the Advanced National Seismic System through the installation, operation, and maintenance of seismic stations around the world and serves as the premier seismological instrumentation test facility for the U.S. Government.\n\nSustainable access to data, products, services and software from the European seismological Research Infrastructures: the EPOS TCS Seismology\n\nNASA Astrophysics Data System (ADS)\n\nHaslinger, Florian; Dupont, Aurelien; Michelini, Alberto; Rietbrock, Andreas; Sleeman, Reinoud; Wiemer, Stefan; Basili, Roberto; Bossu, RÃ©my; Cakti, Eser; Cotton, Fabrice; Crawford, Wayne; Diaz, Jordi; Garth, Tom; Locati, Mario; Luzi, Lucia; Pinho, Rui; Pitilakis, Kyriazis; Strollo, Angelo\n\n2016-04-01\n\nEasy, efficient and comprehensive access to data, data products, scientific services and scientific software is a key ingredient in enabling research at the frontiers of science. Organizing this access across the European Research Infrastructures in the field of seismology, so that it best serves user needs, takes advantage of state-of-the-art ICT solutions, provides cross-domain interoperability, and is organizationally and financially sustainable in the long term, is the core challenge of the implementation phase of the Thematic Core Service (TCS) Seismology within the EPOS-IP project. Building upon the existing European-level infrastructures ORFEUS for seismological waveforms, EMSC for seismological products, and EFEHR for seismological hazard and risk information, and implementing a pilot Computational Earth Science service starting from the results of the VERCE project, the work within the EPOS-IP project focuses on improving and extending the existing services, aligning them with global developments, to at the end produce a well coordinated framework that is technically, organizationally, and financially integrated with the EPOS architecture. This framework needs to respect the roles and responsibilities of the underlying national research infrastructures that are the data owners and main providers of data and products, and allow for active input and feedback from the (scientific) user community. At the same time, it needs to remain flexible enough to cope with unavoidable challenges in the availability of resources and dynamics of contributors. The technical work during the next years is organized in four areas: - constructing the next generation software architecture for the European Integrated (waveform) Data Archive EIDA, developing advanced metadata and station information services, fully integrate strong motion waveforms and derived parametric engineering-domain data, and advancing the integration of mobile (temporary) networks and OBS deployments in\n\nResearch on history of Chinese seismology\n\nNASA Astrophysics Data System (ADS)\n\nFeng, Rui; Wu, Yuxia\n\n2010-06-01\n\nThe history of Chinese seismology can be traced back to four thousand years before and divided into four stages, i.e., primitive knowledge, worship of nature, perceptual knowledge and scientific research. The second stage ran in the whole Qin-Han dynasties, and the fourth stage began from Emperor Kangxi in Qing Dynasty and continued to the present. So far China has made four great contributions to seismological development of the world, i.e., the invention of Heng Zhangâs seismoscope, great amount of historical records of earthquakes of four thousand years, most abundant anomaly data before earthquakes, and successful practice of earthquake prediction in Haicheng. However, the seismological research in China at present is still on the junior and developing stage. Now we have been carrying on some recessively historical load in our mind such as the subconsciousness of absolute obedience, habit of phenomenological study as well as the methods of philosophical analysis without sincerity. For constructing a high-level Chinese culture in seismological research, we need to pay attention to combining the phenomenological research with experiment, observation and theory study. It is also suggested to take the appropriated measures matched with the present research level in seismology, as well as to promote coexisting and merging of multi-cultures.\n\nIntroduction: seismology and earthquake engineering in Central and South America.\n\nUSGS Publications Warehouse\n\nEspinosa, A.F.\n\n1983-01-01\n\nReports the state-of-the-art in seismology and earthquake engineering that is being advanced in Central and South America. Provides basic information on seismological station locations in Latin America and some of the programmes in strong-motion seismology, as well as some of the organizations involved in these activities.-from Author\n\nEPOS-Seismology: building the Thematic Core Service for Seismology during the EPOS Implementation Phase\n\nNASA Astrophysics Data System (ADS)\n\nHaslinger, Florian; EPOS Seismology Consortium, the\n\n2015-04-01\n\ncollection and dissemination mechanisms, as well as improving historical earthquake data services; - the development of a comprehensive suite of earthquake hazard products, tools, and services harmonized on the European level and available through a common access platform, encompassing information on seismic sources, seismogenic faults, ground-motion prediction equations, geotechnical information, and strong-motion recordings in buildings, together with an interface to earthquake risk; - a portal implementation of computational seismology tools and services, specifically for seismic waveform propagation in complex 3D media following the results of the VERCE project, and initiating the inclusion of further suitable codes on that portal in discussion with the community, forming the basis of EPOS computational earth science infrastructure. Important features common to all tasks are the development of EPOS-wide integrated and interoperable metadata structures, the introduction and utilization of adequate and referencable persistent identifiers for data and products, and the implementation of appropriate user access and authorization mechanisms. Here we present further details on the technical work plan for Seismology during the EPOS Implementation Phase and its integration into the overall EPOS build-up, together with the current view and state of the discussion on the development of adequate governance structures, and discuss how we envision the interaction with and involvement of the wider community outside the consortium in these activities.\n\nGlobal Federation of Data Services in Seismology: Extending the Concept to Interdisciplinary Science\n\nNASA Astrophysics Data System (ADS)\n\nAhern, Tim; Trabant, Chad; Stults, Mike; VanFossen, Mick\n\n2016-04-01\n\nThe International Federation of Digital Seismograph Networks (FDSN) sets international standards, formats, and access protocols for global seismology. Recently the availability of an FDSN standard for web services has enabled the development of a federated model of data access. With a growing number of internationally distributed data centers supporting compatible web services the task of federation is now fully realizable. The utility of this approach is already starting to bear fruit in seismology. This presentation will highlight the advances the seismological community has made in the past year towards federated access to seismological data including waveforms, earthquake event catalogs, and metadata describing seismic stations. It will include a discussion of an IRIS Federator as well as an emerging effort to develop an FDSN Federator that will allow seamless access to seismological information across multiple FDSN data centers. As part of the NSF EarthCube initiative as well as the US-European data coordination project (COOPEUS), IRIS and several partners, collectively called GeoWS, have been extending the concept of standard web services to other domains. Our primary partners include Lamont Doherty Earth Observatory (marine geophysics), Caltech (tectonic plate reconstructions), SDSC (hydrology), UNAVCO (geodesy), and Unidata (atmospheric sciences). Additionally, IRIS is working with partners at NOAA's National Centers for Environmental Information (NCEI) , NEON, UTEP, WOVOdat, INTERMAGNET, Global Geodynamics Program, and the Ocean Observatory Initiative (OOI) to develop web services for those domains. The ultimate goal is to allow discovery, access, and utilization of cross-domain data sources. One of the significant outcomes of this effort is the development of a simple text and metadata representation for tabular data called GeoCSV, that allows straightforward interpretation of information from multiple domains by non-domain experts.\n\nOn the Analysis of Wind-Induced Noise in Seismological Recordings\n\nNASA Astrophysics Data System (ADS)\n\nLott, Friederike F.; Ritter, Joachim R. R.; Al-Qaryouti, Mahmoud; Corsmeier, Ulrich\n\n2017-03-01\n\nAtmospheric processes, ranging from microscale turbulence to severe storms on the synoptic scale, impact the continuous ground motion of the earth and have the potential to induce strong broad-band noise in seismological recordings. We designed a target-oriented experiment to quantify the influence of wind on ground motion velocity in the Dead Sea valley. For the period from March 2014 to February 2015, a seismological array, consisting of 15 three-component short-period and broad-band stations, was operated near Madaba, Jordan, complemented by one meteorological tower providing synchronized, continuous three-component measurements of wind speed. Results reveal a pronounced, predominantly linear increase of the logarithmic power of ground motion velocity with rising mean horizontal wind speed at all recording stations. Measurements in rough, mountainous terrain further identify a strong dependency of wind-induced noise on surface characteristics, such as topography and, therefore, demonstrate the necessity to consider wind direction as well. To assess the noise level of seismological recordings with respect to a dynamically changing wind field, we develop a methodology to account for the dependency of power spectral density of ground motion velocity on wind speed and wind direction for long, statistically significant periods. We further introduce the quantitative measure of the ground motion susceptibility to estimate the vulnerability of seismological recordings to the presence of wind.\n\nSeismology in Japan in 1939-1947\n\nUSGS Publications Warehouse\n\nKawasumi, Hirosi\n\n1950-01-01\n\nIn the latter half of this period the seismology in Japan was so much affected by the war that retrogressions in the instrumental seismology became very remarkable. Much regretted three leading seismologists, professors Ishimoto, Sezawa, and Inamura died in this period. But the seismic activities in this well-known land of earthquakes were not less active than usual as will be seen in the annexed table of destructive earthquakes. Seismologists in this country are now endeavoring to restore its former prosperity in this bitter circumstance.\n\nReflections from the interface between seismological research and earthquake risk reduction\n\nNASA Astrophysics Data System (ADS)\n\nSargeant, S.\n\n2012-04-01\n\nScientific understanding of earthquakes and their attendant hazards is vital for the development of effective earthquake risk reduction strategies. Within the global disaster reduction policy framework (the Hyogo Framework for Action, overseen by the UN International Strategy for Disaster Reduction), the anticipated role of science and scientists is clear, with respect to risk assessment, loss estimation, space-based observation, early warning and forecasting. The importance of information sharing and cooperation, cross-disciplinary networks and developing technical and institutional capacity for effective disaster management is also highlighted. In practice, the degree to which seismological information is successfully delivered to and applied by individuals, groups or organisations working to manage or reduce the risk from earthquakes is variable. The challenge for scientists is to provide fit-for-purpose information that can be integrated simply into decision-making and risk reduction activities at all levels of governance and at different geographic scales, often by a non-technical audience (i.e. people without any seismological/earthquake engineering training). The interface between seismological research and earthquake risk reduction (defined here in terms of both the relationship between the science and its application, and the scientist and other risk stakeholders) is complex. This complexity is a function of a range issues that arise relating to communication, multidisciplinary working, politics, organisational practices, inter-organisational collaboration, working practices, sectoral cultures, individual and organisational values, worldviews and expectations. These factors can present significant obstacles to scientific information being incorporated into the decision-making process. The purpose of this paper is to present some personal reflections on the nature of the interface between the worlds of seismological research and risk reduction, and the\n\nRotational seismology\n\nUSGS Publications Warehouse\n\nLee, William H K.\n\n2016-01-01\n\nRotational seismology is an emerging study of all aspects of rotational motions induced by earthquakes, explosions, and ambient vibrations. It is of interest to several disciplines, including seismology, earthquake engineering, geodesy, and earth-based detection of Einsteinâs gravitation waves.Rotational effects of seismic waves, together with rotations caused by soilâstructure interaction, have been observed for centuries (e.g., rotated chimneys, monuments, and tombstones). FigureÂ 1aÂ shows the rotated monument to George Inglis observed after the 1897 Great Shillong earthquake. This monument had the form of an obelisk rising over 19 metres high from a 4 metre base. During the earthquake, the top part broke off and the remnant of some 6 metres rotated about 15Â° relative to the base. The study of rotational seismology began only recently when sensitive rotational sensors became available due to advances in aeronautical and astronomical instrumentations.\n\nThe Colombia Seismological Network\n\nNASA Astrophysics Data System (ADS)\n\nBlanco Chia, J. F.; Poveda, E.; Pedraza, P.\n\n2013-05-01\n\nThe latest seismological equipment and data processing instrumentation installed at the Colombia Seismological Network (RSNC) are described. System configuration, network operation, and data management are discussed. The data quality and the new seismological products are analyzed. The main purpose of the network is to monitor local seismicity with a special emphasis on seismic activity surrounding the Colombian Pacific and Caribbean oceans, for early warning in case a Tsunami is produced by an earthquake. The Colombian territory is located at the South America northwestern corner, here three tectonic plates converge: Nazca, Caribbean and the South American. The dynamics of these plates, when resulting in earthquakes, is continuously monitored by the network. In 2012, the RSNC registered in 2012 an average of 67 events per day; from this number, a mean of 36 earthquakes were possible to be located well. In 2010 the network was also able to register an average of 67 events, but it was only possible to locate a mean of 28 earthquakes daily. This difference is due to the expansion of the network. The network is made up of 84 stations equipped with different kind of broadband 40s, 120s seismometers, accelerometers and short period 1s sensors. The signal is transmitted continuously in real-time to the Central Recording Center located at BogotÃ¡, using satellite, telemetry, and Internet. Moreover, there are some other stations which are required to collect the information in situ. Data is recorded and processed digitally using two different systems, EARTHWORM and SEISAN, which are able to process and share the information between them. The RSNC has designed and implemented a web system to share the seismological data. This innovative system uses tools like Java Script, Oracle and programming languages like PHP to allow the users to access the seismicity registered by the network almost in real time as well as to download the waveform and technical details. The coverage\n\nA seismologically consistent compositional model of Earth's core.\n\nPubMed\n\nBadro, James; CÃ´tÃ©, Alexander S; Brodholt, John P\n\n2014-05-27\n\nEarth's core is less dense than iron, and therefore it must contain \"light elements,\" such as S, Si, O, or C. We use ab initio molecular dynamics to calculate the density and bulk sound velocity in liquid metal alloys at the pressure and temperature conditions of Earth's outer core. We compare the velocity and density for any composition in the (Fe-Ni, C, O, Si, S) system to radial seismological models and find a range of compositional models that fit the seismological data. We find no oxygen-free composition that fits the seismological data, and therefore our results indicate that oxygen is always required in the outer core. An oxygen-rich core is a strong indication of high-pressure and high-temperature conditions of core differentiation in a deep magma ocean with an FeO concentration (oxygen fugacity) higher than that of the present-day mantle.\n\nBayesian coronal seismology\n\nNASA Astrophysics Data System (ADS)\n\nArregui, IÃ±igo\n\n2018-01-01\n\nIn contrast to the situation in a laboratory, the study of the solar atmosphere has to be pursued without direct access to the physical conditions of interest. Information is therefore incomplete and uncertain and inference methods need to be employed to diagnose the physical conditions and processes. One of such methods, solar atmospheric seismology, makes use of observed and theoretically predicted properties of waves to infer plasma and magnetic field properties. A recent development in solar atmospheric seismology consists in the use of inversion and model comparison methods based on Bayesian analysis. In this paper, the philosophy and methodology of Bayesian analysis are first explained. Then, we provide an account of what has been achieved so far from the application of these techniques to solar atmospheric seismology and a prospect of possible future extensions.\n\nRotational Seismology: AGU Session, Working Group, and Website\n\nUSGS Publications Warehouse\n\nLee, William H.K.; Igel, Heiner; Todorovska, Maria I.; Evans, John R.\n\n2007-01-01\n\nIntroduction Although effects of rotational motions due to earthquakes have long been observed (e. g., Mallet, 1862), nevertheless Richter (1958, p. 213) stated that: 'Perfectly general motion would also involve rotations about three perpendicular axes, and three more instruments for these. Theory indicates, and observation confirms, that such rotations are negligible.' However, Richter provided no references for this claim. Seismology is based primarily on the observation and modeling of three-component translational ground motions. Nevertheless, theoretical seismologists (e.g., Aki and Richards, 1980, 2002) have argued for decades that the rotational part of ground motions should also be recorded. It is well known that standard seismometers are quite sensitive to rotations and therefore subject to rotation-induced errors. The paucity of observations of rotational motions is mainly the result of a lack, until recently, of affordable rotational sensors of sufficient resolution. Nevertheless, in the past decade, a number of authors have reported direct observations of rotational motions and rotations inferred from rigid-body rotations in short baseline accelerometer arrays, creating a burgeoning library of rotational data. For example, ring laser gyros in Germany and New Zealand have led to the first significant and consistent observations of rotational motions from distant earthquakes (Igel et al., 2005, 2007). A monograph on Earthquake Source Asymmetry, Structural Media and Rotation Effects was published recently as well by Teisseyre et al. (2006). Measurement of rotational motions has implications for: (1) recovering the complete ground-displacement history from seismometer recordings; (2) further constraining earthquake rupture properties; (3) extracting information about subsurface properties; and (4) providing additional ground motion information to earthquake engineers for seismic design. A special session on Rotational Motions in Seismology was convened by H\n\nDetermination of differential arrival times by cross-correlating worldwide seismological data\n\nNASA Astrophysics Data System (ADS)\n\nGodano, M.; Nolet, G.; Zaroli, C.\n\n2012-12-01\n\nCross-correlation delays are the preferred body wave observables in global tomography. Heterogeneity is the main factor influencing delay times found by cross-correlation. Not only the waveform, but also the arrival time itself is affected by differences in seismic velocity encountered along the way. An accurate method for estimating differential times of seismic arrivals across a regional array by cross-correlation was developed by VanDecar and Crosson [1990]. For the estimation of global travel time delays in different frequency bands, Sigloch and Nolet [2006] developed a method for the estimation of body wave delays using a matched filter, which requires the separate estimation of the source time function. Sigloch et al. [2008] found that waveforms often cluster in and opposite the direction of rupture propagation on the fault, confirming that the directivity effect is a major factor in shaping the waveform of large events. We propose a generalization of the VanDecar-Crosson method to which we add a correction for the directivity effect in the seismological data. The new method allows large events to be treated without the need to estimate the source time function for the computation of a matched synthetic waveform. The procedure consists in (1) the detection of the directivity effect in the data and the determination of a rupture model (unilateral or bilateral) explaining the differences in pulse duration among the stations, (2) the determination of an apparent fault rupture length explaining the pulse durations, (3) the removal of the delay due to the directivity effect in the pulse duration , by stretching or contracting the seismograms for directive and anti-directive stations respectively and (4) the application of a generalized VanDecar and Crosson method using only delays between pairs of stations that have an acceptable correlation coefficient. We validate our method by performing tests on synthetic data. Results show that the error between theoretical\n\nA seismologically consistent compositional model of Earthâs core\n\nPubMed Central\n\nBadro, James; CÃ´tÃ©, Alexander S.; Brodholt, John P.\n\n2014-01-01\n\nEarthâs core is less dense than iron, and therefore it must contain âlight elements,â such as S, Si, O, or C. We use ab initio molecular dynamics to calculate the density and bulk sound velocity in liquid metal alloys at the pressure and temperature conditions of Earth's outer core. We compare the velocity and density for any composition in the (FeâNi, C, O, Si, S) system to radial seismological models and find a range of compositional models that fit the seismological data. We find no oxygen-free composition that fits the seismological data, and therefore our results indicate that oxygen is always required in the outer core. An oxygen-rich core is a strong indication of high-pressure and high-temperature conditions of core differentiation in a deep magma ocean with an FeO concentration (oxygen fugacity) higher than that of the present-day mantle. PMID:24821817\n\nForensic seismology\n\nUSGS Publications Warehouse\n\nThirlaway, H. I. S.\n\n1979-01-01\n\nTwenty years ago, politicians, concerned a the slow progress of negotiations to stop nuclear weapons testing, described the state of seismology as being in the equivalent of the Stone Age. this assessment spurred the beginning of research and development at the Atomic Weapons Research Establishment near the village of Aldermaston, England. the object was to establish the limits of seismology for the detection and identification of underground explosions against a background of earthquakes. Thereby, verification that there was compliance with a treaty to ban further nuclear tests could be assessed before making political decisions. Negotiations now taking place in Geneva between the Soviet Union, the United States, and the United Kingdom are aimed at such a treaty. Â\n\nRotational Seismology Workshop of February 2006\n\nUSGS Publications Warehouse\n\nEvans, John R.; Cochard, A.; Graizer, Vladimir; Huang, Bor-Shouh; Hudnut, Kenneth W.; Hutt, Charles R.; Igel, H.; Lee, William H.K.; Liu, Chun-Chi; Majewski, Eugeniusz; Nigbor, Robert; Safak, Erdal; Savage, William U.; Schreiber, U.; Teisseyre, Roman; Trifunac, Mihailo; Wassermann, J.; Wu, Chien-Fu\n\n2007-01-01\n\nIntroduction A successful workshop titled 'Measuring the Rotation Effects of Strong Ground Motion' was held simultaneously in Menlo Park and Pasadena via video conference on 16 February 2006. The purpose of the Workshop and this Report are to summarize existing data and theory and to explore future challenges for rotational seismology, including free-field strong motion, structural strong motion, and teleseismic motions. We also forged a consensus on the plan of work to be pursued by this international group in the near term. At this first workshop were 16 participants in Menlo Park, 13 in Pasadena, and a few on the telephone. It was organized by William H. K. Lee and John R. Evans and chaired by William U. Savage in Menlo Park and by Kenneth W. Hudnut in Pasadena. Its agenda is given in the Appendix. This workshop and efforts in Europe led to the creation of the International Working Group on Rotational Seismology (IWGoRS), an international volunteer group providing forums for exchange of ideas and data as well as hosting a series of Workshops and Special Sessions. IWGoRS created a Web site, backed by an FTP site, for distribution of materials related to rotational seismology. At present, the FTP site contains the 2006 Workshop agenda (also given in the Appendix below) and its PowerPoint presentations, as well as many papers (reasonable-only basis with permission of their authors), a comprehensive citations list, and related information. Eventually, the Web site will become the sole authoritative source for IWGoRS and shared information: http://www.rotational-seismology.org ftp://ehzftp.wr.usgs.gov/jrevans/IWGoRS_FTPsite/ With contributions from various authors during and after the 2006 Workshop, this Report proceeds from the theoretical bases for making rotational measurements (Graizer, Safak, Trifunac) through the available observations (Huang, Lee, Liu, Nigbor), proposed suites of measurements (Hudnut), a discussion of broadband teleseismic rotational\n\nUsing coronal seismology to estimate the magnetic field strength in a realistic coronal model\n\nNASA Astrophysics Data System (ADS)\n\nChen, F.; Peter, H.\n\n2015-09-01\n\nAims: Coronal seismology is used extensively to estimate properties of the corona, e.g. the coronal magnetic field strength is derived from oscillations observed in coronal loops. We present a three-dimensional coronal simulation, including a realistic energy balance in which we observe oscillations of a loop in synthesised coronal emission. We use these results to test the inversions based on coronal seismology. Methods: From the simulation of the corona above an active region, we synthesise extreme ultraviolet emission from the model corona. From this, we derive maps of line intensity and Doppler shift providing synthetic data in the same format as obtained from observations. We fit the (Doppler) oscillation of the loop in the same fashion as done for observations to derive the oscillation period and damping time. Results: The loop oscillation seen in our model is similar to imaging and spectroscopic observations of the Sun. The velocity disturbance of the kink oscillation shows an oscillation period of 52.5 s and a damping time of 125 s, which are both consistent with the ranges of periods and damping times found in observations. Using standard coronal seismology techniques, we find an average magnetic field strength of Bkink = 79 G for our loop in the simulation, while in the loop the field strength drops from roughly 300 G at the coronal base to 50 G at the apex. Using the data from our simulation, we can infer what the average magnetic field derived from coronal seismology actually means. It is close to the magnetic field strength in a constant cross-section flux tube, which would give the same wave travel time through the loop. Conclusions: Our model produced a realistic looking loop-dominated corona, and provides realistic information on the oscillation properties that can be used to calibrate and better understand the result from coronal seismology. A movie associated with Fig. 1 is available in electronic form at http://www.aanda.org\n\nSeismology and space-based geodesy\n\nNASA Technical Reports Server (NTRS)\n\nTralli, David M.; Tajima, Fumiko\n\n1993-01-01\n\nThe potential of space-based geodetic measurement of crustal deformation in the context of seismology is explored. The achievements of seismological source theory and data analyses, mechanical modeling of fault zone behavior, and advances in space-based geodesy are reviewed, with emphasis on realizable contributions of space-based geodetic measurements specifically to seismology. The fundamental relationships between crustal deformation associated with an earthquake and the geodetically observable data are summarized. The response and spatial and temporal resolution of the geodetic data necessary to understand deformation at various phases of the earthquake cycle is stressed. The use of VLBI, SLR, and GPS measurements for studying global geodynamics properties that can be investigated to some extent with seismic data is discussed. The potential contributions of continuously operating strain monitoring networks and globally distributed geodetic observatories to existing worldwide modern digital seismographic networks are evaluated in reference to mutually addressable problems in seismology, geophysics, and tectonics.\n\nCoronal Seismology -- Achievements and Perspectives\n\nNASA Astrophysics Data System (ADS)\n\nRuderman, Michael\n\nexplanation of the oscillation damping is resonant absorption. The damping due to resonant absorption is, broadly speaking, proportional to the inhomogeneity scale of the density in the loop in the transverse direction. This fact was used to estimate the density inhomogeneity scale from the observations. The first observation of the coronal loop transverse oscillations gave a strong boost to the theoretical study of this phenomenon. In the last ten years theorists sufficiently refined their models taking into account such loop properties as the density variation in the longitudinal and transverse directions, the twist of the magnetic field, the non-circular loop cross-section, the variation of the cross-section along the loop, and the loop curvature. Now, to obtain more accurate estimates of the coronal plasma parameters, we need the following from the observations: (i) Since the frequency of the loop oscillation depends on the plasma density, more accurate data on this quantity is required. (ii) Since the estimate of the coronal temperature strongly depends of the loop shape, an accurate three-dimensional picture of the loop is desirable. (iii) The fundamental frequency and first overtone of the loop oscillation are sufficiently affected by the variation of the loop cross-section. The observational data on this quantity is important for further progress of the coronal seismology.\n\nBenefits of rotational ground motions for planetary seismology\n\nNASA Astrophysics Data System (ADS)\n\nDonner, S.; Joshi, R.; Hadziioannou, C.; Nunn, C.; van Driel, M.; Schmelzbach, C.; Wassermann, J. M.; Igel, H.\n\n2017-12-01\n\nExploring the internal structure of planetary objects is fundamental to understand the evolution of our solar system. In contrast to Earth, planetary seismology is hampered by the limited number of stations available, often just a single one. Classic seismology is based on the measurement of three components of translational ground motion. Its methods are mainly developed for a larger number of available stations. Therefore, the application of classical seismological methods to other planets is very limited. Here, we show that the additional measurement of three components of rotational ground motion could substantially improve the situation. From sparse or single station networks measuring translational and rotational ground motions it is possible to obtain additional information on structure and source. This includes direct information on local subsurface seismic velocities, separation of seismic phases, propagation direction of seismic energy, crustal scattering properties, as well as moment tensor source parameters for regional sources. The potential of this methodology will be highlighted through synthetic forward and inverse modeling experiments.\n\nObsPy: A Python Toolbox for Seismology\n\nNASA Astrophysics Data System (ADS)\n\nKrischer, Lion; Megies, Tobias; Sales de Andrade, Elliott; Barsch, Robert; MacCarthy, Jonathan\n\n2017-04-01\n\nIn recent years the Python ecosystem evolved into one of the most powerful and productive scientific environments across disciplines. ObsPy (https://www.obspy.org) is a fully community-driven, open-source project dedicated to providing a bridge for seismology into that ecosystem. It does so by offering Read and write support for essentially every commonly used data format in seismology with a unified interface and automatic format detection. This includes waveform data (MiniSEED, SAC, SEG-Y, Reftek, â¦) as well as station (SEED, StationXML, â¦) and event meta information (QuakeML, ZMAP, â¦). Integrated access to the largest data centers, web services, and real-time data streams (FDSNWS, ArcLink, SeedLink, ...). A powerful signal processing toolbox tuned to the specific needs of seismologists. Utility functionality like travel time calculations with the TauP method, geodetic functions, and data visualizations. ObsPy has been in constant development for more than seven years and is developed and used by scientists around the world with successful applications in all branches of seismology. Additionally it nowadays serves as the foundation for a large number of more specialized packages. This presentation will give a short overview of the capabilities of ObsPy and point out several representative or new use cases. Additionally we will discuss the road ahead as well as the long-term sustainability of open-source scientific software.\n\nEPOS: Integrating seismological Research Infrastructures within Europe\n\nNASA Astrophysics Data System (ADS)\n\nEck Van, Torild; Clinton, John; Haslinger, Florian; Michelini, Alberto\n\n2013-04-01\n\nSeismological data, products and models are currently produced in Europe within individual countries or research organizations, and with the contribution of coordinating organizations like ORFEUS and EMSC. In spite of these partly scattered resources, significant scientific results are obtained, excellent monitoring and information systems are operational and a huge amount of research quality data is being archived and disseminated. The seismological community, however, realizes that an effective European-scale integration of seismological and related geophysical data, products and models, combined with broad and easy access, is needed to facilitate future top level geoscience, for example, to appropriately harness the technological advancements enabling large scale and near-real time data processing. Here we present the technical concepts and developments within European seismology that will build the next generation of integrated services. Within the EPOS initiative and a number of related projects, where seismology infrastructure and IT developments are merging, in depth discussions are on-going on how to realize an effective integration. Concepts and visions addressing the obviously complex challenges resulting from the current highly distributed facilities and resources in Europe are emerging and are already partly being implemented. We will provide an overview of developments within key EU projects (NERA, VERCE, COOPEUS, EUDAT, REAKT, COMMIT, etc) and demonstrate how these are in coherence with EPOS and other on-going global initiatives. Within seismology current focus is on addressing IT related challenges to a) organize distributed data archives, develop metadata attributes for improved data searching, specifically including quality indicators, and define products from data and/or models, and b) define and create(on-line) monitoring, data access and processing tools. While developments to meet those challenges originate partly from within the community\n\nQuantifying and modeling long-range cross correlations in multiple time series with applications to world stock indices\n\nNASA Astrophysics Data System (ADS)\n\nWang, Duan; Podobnik, Boris; HorvatiÄ, Davor; Stanley, H. Eugene\n\n2011-04-01\n\nWe propose a modified time lag random matrix theory in order to study time-lag cross correlations in multiple time series. We apply the method to 48 world indices, one for each of 48 different countries. We find long-range power-law cross correlations in the absolute values of returns that quantify risk, and find that they decay much more slowly than cross correlations between the returns. The magnitude of the cross correlations constitutes âbad newsâ for international investment managers who may believe that risk is reduced by diversifying across countries. We find that when a market shock is transmitted around the world, the risk decays very slowly. We explain these time-lag cross correlations by introducing a global factor model (GFM) in which all index returns fluctuate in response to a single global factor. For each pair of individual time series of returns, the cross correlations between returns (or magnitudes) can be modeled with the autocorrelations of the global factor returns (or magnitudes). We estimate the global factor using principal component analysis, which minimizes the variance of the residuals after removing the global trend. Using random matrix theory, a significant fraction of the world index cross correlations can be explained by the global factor, which supports the utility of the GFM. We demonstrate applications of the GFM in forecasting risks at the world level, and in finding uncorrelated individual indices. We find ten indices that are practically uncorrelated with the global factor and with the remainder of the world indices, which is relevant information for world managers in reducing their portfolio risk. Finally, we argue that this general method can be applied to a wide range of phenomena in which time series are measured, ranging from seismology and physiology to atmospheric geophysics.\n\nQuantifying and modeling long-range cross correlations in multiple time series with applications to world stock indices.\n\nPubMed\n\nWang, Duan; Podobnik, Boris; HorvatiÄ, Davor; Stanley, H Eugene\n\n2011-04-01\n\nWe propose a modified time lag random matrix theory in order to study time-lag cross correlations in multiple time series. We apply the method to 48 world indices, one for each of 48 different countries. We find long-range power-law cross correlations in the absolute values of returns that quantify risk, and find that they decay much more slowly than cross correlations between the returns. The magnitude of the cross correlations constitutes \"bad news\" for international investment managers who may believe that risk is reduced by diversifying across countries. We find that when a market shock is transmitted around the world, the risk decays very slowly. We explain these time-lag cross correlations by introducing a global factor model (GFM) in which all index returns fluctuate in response to a single global factor. For each pair of individual time series of returns, the cross correlations between returns (or magnitudes) can be modeled with the autocorrelations of the global factor returns (or magnitudes). We estimate the global factor using principal component analysis, which minimizes the variance of the residuals after removing the global trend. Using random matrix theory, a significant fraction of the world index cross correlations can be explained by the global factor, which supports the utility of the GFM. We demonstrate applications of the GFM in forecasting risks at the world level, and in finding uncorrelated individual indices. We find ten indices that are practically uncorrelated with the global factor and with the remainder of the world indices, which is relevant information for world managers in reducing their portfolio risk. Finally, we argue that this general method can be applied to a wide range of phenomena in which time series are measured, ranging from seismology and physiology to atmospheric geophysics.\n\nObsPy: A Python toolbox for seismology - Sustainability, New Features, and Applications\n\nNASA Astrophysics Data System (ADS)\n\nKrischer, L.; Megies, T.; Sales de Andrade, E.; Barsch, R.; MacCarthy, J.\n\n2016-12-01\n\nObsPy (https://www.obspy.org) is a community-driven, open-source project dedicated to offer a bridge for seismology into the scientific Python ecosystem. Amongst other things, it provides Read and write support for essentially every commonly used data format in seismology with a unified interface. This includes waveform data as well as station and event meta information. A signal processing toolbox tuned to the specific needs of seismologists. Integrated access to the largest data centers, web services, and databases. Wrappers around third party codes like libmseed and evalresp. Using ObsPy enables users to take advantage of the vast scientific ecosystem that has developed around Python. In contrast to many other programming languages and tools, Python is simple enough to enable an exploratory and interactive coding style desired by many scientists. At the same time it is a full-fledged programming language usable by software engineers to build complex and large programs. This combination makes it very suitable for use in seismology where research code often must be translated to stable and production ready environments, especially in the age of big data. ObsPy has seen constant development for more than six years and enjoys a large rate of adoption in the seismological community with thousands of users. Successful applications include time-dependent and rotational seismology, big data processing, event relocations, and synthetic studies about attenuation kernels and full-waveform inversions to name a few examples. Additionally it sparked the development of several more specialized packages slowly building a modern seismological ecosystem around it. We will present a short overview of the capabilities of ObsPy and point out several representative use cases and more specialized software built around ObsPy. Additionally we will discuss new and upcoming features, as well as the sustainability of open-source scientific software.\n\nThe European seismological waveform framework EIDA\n\nNASA Astrophysics Data System (ADS)\n\nTrani, Luca; Koymans, Mathijs; Quinteros, Javier; Heinloo, Andres; Euchner, Fabian; Strollo, Angelo; Sleeman, Reinoud; Clinton, John; Stammler, Klaus; Danecek, Peter; Pedersen, Helle; Ionescu, Constantin; Pinar, Ali; Evangelidis, Christos\n\n2017-04-01\n\nThe ORFEUS1 European Integrated Data Archive (EIDA2) federates (currently) 11 major European seismological data centres into a common organisational and operational framework which offers: (a) transparent and uniform access tools, advanced services and products for seismological waveform data; (b) a platform for establishing common policies for the curation of seismological waveform data and the description of waveform data by standardised quality metrics; (c) proper attribution and citation (e.g. data ownership). After its establishment in 2013, EIDA has been collecting and distributing seamlessly large amounts of seismological data and products to the research community and beyond. A major task of EIDA is the on-going improvement of the services, tools and products portfolio in order to meet the increasingly demanding users' requirements. At present EIDA is entering a new operational phase and will become the reference infrastructure for seismological waveform data in the pan-European infrastructure for solid-Earth science: EPOS (European Plate Observing System)3. The EIDA Next Generation developments, initiated within the H2020 project EPOS-IP, will provide a new infrastructure that will support the seismological and multidisciplinary EPOS community facilitating interoperability in a broader context. EIDA NG comprises a number of new services and products e.g.: Routing Service, Authentication Service, WFCatalog, Mediator, Station Book and more in the near future. In this contribution we present the current status of the EIDA NG developments and provide an overview of the usage of the new services and their impact on the user community. 1 www.orfeus-eu.org/ 2 www.orfeus-eu.org/eida/eida.html 3 www.epos-ip.org\n\nAustralian Seismological Reference Model (AuSREM): crustal component\n\nNASA Astrophysics Data System (ADS)\n\nSalmon, M.; Kennett, B. L. N.; Saygin, E.\n\n2013-01-01\n\nAlthough Australia has been the subject of a wide range of seismological studies, these have concentrated on specific features of the continent at crustal scales and on the broad scale features in the mantle. The Australian Seismological Reference Model (AuSREM) is designed to bring together the existing information, and provide a synthesis in the form of a 3-D model that can provide the basis for future refinement from more detailed studies. Extensive studies in the last few decades provide good coverage for much of the continent, and the crustal model builds on the various data sources to produce a representative model that captures the major features of the continental structure and provides a basis for a broad range of further studies. The model is grid based with a 0.5Â° sampling in latitude and longitude, and is designed to be fully interpolable, so that properties can be extracted at any point. The crustal structure is built from five-layer representations of refraction and receiver function studies and tomographic information. The AuSREM crustal model is available at 1 km intervals. The crustal component makes use of prior compilations of sediment thicknesses, with cross checks against recent reflection profiling, and provides P and S wavespeed distributions through the crust. The primary information for P wavespeed comes from refraction profiles, for S wavespeed from receiver function studies. We are also able to use the results of ambient noise tomography to link the point observations into national coverage. Density values are derived using results from gravity interpretations with an empirical relation between P wavespeed and density. AuSREM is able to build on a new map of depth to Moho, which has been created using all available information including Moho picks from over 12 000 km of full crustal profiling across the continent. The crustal component of AuSREM provides a representative model that should be useful for modelling of seismic wave\n\nPromoting seismology education and research via the IRIS Education and Public Outreach Program\n\nNASA Astrophysics Data System (ADS)\n\nTaber, J. J.; Bravo, T. K.; Dorr, P. M.; Hubenthal, M.; Johnson, J. A.; McQuillan, P.; Sumy, D. F.; Welti, R.\n\n2015-12-01\n\nThe Incorporated Research Institutions for Seismology's Education and Public Outreach (EPO) program is committed to advancing awareness and understanding of seismology and geophysics, while inspiring careers in the Earth sciences. To achieve this mission, IRIS EPO combines content and research expertise of consortium membership with educational and outreach expertise of IRIS staff to create a portfolio of programs, products, and services that target a range of audiences, including grades 6-12 students and teachers, undergraduate and graduate students, faculty, and the general public. IRIS also partners with UNAVCO and other organizations in support of EarthScope where the facilities are well-suited for sustained engagement of multiple audiences. Examples of research-related EPO products and services include the following resources. Tools developed in collaboration with IRIS Data Services provide public and educational access to data, and to a suite of data products. Teachers can stream seismic data from educational or research sensors into their classroom, and the Active Earth Monitor display, designed for visitor centers, universities and small museums, provides views of recent data along with animations that explain seismology concepts, and stories about recent research. Teachable Moment slide sets, created in collaboration with the University of Portland within 24 hours of major earthquakes, provide interpreted USGS tectonic maps and summaries, animations, visualizations, and other event-specific information so educators can explore newsworthy earthquakes with their students. Intro undergraduate classroom activities have been designed to introduce students to some grand challenges in seismological research, while our Research Experiences for Undergraduates program pairs students with seismology researchers throughout the Consortium and provides the opportunity for the students to present their research at a national meeting. EPO activities are evaluated via a\n\nThe international seismological observing period in Africa\n\nUSGS Publications Warehouse\n\nEngdahl, E.R.; Bergman, Eric A.\n\n1992-01-01\n\nThe International Seismological Observing Period (ISOP) is a specific time interval designated for enhanced international cooperation in the collection and dissemination of observatory measurements from the global seismographic network. The primary purpose of the ISOP is to strengthen the international infrastructure that supports current seismological practice and increase the cooperation among nations that operate seismological observatories. Measurements, reported by the existing global network and compiled by agencies such as the International Seismological Centre (ISC), are providing new information about earthquakes and the structure of the Earth of fundamental importance to the Earth sciences. However, these data represent but a small fraction of the information contained in the seismograms. One of the goals of the ISOP is to collect improved sets of data. In particular, the measurement and reporting of later-arriving phases, during a fixed ISOP period, from earthquakes selected for detailed observation by the cooperating stations will be encouraged. The use of advanced, digital instrumentation provides an unprecedented opportunity for enhancing the methods of seismogram interpretation and seismic parameter extraction, by the implementation of digital processing methods at seismic observatories worldwide. It must be ensured that this new information will be available to the entire seismological community. It is believed that this purpose is best served with an ISOP that promotes increased on-site processing at digital stations in Africa and elsewhere. Improvements in seismology require truly international cooperation and the educational aspects of seismological practice form one of the goals of the ISOP. Thus, workshops will be needed in Africa to train analysts in ISOP procedures and to introduce them to modern techniques and applications of the data. Participants will, thus, benefit from theoretical results and practical experience that are of direct\n\nSeismological Data Stewardship at the IRIS DMC: The Role of a Dedicated Data Management System for Seismology\n\nNASA Astrophysics Data System (ADS)\n\nBenson, R. B.; Ahern, T. K.; Trabant, C.; Casey, R.\n\n2011-12-01\n\nSince the founding of the Incorporated Research Institutions for Seismology (IRIS) in 1984, there has been a core program for data management, quite unique at the time, dedicated solely to ensuring that data recorded by IRIS and it's partners had a perpetual data management framework that ensures data will be searchable, well-documented, and preserved so that future generations can, at it's core, have an accurate history of ground motion recordings. This goal is manifest in the IRIS Data Management System, or DMS. The mission of this NSF-EAR facility is \"To provide reliable and efficient access to high quality seismological and related geophysical data, generated by IRIS and its domestic and international partners, and to enable all parties interested in using these data to do so in a straightforward and efficient manner\". This presentation will focus on the data management business rules that capture the data life-cycle of 3 different segments of seismological and related geophysical data managed by IRIS: - Images and parametric information of historical analog data, - Non-real time quality-controlled digital data, - Real time data that streams into the DMC through a number of different protocols. We will describe how data collection, curation, and distribution to users are cataloged to provide an accurate provenance log of contributed data, which are passed along to both the consumer and network data provider. In addition, we will discuss the need and business rules that apply to metadata and how it is managed.\n\nSeismological medals\n\nUSGS Publications Warehouse\n\nSchmidt, P.\n\n1987-01-01\n\nSeismic events are environmental events, so it is not surprising that mankind, in coming to terms with earthquakes, has tried to express his feelings about them in an artistic manner too. By understanding the topical importance of medals in seismological affairs, we can appreciate the hertiage of the past.Â\n\nSEIS-PROV: Practical Provenance for Seismological Data\n\nNASA Astrophysics Data System (ADS)\n\nKrischer, L.; Smith, J. A.; Tromp, J.\n\n2015-12-01\n\nIt is widely recognized that reproducibility is crucial to advance science, but at the same time it is very hard to actually achieve. This results in it being recognized but also mostly ignored by a large fraction of the community. A key ingredient towards full reproducibility is to capture and describe the history of data, an issue known as provenance. We present SEIS-PROV, a practical format and data model to store provenance information for seismological data. In a seismological context, provenance can be seen as information about the processes that generated and modified a particular piece of data. For synthetic waveforms the provenance information describes which solver and settings therein were used to generate it. When looking at processed seismograms, the provenance conveys information about the different time series analysis steps that led to it. Additional uses include the description of derived data types, such as cross-correlations and adjoint sources, enabling their proper storage and exchange. SEIS-PROV is based on W3C PROV (http://www.w3.org/TR/prov-overview/), a standard for generic provenance information. It then applies an additional set of constraints to make it suitable for seismology. We present a definition of the SEIS-PROV format, a way to check if any given file is a valid SEIS-PROV document, and two sample implementations: One in SPECFEM3D GLOBE (https://geodynamics.org/cig/software/specfem3d_globe/) to store the provenance information of synthetic seismograms and another one as part of the ObsPy (http://obspy.org) framework enabling automatic tracking of provenance information during a series of analysis and transformation stages. This, along with tools to visualize and interpret provenance graphs, offers a description of data history that can be readily tracked, stored, and exchanged.\n\nInternational seismological data center: Preparation of an experimental data base\n\nNASA Astrophysics Data System (ADS)\n\nIsraelson, H.; Jeppsson, I.; Barkeby, G.\n\n1980-11-01\n\nAn experimental data base compiled for a temporary international seismological data center is presented. Data include recording and measurements at 60 globally distributed seismological stations for a one week period. Data for definition, location and magnitude estimation of seismic events are examined. Original digital records from 11 seismological research observatories around the world are also analyzed to provide additional identification data. It is shown that the routine measurement and reporting of data at seismological stations as proposed by the Seismic Experts Group at the UN Committee of Disarmament, is an onerous task that goes far beyond current seismological practices.\n\nTrends and opportunities in seismology. [Asilomar, California, January 3--9, 1976\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nNot Available\n\n1977-01-01\n\nThirty-five experts in the fields of geology, geophysics, and engineering, from academia, government, and industry, were invited to participate in a workshop and address the many problems of national and global concern that require seismological expertise for their solutions. This report reviews the history, accomplishments, and status of seismology; assesses changing trends in seismological research and applications; and recommends future directions in the light of these changes and of the growing needs of society in areas in which seismology can make significant contributions. The first part of the volume discusses areas of opportunity (understanding earthquakes and reducing their hazards; exploration,moreÂ Â» energy, and resources; understanding the earth and planets) and realizing the benefits (the roles of Federal, state, and local governments, industry, and universities). The second part, Background and Progress, briefly considers each of the following topics: the birth and early growth of seismology, nuclear test monitoring and its scientific ramifications, instrumentation and data processing, geodynamics and plate tectonics, theoretical seismology, structure and composition of the earth, exploration seismology, seismic exploration for minerals, earthquake source mechanism studies, engineering seismology, strong ground motion and related earthquake hazards, volcanoes, tsunamis, planetary seismology, and international aspects of seismology. 26 figures. (RWR)Â«Â less\n\nA Global Network for Educational Seismology ready to be used by everyone\n\nNASA Astrophysics Data System (ADS)\n\nCourboulex, F.; BÃ©renguer, J.; Tocheport, A.; Esnault, Y.; Larroque, C.; Jouffrey, F.; Nolet, G.; Deschamps, A.; Sladen, A.; Balestra, J.\n\n2013-12-01\n\nThe French ';Sismos Ã l'Ecole' (Seismology at School or SaE) network currently comprises 60 seismic stations installed in French high schools: 40 inside France and 20 around the world (including the ';La Perouse' school in San Francisco). At this moment the network is mainly composed of 3-component digital stations with a broad-band sensor. All data have open access through a website (www.edusismo.org). Seismograms are used by students, teachers and researchers. In addition to this worldwide permanent backbone we are developing a secondary network with a simpler low-cost station: a basic digitizer with a one-component sensor that can be fixed to the wall of a school. The data of these stations are also freely available in real time and permit the development of student projects on seismology and seismic risk in a larger number of schools. The SaE network currently involves about 100 secondary teachers, as well as 20 researchers motivated to give students practical experience on a broad range of topics involving several disciplines in secondary education (geology, physics, geography, technology ...). The network is a starting point for more advanced educational activities such as the processing and interpretation of real data, quality assessment, and use of databases. In addition it promotes the awareness of seismic risk. We invite all the teachers and researchers around the world who would like to do experimental seismology with their students to use the data and the tools on the website that are in both a French and an English version. For the past 2 years, SaE has also been expanding through the European NERA project, which aim is to share data and experience in educational seismology in Europe and abroad. We shall soon add a new component 'Adopt a Mermaid' - in which classes can follow the new floating seismometers developed at Geoazur (see session S008) and deployed in the Mediterranean and Indian Ocean, try to predict their trajectories and learn about the\n\nLarge earthquake rates from geologic, geodetic, and seismological perspectives\n\nNASA Astrophysics Data System (ADS)\n\nJackson, D. D.\n\n2017-12-01\n\nEarthquake rate and recurrence information comes primarily from geology, geodesy, and seismology. Geology gives the longest temporal perspective, but it reveals only surface deformation, relatable to earthquakes only with many assumptions. Geodesy is also limited to surface observations, but it detects evidence of the processes leading to earthquakes, again subject to important assumptions. Seismology reveals actual earthquakes, but its history is too short to capture important properties of very large ones. Unfortunately, the ranges of these observation types barely overlap, so that integrating them into a consistent picture adequate to infer future prospects requires a great deal of trust. Perhaps the most important boundary is the temporal one at the beginning of the instrumental seismic era, about a century ago. We have virtually no seismological or geodetic information on large earthquakes before then, and little geological information after. Virtually all-modern forecasts of large earthquakes assume some form of equivalence between tectonic- and seismic moment rates as functions of location, time, and magnitude threshold. That assumption links geology, geodesy, and seismology, but it invokes a host of other assumptions and incurs very significant uncertainties. Questions include temporal behavior of seismic and tectonic moment rates; shape of the earthquake magnitude distribution; upper magnitude limit; scaling between rupture length, width, and displacement; depth dependence of stress coupling; value of crustal rigidity; and relation between faults at depth and their surface fault traces, to name just a few. In this report I'll estimate the quantitative implications for estimating large earthquake rate. Global studies like the GEAR1 project suggest that surface deformation from geology and geodesy best show the geography of very large, rare earthquakes in the long term, while seismological observations of small earthquakes best forecasts moderate earthquakes\n\nseismo-live: Training in Seismology using Jupyter Notebooks\n\nNASA Astrophysics Data System (ADS)\n\nIgel, Heiner; Krischer, Lion; van Driel, Martin; Tape, Carl\n\n2017-04-01\n\nPractical training in computational methodologies is still underrepresented in Earth science curriculae despite the increasing use of sometimes highly sophisticated simulation and data processing technologies in research projects. At the same time well-engineered community codes make it easy to return results yet with the danger that the inherent traps of black-box solutions are not well understood. For this purpose we have initiated a community platform (www.seismo-live.org) where Python-based Jupyter notebooks can be accessed and run without necessary downloads or local software installations. The increasingly popular Jupyter notebooks allow combining markup language, graphics, equations, with interactive, executable python codes. The platform already includes general Python training, introduction to the ObsPy library for seismology as well as seismic data processing, noise analysis, and a variety of forward solvers for seismic wave propagation. In addition, an example is shown how Jupyter notebooks can be used to increase reproducibility of published results. Submission of Jupyter notebooks for general seismology are encouraged. The platform can be used for complementary teaching in Earth Science courses on compute-intensive research areas. We present recent developments and new features.\n\nSeismological mechanism analysis of 2015 Luanxian swarm, Hebei province,China\n\nNASA Astrophysics Data System (ADS)\n\nTan, Yipei; Liao, Xu; Ma, Hongsheng; Zhou, Longquan; Wang, Xingzhou\n\n2017-04-01\n\nThe seismological mechanism of an earthquake swarm, a kind of seismic burst activity, means the physical and dynamic process in earthquakes triggering in the swarm. Here we focus on the seismological mechanism of 2015 Luanxian swarm in Hebei province, China. The process of digital seismic waveform data processing is divided into four steps. (1) Choose the three components waveform of earthquakes in the catalog as templates, and detect missing earthquakes by scanning the continues waveforms with matched filter technique. (2) Recalibrate P and S-wave phase arrival time using waveform cross-correlation phase detection technique to eliminate the artificial error in phase picking in the observation report made by Hebei seismic network, and then we obtain a more complete catalog and a more precise seismic phase report. (3) Relocate the earthquakes in the swarm using hypoDD based on phase arrival time we recalibrated, and analyze the characteristics of swarm epicenter migration based on the earthquake relocation result. (4) Detect whether there are repeating earthquakes activity using both waveform cross-correlation standard and whether rupture areas can overlapped. We finally detect 106 missing earthquakes in the swarm, 66 of them have the magnitude greater than ML0.0, include 2 greater than ML1.0. Relocation result shows that the epicenters of earthquakes in the swarm have a strip distribution in NE-SW direction, which indicates the seismogenic structure may be a NE-SW trending fault. The spatial-temporal distribution variation of epicenters in the swarm shows a kind of two stages linear migration characteristics, in which the first stage has appeared with a higher migration velocity as 1.2 km per day, and the velocity of the second step is 0.0024 km per day. According to the three basic models to explain the seismological mechanism of earthquake swarms: cascade model, slow slip model and fluid diffusion model, repeating earthquakes activity is difficult to explain by\n\nQuakeML: XML for Seismological Data Exchange and Resource Metadata Description\n\nNASA Astrophysics Data System (ADS)\n\nEuchner, F.; Schorlemmer, D.; Becker, J.; Heinloo, A.; KÃ¤stli, P.; Saul, J.; Weber, B.; QuakeML Working Group\n\n2007-12-01\n\nQuakeML is an XML-based data exchange format for seismology that is under development. Current collaborators are from ETH, GFZ, USC, USGS, IRIS DMC, EMSC, ORFEUS, and ISTI. QuakeML development was motivated by the lack of a widely accepted and well-documented data format that is applicable to a broad range of fields in seismology. The development team brings together expertise from communities dealing with analysis and creation of earthquake catalogs, distribution of seismic bulletins, and real-time processing of seismic data. Efforts to merge QuakeML with existing XML dialects are under way. The first release of QuakeML will cover a basic description of seismic events including picks, arrivals, amplitudes, magnitudes, origins, focal mechanisms, and moment tensors. Further extensions are in progress or planned, e.g., for macroseismic information, location probability density functions, slip distributions, and ground motion information. The QuakeML language definition is supplemented by a concept to provide resource metadata and facilitate metadata exchange between distributed data providers. For that purpose, we introduce unique, location-independent identifiers of seismological resources. As an application of QuakeML, ETH Zurich currently develops a Python-based seismicity analysis toolkit as a contribution to CSEP (Collaboratory for the Study of Earthquake Predictability). We follow a collaborative and transparent development approach along the lines of the procedures of the World Wide Web Consortium (W3C). QuakeML currently is in working draft status. The standard description will be subjected to a public Request for Comments (RFC) process and eventually reach the status of a recommendation. QuakeML can be found at http://www.quakeml.org.\n\nNars: Over 30 Years of Seismology\n\nNASA Astrophysics Data System (ADS)\n\nPaulssen, H.\n\n2014-12-01\n\nIt is fair to say that modern seismology steadily evolved from a handful key initiatives and innovations dating back to the early 1980s. (1) The transition from non-mobile, narrow band sensors with analogue recording (pre-1980s) to portable, broadband sensors with digital recorders paved the way to flexible deployments, enabling various array and regional studies with the same instrumentation. Here I mention just two initiatives: NARS, which was the first digital, mobile network of broadband stations deployed in western Europe (1983-1987), and USarray (2003- ), which is the biggest program of recent times. Presently, innovative data acquisition systems for the oceans are underway and they will allow future imaging of the \"inaccessible\" parts of the Earth. (2) In the 1980s seismological data centers were set up to facilitate data archiving and distribution. Since then, open data exchange (not a matter of course) and easy data retrieval have become standard. The impact of this has been phenomenal: most observational studies efficiently retrieve data from these main seismological data centers and the archived seismograms are used for various types of studies, carried out by different persons and groups. (3) Seismic tomography changed the face of seismological research. From travel time to waveform tomography, from ray theory to finite frequency tomography: new and improved tomographic techniques greatly enhanced our images (and understanding) of the Earth's interior. (4) Many of these developments would not have been possible without young, motivated, seismologists that were educated and stimulated by insightful supervisors. One person has had a major impact on all these fields. NARS in the title stands for Nolet greatly Advanced Research in Seismology.\n\nOn seismological moments and magnitudes\n\nUSGS Publications Warehouse\n\nBolt, B. A.\n\n1991-01-01\n\nMy approach to seismology over the years has always been from the point of view of applied mathematics, as exemplified broadly by the work of the late Sir Harold Jeffreys and Professor K. E. Bullen. Both stresses the development of mathematics in the context of physical systems and of modeling, with an eye always on the side of inference. Seismology provided for them and still provides today the almost perfect paradigm; the problem is the resolution of the detailed consitution of the Earth and its geologically short-term dynamics. The latter part, includes, of course, seismic-risk estimation. The last 20 years have seen the construction of a brilliant theoretical Â formalism for linear inverse problems in seismology , although, oddly enough, the current popular Earth models do not take account it. It is interesting too that the narrow opinion, prevelent a decade ago, to the effect that the traditional seismic body-wave approaches to structural definition were superceded, has been largely abandoned under today's banner of tomography-as though the Oldham-Jeffreys-Gutenbery inversions were not tomography.Â\n\nCombining controlled-source seismology and receiver function information to derive 3-D Moho topography for Italy\n\nNASA Astrophysics Data System (ADS)\n\nSpada, M.; Bianchi, I.; Kissling, E.; Agostinetti, N. Piana; Wiemer, S.\n\n2013-08-01\n\nThe accurate definition of 3-D crustal structures and, in primis, the Moho depth, are the most important requirement for seismological, geophysical and geodynamic modelling in complex tectonic regions. In such areas, like the Mediterranean region, various active and passive seismic experiments are performed, locally reveal information on Moho depth, average and gradient crustal Vp velocity and average Vp/Vs velocity ratios. Until now, the most reliable information on crustal structures stems from controlled-source seismology experiments. In most parts of the Alpine region, a relatively large number of controlled-source seismology information are available though the overall coverage in the central Mediterranean area is still sparse due to high costs of such experiments. Thus, results from other seismic methodologies, such as local earthquake tomography, receiver functions and ambient noise tomography can be used to complement the controlled-source seismology information to increase coverage and thus the quality of 3-D crustal models. In this paper, we introduce a methodology to directly combine controlled-source seismology and receiver functions information relying on the strengths of each method and in relation to quantitative uncertainty estimates for all data to derive a well resolved Moho map for Italy. To obtain a homogeneous elaboration of controlled-source seismology and receiver functions results, we introduce a new classification/weighting scheme based on uncertainty assessment for receiver functions data. In order to tune the receiver functions information quality, we compare local receiver functions Moho depths and uncertainties with a recently derived well-resolved local earthquake tomography-derived Moho map and with controlled-source seismology information. We find an excellent correlation in the Moho information obtained by these three methodologies in Italy. In the final step, we interpolate the controlled-source seismology and receiver functions\n\nSGRAPH (SeismoGRAPHer): Seismic waveform analysis and integrated tools in seismology\n\nNASA Astrophysics Data System (ADS)\n\nAbdelwahed, Mohamed F.\n\n2012-03-01\n\nAlthough numerous seismological programs are currently available, most of them suffer from the inability to manipulate different data formats and the lack of embedded seismological tools. SeismoGRAPHer, or simply SGRAPH, is a new system for maintaining and analyzing seismic waveform data in a stand-alone, Windows-based application that manipulates a wide range of data formats. SGRAPH was intended to be a tool sufficient for performing basic waveform analysis and solving advanced seismological problems. The graphical user interface (GUI) utilities and the Windows functionalities, such as dialog boxes, menus, and toolbars, simplify the user interaction with the data. SGRAPH supports common data formats, such as SAC, SEED, GSE, ASCII, and Nanometrics Y-format, and provides the ability to solve many seismological problems with built-in inversion tools. Loaded traces are maintained, processed, plotted, and saved as SAC, ASCII, or PS (post script) file formats. SGRAPH includes Generalized Ray Theory (GRT), genetic algorithm (GA), least-square fitting, auto-picking, fast Fourier transforms (FFT), and many additional tools. This program provides rapid estimation of earthquake source parameters, location, attenuation, and focal mechanisms. Advanced waveform modeling techniques are provided for crustal structure and focal mechanism estimation. SGRAPH has been employed in the Egyptian National Seismic Network (ENSN) as a tool assisting with routine work and data analysis. More than 30 users have been using previous versions of SGRAPH in their research for more than 3 years. The main features of this application are ease of use, speed, small disk space requirements, and the absence of third-party developed components. Because of its architectural structure, SGRAPH can be interfaced with newly developed methods or applications in seismology. A complete setup file, including the SGRAPH package with the online user guide, is available.\n\nInnovative Seismological Techniques for Investigating the Interior Structure of Venus\n\nNASA Astrophysics Data System (ADS)\n\nStevenson, D. J.; Cutts, J. A.; Mimoun, D.\n\n2014-12-01\n\nThe formation, evolution and structure of Venus remain a mystery more than fifty years after the first visit by a robotic spacecraft. Radar images have revealed a surface that is much younger than those of the Moon, Mercury and Mars as well as a variety of enigmatic volcanic and tectonic features quite unlike those generated by plate tectonics on Earth. To understand how Venus works as a planet it is necessary to probe the interior of Venus. To accomplish this seismology must play a key role. Conventional seismology employs sensors in contact with the planetary surface but for Venus theses sensors must tolerate the Venus environment (460oC and 90 bars) for up to a year. The dense atmosphere of Venus, which efficiently couples seismic energy into the atmosphere as infrasonic waves, enables an alternative: detection of infrasonic waves in the upper atmosphere using either high altitude balloons or orbiting spacecraft. In June 2014, the Keck Institute for Space Studies (KISS) at the California Institute of Technology sponsored a one week workshop with 30 specialists in the key techniques and technologies that can bring these technique to readiness. In this paper, we describe the key synergies with earth science drawing on methods from terrestrial seismology and oceanography and identify key technical issues that need to be solved as well as important precursor measurements that should be made.\n\nBringing Seismology's Grand Challenges to the Undergraduate Classroom\n\nNASA Astrophysics Data System (ADS)\n\nBenoit, M. H.; Hubenthal, M.; Taber, J.\n\n2012-12-01\n\nThe \"Seismological Grand Challenges in Understanding Earth's Dynamic Systems,\" a community-written long-range science plan for the next decade, poses 10 questions to guide fundamental seismological research. Written in an approachable fashion suitable for policymakers, the broad questions and supporting discussion contained in this document offer an ideal framework for the development of undergraduate curricular materials. Leveraging this document, we have created a collection of inquiry-based classroom modules that utilize authentic data to modernize seismological instruction in 100 and 200 level undergraduate courses. The modules not only introduce undergraduates to the broad questions that the seismological community seeks to answer in the future but also showcase the numerous areas where modern seismological research is actively contributing to our understanding of fundamental Earth processes. To date 6 in-depth explorations that correspond to the Grand Challenges document have been developed. The specific topics for each exploration were selected to showcase modern seismological research while also covering topics commonly included in the curriculum of these introductory classes. The activities that have been created and their corresponding Grand Challenge are: -A guided inquiry that introduces students to episodic tremor and slip and compares the GPS and seismic signatures of ETS with those produced from standard tectonic earthquakes (Grand Challenge \"How do faults slip?\"). - A laboratory exercise where students engage in b-value mapping of volcanic earthquakes to assess potential eruption hazards (How do magmas ascend and erupt?). - A module that introduces students to glacial earthquakes in Greenland and compares their frequency and spatial distribution to tectonic earthquakes (How do processes in the ocean and atmosphere interact with the solid Earth?). -A suite of activities that introduce students to oil and gas exploration, including an activity that\n\nBringing Seismology's Grand Challenges to the Undergraduate Classroom\n\nNASA Astrophysics Data System (ADS)\n\nBenoit, M. H.; Taber, J.; Hubenthal, M.\n\n2011-12-01\n\nThe \"Seismological Grand Challenges in Understanding Earth's Dynamic Systems,\" a community-written long-range science plan for the next decade, poses 10 questions to guide fundamental seismological research. Written in an approachable fashion suitable for policymakers, the broad questions and supporting discussion contained in this document offer an ideal framework for the development of undergraduate curricular materials. Leveraging this document, we have created a collection of inquiry-based classroom modules that utilize authentic data to modernize seismological instruction in 100 and 200 level undergraduate courses. The modules not only introduce undergraduates to the broad questions that the seismological community seeks to answer in the future but also showcase the numerous areas where modern seismological research is actively contributing to our understanding of fundamental Earth processes. To date 6 in-depth explorations that correspond to the Grand Challenges document have been developed. The specific topics for each exploration were selected to showcase modern seismological research while also covering topics commonly included in the curriculum of these introductory classes. Examples of activities that have been created and their corresponding Grand Challenge include: -A guided inquiry that introduces students to episodic tremor and slip and compares the GPS and seismic signatures of ETS with those produced from standard tectonic earthquakes (Grand Challenge \"How do faults slip?\"). - A laboratory exercise where students engage in b-value mapping of volcanic earthquakes to assess potential eruption hazards (How do magmas ascend and erupt?). - A module that introduce students to glacial earthquakes in Greenland and compares their frequency and spatial distribution to tectonic earthquakes (How do processes in the ocean and atmosphere interact with the solid Earth?). What is the relationship between stress and strain in the lithosphere? - An activity that\n\nSeismologically determined bedload flux during the typhoon season.\n\nPubMed\n\nChao, Wei-An; Wu, Yih-Min; Zhao, Li; Tsai, Victor C; Chen, Chi-Hsuan\n\n2015-02-05\n\nContinuous seismic records near river channels can be used to quantify the energy induced by river sediment transport. During the 2011 typhoon season, we deployed a seismic array along the Chishan River in the mountain area of southern Taiwan, where there is strong variability in water discharge and high sedimentation rates. We observe hysteresis in the high-frequency (5-15â Hz) seismic noise level relative to the associated hydrological parameters. In addition, our seismic noise analysis reveals an asymmetry and a high coherence in noise cross-correlation functions for several station pairs during the typhoon passage, which corresponds to sediment particles and turbulent flows impacting along the riverbed where the river bends sharply. Based on spectral characteristics of the seismic records, we also detected 20 landslide/debris flow events, which we use to estimate the sediment supply. Comparison of sediment flux between seismologically determined bedload and derived suspended load indicates temporal changes in the sediment flux ratio, which imply a complex transition process from the bedload regime to the suspension regime between typhoon passage and off-typhoon periods. Our study demonstrates the possibility of seismologically monitoring river bedload transport, thus providing valuable additional information for studying fluvial bedrock erosion and mountain landscape evolution.\n\nSeismologically determined bedload flux during the typhoon season\n\nPubMed Central\n\nChao, Wei-An; Wu, Yih-Min; Zhao, Li; Tsai, Victor C.; Chen, Chi-Hsuan\n\n2015-01-01\n\nContinuous seismic records near river channels can be used to quantify the energy induced by river sediment transport. During the 2011 typhoon season, we deployed a seismic array along the Chishan River in the mountain area of southern Taiwan, where there is strong variability in water discharge and high sedimentation rates. We observe hysteresis in the high-frequency (5â15â Hz) seismic noise level relative to the associated hydrological parameters. In addition, our seismic noise analysis reveals an asymmetry and a high coherence in noise cross-correlation functions for several station pairs during the typhoon passage, which corresponds to sediment particles and turbulent flows impacting along the riverbed where the river bends sharply. Based on spectral characteristics of the seismic records, we also detected 20 landslide/debris flow events, which we use to estimate the sediment supply. Comparison of sediment flux between seismologically determined bedload and derived suspended load indicates temporal changes in the sediment flux ratio, which imply a complex transition process from the bedload regime to the suspension regime between typhoon passage and off-typhoon periods. Our study demonstrates the possibility of seismologically monitoring river bedload transport, thus providing valuable additional information for studying fluvial bedrock erosion and mountain landscape evolution. PMID:25652082\n\nCan mobile phones used in strong motion seismology?\n\nNASA Astrophysics Data System (ADS)\n\nD'Alessandro, Antonino; D'Anna, Giuseppe\n\n2013-04-01\n\nMicro Electro-Mechanical Systems (MEMS) accelerometers are electromechanical devices able to measure static or dynamic accelerations. In the 1990s MEMS accelerometers revolutionized the automotive-airbag system industry and are currently widely used in laptops, game controllers and mobile phones. Nowadays MEMS accelerometers seems provide adequate sensitivity, noise level and dynamic range to be applicable to earthquake strong motion acquisition. The current use of 3 axes MEMS accelerometers in mobile phone maybe provide a new means to easy increase the number of observations when a strong earthquake occurs. However, before utilize the signals recorded by a mobile phone equipped with a 3 axes MEMS accelerometer for any scientific porpoise, it is fundamental to verify that the signal collected provide reliable records of ground motion. For this reason we have investigated the suitability of the iPhone 5 mobile phone (one of the most popular mobile phone in the world) for strong motion acquisition. It is provided by several MEMS devise like a three-axis gyroscope, a three-axis electronic compass and a the LIS331DLH three-axis accelerometer. The LIS331DLH sensor is a low-cost high performance three axes linear accelerometer, with 16 bit digital output, produced by STMicroelectronics Inc. We have tested the LIS331DLH MEMS accelerometer using a vibrating table and the EpiSensor FBA ES-T as reference sensor. In our experiments the reference sensor was rigidly co-mounted with the LIS331DHL MEMS sensor on the vibrating table. We assessment the MEMS accelerometer in the frequency range 0.2-20 Hz, typical range of interesting in strong motion seismology and earthquake engineering. We generate both constant and damped sine waves with central frequency starting from 0.2 Hz until 20 Hz with step of 0.2 Hz. For each frequency analyzed we generate sine waves with mean amplitude 50, 100, 200, 400, 800 and 1600 mg0. For damped sine waves we generate waveforms with initial amplitude\n\nJoint Cross Well and Single Well Seismic Studies at Lost Hills, California\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nGritto, Roland; Daley, Thomas M.; Myer, Larry R.\n\n2002-06-25\n\nA series of time-lapse seismic cross well and single well experiments were conducted in a diatomite reservoir to monitor the injection of CO{sub 2} into a hydrofracture zone, based on P- and S-wave data. A high-frequency piezo-electric P-wave source and an orbital-vibrator S-wave source were used to generate waves that were recorded by hydrophones as well as three-component geophones. The injection well was located about 12 m from the source well. During the pre-injection phase water was injected into the hydrofrac-zone. The set of seismic experiments was repeated after a time interval of 7 months during which CO{sub 2} wasmoreÂ Â» injected into the hydrofractured zone. The questions to be answered ranged from the detectability of the geologic structure in the diatomic reservoir to the detectability of CO{sub 2} within the hydrofracture. Furthermore it was intended to determine which experiment (cross well or single well) is best suited to resolve these features. During the pre-injection experiment, the P-wave velocities exhibited relatively low values between 1700-1900 m/s, which decreased to 1600-1800 m/s during the post-injection phase (-5%). The analysis of the pre-injection S-wave data revealed slow S-wave velocities between 600-800 m/s, while the post-injection data revealed velocities between 500-700 m/s (-6%). These velocity estimates produced high Poisson ratios between 0.36 and 0.46 for this highly porous ({approx} 50%) material. Differencing post- and pre-injection data revealed an increase in Poisson ratio of up to 5%. Both, velocity and Poisson estimates indicate the dissolution of CO{sub 2} in the liquid phase of the reservoir accompanied by a pore-pressure increase. The single well data supported the findings of the cross well experiments. P- and S-wave velocities as well as Poisson ratios were comparable to the estimates of the cross well data. The cross well experiment did not detect the presence of the hydrofracture but appeared to be sensitive to\n\n3-D seismology in the Arabian Gulf\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nAl-Husseini, M.; Chimblo, R.\n\nSince 1977 when Aramco and GSI (Geophysical Services International) pioneered the first 3-D seismic survey in the Arabian Gulf, under the guidance of Aramco`s Chief Geophysicist John Hoke, 3-D seismology has been effectively used to map many complex subsurface geological phenomena. By the mid-1990s extensive 3-D surveys were acquired in Abu Dhabi, Oman, Qatar and Saudi Arabia. Also in the mid-1990`s Bahrain, Kuwait and Dubai were preparing to record surveys over their fields. On the structural side 3-D has refined seismic maps, focused faults and fractures systems, as well as outlined the distribution of facies, porosity and fluid saturation. InmoreÂ Â» field development, 3D has not only reduced drilling costs significantly, but has also improved the understanding of fluid behavior in the reservoir. In Oman, Petroleum Development Oman (PDO) has now acquired the first Gulf 4-D seismic survey (time-lapse 3D survey) over the Yibal Field. The 4-D survey will allow PDO to directly monitor water encroachment in the highly-faulted Cretaceous Shu`aiba reservoir. In exploration, 3-D seismology has resolved complex prospects with structural and stratigraphic complications and reduced the risk in the selection of drilling locations. The many case studies from Saudi Arabia, Oman, Qatar and the United Arab Emirates, which are reviewed in this paper, attest to the effectiveness of 3D seismology in exploration and producing, in clastics and carbonates reservoirs, and in the Mesozoic and Paleozoic.Â«Â less\n\nForensic seismology revisited\n\nNASA Astrophysics Data System (ADS)\n\nDouglas, A.\n\n2007-01-01\n\nThe first technical discussions, held in 1958, on methods of verifying compliance with a treaty banning nuclear explosions, concluded that a monitoring system could be set up to detect and identify such explosions anywhere except underground: the difficulty with underground explosions was that there would be some earthquakes that could not be distinguished from an explosion. The development of adequate ways of discriminating between earthquakes and underground explosions proved to be difficult so that only in 1996 was a Comprehensive Nuclear Test Ban Treaty (CTBT) finally negotiated. Some of the important improvements in the detection and identification of underground testsâthat is in forensic seismologyâhave been made by the UK through a research group at the Atomic Weapons Establishment (AWE). The paper describes some of the advances made in identification since 1958, particularly by the AWE Group, and the main features of the International Monitoring System (IMS), being set up to verify the Test Ban. Once the Treaty enters into force, then should a suspicious disturbance be detected the State under suspicion of testing will have to demonstrate that the disturbance was not a test. If this cannot be done satisfactorily the Treaty has provisions for on-site inspections (OSIs): for a suspicious seismic disturbance for example, an international team of inspectors will search the area around the estimated epicentre of the disturbance for evidence that a nuclear test really took place. Early observations made at epicentral distances out to 2,000 km from the Nevada Test Site showed that there is little to distinguish explosion seismograms from those of nearby earthquakes: for both source types the short-period (SP: Ë1 Hz) seismograms are complex showing multiple arrivals. At long range, say 3,000 10,000 km, loosely called teleseismic distances, the AWE Group noted that SP P wavesâthe most widely and well-recorded waves from underground explosionsâwere in\n\nGlobal Federation of Data Services in Seismology: Extending the Concept to Interdisciplinary Science\n\nNASA Astrophysics Data System (ADS)\n\nAhern, T. K.; Trabant, C. M.; Stults, M.; Van Fossen, M.\n\n2015-12-01\n\nThe International Federation of Digital Seismograph Networks (FDSN) sets international standards, formats, and access protocols for global seismology. Recently the availability of an FDSN standard for web services has enabled the development of a federated model of data access. With a growing number of internationally distributed data centers supporting identical web services the task of federation is now fully realizable. This presentation will highlight the advances the seismological community has made in the past year towards federated access to seismological data including waveforms, earthquake event catalogs, and metadata describing seismic stations. As part of the NSF EarthCube project, IRIS and its partners have been extending the concept of standard web services to other domains. Our primary partners include Lamont Doherty Earth Observatory (marine geophysics), Caltech (tectonic plate reconstructions), SDSC (hydrology), UNAVCO (geodesy), and Unidata (atmospheric sciences). Additionally IRIS is working with partners at NOAA's NGDC, NEON, UTEP, WOVODAT, Intermagnet, Global Geodynamics Program, and the Ocean Observatory Initiative (OOI) to develop web services for those domains. The ultimate goal is to allow discovery, access, and utilization of cross-domain data sources. IRIS and a variety of US and European partners have been involved in the Cooperation between Europe and the US (CoopEUS) project where interdisciplinary data integration is a key topic.\n\nCitizen Seismology\n\nNASA Astrophysics Data System (ADS)\n\nBossu, RÃ©my; Gilles, SÃ©bastien; Mazet-Roux, Gilles; Kamb, Linus; Frobert, Laurent\n\n2010-05-01\n\nIn science, projects which involve volunteers for observations, measurements, computation are grouped under the term, Citizen Science. They range from bird or planet census to distributing computing on volonteers's computer. Over the last five years, the EMSC has been developing tools and strategy to collect information on earthquake's impact from the first persons to be informed, i.e. the witnesses. By extension, it is named Citizen Seismology. The European Mediterranean Seismological Centre (EMSC), a scientific not-for-profit NGO, benefits from the high visibility of its rapid earthquake information services (www.emsc-csem.org) which attract an average of more than half a million visits a month from 160 countries. Witnesses converge to its site within a couple of minutes of earthquake's occurrence to find out information about the cause of the shaking they have just been through. The convergence generates brutal increases of hit rate which can be automatically detected. They are often the first indication about the occurrence of a felt event. Witnesses' locations are determined from their IP addresses. Localities exhibiting statistically significant increase of traffic are mapped to produce the \"felt map\". This map available within 5 to 8 minutes of the earthquake's occurrence represents the area where the event was felt. It is the fastest way to collect i"
    }
}