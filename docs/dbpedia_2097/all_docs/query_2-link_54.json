{
    "id": "dbpedia_2097_2",
    "rank": 54,
    "data": {
        "url": "https://som.yale.edu/programs/phd/overview/operations/seminar-series",
        "read_more_link": "",
        "language": "en",
        "title": "Operations Seminar Series",
        "top_image": "https://som.yale.edu/sites/default/files/styles/open_graph/public/2022-10/_DSC1891%20%282400%29.jpeg?h=c3635fa2&itok=lS8vxCsl",
        "meta_img": "https://som.yale.edu/sites/default/files/styles/open_graph/public/2022-10/_DSC1891%20%282400%29.jpeg?h=c3635fa2&itok=lS8vxCsl",
        "images": [
            "https://som.yale.edu/themes/custom/som/images/logos/yalesom_logo_stacked-min.svg",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2023-10/DSC_6299.JPG.webp?itok=SYJKoJJv",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2024-03/_DSC3859.jpg.webp?itok=fycZCia2",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2024-03/DSC_7028.JPG.webp?itok=TBgH1wG5",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2024-03/_DSC5726.jpg.webp?itok=JENscosN",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2023-10/161019-155-SOM-Exec-Edu-Womens-Leadership-2.jpg.webp?itok=qZNxuzYU",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2023-10/ysm_awards_675_52484095999_o.jpg.webp?itok=RKQOFZck",
            "https://som.yale.edu/sites/default/files/styles/card_420_/public/2024-03/_DSC4992_0.jpg.webp?itok=lwfXbEgw",
            "https://som.yale.edu/themes/custom/som/images/logos/yale_university_logo.svg",
            "https://som.yale.edu/themes/custom/som/images/logos/gn_logo.svg",
            "https://som.yale.edu/themes/custom/som/images/logos/ampersand_business_society.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2024-08-15T10:51:58-04:00",
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/themes/custom/som/images/favicons/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://som.yale.edu/programs/phd/overview/operations/seminar-series",
        "text": "The Yale Operations Seminar Series presents recent research papers in operations. The goal is to bring researchers from other universities to the Yale campus to stimulate exchange of ideas and deepen understanding of operations trends. These seminars are geared towards faculty and PhD students interested in operations research and management. Leading operations scholars, both internal and external will present their latest research. Doctoral students will meet with faculty prior to these seminars to review the papers and related literature. Participation in this seminar is required throughout the program.\n\nFaculty Coordinator: Faidra Monachou, Assistant Professor of Operations Management, faidra.monachou@yale.edu\n\nFaculty Support Coordinator: Nicole Morales, Senior Administrative Assistant, nicole.morales@yale.edu\n\nSeminar Series is held on Tuesdays from 11:45 a.m.-12:45 p.m., in 4400 at Edward P. Evans Hall (165 Whitney Avenue, New Haven) and via Zoom.\n\nAn email notice with abstract and paper will be sent in advance of each talk in the series.\n\nFall 2024\n\nSeptember 3: Jean Pauphilet, Assistant Professor of Management Science and Operations, London Business School\n\nTitle: Optimizing the path towards plastic-free oceans\n\nAbstract: Millions of tons of plastic are poured in the seas every year, damaging entire ecosystems from the coastlines up to the open waters. We partner with a non-profit organization and use optimization to help clean up oceans from plastic faster. Specifically, we optimize the route of their plastic collection system in the ocean to maximize the quantity of plastic collected over time. We formulate the problem as a longest path problem in a well-structured graph. However, since collection directly impacts future plastic density, the corresponding edge lengths are non-linear polynomials. After analyzing the structural properties of the edge lengths, we propose a search-and-bound method, which leverages a relaxation of the problem solvable via dynamic programming and clustering, to efficiently find high-quality solutions (within 6%-optimal in practice). On one-year of ocean data, our optimization-based routing approach increases the quantity of plastic collected by over 60% compared with their current routing strategy, hence speeding up the progress towards plastic-free oceans.\n\nSpring 2024\n\nApril 30: George Chen, Assistant Professor of Management Science and Operations, London Business School\n\nTitle: The Sooner, the Better? Optimal Vaccination Policy with Limited Vaccine Supply\n\nAbstract: We study the optimal single-dose vaccination policy in an infectious disease outbreak, considering both the limited total supply of the vaccine and its imperfect efficacy, which provides partial immunity to each vaccinated individual. The inclusion of imperfect efficacy introduces an additional compartment to the celebrated Susceptible-Infectious-Recovered (SIR) model, giving rise to an infinite horizon nonlinear optimal control problem. To facilitate theoretical analysis, we propose a novel variable transformation that converts the problem into an equivalent form with linear dynamics. Leveraging this transformation, we derive a closed-form expression for the optimal vaccination policy under infinite administrative capacity and establish theoretical structures for the optimal policy under finite capacity. Our results suggest that delaying the start of the vaccination process may be optimal, especially when the vaccine is less effective, the vaccine supply is more limited, and the disease is more infectious. The optimality of delay occurs because the individual-level benefit of vaccination with imperfect vaccines, in terms of the reduction of infection risk over the course of a disease outbreak, is non-monotonic in time; hence maximizing the overall benefit of vaccination requires a strategic allocation of limited vaccine supply over time. Building on these theoretical findings, our numerical study verifies these insights based on sensitivity results. We demonstrate the significant benefit of delay in reducing the total number of infections compared to policies without delay. Our study contributes to the methodology of solving optimal control problems in the context of infectious disease outbreaks. Moreover, it highlights scenarios in which delaying the start of the vaccination process can be beneficial-an aspect of vaccination policy design that has been overlooked in the literature but has important implications for practice.\n\n___________________________________________________________________\n\nApril 16: Fernanda Bravo, Assistant Professor of Decisions, Operations and Technology Management, UCLA Anderson School of Management\n\nTitle: Enhancing Safety Signaling: Integrating Clinical Trials and Post-Marketing Adverse Event Reports\n\nAbstract: Problem definition: Negative side effects from taking a drug, termed adverse drug reactions (ADRs), cause numerous emergency room visits and thousands of deaths a year in the U.S. alone. Ideally, regulators, such as the U.S. Food and Drug Administration (FDA), detect all safety issues before a drug’s marketing approval based on clinical trial results. However, trials are often too small or too short in duration to detect rare or slow-developing ADRs. As a result, regulators rely on spontaneous ADR reporting systems (e.g., the FDA’s FAERS system) to detect potential safety issues. Specifically, they employ this data to generate hypotheses about potential safety issues (termed safety signals) by identifying side effects that occur at a disproportionately high rate in patients taking a drug versus patients taking other drugs for the same condition. Reliance on biased observational data – due to selection and reporting differences among patients – can result in regulators flagging safety issues that are not truly present or in missing real safety issues. Methodology/results: In this work, we seek to enhance the hypothesis generation step of safety signaling based on spontaneous ADR reporting systems via a Bayesian methodology that combines pre-approval clinical trials and post-approval observational data for multiple ADRs. We use data from more common adverse events to quantify the direction and magnitude of bias in observational data as compared to clinical trial data and use it to debias the observational data for more rare adverse events. Our key observation is that common and rare ADRs share similar sources of selection and reporting biases. We quantify the benefits of the proposed approach to regulators via both analytical modeling with a stylized dynamic programming model as well as via a detailed numerical evaluation using real-world clinical trials and FAERS data. Numerical results suggest that we can effectively identify scenarios where the proposed approach will improve safety signaling over simpler alternatives, reducing expected Type I and II error costs by 17-41% in these scenarios. Managerial implications: By leveraging regulators’ existing data sources, our approach enhances the hypothesis generation step in post-approval drug surveillance, enabling more accurate and expedited safety signal detection.\n\n___________________________________________________________________\n\nMarch 26: Francis de Vericourt, Professor of Management Sciences, European School of Management and Technology (ESMT)\n\nTitle: Audit and Remediation Strategies in the Presence of Evasion Capabilities\n\nAbstract: In this paper, we explore how to uncover an adverse issue that may occur in organizations with the capability to evade detection. To that end, we formalize the problem of designing efficient auditing and remedial strategies as a dynamic mechanism design model. In this set-up, a principal seeks to uncover and remedy an issue that occurs to an agent at a random point in time, and that harms the principal if not addressed promptly. Only the agent observes the issue’s occurrence, but the principal may uncover it by auditing the agent at a cost. The agent, however, can exert effort to reduce the audit’s effectiveness in discovering the issue. We first establish that this set-up reduces to the optimal stochastic control of a piecewise deterministic Markov process. The analysis of this process reveals that the principal should implement a dynamic cyclic auditing and remedial cost-sharing mechanism, which we characterize in closed form. Importantly, we find that the principal should randomly audit the agent unless the agent’s evasion capacity is not very effective, and the agent cannot afford to self-correct the issue. In this latter case, the principal should follow pre- determined audit schedules.\n\n___________________________________________________________________\n\nMarch 5: Maxime Cohen, Visiting Professor of Operations Management and Shubik Fellow, Yale School of Management\n\nTitle: Incentivizing Healthy Food Choices Using Add-on Bundling: A Field Experiment\n\nAbstract: How can retailers incentivize customers to make healthier food choices? Price, convenience, and taste are known to be among the main drivers behind such choices. Unfortunately, healthier food options are often expensive and not adequately promoted. Interestingly, we are observing recent efforts to nudge customers toward healthier food. In this paper, we conducted a field experiment with a global convenience store chain to better understand how different add-on bundle promotions influence healthy food choices. We considered three types of add-on bundles: (i) an unhealthy bundle (when customers purchased a coffee, they could add a pastry for $1), (ii) a healthy bundle (offering a healthy snack, such as fruit, vegetable, or protein, as a coffee add-on for $1), and (iii) a choice bundle (the option of either a pastry or a healthy snack as a coffee add-on for $1). In addition to our field experiment, we conducted an online lab study to strengthen the validity of our results. We found that offering healthy snacks as part of an add-on bundle significantly increased healthy purchases (and decreased unhealthy purchases). Surprisingly, this finding continued to hold for the choice bundle, that is, even when unhealthy snacks were concurrently on promotion. However, we did not observe a long-term stickiness effect, meaning that customers returned to their original (unhealthy) purchase patterns once the healthy or choice bundle was discontinued. Finally, we show that offering an add-on choice bundle is also beneficial for retailers, who can earn higher revenue and profit.\n\n___________________________________________________________________\n\nFebruary 27: Jacob Leshno, Associate Professor of Economics, University of Chicago, Booth School of Business\n\nTitle: Price-Discovery in Waiting Lists\n\nAbstract: We study price discovery in waiting lists, where waiting times serve as prices. Waiting times adjust based on demand and supply dynamics – increasing when an item is chosen by an agent and decreasing when an item is assigned. This price-discovery heuristic generates prices that never converge but fluctuate around market-clearing prices. We show that under stable agent demand, this heuristic attains at least the allocative efficiency of market clearing prices minus a loss bounded by the granularity of price adjustments. If agent demand changes periodically, this heuristic is asymptotically optimal for an appropriate granularity of price adjustments. The intuition and analysis for the results rely on a connection to the stochastic gradient descent optimization algorithm.\n\n___________________________________________________________________\n\nFebruary 6: Kuang Xu, Associate Professor of Operations and Technology, Stanford Graduate School of Business\n\nTitle: Non-Stationary Bandit Learning via Predictive Sampling\n\nAbstract: Thompson sampling has proven effective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to non-stationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not differentiate actions based on how quickly the information acquired loses its usefulness due to non-stationarity. Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes acquiring information that quickly loses usefulness. Theoretical guarantee on the performance of predictive sampling is established through a Bayesian regret bound. We provide versions of predictive sampling for which computations tractably scale to complex bandit environments of practical interest. Through numerical simulations, we demonstrate that predictive sampling outperforms Thompson sampling in all non-stationary environments examined.\n\nFall 2023\n\nNovember 28: Ken Moon, Assistant Professor of Operations, Information and Decisions, Wharton School, University of Pennsylvania\n\nTitle: Bringing Data Science to the Management of Workforces\n\nAbstract: The talk will cover several, real-world collaborations relating to the operational management of workforces. The main part of the talk will focus on a research project with the Apple Worker Exit Study using extensive data on staffing, productivity, and pay from within a consumer electronics supply chain producing tens of billions in USD revenue quarterly. We study how firms should manage the problem of worker turnover, including its surprising impact on low-skilled workforces and the implications for production, wage, and inventory decisions. Despite the lack of skills, we find that worker turnover impedes coordination between assembly line coworkers by weakening knowledge sharing and relationships. We structurally estimate a dynamic equilibrium model of workers’ endogenous turnover decisions and the firm’s dynamic production and staffing decisions, and we apply reinforcement learning to evaluate managerial alternatives. A less turnover-prone, hence more productive, workforce reduces the firm’s variable production costs by 4.5%, or an estimated $928 million for the studied product. Such benefits justify paying higher efficiency wages even to less skilled workforces; furthermore, interestingly, rational inventory management policies incentivize self-interested firms to reduce rather than tolerate turnover. We also cover more recent research that develops learning algorithms to address the problem of worker stress and burnout for highly skilled workforces (ICU nurses and fighter jet pilots). In particular, we equip the nurses staffing three highly sophisticated ICUs with physiological sensors to identify and prevent exceptionally stressful workflows; and use physiological sensors placed on jet pilots to better train them against fatigue.\n\n___________________________________________________________________\n\nNovember 7: Robert Swinney, Professor in Operations Management, Fuqua School of Business, Duke University\n\nTitle: Sustainability Implications of Supply Chain Responsiveness\n\nAbstract: Problem Definition: A critical decision made by firms is whether to adopt a responsive supply chain (prioritizing speed) or an efficient supply chain (prioritizing cost). We consider the environmental implications of this choice, distinguishing between responsiveness achieved via three pathways: responsive offshore supply chains increase speed by using expedited production and distribution methods; responsive nearshore supply chains increase speed by reducing the physical distance between source and destination for all production; and hybrid nearshore supply chains produce in multiple locations simultaneously, increasing speed by reducing distance on some portion of production. Methodology/Results: Using a model wherein responsiveness increases fixed and marginal costs, decreases leadtimes, and changes the per-unit environmental impact of production and distribution, we identify several results. First, all types of responsiveness can decrease environmental impact relative to an efficient supply chain, showing any form of responsiveness has potential to improve sustainability. Second, despite this, all types of responsiveness can also increase environmental impact relative to an efficient supply chain, particularly if demand variability is high. This is precisely when responsiveness is most profitable to the firm, indicating a tension between firm and environmental preferences. Third, a win-win outcome in which responsiveness both maximizes firm profit and minimizes environmental impact is most likely to occur when demand variability is high and unsatisfied customers substitute with a product that generates high environmental impact. Fourth, the firm may have incentive to choose a supply chain that does not minimize (and may maximize) environmental impact, especially at low-to-moderate demand variability. Managerial Implications: While responsive supply chains can improve sustainability, they also generate the potential for misalignment of profit and environmental performance. We discuss the implications of this for firms and for policymakers seeking to encourage firms to use supply chains that generate the least environmental impact.\n\n___________________________________________________________________\n\nOctober 31: Ilan Lobel, Professor of Technology, Operations, and Statistics, Stern School of Business, New York University\n\nTitle: Reducing Marketplace Interference Bias Via Shadow Prices\n\nAbstract: Marketplace companies rely heavily on experimentation when making changes to the design or operation of their platforms. The workhorse of experimentation is the randomized controlled trial (RCT), or A/B test, in which users are randomly assigned to treatment or control groups. However, marketplace interference causes the Stable Unit Treatment Value Assumption (SUTVA) to be violated, leading to bias in the standard RCT metric. In this work, we propose techniques for platforms to run standard RCTs and still obtain meaningful estimates despite the presence of marketplace interference. We specifically consider a generalized matching setting, in which the platform explicitly matches supply with demand via a linear programming algorithm. Our first proposal is for the platform to estimate the value of global treatment and global control via optimization. We prove that this approach is unbiased in the fluid limit. Our second proposal is to compare the average shadow price of the treatment and control groups rather than the total value accrued by each group. We prove that this technique corresponds to the correct first-order approximation (in a Taylor series sense) of the value function of interest even in a finite-size system. We then use this result to prove that, under reasonable assumptions, our estimator is less biased than the RCT estimator. At the heart of our result is the idea that it is relatively easy to model interference in matching-driven marketplaces since, in such markets, the platform intermediates the spillover.\n\n___________________________________________________________________\n\nOctober 10: Moshe Haviv, Professor at School of Data Science, The Chinese University of Hong Kong, Shenzhen\n\nTitle: Intermediate priorities and balancing the C-mu rule\n\nAbstract: The Cµ rule is well known to be socially optimal in the sense that it minimizes the overall mean waiting costs of queueing. Yet, this rule is blind to fairness. In particular, it is possible that costumers with a low waiting cost per unit of time end up suffering more than those with a high such cost. We suggest here a fairer regime that minimizes the overall cost under the constraint that this anomaly does not exist. It is based on partitioning customers’ classes into leagues, such that by the Cµ rule absolute priority is granted between the leagues, while relative or accumulated priority is assumed to be between leagues. To that end we revisit some results on such priority regimes and derive some new ones.\n\n___________________________________________________________________\n\nSeptember 26: Nick Arnosti, Assistant Professor of Industrial and Systems Engineering, University of Minnesota\n\nTitle: Target the vulnerable? An analysis of rapid rehousing prioritization\n\nAbstract: We model the problem facing a policymaker who must allocate rapid rehousing support to people experiencing homelessness and wishes to minimize the steady-state size of the homeless population. Typically, support is given to the most vulnerable applicants, or to applicants most likely to remain housed. We show that these approaches may result in a homeless population that is arbitrarily larger than what could be achieved by an optimal policy.\n\nWe then study a family of policies where the policymaker does not differentiate between agents based on their characteristics and show that within this family FIFO queues are the policies that best target the most vulnerable. We then show that if the most vulnerable households are also the ones that most benefit from housing assistance then a FIFO queue minimizes the expected unhoused population. Conversely, a LIFO queue is optimal if the least vulnerable households benefit most from housing assistance.\n\n___________________________________________________________________\n\nSeptember 12: Soroush Saghafian, Associate Professor of Public Policy, Harvard Kennedy School\n\nTitle: Making AI Impactful in Healthcare\n\nAbstract: There is an increasing amount of evidence that Machine Learning and Artificial Intelligent algorithms can be used to enhance clinical care. In this talk, I address two critical aspects that can significantly improve the impact of such algorithms in healthcare practices: (1) moving beyond associations, and creating algorithms capable of causal reasoning under ambiguity, and (2) a human-algorithm “centaur” model of care and decision-making, in which the power of human intuition is combined with the outstanding capabilities of algorithms. I describe our latest research at the Public Impact Analytics Science Lab (PIAS-Lab) at Harvard on these subjects, and discuss findings based on our various collaborations with the Mayo Clinic as well as some other public and private organizations.\n\nDistributed Papers:\n\nSaghafian, S. “Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach,” Management Science, 2023 (forthcoming).\n\nOrfanoudaki, A., Saghafian, S., Song, K., Cook, C.B. and H.A. Chakkera. “Algorithm, Human, or the Centaur: How to Enhance Clinical Care?” Management Science (under revision), 2023.\n\nSpring 2023\n\nApril 25: Michael Toffel, Senator John Heinz Professor of Environmental Management and Professor of Business Administration, Harvard University\n\nTitle: Second- versus Third-party Audit Quality: Evidence from Global Supply Chain Monitoring\n\nAbstract: To capitalize on the superior credibility and flexibility and lower cost of external assessments, many global buyers are shifting from using their own employee (“second-party”) auditors to rely more heavily (or entirely) on third-party auditors to monitor and prevent environmental and social misconduct in supply chains. This trend is supported by ingrained assumptions about auditor incentives; namely, that third-party auditors’ greater independence reduces bias and improves audit quality. However, some are concerned that this trend risks eroding audit quality. Drawing on agency theory to provide a more nuanced understanding of auditor incentives and data from a leading global fashion brand, we find such concerns warranted: third-party auditors are less effective at citing violations at a given factory than second-party auditors, especially as regions exhibit (a) more corruption or (b) less potential oversight by second-party auditors. Global buyers can bolster third-party-audit quality by increasing the presence of second-party auditors in a given region, by emphasizing such deployments in more corrupt regions, and by rotating among different third-party audit firms. Our findings can inform better-designed monitoring not only of suppliers, but also of other business partners that create risks for brands, such as franchisees, distributors, vendors, and purchasing agents.\n\n___________________________________________________________________\n\nApril 18: Amy Ward, Rothman Family Professor of Operations Management, Booth School of Business\n\nTitle: When Machine Learning Impacts Resource Allocation Decisions: OM in Criminal Justice\n\nAbstract: The “revolving door” phenomenon, in which formerly incarcerated individuals often recidivate and end up being re-incarcerated, is a significant contributor to the mass incarceration problem in the US. Community-based incarceration diversion programs are shown to be an effective strategy to break this cycle. However, these programs often have limited capacity, so decision makers must decide who to admit and prioritize under the capacity limit. This is often done with the aid of machine learning (ML) algorithms, which classify each individual based on their recidivism risk. However, inaccurate ML classifications may result in suboptimal recommendations and further exacerbate the existing disparities in program access. To address this issue, we combine queueing theory and machine learning to study optimal admission decisions for diversion programs, taking into account limited capacity, treatment effectiveness, and the costs of recidivism and incarceration. Using fluid optimization, we show the optimal policy has a threshold structure when the predictions are sufficiently accurate, but that otherwise incorporating some randomization improves performance. This leads to guidelines for when to involve human judgement via human-in-the-loop decision override. Finally, we touch on issues of fairness that may arise in the implementation of these policies.\n\n*This is based on joint work with Pengyi Shi (Purdue University), Zhiqiang Zhang (PhD Student, University of Chicago), and Antonio Castellanos (Postdoctoral Researcher, University of Chicago).\n\n___________________________________________________________________\n\nApril 11: Guihua Wang, Assistant Professor of Operations Management, University of Texas at Dallas\n\nTitle: The Spillover Effect of Suspending Non-essential Surgery: Evidence from Kidney Transplantation\n\nAbstract: The COVID-19 pandemic has posed an epic challenge to the U.S. healthcare industry. Between March and April 2020, multiple state governors issued orders to temporarily suspend non-essential surgical procedures. The suspensions caused the healthcare industry to shed millions of jobs, raising concerns about the availability of essential procedures. In this paper, we estimate the potential spillover effect of suspending non-essential surgery on patient access to essential health services, using deceased-donor kidney transplantation as the clinical setting. Through analyzing a dataset of all U.S. kidney transplantation procedures, we observe a steep reduction in the volume of deceased-donor kidney transplantation across nearly all states amid the initial months of the pandemic. However, states that suspended non-essential surgery experienced far steeper reductions than those without. Using a difference-in-differences approach, we estimate a state-level suspension of non-essential surgery led to a 23.6% reduction in the transplant volume. Our study reveals the spillover effect of state-level health policies on patient access to essential services such as deceased-donor kidney transplantation. Our mediation analysis shows 38.7% of the spillover effect can be attributable to the change in healthcare employment, indicating these suspensions caused hospitals to reduce the size of their workforces required for all procedures, which ultimately had a negative impact on access to essential procedures. Instead of suspending all non-essential surgery in the event of a future pandemic, policymakers should consider more granular approaches to safeguarding the healthcare workforce critical to supporting essential services.\n\n___________________________________________________________________\n\nFebruary 28: Hessam Bavafa, Associate Professor of Operations and Information Management, Wisconsin School of Business\n\nTitle: Beyond Means: Unpacking Performance Variability\n\nAbstract: Little is known about how people-centric factors affect the shape of service time distributions, despite distributional statistics (variance or quantiles) being key drivers of system performance in many service industries. We investigate the impact of two people-centric factors—worker experience and fatigue—on the average, variance, and quantiles of service times in paramedic operations. Our analysis uses data on the performance of 368,634 paramedic teams in the London Ambulance Service over 10 years.\n\n___________________________________________________________________\n\nFebruary 7: Andrew Schaefer, Noah Harding Chair and Professor of Computational and Applied Mathematics, Rice University\n\nTitle: Outcome-Based Regulation and Adverse Selection in Lung Transplantation\n\nAbstract: Organ transplantation programs in the United States have seen increased scrutiny of outcomes in the past twenty years. Under regulations by the Organ Procurement Transplantation Network (OPTN) and Centers for Medicare and Medicaid (CMS), the United States has seen a rise in risk-averse patient selection among transplant programs, resulting in decreased transplantation volume for some programs. However, there is debate in the clinical literature over whether this observed response is rational. In this work, we develop a chance-constrained mixed-integer program to model the perspective of a transplant program that seeks to simultaneously maximize transplant volume and control the risk of OPTN/CMS penalization. Using our model, we demonstrate that under realistic conditions, it may be rational for a transplant program to curtail its transplant volume in order to avoid penalization. Moreover, we demonstrate that this incentive does not disappear even if regulators use accurate risk adjustment for high-risk patients. Our findings provide the first rigorous theoretical evidence that OPTN/CMS regulations create incentives for programs to reject certain medically-suitable patients.\n\n___________________________________________________________________\n\nJanuary 31: Yale Herer, Professor of Industrial Engineering and Management, Technion, Israel Institute of Technology\n\nTitle: An asymptotic perspective on risk pooling: Limitations and relationship to transshipments\n\nAbstract: In this talk we provide a novel perspective on risk pooling approaches by characterizing and comparing their asymptotic performance, highlighting the conditions under which one approach dominates the other. More specifically, we determine the inventory policy and the expected total costs of systems under physical and information pooling as the number of locations grows. We show that physical pooling dominates information pooling in settings with no additional per-item and per-location costs for operating the centralized system. In the presence of such costs, however, information pooling becomes a viable alternative to physical pooling. Through asymptotic analysis, we also address the grouping problem, the division of a given set of non-identical locations into an ordered collection of mutually exclusive and collectively exhaustive subsets of predetermined sizes and demonstrate that homogeneous groups, comprising locations with similar demand volatility, achieve a lower expected total cost. Finally, the convergence of the expected total costs and the base stock levels under the two pooling approaches is demonstrated through a simple numerical illustration. Our analysis supports the assertion that it is important to consider not only the individual characteristics of each location in isolation, but also the interactions among them, when designing pooling systems.\n\nThis talk is based on the publication: Yale T. Herer & Enver Yücesan (2022) An asymptotic perspective on risk pooling: Limitations and relationship to transshipments, IISE Transactions, DOI: 10.1080/24725854.2022.2086719\n\nFall 2022\n\nDecember 6: Robert Shumsky, Professor of Operations Management, Tuck School of Business at Dartmouth\n\nTitle: Wait Time Information Design\n\nAbstract: When customers arrive, service providers often collect information to generate delay forecasts. We study how delay data-collection and forecasting systems can be designed to improve customer satisfaction. We assume that customers may be loss-averse in the sense that an increase in the expected wait causes more distress than the positive response caused by an equivalent decrease and that they may be risk conscious in that an increase in the variance of expected delay reduces utility. Our goal is to find the structure of delay information that optimizes the customers’ experience while waiting. Delay forecasts follow Bayes' rule, given a prior distribution, the additional information collected for a particular customer, and the passage of time. We find that when loss aversion dominates, the optimal delay information focuses on the tails of the delay distribution. When risk consciousness is dominant more traditional information about the duration of delay--along a continuum from `short' to `long'--is optimal, and this information should be most precise about the longest delays. The optimal information design also affects the timing of delay revelation. When customers are loss averse, it is optimal to avoid changes in expected delay over time, so that waiting times are revealed as customers go into service. When customers are risk conscious, it is optimal to provide information so that they learn the good (or bad) news immediately, when they arrive.\n\nNovember 8: Brian Denton, Stephen M. Pollock Professor and Chair of Industrial and Operations Engineering, University of Michigan\n\nTitle: Predictive Models for Optimizing Imaging Decisions for Detection of Metastatic Prostate Cancer\n\nAbstract: In this talk I will discuss data-analytics approaches to develop, calibrate, and validate predictive models, to help urologists in a large state-wide collaborative make prostate cancer staging decisions based on individual patient risk factors. The models we developed predict the probability a patient who receives radiographic imaging will have metastatic cancer. The models were developed using observational data for patients diagnosed with prostate cancer. We used several machine learning methods and compared their performance at predicting outcomes of imaging. The models were validated using statistical methods based on bootstrapping and subsequent evaluation on out-of-sample data. These models were used to design guidelines that seek to optimally weigh the benefits and harms of radiological imaging for detection of metastatic prostate cancer. The Michigan Urological Surgery Improvement Collaborative, a state-wide medical collaborative, implemented these guidelines, which were predicted to reduce unnecessary imaging by more than 40% and limit the percentage of patients with missed metastatic disease to be less than 1%. The effects of the guidelines were measured post-implementation to confirm their impact on reducing unnecessary imaging across the state of Michigan. Time permitting, I will finish the talk by summarizing additional work on models for optimizing other types of decisions relevant to early detection of prostate cancer. OR Practice–Data Analytics for Optimal Detection of Metastatic Prostate Cancer (informs.org).\n\nOctober 25: Chaithanya Bandi, Associate Professor of Analytics and Operations, NUS Business School\n\nTitle: Online Scheduling in data-rich but uncertain environments: A case study at PGIMER hospital\n\nAbstract: In this talk, I will begin by giving an overview of three different problems motivated from our collaboration with PGIMER hospital in India. PGIMER is one of the largest public hospitals in India and was among the first hospitals to be part of the Digital India campaign. The resulting digitization enabled our data-driven study of operations in this hospital. We considered three different but related problems in this hospital: (1) Modeling and calibrating the complex dynamics of patient flows in this hospital; (2) Optimal design of operations and (3) Optimal staffing and scheduling. In this talk, I will focus on the intraday scheduling problem in a group of orthopaedic clinics where the planner schedules appointment times, given a sequence of appointments. We consider patient re-entry, where patients may be required to go for an x-ray examination, returning to the same doctor they have seen and variability in patient behaviours such as walk-ins, earliness, and no-shows, which leads to inefficiency such as long patient waiting time and physician overtime. In our data set, we find significant variability in patient behaviours. We formulate the problem as a two-stage optimization problem, where scheduling decisions are made in the first stage. Queue dynamics in the second stage are modeled under a P-Queue paradigm, which minimizes a risk index representing the chance of violating performance targets, such as patient waiting times. The model reduces to a sequence of mixed-integer linear-optimization problems. Our model achieves significant reductions, in comparative studies against a sample average approximation (SAA) model, on patient waiting times, while keeping server overtime constant. Our simulations further characterize the types of uncertainties under which SAA performs poorly. Managerial insights: We present an optimization model that is easy to implement in practice and tractable to compute. Our simulations indicate that not accounting for patient re-entry or variability in patient behaviours will lead to suboptimal policies, especially when they have specific structure that should be considered. https://pubsonline.informs.org/doi/epdf/10.1287/msom.2020.0959\n\nOctober 11: Adam Elmachtoub, Associate Professor of Industrial Engineering and Operations Research at Columbia University\n\nTitle: Simple and Fair Pricing Strategies\n\nSummary: In this talk, we survey several recent results on using simple and fair pricing strategies as alternatives to dynamic and personalized pricing strategies.\n\nWe show that our policies can be near-optimal, consumer-friendly, and easily implementable.\n\nSeptember 13: Omar Besbes, Vikram S. Pandit Professor of Business, Columbia Business School\n\nTitle: Data-driven decisions: how big should your data really be?\n\nAbstract: We consider two fundamental questions in data-driven decision making: 1) how should a decision-maker construct a mapping from historical data to decisions? 2) how much data is needed to operate ``effectively”? We discuss various central applications in pricing and capacity decisions, together with different associated data structures. We present recent results that enable to quantify (robustly) achievable performance across data sizes, small and big. These results yield fundamental practical insights on the economics of data sizes: in many applications, a little data can go a long way in optimizing decisions.\n\nThe talk will draw on results from a series of papers:\n\nAllouah, Bahamou, and Besbes, Pricing with Samples. Available at SSRN: https://ssrn.com/abstract=3334650\n\nAllouah, Bahamou, and Besbes, Optimal Pricing with a Single Point. Available at SSRN: https://ssrn.com/abstract=3801056\n\nBesbes and Mouchtaki, How Big Should Your Data Really Be? Data-Driven Newsvendor: Learning One Sample at a Time. Available at SSRN: https://ssrn.com/abstract=3878155\n\nSpring 2022 - Virtual & In Person\n\nCarri Chan (Professor of Business, Decision, Risk, and Operations, Columbia Business School), May 10\n\nPlease join us on Tuesday, May 10th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nPrediction-driven Surge Planning With Applications in the Emergency Department\n\nOptimizing emergency department (ED) nurse staffing decisions to balance the quality of service and staffing cost can be extremely challenging, especially when there is a high level of uncertainty in patient-demand. Increasing data availability and continuing advancements in predictive analytics provide an opportunity to mitigate demand-rate uncertainty by utilizing demand forecasts. In this work, we study a two-stage prediction framework that is synchronized with the base (made months in advance) and surge (made nearly real-time) staffing decisions in the ED. We quantify the benefit of the more expensive surge staffing. We also propose a near-optimal two-stage staffing policy that is straightforward to interpret and implement. Lastly, we develop a unified framework that combines parameter estimation, real-time demand forecasts, and staffing in the ED. High fidelity ED simulation experiments demonstrate that the proposed framework can reduce staffing costs by 8% – 17% while guaranteeing timely access to care.\n\nVille Satopää (Assistant Professor, Technology and Operations Management, INSEAD), May 5\n\nPlease join us on Thursday, May 5th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nHerding in Probabilistic Forecasts\n\nDecision makers often ask experts to forecast a future state. Experts, however, can be biased. In the economics and psychology literature, one extensively studied behavioral bias is called herding. Under strong levels of herding, disclosure of public information may lower forecasting accuracy. This result, however, has been derived only for point forecasts. In this paper, we consider experts' probabilistic forecasts under herding, find a closed-form expression for the first two moments of a unique equilibrium forecast, and show that the experts report too similar locations and inflate the variance of their forecasts due to herding. Furthermore, we show that the negative externality of public information no longer holds. In addition to reacting to new information as expected, probabilistic forecasts contain more information about the experts' full beliefs and interpersonal structure. This facilitates model estimation. To this end, we consider a one-shot setting with one forecast per expert and show that our model is identifiable up to an infinite number of solutions based on point forecasts, but up to two solutions based on probabilistic forecasts. We then provide a Bayesian estimation procedure for these two solutions and apply it to economic forecasting data collected by the European Central Bank and the Federal Reserve Bank of Philadelphia. We find that, on average, the experts invest around 19% of their efforts into making similar forecasts. The level of herding shows an increasing trend from 1999 to 2007 but drops sharply during the financial crisis of 2007-2009, and then rises again until 2019.\n\nFrancis de Véricourt (Chaired Professor of Management Science, ESMT Berlin), May 3\n\nPlease join us on Tuesday, May 3rd, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nIs your machine better than you? You may never know.\n\nAI systems are increasingly demonstrating their capacity to make better predictions than human experts. Yet, recent empirical studies suggest that professionals sometimes doubt the quality of these systems, and as a result overrule machine-based prescriptions. This paper explores the extent to which a decision maker (DM) can properly assess whether a machine produces better recommendations. To that end, we analyze an elementary dynamic Bayesian framework, in which a machine performs repeated decision tasks under a DM’s supervision. The task consists in deciding whether to take an action or not. Crucially, the DM observes the accuracy of the machine’s prediction on the task only if she ultimately takes the action. As she observes the machine’s accuracy, the DM updates her belief about whether the machine’s predictions outperform her own. Depending on this belief, however, the DM sometimes overrides the machine, which affect her ability to assess it.\n\nIn this set-up, we characterize the evolution of the DM's belief and overruling decisions over time. We identify situations under which the DM’s belief oscillates forever, i.e., the DM always hesitates whether the machine is better. In this case, the DM never fully ignores the machine but regularly overrules it. We further find that the DM’s belief sometimes converges to a Bernoulli random variable, i.e., the DM ends up wrongly believing that the machine is better (or worse) with positive probability. We fully characterize the conditions under which these failures to learn occur. These results highlight some fundamental limitations in our ability to determine whether machines make better decision than experts. They further provide a novel explanation for why humans may collaborate with machines – even when one may actually outperform the other.\n\nHuifeng Su (Doctoral Student, Yale School of Management), April 26\n\nPlease join us on Tuesday, April 26th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nThe Impact of Hallway Placement on Emergency Department Quality of Care\n\nEmergency Department (ED) crowding is a constant and relentless operational challenge that hospitals face across the country. With the intention to make timely care accessible to more patients, the emergency department often takes advantage of an additional source of capacity within the ED — the hallways. In this study, we investigate and quantify the impact of patient placement in the hallway on ED patient flow and quality measures through a quasi-experimental research design. In addition, we conduct heterogeneous analysis across ED operational settings to understand whether hallway placement uniformly backfires across utilization levels.\n\nMaxime Cohen (Scale AI Chair Professor of Retail and Operations Management, McGill University), April 19\n\nPlease join us on Tuesday, April 19th, 11:45 am-12:45 pm EDT via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nFrustration-Based Promotions: Field Experiments in Ride-Sharing\n\nThe service industry has become increasingly competitive. One of the main drivers for increasing profits and market share is service quality. When consumers encounter a bad experience, or a frustration, they may be tempted to stop using the service. In collaboration with the ride-sharing platform Via, our goal is to understand the benefits of proactively compensating customers who have experienced a frustration. Motivated by historical data, we consider two types of frustrations: long waiting times and long travel times. We design and run three field experiments to investigate how different types of compensation affect the engagement of riders who experienced a frustration. We find that sending proactive compensation to frustrated riders (i) is profitable and boosts their engagement behavior, (ii) works well for long waiting times but not for long travel times, (iii) seems more effective than sending the same offer to nonfrustrated riders, and (iv) has an impact moderated by past usage frequency. We also observe that the best strategy is to send credit for future usage (as opposed to waiving the charge or sending an apologetic message).\n\nJonas Oddur Jonasson (Assistant Professor, Operations Management, MIT Sloan), April 12\n\nPlease join us on Tuesday, April 12th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nRedesigning Sample Transportation in Malawi Through Improved Data Sharing and Daily Route Optimization\n\nHealthcare systems in resource-limited settings rely on diagnostic networks in which medical samples (e.g. blood, sputum) and results need to be transported between geographically dispersed healthcare facilities and centralized laboratories. Due to lack of updated information, existing sample transportation (ST) systems typically operate fixed schedules which do not account for demand variability. We present an innovative approach for timely collection of information on transportation demand (samples and results) using low-cost technology based on feature phones and integrate it with a novel Multi-Stage version of the Dynamic Multi-Period Vehicle Routing Problem to generate daily routes in response to this updated information. We design the Optimized Sample Transportation (OST) system which comprises two components: a novel data sharing platform to monitor incoming sample volumes at healthcare facilities, and an optimization based solution approach to the problem of routing and scheduling courier trips in a multi-stage transportation system. We implement OST in collaboration with Riders For Health, who operate the national ST system in Malawi. Our solution approach performs well in a range of numerical experiments. Based on analysis of implementation data describing over 20,000 samples and results transported during July-October 2019, we show that the implementation of OST routes reduced average ST delays in three districts of Malawi by approximately 25%. In addition, the proportion of unnecessary trips by ST couriers decreased by 55%. Results from our implementation demonstrate the practical feasibility of our novel approach for improving centralized ST operations in Malawi and its broader applicability to other resource-limited settings, particularly in sub-Saharan Africa.\n\nMichael Blair (Doctoral Student, Yale School of Management), April 5\n\nPlease join us on Tuesday, April 5th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nEstimating the Impact of Climate Change: An Empirical Analysis of Smart Thermostat Data\n\nUsing a rich micro-level dataset, we empirically analyze smart thermostat data to understand the relationship between households' thermostat settings and their ambient environment. Using a unique methodology combining Dynamic Linear Models, random effects, and Bayesian Statistics, we develop models for short and long-term behavior. Using weather simulations we estimate the impact of climate change, and identify key patterns in household actions that drive large differences in consumption.\n\nYen-Shao Chen (Doctoral Student, Yale School of Management), March 29\n\nPlease join us on Tuesday, March 29th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/94959863259?pwd=YzBYSXV6bFM4QWVpSWxmdEs4Y2tHdz09\n\nControl of Nonlinear Opinion Dynamics in Social Networks\n\nOur goal is to persuade large-scale social networks. Persuasion here means using agents to optimize a function of the opinions in the network. Many of the opinion dynamics models which capture realistic behaviors are nonlinear. This nonlinearity makes it difficult to learn a policy that optimizes the opinion function. In this study, we provide a mathematical model that describes nonlinear opinion dynamics and learn a policy to maximize the mean opinion using optimal control theory. Our control policy not only achieves the optimal objective in certain networks, but it is interpretable, scalable, and efficient for human-like agents in large-scale social networks.\n\nSaravanan Kesavan (Professor of Operations and Sarah Graham Kenan Scholar, UNC Kenan Flagler Business School), March 8\n\nPlease join us on Tuesday, March 8th, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/99910624694?pwd=NlZ4akNzN1lXQ3hQSWk5UWkwQnF2UT09\n\nDoing Well by Doing Good: Improving Store Performance with Responsible Scheduling Practices at the Gap, Inc.\n\nWe estimate the causal effects of responsible scheduling practices on store financial performance at the US retailer Gap, Inc. The randomized field experiment evaluated a multi-component intervention designed to improve dimensions of work schedules – consistency, predictability, adequacy, and employee control – shown to foster employee well-being. The experiment was conducted in 28 stores in the San Francisco and Chicago metropolitan areas for nine months between November 2015 and August 2016. Intent-to-treat (ITT) analyses indicate that implementing responsible scheduling practices increased store productivity by 5.1%, a result of increasing sales (by 3.3%) while also decreasing labor (by 1.8%). Drawing on qualitative interviews with managers and quantitative analyses of employee shift-level data, we offer evidence that the intervention improved financial performance through improved store execution. Our experiment provides evidence that responsible scheduling practices that take worker well-being into account can enhance store productivity by motivating additional employee effort and reducing barriers to employees adhering to the scheduled labor plan.\n\nDaniela Saban (Associate Professor of Operations, Information & Technology, Stanford Graduate School of Business), March 1\n\nPlease join us on Tuesday, March 1st, 11:45 am-12:45 pm EDT in 4200 or via Zoom link:\n\nhttps://yale.zoom.us/j/91755127389?pwd=U2k2L2VuZ1RVd2NmWldQTEt5VFFLZz09\n\nImproving Match Rates in Dating Markets Through Assortment Optimization\n\nMotivated by our collaboration with an online dating company, we study how a platform should dynamically select the set of potential partners to show to each user in each period in order to maximize the expected number of matches in a time horizon, where a match is formed only after two users like each other, possibly in different periods. Our work combines several methodologies. We model the platform's problem as a dynamic optimization problem. We use econometric tools and exploit a change in the company's algorithm in order to estimate the users' preferences as well as other parameters of interest. We find that the number of matches obtained in the recent past has a negative effect on the like behavior of users. We propose a family of heuristics to solve the platform's problem that leverage these data findings, and use simulations to assess their benefits. Two field experiments show that our algorithm yields at least 27% more matches relative to our industry partner's algorithm. Overall, our results highlight the importance of correctly accounting for the preferences, behavior, and activity metrics of users on both ends of a transaction to improve the operational efficiency of matching platforms.\n\nKejia Hu (Assistant Professor of Operations Management, Vanderbilt University, Owen Graduate School of Business), February 1\n\nPlease join us on Tuesday, February 1st, 11:45 am-12:45 pm EDT via Zoom link:\n\nhttps://yale.zoom.us/j/95056298950?pwd=d0NCL3RMYTlSdWVGbDJkV3UyQWJmQT09\n\nTo What Extent Do Workers’ Preferences Matter?\n\nOur research investigates how preference satisfaction, particularly intrinsic values such as psychological comfort, can improve a worker’s service efficiency and quality. Examining a comprehensive dataset linking surgeons’ performances to their preferences for operating rooms, we not only confirm the significant role of intrinsic values in driving workers’ service efficiency and quality but also quantify the preference satisfaction effect as large enough to serve as a new managerial lever for firms. However, we also find that compared to workers without preferences, workers with preferences perform better if satisfied, but worse if unsatisfied. This suggests that firms should consider the cultivation of workers’ preferences only if their systems can satisfy their workers. Furthermore, our second-order analysis suggests that in a restricted system, managers should prioritize satisfying workers with heavy workloads or complex tasks to achieve the greatest improvement. Finally, we update the surgery scheduling framework by incorporating surgeons’ preferences. Our counterfactual analysis demonstrates that preference satisfaction can achieve huge benefits in operation cost saving and patient welfare improvement at little expense. For the operations in our sample, we find satisfying surgeons’ preferences can reduce healthcare costs by over 4 million dollars, not to mention the potential for significant improvement in patients’ and surgeons’ welfare."
    }
}