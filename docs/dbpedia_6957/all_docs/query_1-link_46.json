{
    "id": "dbpedia_6957_1",
    "rank": 46,
    "data": {
        "url": "https://www.jneurosci.org/content/38/46/9955",
        "read_more_link": "",
        "language": "en",
        "title": "Implicit Memory for Complex Sounds in Higher Auditory Cortex of the Ferret",
        "top_image": "https://www.jneurosci.org/sites/default/files/highwire/jneuro/38/46.cover-source.jpg",
        "meta_img": "https://www.jneurosci.org/sites/default/files/highwire/jneuro/38/46.cover-source.jpg",
        "images": [
            "https://www.jneurosci.org/sites/default/files/mobile-logo.png",
            "https://www.jneurosci.org/sites/default/files/jneuro%20logo.png",
            "https://www.jneurosci.org/sites/all/modules/contrib/panels_ajax_tab/images/loading.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F1.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F1.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F2.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F2.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F3.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F3.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F4.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F4.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F5.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F5.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F6.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F6.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F7.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F7.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F8.medium.gif",
            "https://www.jneurosci.org/content/jneuro/38/46/9955/F8.medium.gif",
            "https://www.jneurosci.org/sites/default/files/styles/medium/public/highwire/jneuro/38/46.cover-source.jpg?itok=ob4aI3pV",
            "https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/twitter.png",
            "https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/fb-blue.png",
            "https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/mendeley.png",
            "https://www.jneurosci.org/sites/default/files/files/JNeurosci_footer_logo_forJCore_386x100.png",
            "https://www.jneurosci.org/sites/default/files/files/SfN_footer_logo_forJCore_336x100.png",
            "https://googleads.g.doubleclick.net/pagead/viewthroughconversion/952157035/?value=0&guid=ON&script=0"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Kai Lu",
            "Wanyi Liu",
            "Peng Zan",
            "Stephen V. David",
            "Jonathan B. Fritz",
            "Shihab A. Shamma"
        ],
        "publish_date": "2018-11-14T00:00:00",
        "summary": "",
        "meta_description": "Responses of auditory cortical neurons encode sound features of incoming acoustic stimuli and also are shaped by stimulus context and history. Previous studies of mammalian auditory cortex have reported a variable time course for such contextual effects ranging from milliseconds to minutes. However, in secondary auditory forebrain areas of songbirds, long-term stimulus-specific neuronal habituation to acoustic stimuli can persist for much longer periods of time, ranging from hours to days. Such long-term habituation in the songbird is a form of long-term auditory memory that requires gene expression. Although such long-term habituation has been demonstrated in avian auditory forebrain, this phenomenon has not previously been described in the mammalian auditory system. Utilizing a similar version of the avian habituation paradigm, we explored whether such long-term effects of stimulus history also occur in auditory cortex of a mammalian auditory generalist, the ferret. Following repetitive presentation of novel complex sounds, we observed significant response habituation in secondary auditory cortex, but not in primary auditory cortex. This long-term habituation appeared to be independent for each novel stimulus and often lasted for at least 20 min. These effects could not be explained by simple neuronal fatigue in the auditory pathway, because time-reversed sounds induced undiminished responses similar to those elicited by completely novel sounds. A parallel set of pupillometric response measurements in the ferret revealed long-term habituation effects similar to observed long-term neural habituation, supporting the hypothesis that habituation to passively presented stimuli is correlated with implicit learning and long-term recognition of familiar sounds.\n\nSIGNIFICANCE STATEMENT Long-term habituation in higher areas of songbird auditory forebrain is associated with gene expression and is correlated with recognition memory. Similar long-term auditory habituation in mammals has not been previously described. We studied such habituation in single neurons in the auditory cortex of awake ferrets that were passively listening to repeated presentations of various complex sounds. Responses exhibited long-lasting habituation (at least 20 min) in the secondary, but not primary auditory cortex. Habituation ceased when stimuli were played backward, despite having identical spectral content to the original sound. This long-term neural habituation correlated with similar habituation of ferret pupillary responses to repeated presentations of the same stimuli, suggesting that stimulus habituation is retained as a long-term behavioral memory.",
        "meta_lang": "en",
        "meta_favicon": "https://www.jneurosci.org/sites/default/files/images/favicon.ico",
        "meta_site_name": "Journal of Neuroscience",
        "canonical_link": "https://www.jneurosci.org/content/38/46/9955",
        "text": "Subjects.\n\nAdult female ferrets, Mustela putorius (n = 6), were used for this study. Three ferrets were used for electrophysiological recordings from auditory cortex and three additional ferrets were used for pupillometry measurement. All ferrets used in this study had been previously trained on auditory streaming instrumental tasks (Lu et al., 2017) that were unrelated to this implicit habituation procedure. The ferrets were housed on a 12 h light/dark cycle. They were placed on a water-control protocol in which they received their daily liquid during experimental sessions on 2 d per week and obtained ad libitum water on the other 5 d per week. All experimental procedures were in accordance with National Institutes of Health policy on animal care and use and conformed to a protocol approved by the Institutional Animal Care and Use Committee of University of Maryland.\n\nSurgeries.\n\nA head-post was surgically implanted to stabilize the head for neurophysiological and pupillary recordings. Animals were anesthetized with isoflurane (1.5–2% in oxygen) and a customized stainless-steel head post was surgically implanted on the ferret skull under aseptic conditions. The skull covering the auditory cortex was exposed and covered by a thin layer of Heraeus Kulzer Charisma (1 mm thick) and surrounded by a thicker wall built with Charisma (3 mm thick). After recovery from surgery, the animals were habituated to head restraint in a customized holder, which fixed the head post stably in place and restrained the body in a plastic tube. Two days before electrophysiological recording, a small craniotomy (1–3 mm diameter) was made above auditory cortex for electrophysiological recordings. At the beginning and end of each recording session, the craniotomy was thoroughly rinsed with sterile saline. At the end of a recording session, the craniotomy and well was filled with topical antibiotics (in saline solution) that were rotated on a weekly basis (either Baytril or cefazolin). After drying with sterile eye spears, the well was filled with silicone (sterile vinyl polysiloxane impression material, Examix NDS), which provided a tight, protective seal for the well. The silicone plug could be removed easily at the next recording session. Necessary steps were taken to maintain sterility in the craniotomy region during all procedures. After recordings were completed in the original craniotomy, it was gradually enlarged by removing adjacent small adjacent bone sections of the skull over successive months of recording to eventually provide access for electrode recordings to the entire A1 and dPEG. The procedure for enlarging the craniotomy was identical to that followed for drilling the original craniotomy.\n\nElectrophysiological recording.\n\nElectrophysiological recordings were made in a walk-in double-walled soundproof booth (IAC). The awake animal was immobilized in a comfortable tube and the implanted head post was clamped to fix the head in place relative to a stereotaxic frame. Recordings were conducted in primary A1 and in dPEG of both left and right hemispheres. In each recording, 4∼8 tungsten microelectrodes (2–3 MΩ, FHC) were introduced through the craniotomies and controlled by independently moveable drives (Electrode Positioning System, Alpha-Omega). Raw neural activity traces were amplified, filtered, and digitally acquired by a data acquisition system (AlphaLab, Alpha-Omega). Multiunit neuronal responses were monitored online (including all spikes that rose above a threshold level of 3.5 SD of baseline noise). Single units were isolated online by searching for single-unit activity. Bandpass noise (0.2 s duration, 1 octave bandwidth) and pure tone (0.2 s duration) stimuli were presented to search for responsive sites. After recordings, single units were isolated again by off-line customized spike-sorting software, which was based on a PCA and template-matching algorithm (Meska-PCA, NSL). As auditory responses were found, the frequency tuning of neurons were determined by pure tone and temporally orthogonal ripple combinations (Depireux et al., 2001). Following characterization of receptive field properties and frequency tuning, stimulus playback experiments were performed.\n\nAuditory field localization.\n\nThe approximate location of A1 was initially determined by stereotaxic coordinates and then refined with neurophysiological mapping of the tonotopic map in A1 (Bizley et al., 2005). The posterior border of A1 (along the suprasylvian sulcus) was marked by the presence of visual responses from neighboring visual cortex. The location of dPEG was determined neurophysiologically by tonotopically mapping A1 and dPEG, which share a common low-frequency border (Fig, 1; Atiani et al., 2014; Bizley et al., 2005, 2015). The tonotopic gradient in A1 goes from high- to low-frequency along a rostrally tilted dorsoventral axis until the gradient reversed and best frequency increases again in the mirror frequency maps in the two areas that comprise the dPEG-PPF and PSF. In addition to the A1/dPEG tonotopic gradient reversal, transition to dPEG was also marked by somewhat longer latencies, greater sustained responses and weaker envelope phase-locking than in A1 (Atiani et al., 2014; Bizley et al., 2005). The ventral boundary of the dPEG was determined by abrupt transition from high-frequency tuning to broad low-frequency tuning (Atiani et al., 2014; Bizley et al., 2005, 2015).\n\nAuditory stimuli and experimental design.\n\nAcoustic stimuli were comprised of 73 short samples of animal vocalizations, speech, vocal and instrumental music, and sampled at 40 kHz. Animal vocalizations and human speech were 2–4 s long (Fig. 2A). Instrumental music excerpts were 3–5 s long. All stimulus amplitudes were presented at 65 dB SPL from a speaker placed 1 m in front of the animal in a large, walk-in double-walled soundproof booth (IAC).\n\nThe habituation paradigm used to habituate the animal to a specific complex sound sequence was very similar to the paradigm used in previous avian studies (Chew et al., 1995, 1996). It consisted of three phases, with three blocks in each phase (Fig. 2B). In Phase 1, three distinct stimuli, novel to the animal, were presented for 50 repetitions each, in three sequential blocks, with a 6 s interstimulus gap between stimuli (the same timing was used in the following 2 phases as well). Each block of 50 repetitions lasted ∼10 min, and thus the entire Phase 1 lasted ∼30 min. In Phase 2, familiarity to the same three original stimuli from Phase 1 was tested by presenting 25 repetitions in each block in the same order, so that each now-familiar stimulus was presented ∼20 min after its last presentation in Phase 1. In Phase 3, the same three stimuli were reversed temporally to generated sounds with novel temporal features but minimally changed spectral characteristics. Reversed stimuli were presented in the same order as the three original stimuli from Phase 1, with 25 repetitions in each block.\n\nIt should be noted that we did not attempt to habituate cells with simple tonal stimuli because these stimuli were routinely used to search for units and characterize their tuning curves, so that pure tones were not novel for the animals. Furthermore, the time window available for retesting all neurons for persistence of memory effects was limited to the minimal time we could hold cells reliably, which was at least 1 h, hence the combined duration of the three Phases.\n\nData analysis.\n\nThe amplitude of auditory responses was defined as the average spike-rate in the response window (from stimulus onset to 250 ms after stimulus offset. The baseline activity was quantified as the average spike-rate during the period of 1 s before stimulus onset. Any recording with significant change in baseline activity within or between habituation phases was excluded from further analysis (criterion within phases: Spearman correlation p < 0.01; between phases: Kolmogorov–Smirnov two-sample test, p < 0.01). Stability of single units throughout each recording was confirmed by stable spike waveforms. If there were changes in spike waveform during the recording, the neurons were not used for further analysis.\n\nQuantification of habituation effect.\n\nTo quantify habituation of auditory responses in Phase 1, the response rate for each single unit was quantified on a trial-by-trial basis (see Fig. 4C). Responses from trial 2 to 17 in each block (i.e., 1 stimulus type) in Phase 1 were averaged. These 16 trials (i.e., stimulus presentations) constituted the initial ∼one-third of the stimulus presentations in the block, whose mean was defined as the starting-response for a given novel stimulus. Following paradigms used previously in the songbird literature (Phan et al., 2006; Phan and Vicario, 2010), the first stimulus was excluded from the analysis as it usually had a relatively strong and variable response that quickly adapted (in the Discussion, we will separately discuss and summarize responses to the first stimulus in the block). Similarly, response rates from the last 16 trials in each block were averaged and defined as the end-response. For each recorded neuron, three types of stimuli were tested. Both the starting- and end-responses were averaged across all these stimuli for a given neuron, so that the response amplitude change (i.e., the difference between starting- and end-response firing rates) was measured as a characteristic property of each neuron for each novel stimulus.\n\nDynamics of the habituation process were quantified by linear regression (following closely procedures used by Chew et al., 1995; Phan et al., 2006; Phan and Vicario, 2010) across all trials as follows: (1) The response rate of each trial in each block was divided by the average response from trials 2 to 6 inclusive. This normalization converted the raw spike rate in each trial to a percentage of the averaged response amplitude at the beginning of each block. (2) A linear regression between trial number and normalized response amplitudes was performed for all trials (excluding the first trial) and the slope of the linear regression was calculated. (3) Regression slopes from the three tested stimuli (blocks) in each phase were averaged.\n\nRegression slopes were compared across the three test phases and also compared between A1 and dPEG. For the cross-phase comparison, regression slopes for Phase 1 were only calculated from the first half of the trials, so that equal number of trials (25, because 25 repetitions were presented in Phases 2 and 3) were measured in all of the three phases (following procedure used by Phan et al., 2006; Velho et al., 2012). To compare regression slopes across different stimulus classes, all stimuli were assigned to one of three classes of auditory stimuli: (A) Animal vocalizations, (B) musical excerpts and vocal songs, and (C) human speech. Regression slopes within each stimulus class were pooled and compared.\n\nCalculation of mutual information.\n\nWe analyzed changes in mutual information (MI) carried by spike trains during habituation to novel stimuli in Phase 1. MI was calculated as the difference between the entropy associated with all responses of a neuron and the entropy of responses to a given stimulus, following standard procedures (Nelken and Chechik, 2007). The first 25 trials of the three novel stimuli in test Phase 1 were chosen for calculating MI for novel stimuli. MI was calculated from randomly selected subsets of data of three sizes [∼50% (12), 80% (20), and 100% (25) of the first 25 trials]. Then a linear regression between MIs and the reciprocal of the sample size in each dataset was calculated. The intercept of the linear regression provided an estimate of the unbiased MI. Because the acoustic stimuli had different durations, only the first 800 ms was used for the MI calculations, with 80 ms as the bin size. This limited duration was used so as to use fewer trials for the MI calculation and capture its dynamics. Following the same procedure, MI for the familiar stimuli was calculated from the last 25 trials of the same stimuli in the block. In other words, for each neuron, we computed one MI value for the first 25 trials in Phase 1 and one for the last 25 trials in Phase 1. The difference between MI (novel) and MI (familiar) corresponds to the MI change (ΔMI). We averaged ΔMI over all neurons.\n\nPupillary measurements.\n\nWe tested pupillary size changes during long-term stimulus habituation. Three naive ferrets were tested with the same paradigm, where animals were head-fixed, passively listening to sound presentations in three test phases. Pupillary changes were recorded at 3 Hz using a DCC1545M camera (Thorlabs; TML-HP 1_ Telecentric lens, Edmund Optics) with regular illumination. Recorded images were analyzed and pupillary size was measured offline. Baseline pupillary size was calculated by averaging measurements in 2 s windows before stimulus onset. Pupillary responses to stimuli were measured in 5 s windows after stimulus onset. Then pupillary size measured in the response window was adjusted by subtracting the baseline pupillary measurement in each trial. To compare the pupillary responses to novel stimuli and familiar stimuli, pupillary responses, as a function of time, were calculated in the same way as analysis of post-stimulus time histogram (PSTH) differences (except that more repetitions were used in the analysis because of the much lower sampling rate of pupillary recording compared with electrophysiology). Pupillary responses to the first 15 trials of novel sounds were pooled together and compared with pupillary responses to the last 15 trials of familiar sounds.\n\nThe latency of pupillary responses was determined in the same way as the analysis of temporal profile of neural habituation. Habituation curves of pupillary responses were estimated from trial-by-trial pupillary measurements as in the analysis of habituation curves of the neural data.\n\nStatistical methods.\n\nResults were plotted as histograms or cumulative frequency distributions (which reveal details of multiple distributions) and also as conventional box-and-whisker plots. Because sample distributions in some tests did not satisfy criteria for parametric tests, nonparametric statistics were used. Changes in response rates over repetitive stimulation and slopes of linear regression from the neuron population were tested by the Wilcoxon matched pairs test (the nonparametric version of one-sample t test). Differences between test phases were similarly tested. Friedman ANOVA tests were used to test multiple matched samples. For non-matched samples, differences between the two brain regions (A1 and dPEG) were tested by the Kolmogorov–Smirnov two-sample test (the nonparametric version of two-sample t test). Median tests (similar to one-factor ANOVA) were applied to multiple non-matched samples."
    }
}