{
    "id": "dbpedia_5702_0",
    "rank": 25,
    "data": {
        "url": "https://www.blumenthal.senate.gov/about/issues/kids-online-safety-act",
        "read_more_link": "",
        "language": "en",
        "title": "U.S. Senator Richard Blumenthal",
        "top_image": "https://www.blumenthal.senate.gov/assets/images/sharelogo.jpg",
        "meta_img": "https://www.blumenthal.senate.gov/assets/images/sharelogo.jpg",
        "images": [
            "https://www.blumenthal.senate.gov/assets/images/logo.svg",
            "https://www.blumenthal.senate.gov/assets/images/logo_secondary.svg",
            "https://www.blumenthal.senate.gov/imo/media/image/Untitled-3.png",
            "https://www.blumenthal.senate.gov/imo/media/image/100521-RP2-1216.jpg",
            "https://www.blumenthal.senate.gov/imo/media/image/443A7407.JPG",
            "https://www.blumenthal.senate.gov/imo/media/image/KOSA%20Social%20Media_3.png",
            "https://www.blumenthal.senate.gov/imo/media/image/KOSA%20Social%20Media_2.png",
            "https://www.blumenthal.senate.gov/imo/media/image/KOSA%20Social%20Media_4.png",
            "https://www.blumenthal.senate.gov/imo/media/image/KOSA%20Social%20Media_5.png",
            "https://www.blumenthal.senate.gov/imo/media/image/KOSA%20Social%20Media_1.png",
            "https://www.blumenthal.senate.gov/imo/media/image/KOSA%20Social%20Media_6.png",
            "https://www.blumenthal.senate.gov/imo/media/image/443A7447.JPG",
            "https://www.blumenthal.senate.gov/imo/media/image/102621-JS5-323.jpg",
            "https://www.blumenthal.senate.gov/imo/media/image/100521-RP1-075.jpg",
            "https://www.blumenthal.senate.gov/imo/media/image/2022.11.15_KOSA%20Parents%20Meeting_SDMC_11.jpg",
            "https://www.blumenthal.senate.gov/imo/media/image/Young%20People%20Roundtable%2010.231.png",
            "https://www.blumenthal.senate.gov/imo/media/image/2022.12.6_KOSA%20Parent%20&%20Youth%20Meeting_4.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "The Official U.S. Senate website of Senator Richard Blumenthal of Connecticut",
        "meta_lang": "en",
        "meta_favicon": "/assets/images/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://www.blumenthal.senate.gov/about/issues/kids-online-safety-act",
        "text": "No, the Kids Online Safety Act does not give state Attorneys General or FTC the power to bring lawsuits over content or speech. The Kids Online Safety Act would not censor, block, or remove any content from the internet.\n\nThe Kids Online Safety Act targets the harms that online platforms cause through their own product and business decisions – like how they design their products and applications to keep kids online for as long as possible, train their algorithms to exploit vulnerabilities, and target children with advertising.\n\nAdditionally, the Kids Online Safety Act does not amend Section 230 of the Communications Decency Act, which provides immunity to online platforms for third-party content. As a result, any lawsuits brought by the FTC over the content that online platforms host are likely to be quickly tossed out of court.\n\nFinally, the bill includes a specific, express provision ensuring that a company cannot be liable for providing content to young users when the user has searched for that content.\n\nThe “duty of care” requires social media companies to prevent and mitigate certain harms that they know their platforms and products are causing to young users as a result of their own design choices, such as their recommendation algorithms and addictive product features. The specific covered harms include suicide, eating disorders, substance use disorders, and sexual exploitation.\n\nFor example, if an app knows that its constant reminders and nudges are causing its young users to obsessively use their platform, to the detriment of their mental health or to financially exploit them, the duty of care would allow the FTC to bring an enforcement action. This would force app developers to consider ahead of time where theses nudges are causing harms to kids, and potentially avoid using them.\n\nCompanies in every other industry in America are required to take meaningful steps to prevent users of their products from being hurt, and this simply extends that same kind of responsibility to social media companies, too.\n\nImportantly, not all platforms have the same functionality or business model, so the duty of care forces online platforms to consider and address the negative impacts of their specific product or service on younger users, without imposing rules that may not work for each website or service.\n\nThe duty of care only applies to a fixed and clearly established set of harms, and sets a high standard for what online platforms can be held accountable for.\n\nThis specific list of harms includes medically-recognized mental health disorders (suicidal behaviors, eating disorders, and substance use disorders), addictive use, illicit drugs, and federally-defined child sexual exploitation crimes.\n\nThe FTC – which has the power to enforce the duty of care – cannot add or change the harms covered under the bill.\n\nNo, the Kids Online Safety Act does not make online platforms liable for the content they host or choose to remove.\n\nAdditionally, the bill includes a specific, express provision ensuring that a company cannot be liable for providing content to young users when the user has searched for that content.\n\nNo, the Kids Online Safety Act actually includes an express provision ensuring that a company cannot be liable for providing content to young users when the user has searched for that content. And, in order to ensure that mental health support services are protected and encouraged, the bill provides explicit protections for those services (ex. National Suicide Hotline, substance abuse organizations, or LGBTQ youth centers).\n\nThat means that a social media platform doesn’t face any legal liability when users log onto their platforms and seek out helpful resources, like the National Suicide Hotline or information about how to treat substance abuse.\n\nNo, the Kids Online Safety Act does not impose age verification requirements or require platforms to collect more data about users (government IDs or otherwise).\n\nIn fact, the bill states explicitly that it does not require age gating, age verification, or the collection of additional data from users.\n\nUnder the Kids Online Safety Act, if an online platform already knows that a user is underage, then it has to provide the safety and privacy protections required by the legislation—the platform cannot bury its head in the sand when it knows a user is underage.\n\nOnline platforms often already request a date of birth from new users, either for advertising and profiling the user, or for compliance with Children's Online Privacy Protection Act (COPPA). Online platforms also frequently collect or purchase substantial amounts of other data to understand more about their users.\n\nBut if an online platform truly doesn’t know the age of the user, then it does not face any obligation to provide protections or safeguards under the bill or to collect more data in order to determine the user’s age.\n\nNo, teenage users don’t need permission to create new accounts or go online. The bill does require permissions and safeguards for young children, those under the age of 13, similar to existing law under COPPA.\n\nNo, the Kids Online Safety Act doesn’t require the disclosure of private information such as browsing history, messages, or friends lists, to parents or other users.\n\nWhat the Kids Online Safety Act does do is create an obligation for platforms and apps to provide safeguards and tools to parents and kids. These guardrails are focused on protecting kids’ privacy, preventing addictive use, and disconnecting users from recommendation systems. Parental tools – such as the ability to restrict purchases and financial transactions, as well as to view and control privacy and account settings or metrics of total time spent on the platform – are turned on by default for children (under age 13). They are provided only as an option for teens (aged 13 to 16) to turn on as families choose.\n\nThe bill also includes additional protections and guardrails on the parents’ tools to protect the privacy of minors, such as requiring platforms to notify teens and children when parental controls are enabled.\n\nNo, the Kids Online Safety Act only covers social media, social networks, multiplayer online video games, social messaging applications, and video streaming services. It does not include blogs or personal websites.\n\nNo, websites run by non-profits organizations – which often host important and valuable educational and support services – are not covered by the scope of the legislation."
    }
}