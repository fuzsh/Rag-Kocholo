{
    "id": "dbpedia_6296_2",
    "rank": 49,
    "data": {
        "url": "https://content.iospress.com/articles/semantic-web/sw233469",
        "read_more_link": "",
        "language": "en",
        "title": "box classifiers in the space of semantic queries",
        "top_image": "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g016.jpg",
        "meta_img": "",
        "images": [
            "https://content.iospress.com:443/static/img/latest_header_img.png@2.6.8-2-gb19ff93",
            "https://content.iospress.com:443/static/img/openaccess_icon.png@2.6.8-2-gb19ff93",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g001.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g002.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g003.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g004.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g005.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g006.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g007.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g008.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g009.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g010.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g011.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g012.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g013.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g014.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g015.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g016.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g017.jpg",
            "https://content.iospress.com:443/media/sw-prepress/sw--1--1-sw233469/sw--1-sw233469-g018.jpg",
            "https://content.iospress.com/fragr/images/J24_3782 IOS Press Banners Ads_moving-soon_268x268.jpg",
            "https://www.iospress.com/sites/default/files/media/images/2021-09/Content-site_square-banner_signup-journal-newsletters_2021.png",
            "https://content.iospress.com:443/static/img/mock_up_footer_new.png@2.6.8-2-gb19ff93",
            "https://content.iospress.com:443/static/img/sem_logo.png@2.6.8-2-gb19ff93"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Menis-Mastromichalakis"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Deep learning models have achieved impressive performance in various tasks, but they are usually opaque with regards to their inner complex operation, obfuscating the reasons for which they make decisions. This opacity raises ethical and legal concer",
        "meta_lang": "en",
        "meta_favicon": "https://content.iospress.com:443/static/img/favicon.ico@2.6.8-2-gb19ff93",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "4.3.1.Query least common subsumer\n\nOur first approach for merging queries is using the query least common subsumer (QLCS). In the next few paragraphs we will present how to construct such a query from two SAV queries which will make apparent that the QLCS of two SAV queries always exists. As mentioned in Section 2, a QLCS is a most specific generalization of two queries. By choosing to use QLCS(qA,qB) (since QLCS is unique up to syntactical equivalence, we assume that QLCS(qA,qB) represents one such QLCS for qA and qB) in the place of Merge(qA,qB) in Alg. 1, and assuming that the input set of individuals is I={a1,…,an}, it should be obvious that the last query computed by Alg. 1 will be q=QLCS(MSQ(a1,A),MSQ(a2,A),…,MSQ(an,A)). For any query q′ such that cert(q′,A)⊇I, it will by definition hold that MSQ(ai,A)⩽Sq′, i=1,…,n. Therefore, q⩽Sq′, which implies that cert(q,A)⊆cert(q′,A). This means that if there is an exact explanation rule query of I, that will be a QLCS of its MSQs, while if there is not, the computed QLCS explanation rule query will have the fewest possible exceptions. Thus, the main advantage of using the QLCS is that it guarantees “optimality” of the computed explanations.\n\nTo compute a QLCS we use an extension of the Kronecker product of graphs to labeled graphs. Given two labeled graphs G1=(V1,E1,ℓV1,ℓE1) and G2=(V2,E2,ℓV2,ℓE2), which in our case will represent queries, their Kronecker product G=G1×G2 is the graph G=(V,E,ℓV,ℓE), where V=V1×V2, E={⟨⟨u1,v1⟩,⟨u2,v2⟩⟩|⟨u1,u2⟩∈E1,⟨v1,v2⟩∈E2, and ℓE1(⟨u1,u2⟩)∩ℓE2(⟨v1,v2⟩)≠∅}⊆V×V, ℓV:V→2CN with ℓV(⟨v1,v2⟩)=ℓV1(v1)∩ℓV2(v2), and ℓE:E→2RN with ℓE(⟨⟨u1,v1⟩,⟨u2,v2⟩⟩)=ℓE1(⟨u1,u2⟩)∩ℓE2(⟨v1,v2⟩).\n\nExample 6.\n\nFig. 4 shows the Kronecker product of the query graphs of Example 4.\n\nFig. 4.\n\nAs with the Kronecker product of unlabeled graphs, for any graph H, we have that H→G1,G2 if and only if H→G1×G2 [70]. Since we are interested in graphs representing SAV queries, we can assume that H, G1, G2 are connected. Assuming that G1, G2 represent two SAV queries q1, q2 (with answer variable x), it will specifically hold that H→G1,G2 if and only if H→conn(⟨x,x⟩,G1×G2), where conn(⟨x,x⟩,G1×G2) is the connected component of G1×G2 containing the pairs of answer variables node ⟨x,x⟩. Let q be the query whose query graph is the connected component of G1×G2 containing node ⟨x,x⟩, with node ⟨x,x⟩ replaced by x (the answer variable of the new query) and all other nodes of that connected component replaced by distinct arbitrary variable names other than x. Since we allow SAV queries to have empty bodies, even if the node ⟨x,x⟩ is not labeled with any atoms it corresponds to a valid query that obviously subsumes q1 and q2. Because homomorphisms between query graphs correspond to subsumption relations between the respective queries, and vice versa, it will hold that q1,q2⩽Sq and for any other query q′ s.t. q1,q2⩽Sq′ it will hold that Gq′→G1,G2, therefore Gq′→G1×G2 and therefore q⩽Sq′. Computing G1×G2 is therefore a concrete way to construct the QLCS.\n\nFor use with Alg. 1, we denote a call to the concrete function implementing that approach for computing QLCS(q1,q2) by KRONECKERQLCS(q1,q2). The time complexity of KRONECKERQLCS(q1,q2) is O(|var(q1)|2·|var(q2)|2), and the Kronecker product of the graphs G1, G2, contains |V1|·|V2| nodes. Therefore, the final query constructed by Alg. 1 using KRONECKERQLCS(q1,q2) to implement Merge(q1,q2) will have O(mn) variables, where m=maxi=1,…,n|var(qi)| is the maximum variable count of the MSQs, and n=|I| is the number of individuals in I. Constructing this query is by far the most expensive operation of the algorithm and dominates the running time with a complexity of O(m2n). This makes the use of the above procedure for computing QLCS’s prohibitive for merging queries. However, the query obtained using the Kronecker product is in general not condensed, and in general will contain many redundant atoms and variables.\n\nExample 7.\n\nFig. 5 shows the QLCS of the MSQs of Example 4, extracted from the Kronecker product of Example 6. It is obvious that the nodes with label {Finding} are redundant due to the presence of the nodes with label {SoreThroat,Finding} and {LungFinding,Finding}.\n\nFig. 5.\n\nRemoving the redundant parts of a query is essential not only for reducing the running time of the algorithm. Since these queries are intended to be shown to humans as explanations, ensuring that they are compact is imperative to improve comprehensibility. As mentioned in Section 2, the operation that compacts a query by creating a syntactically equivalent query by removing all its redundant parts is condensation. However, condensing a query is coNP-complete [27]. For this reason, we utilize Alg. 2, an approximation algorithm which removes redundant conjuncts and variables without a guarantee of producing a fully condensed query.\n\nAlgorithm 2:\n\nAlg. 2 iterates through the variables of the input query, and checks if deleting one of them is equivalent to unifying it with another one. In particular, at each iteration of the main loop, the algorithm attempts to find a variable suitable for deletion. If none is found, the loop terminates. The inner loop iterates through all pairs of variables. At each iteration, variable v′ is deleted if unifying it with v, by replacing all instances of v′ in the query with v, produces no new conjuncts. By unifying variable v′ with v, all conjuncts of the form C(v′) become C(v) and all conjuncts of the forms r(v′,v″), r(v″,v′), r(v′,v′) become r(v,v″), r(v″,v), r(v,v), respectively. If these conjuncts are already present, then removing them is equivalent to unifying v′ with v. Alg. 2 is correct because removing a variable from query q produces a query that subsumes q, while unifying two variables of q produces a query that is subsumed by q. Therefore, Alg. 2 produces syntactically equivalent queries.\n\nExample 8.\n\nWe can showcase an example of Alg. 2 detecting an extraneous variable in the QLCS of q1 and q2 from Example 7, running the main loop for v=y1 and v′=y2. The condition at line 3 first checks if the label of node v′, {Finding}, is a subset of the label of node v, {SoreThroat,Finding}, which is true. Then for every incoming edge to v′ it checks if there is an edge incoming to v with the same label and origin. They both have one incoming edge from node x labeled with hasFinding so the second condition will also evaluate to true. Node v′ has no incoming edges, so the third condition will also evaluate to true. Therefore, Alg. 2 will detect node v′ as extraneous and delete it. Running the entire algorithm for this query will result in the query represented in Fig. 6 as a graph.\n\nThe main loop of Alg. 2 is executed at most var(q) times, since at each loop either a variable is deleted or the loop terminates. The inner loop checks all pairs of variables (O(|var(q)|2)), and the if condition requires O(var(q)) set comparisons of size at most |CN|, and 2|RN| comparisons of rows and columns of adjacency matrices. Treating |CN| and |RN| as constants, the complexity of Algorithm 2 is O(|var(q)|4).\n\nGiven the above, our first practical implementation of Alg. 1, uses GRAPHMSQ(a,A) to implement MSQ(a,A), and APPROXQUERYMINIMIZE(KRONECKERQLCS(qA,qB)) to implement Merge(qA,qB).\n\nRegardless of the approximate query minimization described above, even if full query condensation could be performed, there is no guarantee that condensing the queries computed by Alg. 1 using QLCS as the merge operation, have meaningfully smaller condensations. This led us to two different approaches for further dealing with the rapidly growing queries QLCS produces.\n\nThe simplest approach to address this problem is to reject any queries produced by KRONECKERQLCS(q1,q2) that, even after minimization, have variable counts higher than a pre-selected threshold. This strategy essentially introduces a weaker version of Alg. 1, without the guarantees of optimality, but with polynomial running time, which is outlined in Alg. 3, which we call KGrules-HT.\n\nFig. 6.\n\nAlgorithm 3:\n\nAlg. 3 is the same as Alg. 1 except that q is not added to L and S unless its variable count is less than or equal to an input threshold, t. This simple change reduces the complexity of the algorithm to polynomial in terms of |I| and t. It should be noted that setting a very low threshold for t could potentially lead to all queries being rejected and the algorithm returning an empty set. The effects of t on the queries produced can vary significantly for different inputs and therefore different explanation datasets, thus t should be adjusted experimentally. It is also assumed that all MSQ’s created when initializing L have less than t variables.\n\nIf we let n=|I|, calculating the query dissimilarity for all pairs of queries, costs O(n2t2) operations. Using memoization limits the cost of calculating the dissimilarity through all iterations to O(n2t2). Each iteration of the main loop involves O(n2) operations for selecting qA, qB and O(t4) operations for calculating their QLCS. Thus, in total, Alg. 3 has a running time of O(n3+n2t2+nt4).\n\nOur second approach to overcome the problem posed by the rapidly growing size of the queries produced by QLCS was to consider a different merge operation, which is described in the following section.\n\n5.2.3.Results\n\nThe explanation rules generated for the ResNet34 classifier using KGrules-H and QLCS as the merge operation, as outlined in Section 4.3.1, are shown in Table 6, where we show the rule, the value of each metric and the numbers of positive individuals. The term positive individuals refers to the certain answers of the respective explanation rule query that are also elements of the pos-set (they are classified in the respective class).\n\nIn our representation of explanation rule queries in Tables 6, 7 we have omitted the answer variable x, along with all conjuncts of the form x contains y and conjuncts of the form Object(y), for brevity. In addition, the rules in the Table are not formally written, to make more visually clear the characteristics of the objects involved. For example, the rule of the first row (Best precision for class 1) would formally be written Exemplar(x), contains(x,y1), contains(x,y2), contains(x,y3), Large(y1), Cube(y1), Gray(y1), Large(y2), Cylinder(y2), Large(y3),Metal(y3)→Class1(x).\n\nThe algorithm found a correct rule (precision=1) for each class, in addition to a rule query with recall = 1, whose certain answers are a superset of the positive set. The best degree was achieved for class 3, which lacks a confounding factor, meaning the classifier is not expected to be biased. Correct rule queries are of particular interest since they can be translated into guaranteed IF-THEN rules which the classifier follows on the particular dataset. For instance the highest recall correct rule query for class 1 is translated into the rule “If the image contains a Large Gray Cube, a Large Cylinder and a Large Metal Object then it is classified to class 1.”. This rule clearly shows the bias of the classifier, since it is the description of the class with the added confounding factor (the Large Cube is Gray). Similarly the (not correct) rule query with recall = 1 for the same class can be translated into the rule “If the image does not contain a Large Cube then it is not classified to class 1”, since the set of certain answers is a super set of the positive set. We observed that correct rule queries tend to be more specific than others, with the most general rules with exceptions being those with recall = 1. Other rules which were correct with exceptions, tended to lie somewhere in the middle with respect to how general or specific they are, but they were the ones which lead to the highest values of degree. By observing these results, we concluded that in practice, a set of rules, both correct and with exceptions, can give us a very clear picture of what the black-box classifier is doing. However, in order to not overwhelm an end-user with a large number of rules, we should develop a strategy to select which rules to show to the user. Here, as opposed to the Mushroom experiment (Section 5.1) the strategy we used was to show the highest recall, highest precision and highest degree rules, along with their exceptions if any, but as mentioned, we plan to explore additional strategies in the future, such as showing disjunctions of correct rules.\n\nIt is interesting to note that the rule query with recall = 1 produced for class 1 contained a Large Cube but not a Large Cylinder, which is also in the description of the class. This shows that in the training process the classifier learned to pay more attention to the presence of cubes rather than the presence of cylinders. The elements of the highest recall correct rule that differ from the true description of class 1 can be a great starting point for a closer inspection of the classifier. We expected the presence of a Gray Cube from the confounding factor introduced in the training and validation sets, but in a real world scenario similar insights can be reached by inspecting the queries. In our case, we further inquired the role that the Gray Cube and the Large Metal Object play in the correct rule by removing either of them from the query and examining its behavior. In Table 7 we can see that the gray color was essential for the correct rule while the Large Metal Object was not, and in fact its removal improved the rule and returned almost the entire class.\n\nAnother result that piqued our attention was the highest degree explanation for class 3 which is the actual rule that describes this class. This explanation was not a correct rule, since it had two exceptions, which we can also see in the confusion matrix of the classifier and we were interested to examine what sets these two individuals apart. We found that both of these individuals are answers to the query “y1 is Large, Gray, Cube”. This showed us once again the great effect the confounding factor of class 1 had on the classifier.\n\nOur overall results show that the classifier tended to emphasize low level information such as color and shape and ignored higher level information such as texture and the combined presence of multiple objects. This was the reason why the confounding factor of class 1 had an important effect to the way images were classified, while the confounding factor of class 2 seemed to have had a much smaller one. Furthermore, the added bias made the classifier reject class 1 images, which however had to be classified to one of the other two classes (no class was not an option). Therefore one of the other classes had to be “polluted” by samples which were not confidently classified to a class. This motivates us to expand the framework in the future to work with more informative sets than the pos-set, such as elements which were classified with high confidence, and false and true, negatives and positives\n\nTable 6\n\nMetricExplanation rulesPrecisionRecallDegreePositivesClass 1Best precisiony1 is Large, Cube, Gray.1.000.660.6683y2 is Large, Cylinder.y3 is Large, Metal.Best recally1 is Large, Cube.0.091.000.09125Best degreey1 is Large, Cube, Gray.1.000.660.6683y2 is Large, Cylinder.y3 is Large, Metal.Class 2Best precisiony1 is Small, Sphere.1.000.090.09116y2 is Large, Rubber.y3 is Small, Metal, Cube.y4 is Small, Brown.y5 is Small, Rubber, Cylinder.Best recally1 is Cube.0.631.000.631247Best degreey1 is Metal, Cube.0.780.80.651005y2 is Small, Metal.Class 3Best precisiony1 is Metal, Blue.1.000.420.42365y2 is Large, Blue, Sphere.y3 is Yellow, Small, Sphere.y4 is Small, Rubber.y5 is Metal, Sphere.Best recally1 is Large.0.421.000.42878y2 is Sphere.Best degreey1 is Yellow, Small, Sphere.0.990.850.85748y2 is Large, Blue, Sphere.\n\nTable 7\n\nQueryPositivesNegativesy1 is Large, Cube. y2 is Large, Cylinder. y3 is Large, Metal.108547y1 is Large, Cube, Gray. y2 is Large, Cylinder.930\n\n5.4.3.Results\n\nFor MNIST there does not exist a ground truth semantic description for each class, as was the case for CLEVR-Hans3, nor is there a pre-determined bias of the classifier, thus we could not easily measure our framework’s usefulness in this regard. Instead, since the explanation dataset was constructed automatically, we explored quality related features of the generated explanations.\n\nFor all digits the algorithm produced at least one correct rule (precision = 1) and a rule with exceptions with recall = 1. The highest degree of rule queries for each digit are shown as a bar-plot in Fig. 12a. In general, the values of the metric seem low, with the exception of digit 0, which would indicate that the algorithms did not find a single rule which approximates the pos-set to a high degree. For some of the digits, including 0, the highest degree rule is also a correct rule. For closer inspection, we show the best degree rule query for digit 0 which is the highest, and for digit 5 which is the lowest.\n\nFig. 12.\n\nThe explanation rule for digit 0 involved six lines, as indicated by the conjuncts contains(x,y1), contains(x,y2), contains(x,y3), contains(x,y4), contains(x,y5), contains(x,y6). For five of the six lines, the explanation rule query included their location in the image, indicated by the conjuncts TopCenter(y1), BotRight(y2), BotCenter(y2), MidRight(y3), TopRight(y5), BotCenter(y6). For all six lines the explanation rule included information about their orientation, indicated by the conjuncts Line45deg(y1), Line45deg(y2), Line90deg(y3), Line90deg(y4), Line135deg(y5), Line135deg(y6). Finally, the rule-query included the following conjuncts which show which lines intersect each other intersects(y1,y4), intersects(y2,y3), intersects(y3,y5), intersects(y4,y6). A rule query with so many conjuncts could potentially be difficult for a user to decipher, so in this case we found it useful to visualize the rules. The above rule is visualized in Fig. 13a. The visualization is clear and intuitive as an explanation for digits classified as zeroes, however visualization of rules will not be possible in all applications. This shows the importance of taking under consideration understandability when designing explaination pipelines, which in our case depends mostly on the vocabulary and expressivity of the underlying explanation dataset. In this case, the vocabulary used was itself somewhat obscure for users (sets of intersecting lines are not easy to understand by reading a rule), which could have been mitigated if the explanation dataset had been curated by humans and not created automatically. In this particular use-case it was not a problem however, since the visualization of rules was easy in most cases.\n\nFig. 13.\n\nFig. 14.\n\nThe highest degree explanation rule for digit 5, which was the lowest out of the best of all digits, again involved six lines indicated by the conjuncts contains(x,y1), contains(x,y2), contains(x,y3), contains(x,y4), contains(x,y5), contains(x,y6). This time however, only three lines had information about their location in the image, indicated by the conjuncts BotCenter(y2), BotCenter(y4), MidCenter(y5), and five lines had information about their orientation Line0deg(y1), Line0deg(y2), Line45deg(y3), Line45deg(y4) Line135deg(y6). Furthermore, this rule-query included information about the size of two lines, indicated by the conjuncts Medium(y4), Short(y6). Finally, as with before, we get a set of conjuncts showing which lines intersect each other: intersects(y1,y3), intersects(y2,y4), intersects(y3,y5). This rule query is not easy to understand and it is even difficult to visualize, since there is not enough information about the location of each line, thus it is not actually usable. This was expected to an extent, due to the low value of the degree metric, but again highlights the importance of taking usability under consideration when choosing which rule-queries to show to a user.\n\nRegarding correct rules, the algorithm produced several for each digit. Since the sets of certain answers of correct rule queries are subsets of the pos-set of each class, we measured the per class fidelity of the disjunction of all correct rules, as if giving a user a rule-set, similarly to the Mushroom experiment (Section 5.1). In Fig. 12c we show as a bar-plot the fidelity for each class. With the exception of digit one, the pos-sets of all digits were sufficiently covered by the set of correct rules. The failure for digit 1 was expected, since the descriptions of the exemplars classified as 1 contain few lines (for example consisting of a single large line in the middle) which tend to be part of descriptions of other digits as well (all digits could be drawn in a way in which there is a single line in the middle). This is a drawback of the open world assumption of DLs since we cannot guarantee the non-existence of lines that are not provided in the descriptions. The open world assumption is still desirable since it allows for incomplete descriptions of exemplars. In cases such as the medical motivating example used throughout this paper, a missing finding such as “Dyspnoea” does not always imply that the patient does not suffer from dyspnoea. It could also be a symptom that has not been detected or has been overlooked.\n\nThe highest recall of a single correct rule for each digit is shown as a bar-plot in Fig. 12b. Since correct rules are easily translated into IF-THEN rules, we expected them to be more informative than the highest degree ones, which requires looking at the exceptions to gain a clearer understanding of the rule. We investigate closer by analyzing the best correct rule for each digit.\n\nFor digit 0, the best correct rule was the same as the highest degree rule presented previously. In Fig. 14a we provide an example of a six misclassified as a 0, which follows this correct rule. Comparing the misclassified 6 with the visualizations for rules of the digits 0 (Fig. 13a) and 6 (Fig. 13f) we can see that this 6 might have been misclassified as a 0 because the closed loop part of the digit reaches the top of the image. According to the correct rule for 0, an image that contains two vertical semicircles in the left and right sides of the image is classified as a 0, and because of this peculiarity in the drawing of the misclassified six, the image (Fig. 13a) obeys this rule.\n\nThe best correct rule for digit 1 had the lowest recall out of all correct rules for other digits, which means that it returned a small subset of the positives. Specifically, this rule returned only two of the 30 individuals classified as the digit 1. It was still usable as an explanation however, as it only involved two lines contains(x,y1), contains(x,y2), both of which were thoroughly described with regard to their location BotCenter(y1), MidCenter(y1), TopCenter(y1), BotCenter(y2), their orientation Line90deg(y1), Line135deg(y2), their length Long(y1), Short(y2) and the fact that they intersect intersects(y1,y2). This rule is visualized in Fig. 13b.\n\nFor digit 2, the best correct rule query returned nine out of the 25 positives, three of which were missclassified by the classifier. This rule involved three lines, of which two had conjuncts indicating their location BotRight(y1), BotLeft(y3), BotCenter(y3), MidCenter(y3), only one line contained information about its orientation and size Line45deg(y3), Long(y3), and the only other information was that intersects(y2,y3). Note that for y2 the only available information was that it intersects y3. This query is difficult to visualize, due to the missing information about two of the three lines, however it is still useful as an explanation. Specifically, y3 represents a long diagonal line from the bottom left to the middle of the image, which is a characteristic of only the digits 2 and 7. Additionally, there is a line of any orientation in the bottom right of the image, which would differentiate it from a typical 7, and another line which intersects the long diagonal at any position. As is apparent also in the confusion matrix of the classifier on the explanation dataset (Fig. 11), the black-box often mixed up sevens with twos, and this explanation rule returns one of the sevens which is misclassified as a two, shown in Fig. 14d. This digit is not typically drawn, and from the rule query the information we get is that it might have been misclassified because of the existence of a line at the bottom right.\n\nTo investigate closer, the next correct rule which we analyze is that of highest recall for digit 7. This query returned only three of the 24 images which were classified as sevens, and all three were correct predictions by the classifier. The rule involved two intersecting lines (intersects(y1,y2)), of which the first is described as Line0deg(y1), Long(y1) TopLeft(y1), TopCenter(y1), TopRight(y1) which is clearly the characteristic top part of the digit, while the second line is described as Line45deg(y2)), BotCenter(y2), MidCenter(y2), MidRight(y2), Long(y2), which is the diagonal part of the digit. The description of the diagonal has a different description than the diagonal line which was part of the rule for digit 2. Instead of BotLeft(y), the rule contains a conjunct MidRight(y). This could be another hint as to why the 7 shown in Fig. 14d was not classified as correctly, as the digit appears to be leaning slightly to the right, which makes the diagonal pass through BotLeft, which is in the description of the diagonal for a digit 2 instead of MidRight which is for digit 7. To conclude if this is the case however would require investigating more rules, since the one presented covers only a subset of exemplars classified as digit 7.\n\nFor digit 3, the best correct explanation rule returned five of the 26 individuals which were classified as 3, including one misclassified 8. This rule involved seven different lines, thus it was not expected to be understandable by a user at a glance. However, there was plentiful information for each line in the rule, which made it possible to visualize. Specifically, regarding the location of the lines, the rule query contained the conjuncts TopCenter(y1), BotCenter(y2), BotCenter(y3), BotRight(y4), MidRight(y4), TopCenter(y5), MidCenter(y6), BotCenter(y7). Regarding orientation, five of the seven lines had relevant conjuncts: Line0deg(y2), Line45deg(y3), Line90deg(y4), Line135deg(y6), Line135deg(y7). Additionally, three lines had information about their size Short(y4), Short(y5), Medium(y6). Finally, the explanation rule contained conjuncts showing which lines intersect each other: intersects(y1,y5), intersects(y2,y3), intersects(y2,y7), intersects(y3,y4), intersects(y4,y6). This rule-query is visualized in Fig. 13c. An interesting aspect of this explanation, is that the two lines which are at the top center (y1 and y5) do not have a specified orientation, while the other four lines are involved in more conjuncts in the explanation rule query and are described in more detail. This could be an indication of the importance of these lines for a digit to be classified as a 3. However, these lines could also be a part of other digits such as 5, which is the next digit which we analyze.\n\nFor the digit 5, the best correct rule query returned four of the 31 positives for the class of which one is a misclassified 3. It is a very specific query involving seven lines, all of which are described regarding their orientation Line45deg(y1), Line135deg(y2), Line45deg(y3), Line0deg(y4), Line0deg(y5), Line135deg(y6), Line90deg(y7), and their location BotCenter(y1), BotLeft(y2), BotCenter(y2), MidCenter(y3), BotCenter(y4), TopRight(y5), TopCenter(y5), MidRight(y6), MidCenter(y6), MidRight(y7), BotRight(y7). There was no information about lines’ sizes, and there are five line intersections intersects(y1,y4), intersects(y1,y7), intersects(y2,y4), intersects(y3,y5), intersects(y6,y7). This query is visualized in Fig. 13e. An interesting aspect of this rule-query is the fact that it contains a misclassified 3 in its set of certain answers, specifically the three shown in Fig. 14c. In the context of the proposed framework, the 3 is misclassified because it obeys the correct rule for the digit 5. From comparing the visualization of the correct rule for the digit 5, and the misclassified 3, we can see that the digit obeys the rule because the top part of the three is vertically compressed, making it less distinguishable from a 5. This clearly shows us a potential flaw of the classifier.\n\nFor the digit 4, the best correct rule query returned five of the 22 positives all of which were correct predictions. The query involved three lines which were all well described regarding their orientation Line0deg(y1), Line45deg(y2), Line90deg(y3), and their location MidCenter(y1), MidCenter(y2), BotCenter(y3), MidCenter(y3), TopCenter(y3). Two lines were also described with respect to their size Medium(y1), Long(y3), and there were two intersections of lines intersects(y1,y2), intersects(y1,y3). This rule is visualized in Fig. 13d. This is a straight-forward description of the digit four, and as expected it covers only true positives.\n\nFor the digit 6, the best resulting correct rule involved the most variables (each representing a line) out of all correct rules. It returned four of the 18 positives for the class all of which were correct predictions. Of the eight lines described in the query, seven had information about their orientation Line0deg(y1), Line45deg(y2), Line45deg(y3), Line45deg(y4), Line90deg(y5), Line135deg(y7), Line135deg(y8). All lines were desribed with respect to their position BotCenter(y1), TopCenter(y2), MidCenter(y3), BotRight(y4), MidCenter(y5), MidRight(y6), MidRight(y7), BotCenter(y8), MidCenter(y8). Additionally four lines had a determined size Short(y1), Short(y6), Short(y7), Medium(y8), and there were five intersections of lines intersects(y1,y4), intersects(y1,y8), intersects(y2,y5), intersects(y5,y8), intersects(y6,y7). This rule is visualized in Fig. 13f, it is a straight-forward description of a digit 6.\n\nFor digit 8, the best correct rule query returned four of the 20 positives, all of which are classified correctly. It involved seven lines, of which five were described with respect to their orientation Line45deg(y2), Line90deg(y3), Line135deg(y5), Line45deg(y6), Line0deg(y7), six regarding their location MidCenter(y1), BotCenter(y2), BotCenter(y3), MidCenter(y3), BotCenter(y4), TopCenter(y6), TopCenter(y7), and five regarding their size: Medium(y1), Short(y3), Short(y4), Short(y5), Short(y7). Finally, the rule query involved four intersections of lines intersects(y1,y3), intersects(y2,y4), intersects(y5,y7), intersects(y6,y7). This rule is difficult to visualize due to the missing information (only four of the seven lines have information about both their location and orientation), and thus is not really useful as an explanation.\n\nFinally, the best correct rule query for digit 9 returned five of the 15 positives, of which all were correct predictions by the classifier. It involved six lines which were all thoroughly described regarding their orientation Line0deg(y1), Line0deg(y2), Line45deg(y3), Line90deg(y4), Line135deg(y5), Line135deg(y6), and their location TopCenter(y1), MidCenter(y2), TopCenter(y3), MidCenter(y3), MidLeft(y3), MidRight(y4), BotRight(y4), TopCenter(y5), MidRight(y5), MidLeft(y6). Additionally, two lines were described regarding their size Medium(y3), Short(y6). The query also contained three conjuncts which indicated intersections of lines intersects(y1,y3), intersects(y1,y5), intersects(y2,y6). This query is visualized in Fig. 13h, it is a straight-forward description of a digit 9."
    }
}