{
    "id": "dbpedia_8582_2",
    "rank": 31,
    "data": {
        "url": "https://github.com/microsoft/semantic-kernel",
        "read_more_link": "",
        "language": "en",
        "title": "edge LLM technology quickly and easily into your apps",
        "top_image": "https://repository-images.githubusercontent.com/607289185/402ae401-d650-438a-bc04-780afb58b560",
        "meta_img": "https://repository-images.githubusercontent.com/607289185/402ae401-d650-438a-bc04-780afb58b560",
        "images": [
            "https://camo.githubusercontent.com/eb5958246794100e79ab3022e067a9b1983e99dc5fb85fbeecaf20b78f54ddda/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f73656d616e7469632d6b65726e656c",
            "https://camo.githubusercontent.com/c554ea8fd8af469df78b3908c42399cfb9f63bf09f07ed6aa049acf1e2d31309/68747470733a2f2f696d672e736869656c64732e696f2f6e756765742f767072652f4d6963726f736f66742e53656d616e7469634b65726e656c",
            "https://github.com/microsoft/semantic-kernel/actions/workflows/dotnet-ci-docker.yml/badge.svg?branch=main",
            "https://github.com/microsoft/semantic-kernel/actions/workflows/dotnet-ci-windows.yml/badge.svg?branch=main",
            "https://github.com/microsoft/semantic-kernel/actions/workflows/java-build.yml/badge.svg?branch=java-development",
            "https://camo.githubusercontent.com/cd5265b7dfae001a18c4e1276acf9004886b3466cecf8a2c8857e2f7dfc3e941/68747470733a2f2f6d6176656e2d6261646765732e6865726f6b756170702e636f6d2f6d6176656e2d63656e7472616c2f636f6d2e6d6963726f736f66742e73656d616e7469632d6b65726e656c2f73656d616e7469636b65726e656c2d6170692f62616467652e737667",
            "https://camo.githubusercontent.com/739090be39360908e54f3f855af10fa8a368992da67772514767f2340ce63dc4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6963726f736f66742f73656d616e7469632d6b65726e656c",
            "https://camo.githubusercontent.com/8d3cbbec5b72e7dce145a1736c86762dd58ef88d56de9f221668ba3f4e520421/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313036333135323434313831393934323932323f6c6162656c3d446973636f7264266c6f676f3d646973636f7264266c6f676f436f6c6f723d776869746526636f6c6f723d643832363739",
            "https://camo.githubusercontent.com/92085c0b0d99eeb94d3dd6fc1d8052118bee6522297834a5347f8fe339907ccf/68747470733a2f2f6c6561726e2e6d6963726f736f66742e636f6d2f656e2d75732f73656d616e7469632d6b65726e656c2f6d656469612f656e74657270726973652d72656164792e706e67",
            "https://user-images.githubusercontent.com/371009/230673036-fad1e8e6-5d48-49b1-a9c1-6f9834e0d165.png",
            "https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg",
            "https://camo.githubusercontent.com/fedcb58d84245ac57f1243d82c8b86b69a1b539c9d4525509924e6ec73b2b19c/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f656e2f332f33302f4a6176615f70726f6772616d6d696e675f6c616e67756167655f6c6f676f2e737667",
            "https://camo.githubusercontent.com/28f772fb965e04befe0cd29eb5b939c68a7821a4dee8396bedf072b241276ebe/68747470733a2f2f6c6561726e2e6d6963726f736f66742e636f6d2f656e2d75732f73656d616e7469632d6b65726e656c2f6d656469612f646f746e65746d61702e706e67",
            "https://camo.githubusercontent.com/de4a22707eb75d31cf5680a7e6aeccdaaa407a1bf2723bf8c50b3e09e93ba261/68747470733a2f2f6c6561726e2e6d6963726f736f66742e636f6d2f656e2d75732f73656d616e7469632d6b65726e656c2f6d656469612f707974686f6e6d61702e706e67",
            "https://camo.githubusercontent.com/7fb4c43403f20fa119211279c52d458a587d00ab901b85f6b8f4d938e8c81fcb/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6d6963726f736f66742f73656d616e7469632d6b65726e656c",
            "https://avatars.githubusercontent.com/u/31255154?s=64&v=4",
            "https://avatars.githubusercontent.com/u/106823811?s=64&v=4",
            "https://avatars.githubusercontent.com/u/131770526?s=64&v=4",
            "https://avatars.githubusercontent.com/u/6844498?s=64&v=4",
            "https://avatars.githubusercontent.com/u/25789411?s=64&v=4",
            "https://avatars.githubusercontent.com/u/31520774?s=64&v=4",
            "https://avatars.githubusercontent.com/u/177327640?s=64&v=4",
            "https://avatars.githubusercontent.com/u/177327640?s=64&v=4",
            "https://avatars.githubusercontent.com/u/127216156?s=64&v=4",
            "https://avatars.githubusercontent.com/in/29110?s=64&v=4",
            "https://avatars.githubusercontent.com/u/36091529?s=64&v=4",
            "https://avatars.githubusercontent.com/u/13853051?s=64&v=4",
            "https://avatars.githubusercontent.com/u/35585003?s=64&v=4",
            "https://avatars.githubusercontent.com/u/2642209?s=64&v=4",
            "https://avatars.githubusercontent.com/u/19890735?s=64&v=4",
            "https://avatars.githubusercontent.com/u/1615532?s=64&v=4",
            "https://avatars.githubusercontent.com/u/13749212?s=64&v=4",
            "https://avatars.githubusercontent.com/u/68852919?s=64&v=4",
            "https://avatars.githubusercontent.com/u/35783676?s=64&v=4",
            "https://avatars.githubusercontent.com/u/371009?s=64&v=4",
            "https://avatars.githubusercontent.com/u/56417140?s=64&v=4",
            "https://avatars.githubusercontent.com/u/54643756?s=64&v=4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Integrate cutting-edge LLM technology quickly and easily into your apps - microsoft/semantic-kernel",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/microsoft/semantic-kernel",
        "text": "Python\n\n.NET\n\nJava\n\nSemantic Kernel is an SDK that integrates Large Language Models (LLMs) like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C#, Python, and Java. Semantic Kernel achieves this by allowing you to define plugins that can be chained together in just a few lines of code.\n\nWhat makes Semantic Kernel special, however, is its ability to automatically orchestrate plugins with AI. With Semantic Kernel planners, you can ask an LLM to generate a plan that achieves a user's unique goal. Afterwards, Semantic Kernel will execute the plan for the user.\n\nIt provides:\n\nabstractions for AI services (such as chat, text to images, audio to text, etc.) and memory stores\n\nimplementations of those abstractions for services from OpenAI, Azure OpenAI, Hugging Face, local models, and more, and for a multitude of vector databases, such as those from Chroma, Qdrant, Milvus, and Azure\n\na common representation for plugins, which can then be orchestrated automatically by AI\n\nthe ability to create such plugins from a multitude of sources, including from OpenAPI specifications, prompts, and arbitrary code written in the target language\n\nextensible support for prompt management and rendering, including built-in handling of common formats like Handlebars and Liquid\n\nand a wealth of functionality layered on top of these abstractions, such as filters for responsible AI, dependency injection integration, and more.\n\nSemantic Kernel is utilized by enterprises due to its flexibility, modularity and observability. Backed with security enhancing capabilities like telemetry support, and hooks and filters so youâ€™ll feel confident youâ€™re delivering responsible AI solutions at scale. Semantic Kernel was designed to be future proof, easily connecting your code to the latest AI models evolving with the technology as it advances. When new models are released, youâ€™ll simply swap them out without needing to rewrite your entire codebase.\n\nThe Semantic Kernel SDK is available in C#, Python, and Java. To get started, choose your preferred language below. See the Feature Matrix to see a breakdown of feature parity between our currently supported languages.\n\nThe quickest way to get started with the basics is to get an API key from either OpenAI or Azure OpenAI and to run one of the C#, Python, and Java console applications/scripts below.\n\nGo to the Quick start page here and follow the steps to dive in.\n\nAfter Installing the SDK, we advise you follow the steps and code detailed to write your first console app.\n\nGo to the Quick start page here and follow the steps to dive in.\n\nYou'll need to ensure that you toggle to C# in the the Choose a programming language table at the top of the page.\n\nThe Java code is in the semantic-kernel-java repository. See semantic-kernel-java build for instructions on how to build and run the Java code.\n\nPlease file Java Semantic Kernel specific issues in the semantic-kernel-java repository.\n\nThe fastest way to learn how to use Semantic Kernel is with our C# and Python Jupyter notebooks. These notebooks demonstrate how to use Semantic Kernel with code snippets that you can run with a push of a button.\n\nGetting Started with C# notebook\n\nGetting Started with Python notebook\n\nOnce you've finished the getting started notebooks, you can then check out the main walkthroughs on our Learn site. Each sample comes with a completed C# and Python project that you can run locally.\n\nðŸ“– Getting Started\n\nðŸ”Œ Detailed Samples\n\nðŸ’¡ Concepts\n\nFinally, refer to our API references for more details on the C# and Python APIs:\n\nC# API reference\n\nPython API reference\n\nJava API reference (coming soon)\n\nThe Semantic Kernel extension for Visual Studio Code makes it easy to design and test semantic functions. The extension provides an interface for designing semantic functions and allows you to test them with the push of a button with your existing models and data.\n\nWe welcome your contributions and suggestions to SK community! One of the easiest ways to participate is to engage in discussions in the GitHub repository. Bug reports and fixes are welcome!\n\nFor new features, components, or extensions, please open an issue and discuss with us before sending a PR. This is to avoid rejection as we might be taking the core in a different direction, but also to consider the impact on the larger ecosystem.\n\nTo learn more and get started:\n\nRead the documentation\n\nLearn how to contribute to the project\n\nAsk questions in the GitHub discussions\n\nAsk questions in the Discord community\n\nAttend regular office hours and SK community events\n\nFollow the team on our blog\n\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\n\nCopyright (c) Microsoft Corporation. All rights reserved."
    }
}