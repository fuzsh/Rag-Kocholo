{
    "id": "dbpedia_8582_2",
    "rank": 32,
    "data": {
        "url": "https://onnxruntime.ai/",
        "read_more_link": "",
        "language": "en",
        "title": "ONNX Runtime",
        "top_image": "https://i.ibb.co/0YBy62j/ORT-icon-for-light-bg.png",
        "meta_img": "https://i.ibb.co/0YBy62j/ORT-icon-for-light-bg.png",
        "images": [
            "https://onnxruntime.ai/_app/immutable/assets/huggingface-logo.9b20eb58.png",
            "https://onnxruntime.ai/_app/immutable/assets/amd-logo.42b6427e.png",
            "https://onnxruntime.ai/_app/immutable/assets/navitaire-amadeus-logo.a406b27e.png",
            "https://onnxruntime.ai/_app/immutable/assets/camo-logo.1ce61540.png",
            "https://onnxruntime.ai/_app/immutable/assets/nvidia.cc656ba1.png",
            "https://onnxruntime.ai/_app/immutable/assets/sas-logo.8ff5a381.png",
            "https://onnxruntime.ai/_app/immutable/assets/teradata-logo.b8cccc3f.png",
            "https://onnxruntime.ai/_app/immutable/assets/redis-logo.889eee37.png",
            "https://onnxruntime.ai/_app/immutable/assets/oracle-logo.210a5d89.png",
            "https://onnxruntime.ai/_app/immutable/assets/algoriddim-logo.3636b920.png",
            "https://onnxruntime.ai/_app/immutable/assets/Rockchip-logo.ccc73f1d.png",
            "https://onnxruntime.ai/_app/immutable/assets/pieces-logo.93c0e35d.png",
            "https://onnxruntime.ai/_app/immutable/assets/usda-logo.992ea4f5.png",
            "https://onnxruntime.ai/_app/immutable/assets/writer-logo.2a3ccac1.png",
            "https://onnxruntime.ai/_app/immutable/assets/ATLAS-logo.1fa0f849.png",
            "https://onnxruntime.ai/_app/immutable/assets/hypefactors-logo.bbbadacf.png",
            "https://onnxruntime.ai/_app/immutable/assets/antgroup-logo.42a0a801.png",
            "https://onnxruntime.ai/_app/immutable/assets/adobe-logo.1be16bb7.png",
            "https://onnxruntime.ai/_app/immutable/assets/infarm-logo.8b3b161e.png",
            "https://onnxruntime.ai/_app/immutable/assets/intelligenza-etica-logo.a1680dfd.png",
            "https://onnxruntime.ai/_app/immutable/assets/xilinx-logo.54981bb3.png",
            "https://onnxruntime.ai/_app/immutable/assets/clearblade-logo.adf78e67.png",
            "https://onnxruntime.ai/_app/immutable/assets/ue-logo.256899fd.png",
            "https://onnxruntime.ai/_app/immutable/assets/PeakSpeed_logo.db9c1276.png",
            "https://onnxruntime.ai/_app/immutable/assets/bazaarvoice-logo.3d8d2a40.png",
            "https://onnxruntime.ai/_app/immutable/assets/deezer-logo.4f2b9f27.png",
            "https://onnxruntime.ai/_app/immutable/assets/cephable-logo.fe82d157.png",
            "https://onnxruntime.ai/_app/immutable/assets/topazlabs-logo.f736b149.png",
            "https://onnxruntime.ai/_app/immutable/assets/vespa-logo.cf450f3d.png",
            "https://onnxruntime.ai/_app/immutable/assets/intel-logo.d3216f76.png",
            "https://onnxruntime.ai/_app/immutable/assets/PyTorch_logo_black.219eacce.svg",
            "https://onnxruntime.ai/_app/immutable/assets/Windows_logo_and_wordmark.639973d0.svg",
            "https://onnxruntime.ai/_app/immutable/assets/hf-logo-with-title.fc95837e.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "onnx runtime",
            "onnx",
            "onnxruntime",
            "onnx runtime performance",
            "onnx runtime training",
            "onnx runtime inference",
            "onnx runtime cross-platform",
            "onnx runtime cross platform",
            "onnx runtime crossplatform",
            "onnx runtime training and inference",
            "onnx runtime training & inference",
            "onnx runtime training inference",
            "onnx runtime training",
            "onnx runtime inference",
            "onnx runtime cross-platform",
            "onnx runtime cross platform",
            "onnx runtime crossplatform",
            "onnx runtime training and inference",
            "onnx runtime training & inference",
            "onnx runtime training inference"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Cross-platform accelerated machine learning. Built-in optimizations speed up training and inferencing with your existing technology stack.",
        "meta_lang": "en",
        "meta_favicon": "./favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://onnxruntime.ai/",
        "text": "Python\n\nC#\n\nJS\n\nJava\n\nC++\n\nimport onnxruntime as ort model_path = \"path/to/your/onnx/model\" session = ort.InferenceSession(model_path) ... outputs = session.run(None, {\"input\": inputTensor}) print(outputs)\n\nGenerative AI\n\nIntegrate the power of Generative AI and Large language Models (LLMs) in your apps and services with ONNX Runtime. No matter what language you develop in or what platform you need to run on, you can make use of state-of-the-art models for image synthesis, text generation, and more.\n\nLearn more about ONNX Runtime & Generative AI â†’\n\nCross-Platform\n\nDo you program in Python? C#? C++? Java? JavaScript? Rust? No problem. ONNX Runtime has you covered with support for many languages. And it runs on Linux, Windows, Mac, iOS, Android, and even in web browsers.\n\nPerformance\n\nCPU, GPU, NPU - no matter what hardware you run on, ONNX Runtime optimizes for latency, throughput, memory utilization, and binary size. In addition to excellent out-of-the-box performance for common usage patterns, additional model optimization techniques and runtime configurations are available to further improve performance for specific use cases and models."
    }
}