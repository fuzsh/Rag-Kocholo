{
    "id": "correct_foundationPlace_00012_0",
    "rank": 68,
    "data": {
        "url": "https://www.mdpi.com/1424-8220/18/11/3928",
        "read_more_link": "",
        "language": "en",
        "title": "Performance Analysis of NDT-based Graph SLAM for Autonomous Vehicle in Diverse Typical Driving Scenarios of Hong Kong",
        "top_image": "https://pub.mdpi-res.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g001-550.jpg?1570696719",
        "meta_img": "https://pub.mdpi-res.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g001-550.jpg?1570696719",
        "images": [
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1721387811",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1721387811",
            "https://pub.mdpi-res.com/img/journals/sensors-logo.png?8600e93ff98dbf14",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1721387811",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1721387811",
            "https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A1-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A1.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A2-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A2.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A3-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A3.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A4-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g0A4.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g001-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g001.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g002-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g002.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g003-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g003.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g004-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g004.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g005-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g005.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g006-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g006.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g007-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g007.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g008-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g008.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g009-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g009.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g010-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g010.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g011-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g011.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g012-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g012.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g013-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g013.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g014-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g014.png",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g015-550.jpg",
            "https://www.mdpi.com/sensors/sensors-18-03928/article_deploy/html/images/sensors-18-03928-g015.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://www.mdpi.com/img/table.png",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-white-small.png?71d18e5f805839ab?1721387811"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Weisong Wen",
            "Li-Ta Hsu",
            "Guohao Zhang",
            "Li-Ta"
        ],
        "publish_date": "2018-11-14T00:00:00",
        "summary": "",
        "meta_description": "Robust and lane-level positioning is essential for autonomous vehicles. As an irreplaceable sensor, Light detection and ranging (LiDAR) can provide continuous and high-frequency pose estimation by means of mapping, on condition that enough environment features are available. The error of mapping can accumulate over time. Therefore, LiDAR is usually integrated with other sensors. In diverse urban scenarios, the environment feature availability relies heavily on the traffic (moving and static objects) and the degree of urbanization. Common LiDAR-based simultaneous localization and mapping (SLAM) demonstrations tend to be studied in light traffic and less urbanized area. However, its performance can be severely challenged in deep urbanized cities, such as Hong Kong, Tokyo, and New York with dense traffic and tall buildings. This paper proposes to analyze the performance of standalone NDT-based graph SLAM and its reliability estimation in diverse urban scenarios to further evaluate the relationship between the performance of LiDAR-based SLAM and scenario conditions. The normal distribution transform (NDT) is employed to calculate the transformation between frames of point clouds. Then, the LiDAR odometry is performed based on the calculated continuous transformation. The state-of-the-art graph-based optimization is used to integrate the LiDAR odometry measurements to implement optimization. The 3D building models are generated and the definition of the degree of urbanization based on Skyplot is proposed. Experiments are implemented in different scenarios with different degrees of urbanization and traffic conditions. The results show that the performance of the LiDAR-based SLAM using NDT is strongly related to the traffic condition and degree of urbanization. The best performance is achieved in the sparse area with normal traffic and the worse performance is obtained in dense urban area with 3D positioning error (summation of horizontal and vertical) gradients of 0.024 m/s and 0.189 m/s, respectively. The analyzed results can be a comprehensive benchmark for evaluating the performance of standalone NDT-based graph SLAM in diverse scenarios which is significant for multi-sensor fusion of autonomous vehicle.",
        "meta_lang": "en",
        "meta_favicon": "https://pub.mdpi-res.com/img/mask-icon-128.svg?c1c7eca266cd7013?1721387811",
        "meta_site_name": "MDPI",
        "canonical_link": "https://www.mdpi.com/1424-8220/18/11/3928",
        "text": "1\n\nDepartment of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong, China\n\n2\n\nInterdisciplinary Division of Aeronautical and Aviation Engineering, The Hong Kong Polytechnic University, Hong Kong, China\n\n*\n\nAuthor to whom correspondence should be addressed.\n\nSensors 2018, 18(11), 3928; https://doi.org/10.3390/s18113928\n\nSubmission received: 26 September 2018 / Revised: 1 November 2018 / Accepted: 7 November 2018 / Published: 14 November 2018\n\n(This article belongs to the Special Issue Sensors Applications in Intelligent Vehicle)\n\nAbstract\n\n:\n\nRobust and lane-level positioning is essential for autonomous vehicles. As an irreplaceable sensor, Light detection and ranging (LiDAR) can provide continuous and high-frequency pose estimation by means of mapping, on condition that enough environment features are available. The error of mapping can accumulate over time. Therefore, LiDAR is usually integrated with other sensors. In diverse urban scenarios, the environment feature availability relies heavily on the traffic (moving and static objects) and the degree of urbanization. Common LiDAR-based simultaneous localization and mapping (SLAM) demonstrations tend to be studied in light traffic and less urbanized area. However, its performance can be severely challenged in deep urbanized cities, such as Hong Kong, Tokyo, and New York with dense traffic and tall buildings. This paper proposes to analyze the performance of standalone NDT-based graph SLAM and its reliability estimation in diverse urban scenarios to further evaluate the relationship between the performance of LiDAR-based SLAM and scenario conditions. The normal distribution transform (NDT) is employed to calculate the transformation between frames of point clouds. Then, the LiDAR odometry is performed based on the calculated continuous transformation. The state-of-the-art graph-based optimization is used to integrate the LiDAR odometry measurements to implement optimization. The 3D building models are generated and the definition of the degree of urbanization based on Skyplot is proposed. Experiments are implemented in different scenarios with different degrees of urbanization and traffic conditions. The results show that the performance of the LiDAR-based SLAM using NDT is strongly related to the traffic condition and degree of urbanization. The best performance is achieved in the sparse area with normal traffic and the worse performance is obtained in dense urban area with 3D positioning error (summation of horizontal and vertical) gradients of 0.024 m/s and 0.189 m/s, respectively. The analyzed results can be a comprehensive benchmark for evaluating the performance of standalone NDT-based graph SLAM in diverse scenarios which is significant for multi-sensor fusion of autonomous vehicle.\n\n1. Introduction\n\nThe autonomous vehicle [1,2] is well believed to be the next revolutionary technology changing people’s lives in many ways. For fully autonomous vehicles, localization is one of the key parts because accurate and robust positioning is the basics of further perception and path planning missions for autonomous driving. The most promising solution to provide globally referenced positioning is sensor integration of global navigation satellites system (GNSS), light detection and ranging (LiDAR), inertial measurement unit (IMU) and high definition map (HD map). Currently, this solution can provide satisfactory performance in suburban areas [3,4,5,6,7,8,9]. However, the performance of the integration solution can be severely challenged in the deep urbanized area, such as Hong Kong, Tokyo, and New York. Firstly, the accuracy of GNSS positioning can be decreased to 50 m [10,11], due to the blockage, reflection, and diffraction from buildings and moving objects. Moreover, the uncertainty of GNSS positioning, which is significant for sensor fusion, is difficult to model. The IMU can drift over time due to the dense traffic congestions. The matching between the real-time point clouds from LiDAR and offline point clouds from HD Map can also be challenged due to the excessive moving objects, changeable city structures, and environment feature availability. Simultaneous localization and mapping (SLAM) [12,13] is a significant method to provide positioning service based on mapping of point clouds. The accuracy of SLAM-based positioning relies heavily on the mapping between point clouds. In other words, the performance of SLAM is strongly related to the environment. Thus, this paper proposes to evaluate the performance of NDT-based graph SLAM in diverse urban scenarios to further study the relationship, between the performance of SLAM and environment conditions.\n\nNumerous studies [13,14,15,16,17,18] are conducted in the past decades on the LiDAR-based SLAM. The main principle of LiDAR-based SLAM is to continuously track the transformation between successive frames of point clouds. In this case, the performance of SLAM relies heavily on the accuracy of the mapping-based transformation. The LiDAR odometry and mapping (LOAM) [18] can obtain low drift positioning when satisfactory environment features are available, such as the planes and edges. However, the performance of this algorithm can be severely degraded in dense urban areas, due to the excessive moving objects. On one hand, the positioning accuracy cannot be guaranteed with too much dynamic plane features from traffic. On the other hand, the LOAM algorithm did not propose an effective method to model the uncertainty of LiDAR-based positioning. The submap concept is proposed in [13] and the real-time loop closure detection is achieved. However, the uncertainty is not well modeled, and the performance of this algorithm relies heavily on the additional sensors, such as the IMU. The mapping solution, normal distribution transform (NDT), based on the normal distribution transform is proposed in [19]. This method innovatively employs the normal distribution transform to transfer the mapping process into probabilistic continuous functions. However, this method also cannot effectively model the positioning uncertainty caused by moving objects. According to the previous research, the uncertainty caused by the moving objects are not well modeled [20]. To reduce the drift of LiDAR-based positioning, the loop closure detection [14] algorithm is proposed to mitigate the global positioning error. The main idea for loop detection is to identify the two similar poses that the vehicle has gone through. Then, the overall correction of the poses is obtained based on the loop closure to improve accuracy. However, the loop closure is subjected to the availability of closed loop.\n\nBoth the LOAM and the NDT can be used to calculate the transformation between the consecutive frames of point clouds. The LiDAR odometry can be obtained by tracking the continuous transformations. To integrate the LiDAR odometry and other sensors, a sensor fusion framework is needed. Based on the principle of the sensor integration, the sensor integration methods can be divided into two groups, the filtering-based and the smoothing-based integration. The symbolic filtering-based sensor integration method is the Bayes filter, including Kalman filter [21,22], information filter [16,23,24] and particle filter [17,25,26]. The Bayes filter-based sensor integration estimates the current state only based on current observation and the previous state estimation, abandoning all the states before the previous states [27]. This is because of the assumption of the first order of the Markov model which is one of the key assumptions of the Bayes filter. Conversely, the smoothing approaches [28,29,30,31] estimate the pose and map by considering the full sets of measurements between the first epoch and the current epoch. The most well-known smoothing method is the graph-based SLAM [12]. However, no matter which mapping method is chosen, the accuracy of LiDAR-based positioning is significant for final sensor integration.\n\nOur team aims to develop autonomous driving vehicles to facilitate the next generation of the intelligent transportation system of Hong Kong. An accurate and robust localization service is the basis. This paper extensively analyzes the performance of NDT-based graph SLAM in diverse urban scenarios. This paper firstly employs the NDT to calculate the transformation between two consecutive frames. Then, graph optimization is used to optimize all the LiDAR odometry measurements from the first epoch to current epoch. Moreover, this paper estimates the uncertainty of the LiDAR odometry in terms of the degree of matching, number of iterations and time used for NDT optimization. This covariance estimation solution is available in the point cloud library (PCL).\n\nThe main contributions of this paper are listed as follows:\n\n(1)\n\nThis paper proposes to generate the 3D building models of the tested area to define the degree of urbanization of the given scenario. The Skyplot is generated as an indicator of the degree of urbanization and the corresponding definition is presented. The classification criteria of different urban scenarios are proposed using Skyplot features.\n\n(2)\n\nThe multi-sensor integrated localization solution [7,8] tend to evaluate the performance in sparse scenarios with friendly traffic. This paper evaluates the performance of NDT-based graph SLAM in diverse urban scenarios, with different traffic conditions and degree of urbanization.\n\n(3)\n\nThis paper qualitatively analyzes the relationship between the performance of NDT-based graph SLAM and the traffic conditions and degree of urbanization. The evaluated results related to the traffic and performance of LiDAR-based positioning can be a useful basic work for further mitigating the effects of traffic and urbanization to improve the performance of LiDAR-based positioning.\n\nThe rest of the paper is structured as follows. The transformation calculation based on LiDAR is presented in Section 2. The graph-based SLAM is introduced in Section 3 before the experiment evaluation is given in Section 4. Finally, the conclusion and future work are presented in Section 5.\n\n2. The Transformation from LiDAR-based Mapping\n\n2.1. Transformation Calculation\n\nThe principle of LiDAR odometry [18] is to track the transformation between two successive frames of point clouds by matching the two frames of point clouds called reference point cloud and input point cloud in this paper. The matching process is also called point cloud registration. The objective of point cloud registration is to obtain the optimal transformation matrix to match or align the reference and the input point clouds. The most well-known and conventional method of point cloud registration is the iterative closest point (ICP) [32] method. The ICP is a straightforward method to calculate the transformation between two consecutive scans by iteratively searching pairs of nearby points in the two scans and minimizing the sum of all point-to-point distances. The objective function can be expressed as follow [33]:\n\nC ( R ^ , T ^ ) = arg min ∑ i = 1 N | | ( R p i + T ) − q i | | 2\n\n(1)\n\nwhere the N indicates the number of points in one scan. R and T indicates the rotation and translation matrix respectively, to transform the input point cloud ( p i ) into the reference point cloud ( q i ). Objective function C ( R ^ , T ^ ) indicates the transformation error.\n\nThe NDT, modeling the points based on Gaussian distribution, is another method to align two consecutive scans. The NDT innovatively divides the point cloud space into cells and each cell is continuously modeled by a Gaussian distribution. In this case, the discrete point clouds are transformed into successive continuous functions. In this paper, the NDT is chosen as the point cloud registration method for LiDAR odometry. Assuming that the transformation between two consecutive frames of point clouds can be expressed as M = [ T x T y T z R x R y R z ] T . The process of calculating the relative pose between the reference and the input point clouds is listed as follows:\n\n(1)\n\nNormal distribution transform: fetch all the points x i = 1 … n cotained in 3D the cell.\n\nCalculate the mean among all the points, q = 1 n ∑ i x i .\n\nCalculate the covariance matrix μ ,\n\nμ = 1 n ∑ i ( x i − q ) ( x i − q ) T\n\n(2)\n\n(2)\n\nThe matching score is modeled as:\n\nf ( p ) = − score ( p ) = ∑ i exp ( − ( x i ′ − q i ) T μ i − 1 ( x i ′ − q i ) 2 )\n\n(3)\n\nwhere x i indicates the points in the current frame of the scan. x i ′ denotes the point in the previous scan mapped from the current frame using the M . q i and μ i indicate the mean and the covariance of the corresponding normal distribution to point x i ′ in the NDT of the previous scan.\n\n(3)\n\nUpdate the pose using the Quasi-Newton method using the objective function to minimize the score f ( p ) .\n\n(4)\n\nRepeat the steps (2) and (3) until the convergence is achieved.\n\nWith all the points in one frame of point clouds being modeled as cells, the objective of the optimization for NDT is to match current cells into the previous cells with the highest probability. The optimization function f ( p ) can be found in [15]. For each cell containing several points, the corresponding covariance matrix can be calculated and represented by Σ . The shape (circle, plane or linear) of the cell is indicated by the relations between the three eigenvalues of the covariance matrix.\n\n2.2. Uncertainty Estimation of Transformation\n\nAs the transformation calculation is not always accurate, the uncertainty is a significant parameter to model the possible error range of the transformation. The uncertainty is modeled as the covariance. The associated covariance is significant for further sensor integration. During the NDT process, the covariance of the transformation calculation is related to the environment condition and the similarity between the consecutive frames of point clouds. In the graph-based optimization which will be presented in Section 3, the covariance is indicated as the inverse of the information matrix Ω ij . This means the weight of constraint between node i and j.\n\nIn this paper, we propose to use the method in [34] to calculate the covariance of transformation calculation based on the following three items:\n\n(1)\n\nThe degree of matching between the two consecutive frames of point clouds.\n\n(2)\n\nThe used time to complete the transformation calculation.\n\n(3)\n\nThe iteration number used to make the Quasi-Newton method converge.\n\nFor each matching process between reference point cloud i and input point cloud j, we model the degree of matching as:\n\nU d e l t a , i j = 1 n ∑ k = 1 n ( x d e l t a , k ) 2 + ( y d e l t a , k ) 2 + ( z d e l t a , k ) 2\n\n(4)\n\nwhere the U d e l t a , i j represents the degree of matching between the input and the reference point clouds. n represents the number of the points in input point cloud. x d e l t a , k indicates the positional difference in x axis between an input point and a reference point after the convergence of NDT is obtained. y d e l t a , k and z d e l t a , k indicate the positional differences in x and y axis respectively. If the time used to make the NDT converge is t c , the uncertainty related to the time is denoted as:\n\nU t , i j = C t t c\n\n(5)\n\nwhere the C t is the coefficient and is heuristically determined. If the iterations number used to make the NDT converge is N c , the uncertainty related to N c is represented as:\n\nU N , i j = C N N c\n\n(6)\n\nwhere the C N is the coefficient and is heuristically determined. Thus, for each match between a reference point cloud and an input point cloud, the total uncertainty of the transformation calculation is denoted as U i j :\n\nU i j = U d e l t a , i j + U t , i j + U N , i j\n\n(7)\n\nthe information matrix Ω i j can be expressed as:\n\nΩ i j = [ Ω i j p 0 0 Ω i j r ]\n\n(8)\n\nΩ i j p = I / ( C p 2 U i j )\n\n(9)\n\nΩ i j r = I / ( C r 2 U i j )\n\n(10)\n\nwhere I is a unit matrix, C p 2 and C r 2 are heuristically determined coefficients for adjusting the covariance of translation and rotation, respectively. In this case, the covariance of the transformation calculation is correlated with the degree of matching, time used for the NDT convergence and times of iteration.\n\n3. Graph-based SLAM\n\nThis section presents the graph optimization. Pose graph optimization is to construct all the measurements into a graph as constraints and calculate the best set of poses by solving a non-linear optimization problem [12]. In this paper, the constraints are provided by the continuous LiDAR odometry. To implement the graph-based integration optimization, two steps are needed, the graph generation and graph optimization.\n\n3.1. Graph Generation\n\nThe graph consists of edges and vertices [12]. As shown in Figure 1, edges are indicated by observation measurements from the LiDAR odometry. The x i represents pose estimation that include the position and orientation; e i j indicates the error function evaluating the difference between the estimated state and the observed pose measurements; z i j represents the observation and the z ^ i j indicates the expected observation. The blue circles and lines represent the nodes and edges, respectively, which are provided by LiDAR odometry.\n\n3.2. Graph Optimization\n\nThe graph optimization takes all the constraints into a non-linear optimization problem. The main feature of the graph-based optimization is that all the observation measurements are considered. The optimization form is shown following [35]:\n\nF ( x ) = ∑ i , j e ( x i , x j , z ^ i j ) T Ω i j e ( x i , x j , z ^ i j )\n\n(11)\n\nwhere F ( x ) is the optimization function which is the sum of errors of all edges. The Ω i j is the information matrix indicating the importance of each constraint in the global graph optimization. The information matrix is the inverse of the covariance matrix estimated in Section 2. The final solution of this optimization is the x * which satisfied the following function:\n\nx * = argmin F ( x )\n\n(12)\n\nThus, the optimization lies in solving the equation above to obtain the optimal x * . We can see from the optimization form F ( x ) , the covariance of the measurements from LiDAR odometry is represented by the information matrix Ω i j . If the covariance of each measurement is not properly solved, the global optimization will be deflected resulting in the erroneous final pose sets. In other words, the covariance is significant for the performance of the graph optimization.\n\n4. Experimental Evaluation\n\nTo evaluate the performance of NDT-based graph SLAM in diverse urban scenarios, experiments are conducted in three different scenarios with different traffic conditions. The environment features of three scenes are shown as following:\n\n(1)\n\nSparse area: (a) Sparse area with normal traffic. (b) The sparse area with dense traffic.\n\n(2)\n\nSub-urban area: (a) Sub-urban area with normal traffic. (b) The sub-urban area with dense traffic. (presented in the Appendix A)\n\n(3)\n\nDense urban area: (a) Dense urban area with normal traffic. (b) The dense urban area with dense traffic.\n\nDefinition 1.\n\nThe degree of urbanization: The level of urbanization increases from scenes (1) to (3). There is almost no effective and existing way to model the degree of urbanization regarding to the autonomous vehicle. The degree of urbanization is extensively discussed in the GNSS field, as buildings [36,37] and moving objects [20] can have significant effects on the accuracy of GNSS solutions. The Skyplot [38] is employed to represent satellite visibility (LOS: line-of-sight, NLOS: non-line-of-sight) by project both the 3D building models and satellites into the Skyplot coordinate system. Inspired by this, we propose to use the mean mask elevation angle of a Skyplot as an indicator of urbanization. As the building model information are available in Google Maps for research purpose, we construct the 3D building models of the experiment scene shown in Figure 2.\n\nFor a dense urban scenario, the 3D building models generated in a street are shown on the left side in Figure 3, assuming the vehicle is at the position shown in Figure 3 with 3D LiDAR sensor being installed on the top. By connecting a line from the vehicle and building roof, we can denote the mask elevation angle and azimuth angle as α and θ , respectively. Assume that at an azimuth angle θ i , the distance between the vehicle and the building is W and building height is H, we can calculate the corresponding elevation angle α i as:\n\nα i = atan ( H W )\n\n(13)\n\nBy traversing all the azimuth angles from 0 ° to 360 ° with an angular resolution of 1 ° , we can obtain the Skyplot [38] (shown in the right side of Figure 3) regarding the given vehicle position. The inner circle indicates a different elevation angle. The “N” means north. The shaded area means blockage from buildings. Taller buildings cause more blockage, which introduces a higher degree of urbanization.\n\nTherefore, we propose to calculate the mean elevation mask angle as a quantitative indicator of the degree of urbanization of the given scenario as follows:\n\nℶ u r b a n = ∑ i = 1 360 α i / 360\n\n(14)\n\nIn this case, the degree of urbanization of a given scenario is represented by ℶ u r b a n . The ℶ u r b a n for the scenario shown in Figure 3 is 55.32 ° . We propose to define the degree of urbanization using the rules in Table 1. Therefore, the ℶ u r b a n for the scenario in Figure 3 satisfies the dense urban area condition.\n\nDefinition 2.\n\nTraffic conditions: We define that the normal traffic means the common traffic condition density in urban areas with approximately 2–5 vehicles surrounding the ego-vehicle (shown in the left of Figure 4). The dense traffic indicates that there are numerous moving objects on the roads. For example, in rush hours with approximately 8–12 vehicles surrounding the ego-vehicle (shown in the right of Figure 4).\n\n4.1. Experimental Setup\n\nA 3D LiDAR sensor, Velodyne 32, is employed to provide the real-time point clouds scanned from the surroundings. 3D LiDAR is installed on the top of a vehicle during the experiment which can be seen in Figure 5. The LiDAR coordinate system is shown in Figure 5 with the x-axis pointing to the back of the vehicle. The integrated navigation system (NovAtel SPAN-CPT, RTK/INS integrated navigation system with fiber optics gyroscopes) based on local ENU [39] coordinate system is used to provide ground truth. The coordinate system of LiDAR and SPAN-CPT is calibrated at the beginning of the tests.\n\nThe evaluated items in the following experiments include the positioning error of NDT-based graph SLAM and reliability estimation error. Regarding the total positioning error ∈ S L A M , it is calculated by:\n\n∈ S L A M = ( ( E s l a m e − E G T e ) 2 + ( N s l a m n − N G T n ) 2 + ( U s l a m u − U G T u ) 2 )\n\n(15)\n\nwhere E s l a m e , N s l a m n and U s l a m u denote the estimated position in east, north and upward axes of ENU coordinate system. The E G T e , E G T n and E G T u denote the ground truth (by GNSS RTK/INS integrated system) in east, north and upward axes of ENU coordinate system. Assuming that the heading angle of vehicle relative to north of the earth is denoted as R U in radian, then the positioning error ∈ S L A M l o n g i t u d i n a l of a vehicle in longitudinal direction can be calculated by projecting ∈ S L A M into the direction of heading ( R U ). Similarly, the error in the lateral direction can also be calculated by projecting ∈ S L A M into the direction normal to heading direction ( R U ).\n\nThe reliability is calculated as C p U i j . The ground truth for reliability estimation is the actual total positioning error ∈ S L A M . The objective of reliability estimation is to obtain a smallest circle that can cover ∈ S L A M to represent the uncertainty of a given positioning result.\n\n4.2. Experiment in Sparse Area\n\n4.2.1. Experiment 1: Performance Evaluation of NDT-based Graph SLAM in Sparse Area with Normal Traffic\n\nIn this experiment, the scenario is shown in the top panel of Figure 6. The overall drive of a vehicle lasts about 395 s in a sparse area with normal traffic. The height of the surrounding buildings is about 5–10 m high and the width of the streets is approximately 16 m. The ℶ u r b a n for the scenario shown in Figure 6 is about 6 ° – 10 ° satisfying the sparse area condition.\n\nWe can see from the bottom panel of Figure 6, the positioning result of SLAM can well track the ground truth at the beginning of the test. However, due to the accumulated error over time, the SLAM-based trajectory drifts away from the ground truth. The detailed positioning error during the experiment is shown in Figure 7. The top panel shows the positioning error in three different directions. The lateral direction is normal to the driving direction of the vehicle with the longitudinal direction parallel with the driving direction. The bottom panel indicates the reliability estimation. The reliability shown in the bottom panel is calculated based on C p U i j presented in Section 2. We can see that the 3D positioning error ( ∈ S L A M ) almost increases over time with the final positioning error reaching almost 10 m. The estimated reliability can track the 3D positioning error at the very beginning of the test. The estimated reliability tends to fluctuate between 7 m over time in this experimental scenario.\n\nTable 2 shows the mean error and standard deviation of positioning error in three separate directions; 3.44 m of mean error in the lateral direction is obtained with a standard deviation of 1.88 m. The mean positioning error in the longitudinal direction is 3.19 m. Moreover, the mean positioning error in altitude direction is just 3.05 m with a standard deviation of 1.02 m. The mean of 2D (sum of lateral and longitudinal direction) positioning error is 6.64 m which are slightly smaller than the 3D positioning error (9.69 m). As the positioning error accumulates over time using standalone NDT-based graph SLAM, we propose to use the gradient of accumulated error to evaluate the performance of SLAM. The 2D gradient indicates the rate of change of 2D mean positioning error and is obtained with total 2D mean error divided by total epochs. Similarly, the 3D gradient indicates the rate of change of 3D positioning error. The 2D gradient is 0.017, which means that the accumulated error of SLAM increased by meters per second. The 3D positioning error gradient is 0.024 m per second.\n\nRegarding the reliability estimation result (blue dots in the bottom panel of Figure 7), we can find that the C p U i j overestimates the 3D positioning error in the majority of the situations. Moreover, the estimated reliability fluctuates dramatically during the test (from 0 to 15 m).\n\n4.2.2. Experiment 2: Performance Evaluation of NDT-based Graph SLAM in Sparse Area with Dense Traffic\n\nIn this experiment, the scenario is shown in the top panel of Figure 8. The overall drive of the vehicle lasts about 400 s in a sparse area with dense traffic. The height of the surrounding buildings is about 5–10 m high and the width of the streets is approximately 16 m which are similar to experiment 1.\n\nWe can see from the bottom panel of Figure 8, that the positioning result of SLAM can track the ground truth at the beginning of the test. However, due to the accumulated error over time, the SLAM-based trajectory is drifting away from the ground truth. The positioning error during the experiment is shown in Figure 9. We can see that the 3D positioning error increases over time with the final positioning error reaching about 19 m. The estimated reliability can track the 3D positioning error at the very beginning of the test. However, the difference between the estimated reliability of SLAM and the 3D positioning error increases over time. The estimated reliability tends to fluctuate in the vicinity of 5 m over time during the experiment.\n\nTable 3 shows the mean and standard deviation of positioning error in three separate directions; 6.31 m of mean error in the lateral direction is obtained with a standard deviation of 5.26 m. The mean positioning error in the longitudinal direction is 4.91 m. Interestingly, the mean positioning error in altitude direction is just 0.77 m with a standard deviation of 0.84 m. The mean of 2D (sum of lateral and longitudinal directions) positioning error is 11.21 m which are slightly smaller than the 3D positioning error (11.99 m). The 2D gradient is 0.028, which means that the accumulated error of SLAM increased by meters per second. The 3D positioning error gradient is 0.03 m per second.\n\nRegarding the reliability estimation result (blue dots in the bottom panel of Figure 9), we can find that the estimated reliability is even worse than that in experiment 1. From epoch 100 to 400, the actual 3D positioning error is larger than the estimated (reliability). The estimated mean reliability is 5.93 m which are smaller than its ground truth (11.99 m).\n\nThe main reason for this is due to the increased traffic density, compared with experiment 1. According to [40], the dynamic objects from traffic can cause increased uncertainty in LiDAR-based positioning. The evaluated reliability estimation method [34] cannot model the uncertainty caused by dynamic objects. These experimental results show that traffic has a negative effect on the performance of NDT-based graph SLAM.\n\n4.3. Experiment in Dense Urban Area\n\n4.3.1. Experiment 3: Performance Evaluation of NDT-based Graph SLAM in Dense Urban Area with Normal Traffic\n\nIn this experiment, the scenario is shown in the top panel of Figure 10. The overall drive of vehicle lasts about 124 s in dense urban areas with normal traffic. The height of the surrounding buildings is about 59–105 m high and the width of the streets is approximately 16–20 m. The ℶ u r b a n for the scenario shown in Figure 10 is about 50 ° – 63 ° satisfying the dense urban area condition.\n\nWe can see from the bottom panel of Figure 11, the positioning result of SLAM can well track the ground truth at the beginning of the test. However, due to the accumulated error over time, the SLAM-based trajectory is drifting away from the ground truth. The positioning error during the experiment is shown in Figure 11. We can find that the main trend in positioning error is that the positioning error ∈ S L A M increased over time. The 3D positioning error increases over time with the final positioning error reaching about 28 m. The estimated reliability can track the 3D positioning error at the very beginning of the test. However, the difference between the estimated reliability of SLAM and the 3D positioning error increases over time. The estimated reliability tends to fluctuate between 10 and 60 m over time during the experiment.\n\nTable 4 shows the mean and standard deviation of positioning error in three separate directions; 6.73 m of mean error in the lateral direction is obtained with a standard deviation of 4.39 m. The mean positioning error in the longitudinal direction is 4.81 m. Interestingly, the mean positioning error in altitude direction is just 11.90 m which are significantly larger than the other two directions. The mean of 2D (sum of lateral and longitudinal directions) positioning error is 11.54 m with the 3D positioning error reaching 14.85 m. The 2D gradient is 0.094 and the value for the 3D gradient is 0.121.\n\nRegarding the reliability estimation result (blue dots in the bottom panel of Figure 11), from epoch 0 to 60, the actual 3D positioning error is smaller than the estimated (reliability). The estimated mean reliability is 18.90 m which are significantly larger than its ground truth (14.85 m).\n\nBy comparing this with the experiments conducted in the sparse area, the mean 3D gradient of 3D positioning error in dense urban (0.121 m/s) is significantly larger than that in the sparse area (0.024 m/s in normal traffic and 0.03 in normal traffic). These results show that the degree of urbanization has also an impact on the performance of NDT-based graph SLAM.\n\n4.3.2. Experiment 4: Performance Evaluation of NDT-based Graph SLAM in Dense Urban Area with Dense Traffic\n\nIn this experiment, the scenario is shown in the top panel of Figure 12. The overall drive of vehicle lasts about 124 s in dense urban with dense traffic. The height of the surrounding buildings is about 50–175 m high and the width of the streets is approximately 16–20 m. The ℶ u r b a n for the scenario shown in Figure 10 is about 50 ° – 67 ° satisfying the dense urban area condition.\n\nWe can see from the bottom panel of Figure 13, that the positioning result of SLAM can well track the ground truth at the beginning of the test. However, due to the accumulated error over time, the SLAM-based trajectory is drifting away from the ground truth. The positioning error ( ∈ S L A M ) during the experiment is shown in Figure 13. The 3D positioning error increases over time with the final positioning error reaching about 42 m. The estimated reliability can track the 3D positioning error at the very beginning of the test. However, the difference between the estimated reliability of SLAM and the 3D positioning error increases over time. Interestingly, we can find that altitude positioning error in both experiment 3 and experiment 4 dominant the ∈ S L A M .\n\nTable 5 shows the mean and standard deviation of positioning error in three separate directions; 11.25 m of mean error in the lateral direction is obtained with a standard deviation of 5.09 m. The mean positioning error in the longitudinal direction is 2.77 m. Interestingly, the mean positioning error in altitude direction reaches 19.07 m which are significantly larger than the other two directions. The mean of 2D (sum of lateral and longitudinal directions) positioning error is 14.02 m with the 3D positioning error reaching 23.22 m. The 2D gradient is 0.114 and the value for the 3D gradient is 0.189.\n\nRegarding the reliability estimation result (blue dots in the bottom panel of Figure 13), from epoch 20 to 120, the actual 3D positioning error is larger than estimated (reliability). The estimated mean reliability is 14.38 m which are significantly smaller than its ground truth (23.22 m). Interestingly, we can find that it tends to overestimate the uncertainty of SLAM in normal traffic scenario and underestimate that in dense traffic scene. The main reason for this is that the used reliability estimation method cannot model the effects of traffic (dynamic objects). In other words, the dense traffic scenes introduce larger uncertainty. This result again shows that traffic has a bad impact on the performance of NDT-based graph SLAM.\n\n5. Discussion, Conclusion and Future Work\n\n(1) The relationship between the traffic conditions and the performance of NDT-based graph SLAM positioning:\n\nTraffic condition and accuracy of NDT-based graph SLAM: The detailed analysis of the relationship between the traffic conditions and the accuracy of LiDAR-based positioning is shown in Figure 14, which shows the results in two different degrees of traffic conditions. According to the presented six experiments (including two experiments presented in the Appendix A); the accuracy of the SLAM is degraded with increased traffic density. For example, the mean 3D positioning error increased from 1.58 m (experiment 5 with normal traffic) to 1.91 m (experiment 6 with dense traffic). This phenomenon is also the same in the sparse area and dense urban areas. The main reason causing this degradation in SLAM performance is the moving objects in traffic, such as the double-decker bus, cars, and trucks. Our previous research [20] shows that the height of the double-decker bus can go up to 4.5 m in Hong Kong and, thus, it takes up the majority of the field of view (FOV) of 3D LiDAR. The double-decker bus is a moving object on the roads. In this case, the majority of the 3D point clouds are scanned from the moving objects. The points from moving objects can distort the mapping between two consecutive frames of point clouds, thus impairing the accuracy of SLAM. We can also see that the positioning error gradient increases with enhanced traffic density. Overall, traffic conditions have negative effects on the accuracy of NDT-based SLAM. In other words, more dynamic environments with more moving objects introduce more degradation in the positioning accuracy of NDT-based graph SLAM. The evaluated results related to the traffic and accuracy of NDT-based SLAM can be a good benchmark for further mitigating the effects of traffic to improve the accuracy of LiDAR-based positioning.\n\nTraffic condition and reliability estimation: As presented in Experiment 4, it tends to overestimate the uncertainty of SLAM in a normal traffic scenario and underestimate that in dense traffic scene. In other words, the dense traffic scenes introduce larger uncertainty. This result again shows that the traffic has a bad impact on the performance of NDT-based graph SLAM. Proper methods to cope with the dynamic objects are needed to effectively estimate the uncertainty caused by dense traffic.\n\n(2) The relationship between the degree of urbanization and the performance of LiDAR-based positioning:\n\nThe degree of urbanization and accuracy of NDT-based graph SLAM: The detailed analysis of the relationship between the degree of urbanization and the accuracy of NDT-based graph SLAM is shown in Figure 15. According to the six experiments, three levels of areas classified based on the degree of urbanization are presented. We can see from Figure 15, the 3D gradient in sub-urban is similar to that in the sparse area. However, the 3D gradient in dense urban is significantly larger than that in both sparse areas and sub-urban. The main reason for this result is the environment features availability. In the sub-urban and sparse areas experiments, the main features are buildings, moving objects, and some trees, which means that abundant features are available. In the dense urban area, the main features are tall buildings and moving objects, which means less feature availability. Moreover, we can find that the 3D positioning error in altitude direction increases dramatically with an increased degree of urbanization which can be seen by comparing with Experiment 1 and 3. In total, the increased density of urbanization can degrade the accuracy of SLAM-based positioning, especially in the altitude direction. To effectively model the uncertainty of LiDAR-based positioning, the surrounding environment features are needed to be considered, for example, the degree of urbanization. The 3D building model generated in Figure 2 is a potential resource which contains the models of buildings to improve the accuracy of NDT-based graph SLAM. Inspired by this, we are going to employ the 3D building model to facilitate the effects estimation of urbanization on the performance of LiDAR-based positioning.\n\nThe degree of urbanization and reliability estimation of NDT-based graph SLAM: as discussed in experiment 4, the reliability estimation of NDT-based SLAM is highly related to the traffic condition. However, there are no obvious relationships between the reliability estimation and the degree of urbanization according to the presented experiments. In total, the sub-urban area has the smallest mean uncertainty and the dense urban area possesses the largest estimated uncertainty.\n\nInsufficient positioning accuracy and robustness is one of the main technical problems that prevent the arrival of autonomous vehicles in the super-urbanized areas, such as Hong Kong, Tokyo, and New York. According to our previous localization experiments conducted in Hong Kong using multi-sensor fusion (GNSS/IMU/LiDAR/HD Map) method [34] using Kalman filter, we find that the method (GNSS/IMU/LiDAR/HD Map) can obtain satisfactory performance in the sparse area. However, the solution usually fails in a deep urban area with dense traffic. Therefore, we propose to conduct experiments in diverse urban scenarios to find out the effects of traffic and degree of urbanization on LiDAR-based positioning. This is also the main contribution of this paper. Coping with the effects from both traffic and urbanization on the LiDAR-based positioning is significant for the GNSS/INS/LiDAR/HD Map-based localization solution for an autonomous vehicle. We believe that this paper can be a useful basic work to improving the LiDAR-based positioning in dense urban scenarios.\n\n(3) Future work: we aim to employ moving objects detection and 3D building models to improve the performance of NDT-based graph SLAM. Moreover, the uncertainty estimation of LiDAR-based SLAM will be conducted by considering both the traffic conditions and 3D building models.\n\nAuthor Contributions\n\nConceptualization, L.H.; Investigation, W.W.; Methodology, G.Z.\n\nFunding\n\nThis research is funded by Fundamental Research on Free Exploration Category of Shenzhen Municipal Science and Technology Innovation Committee (Project No. JCYJ20170818103653507).\n\nConflicts of Interest\n\nThe authors declare no conflict of interest.\n\nAppendix A\n\nAppendix A.1. Experiment in Sub-Urban Area\n\nAppendix A.1.1. Experiment 5: Performance Evaluation of NDT-Based Graph SLAM in Sub-Urban Area with Normal Traffic\n\nIn this experiment, the scenario is shown in the right panel of Figure A1. The overall drive of vehicle lasts about 64 s in sub-urban with dense traffic. The height of the surrounding buildings is about 10~25 m high and the width of the streets is approximately 16~20 m. The ℶ u r b a n for the scenario shown in Figure A1 is about 20 ° ~ 41 ° satisfying the dense urban area condition. The detailed results for this experiment are shown in Figure A2 and Table A1.\n\nFigure A1. Experiment 5: the trajectory of NDT-based graph SLAM in a sub-urban area with normal traffic condition. The left panel indicates the generated points map and trajectory from SLAM. Right panel represents the snapshot in Google Maps. The black curve indicates the ground truth of the vehicle’s trajectory.\n\nFigure A2. Experiment 5: positioning error and reliability estimation result. The top panel represents the positioning error in lateral, longitudinal and altitude directions, respectively. The bottom panel represents the estimated reliability and 3D positioning error of SLAM.\n\nTable A1. Experiment 5: Performance of NDT-based graph SLAM in a sub-urban area with normal traffic condition.\n\nErrorLateral (m)Longitudinal (m)Altitude (m)Reliability (m)2D (m)2D Gradient (m/s)3D (m)3D Gradient (m/s)Mean0.910.540.154.691.440.0231.580.025Std0.790.480.116.091.050.0161.110.016\n\nAppendix A.1.2. Experiment 6: Performance Evaluation of NDT-Based Graph SLAM in Sub-Urban Area with Dense Traffic\n\nIn this experiment, the scenario is shown in the right panel of Figure A3. The overall drive of vehicle lasts about 64 s in sub-urban with dense traffic. The height of the surrounding buildings is about 10~25 m high and the width of the streets is approximately 16~20 m. The ℶ u r b a n for the scenario shown in Figure A3 is about 20 ° ~ 41 ° satisfying the dense urban area condition. The only difference between experiment 5 and experiment 6 is the density of traffic. The detailed results for this experiment are shown in Figure A4 and Table A2.\n\nFigure A3. Experiment 6: the trajectory of NDT-based graph SLAM in a sub-urban area with dense traffic condition. The left panel indicates the generated points map and trajectory from SLAM. Top panel represents the snapshot in Google Maps. The black curve indicates the ground truth of the vehicle’s trajectory.\n\nFigure A4. Experiment 6: positioning error and reliability estimation result. The top panel represents the positioning error in lateral, longitudinal and altitude directions separately. The bottom panel represents the estimated reliability and 3D positioning error of SLAM.\n\nTable A2. Experiment 4: Performance of NDT-based graph SLAM in a sub-urban area with dense traffic condition.\n\nErrorLateral (m)Longitudinal (m)Altitude (m)Reliability (m)2D (m)2D Gradient (m/s)3D (m)3D Gradient (m/s)Mean0.850.6940.3675.261.540.0241.910.029Std0.590.5370.255.050.940.0151.010.016\n\nReferences\n\nUrmson, C.; Anhalt, J.; Bagnell, D.; Baker, C.; Bittner, R.; Clark, M.; Dolan, J.; Duggins, D.; Galatali, T.; Geyer, C. Autonomous driving in urban environments: Boss and the urban challenge. J. Field Robot. 2008, 25, 425–466. [Google Scholar] [CrossRef]\n\nWei, J.; Snider, J.M.; Kim, J.; Dolan, J.M.; Rajkumar, R.; Litkouhi, B. Towards a Viable Autonomous Driving Research Platform. In Proceedings of the Intelligent Vehicles Symposium (IV), Gold Coast, Australia, 23–26 June 2013; pp. 763–770. [Google Scholar]\n\nFernández, A.; Diez, J.; de Castro, D.; Silva, P.F.; Colomina, I.; Dovis, F.; Friess, P.; Wis, M.; Lindenberger, J.; Fernández, I. Atenea: Advanced Techniques for Deeply Integrated Gnss/Ins/Lidar Navigation. In Proceedings of the 2010 5th ESA Workshop on Satellite Navigation Technologies and European Workshop on GNSS Signals and Signal Processing (NAVITEC), Noordwijk, The Netherlands, 8–10 December 2010; pp. 1–8. [Google Scholar]\n\nFernández, A.; Silva, P.; Colomina, I. Real-time navigation and mapping with mobile mapping systems using lidar/camera/ins/gnss advanced hybridization algorithms: Description and test results. In Proceedings of the 27th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2014, Tampa, FL, USA, 8–12 September 2014; pp. 896–903. [Google Scholar]\n\nGao, Y.; Liu, S.; Atia, M.M.; Noureldin, A. Ins/gps/lidar integrated navigation system for urban and indoor environments using hybrid scan matching algorithm. Sensors 2015, 15, 23286–23302. [Google Scholar] [CrossRef] [PubMed]\n\nGu, Y.; Hsu, L.-T.; Kamijo, S. Gnss/onboard inertial sensor integration with the aid of 3-d building map for lane-level vehicle self-localization in urban canyon. IEEE Trans. Veh. Technol. 2016, 65, 4274–4287. [Google Scholar] [CrossRef]\n\nLevinson, J.; Montemerlo, M.; Thrun, S. Map-based precision vehicle localization in urban environments. In Robotics: Science and Systems; MIT Press: Cambridge, MA, USA, 2007. [Google Scholar]\n\nLevinson, J.; Thrun, S. Robust vehicle localization in urban environments using probabilistic maps. In Proceedings of the 2010 IEEE International Conference on Robotics and Automation (ICRA), Anchorage, AK, USA, 3–7 May 2010; pp. 4372–4378. [Google Scholar]\n\nMeng, X.; Wang, H.; Liu, B. A robust vehicle localization approach based on gnss/imu/dmi/lidar sensor fusion for autonomous vehicles. Sensors 2017, 17, 2140. [Google Scholar] [CrossRef] [PubMed]\n\nHsu, L.-T. Analysis and modeling gps nlos effect in highly urbanized area. Gps Solut. 2018, 22, 7. [Google Scholar] [CrossRef]\n\nKong, S.H. Statistical analysis of urban gps multipaths and pseudo-range measurement errors. IEEE Trans. Aerosp. Electron. Syst. 2011, 47, 1101–1113. [Google Scholar] [CrossRef]\n\nGrisetti, G.; Kummerle, R.; Stachniss, C.; Burgard, W. A tutorial on graph-based slam. IEEE Intell. Transp. Syst. Mag. 2010, 2, 31–43. [Google Scholar] [CrossRef]\n\nHess, W.; Kohler, D.; Rapp, H.; Andor, D. Real-time loop closure in 2d lidar slam. In Proceedings of the IEEE International Conference on Robotics and Automation, Stockholm, Sweden, 16–21 May 2016; pp. 1271–1278. [Google Scholar]\n\nMagnusson, M.; Andreasson, H.; Nuchter, A.; Lilienthal, A.J. Appearance-based loop detection from 3d laser data using the normal distributions transform. In Proceedings of the IEEE International Conference on Robotics and Automation, ICRA’09, Kobe, Japan, 12–17 May 2009; pp. 23–28. [Google Scholar]\n\nMagnusson, M.; Lilienthal, A.; Duckett, T. Scan registration for autonomous mining vehicles using 3d-ndt. J. Field Robot. 2007, 24, 803–827. [Google Scholar] [CrossRef] [Green Version]\n\nThrun, S.; Liu, Y. Multi-robot slam with sparse extended information filers. In Proceedings of the Eleventh International Symposium on Robotics Research, San Francisco, CA, USA, 12–15 October 2005; Springer: Berlin/Heidelberg, Germany; pp. 254–266. [Google Scholar]\n\nTörnqvist, D.; Schön, T.B.; Karlsson, R.; Gustafsson, F. Particle filter slam with high dimensional vehicle model. J. Intell. Robot. Syst. 2009, 55, 249–266. [Google Scholar] [CrossRef]\n\nZhang, J.; Singh, S. Loam: Lidar Odometry and Mapping in Real-Time. In Proceedings of the Robotics: Science and Systems, Berkeley, CA, USA, 12–16 July 2014. [Google Scholar]\n\nStoyanov, T.D. Reliable Autonomous Navigation in Semi-Structured Environments Using the Three-Dimensional Normal Distributions Transform (3d-ndt); Citeseer: University Park, PA, USA, 2012. [Google Scholar]\n\nWen, W.; Zhang, G.; Hsu, L.-T. Exclusion of gnss nlos receptions caused by dynamic objects in heavy traffic urban scenarios using real-time 3d point cloud: An approach without 3d maps. In Proceedings of the 2018 IEEE/ION Position, Location and Navigation Symposium (PLANS), Monterey, CA, USA, 23–26 April 2018; pp. 158–165. [Google Scholar]\n\nHuang, G.P.; Mourikis, A.I.; Roumeliotis, S.I. Analysis and improvement of the consistency of extended kalman filter based slam. In Proceedings of the IEEE International Conference on Robotics and Automation, ICRA 2008, Pasadena, CA, USA, 19–23 May 2008; pp. 473–479. [Google Scholar]\n\nZhu, J.; Zheng, N.; Yuan, Z.; Zhang, Q.; Zhang, X.; He, Y. A slam algorithm based on the central difference kalman filter. In Proceedings of the 2009 IEEE Intelligent Vehicles Symposium, Xi’an, China, 3–5 June 2009; pp. 123–128. [Google Scholar]\n\nCadena, C.; Neira, J. Slam in o (logn) with the combined kalman-information filter. Robot. Auton. Syst. 2010, 58, 1207–1219. [Google Scholar] [CrossRef]\n\nGutmann, J.-S.; Eade, E.; Fong, P.; Munich, M. A constant-time algorithm for vector field slam using an exactly sparse extended information filter. In Robotics: Science and Systems VI; The MIT Press: Cambridge, MA, USA, 2011. [Google Scholar]\n\nFairfield, N.; Kantor, G.; Wettergreen, D. Towards particle filter slam with three dimensional evidence grids in a flooded subterranean environment. In Proceedings of the 2006 IEEE International Conference on Robotics and Automation, ICRA 2006, Orlando, FL, USA, 15–19 May 2006; pp. 3575–3580. [Google Scholar]\n\nSim, R.; Elinas, P.; Little, J.J. A study of the rao-blackwellised particle filter for efficient and accurate vision-based slam. Int. J. Comput. Vis. 2007, 74, 303–318. [Google Scholar] [CrossRef]\n\nWan, G.; Yang, X.; Cai, R.; Li, H.; Wang, H.; Song, S. Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes. arXiv, 2017; arXiv:1711.05805. [Google Scholar]\n\nDellaert, F.; Kaess, M. Square root sam: Simultaneous localization and mapping via square root information smoothing. Int. J. Robot. Res. 2006, 25, 1181–1203. [Google Scholar] [CrossRef]\n\nLu, F.; Milios, E. Globally consistent range scan alignment for environment mapping. Auton. Robots 1997, 4, 333–349. [Google Scholar] [CrossRef]\n\nOlson, E.; Leonard, J.; Teller, S. Fast iterative alignment of pose graphs with poor initial estimates. In Proceedings of the 2006 IEEE International Conference on Robotics and Automation, ICRA 2006, Orlando, FL, USA, 15–19 May 2006; pp. 2262–2269. [Google Scholar] [Green Version]\n\nSakai, T.; Koide, K.; Miura, J.; Oishi, S. Large-scale 3d outdoor mapping and on-line localization using 3d-2d matching. In Proceedings of the 2017 IEEE/SICE International Symposium on System Integration (SII), Taipei, Taiwan, 11–14 December 2017; pp. 829–834. [Google Scholar]\n\nYang, J.; Li, H.; Campbell, D.; Jia, Y. Go-icp: A globally optimal solution to 3d icp point-set registration. arXiv, 2016; arXiv:1605.03344. [Google Scholar] [CrossRef] [PubMed]\n\nChetverikov, D.; Stepanov, D.; Krsek, P. Robust euclidean alignment of 3d point sets: The trimmed iterative closest point algorithm. Image Vis. Comput. 2005, 23, 299–309. [Google Scholar] [CrossRef]\n\nKato, S.; Takeuchi, E.; Ishiguro, Y.; Ninomiya, Y.; Takeda, K.; Hamada, T. An open approach to autonomous vehicles. IEEE Micro 2015, 35, 60–68. [Google Scholar] [CrossRef]\n\nKümmerle, R.; Grisetti, G.; Strasdat, H.; Konolige, K.; Burgard, W. G2O: A general framework for graph optimization. In Proceedings of the 2011 IEEE International Conference on Robotics and Automation (ICRA), Shanghai, China, 9–13 May 2011; pp. 3607–3613. [Google Scholar]\n\nGroves, P.D. Shadow matching: A new gnss positioning technique for urban canyons. J. Navig. 2011, 64, 417–430. [Google Scholar] [CrossRef]\n\nHsu, L.-T.; Gu, Y.; Kamijo, S. 3d building model-based pedestrian positioning method using gps/glonass/qzss and its reliability calculation. Gps Solut. 2016, 20, 413–428. [Google Scholar] [CrossRef]\n\nMarshall, J. Creating and viewing skyplots. Gps Solut. 2002, 6, 118–120. [Google Scholar] [CrossRef]\n\nGroves, P.D. Principles of Gnss, Inertial, and Multisensor Integrated Navigation Systems; Artech House: Norwood, MA, USA, 2013. [Google Scholar]\n\nAkai, N.; Morales, L.Y.; Hirayama, T.; Murase, H. Toward localization-based automated driving in highly dynamic environments: Comparison and discussion of observation models. Available online: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&as_vis=1&q=Toward+localization-based+automated+driving+in+highly+dynamic+environments%3A+Comparison+and+discussion+of+observation+models&btnG= (accessed on 7 November 2018).\n\nFigure 1. Demonstration of the graph generation based on LiDAR odometry.\n\nFigure 2. 3D building models of tested area.\n\nFigure 3. Skyplot generation based on 3D building models.\n\nFigure 4. Scenarios with different traffic conditions. The green boxes indicate the surrounding dynamic vehicles. The left figure shows the scenario with normal traffic and right figure with dense traffic.\n\nFigure 5. Sensors setup of the vehicle: 3D LiDAR sensor is installed on the top of the vehicle. GNSS RTK/INS integrated navigation system is installed on the top of the vehicle next to 3D LiDAR. The GNSS RTK/INS in ENU coordinate system is used to provide the ground truth of vehicle’s position.\n\nFigure 6. Experiment 1: the trajectory of NDT-based graph SLAM in a sparse area with normal traffic condition. Top panel represents the snapshot in Google Maps. The black curve indicates the ground truth of the vehicle’s trajectory. The bottom panel indicates the generated points map and trajectory from SLAM and ground truth.\n\nFigure 7. Experiment 1: positioning error and reliability estimation result. The top panel represents the positioning error in lateral, longitudinal and altitude directions, respectively. The bottom panel represents the estimated reliability and 3D positioning error of SLAM.\n\nFigure 8. Experiment 2: the trajectory of NDT-based graph SLAM in a sparse area with dense traffic condition. Top panel represents the snapshot in Google Maps. The black curve indicates the ground truth of the vehicle’s trajectory. The bottom panel indicates the generated points map and trajectory from SLAM.\n\nFigure 9. Experiment 2: positioning error and reliability estimation result. The top panel represents the positioning error in lateral, longitudinal and altitude directions, respectively. The bottom panel represents the estimated reliability and 3D positioning error of SLAM.\n\nFigure 10. Experiment 3: the trajectory of NDT-based graph SLAM in a dense urban area with normal traffic condition. Top panel represents the snapshot in Google Maps. The black curve indicates the ground truth of the vehicle’s trajectory. The bottom panel indicates the generated points map and trajectory from SLAM.\n\nFigure 11. Experiment 3: positioning error and reliability estimation result. The top panel represents the positioning error in lateral, longitudinal and altitude directions, respectively. The bottom panel represents the estimated reliability and 3D positioning error of SLAM.\n\nFigure 12. Experiment 4: the trajectory of NDT-based graph SLAM in a dense urban area with dense traffic condition. Top panel represents the snapshot in Google Maps. The black curve indicates the ground truth of the vehicle’s trajectory. The bottom panel indicates the generated points map and trajectory from SLAM.\n\nFigure 13. Experiment 4: positioning error and reliability estimation result. The top panel represents the positioning error in lateral, longitudinal and altitude directions, respectively. The bottom panel represents the estimated reliability and 3D positioning error of SLAM.\n\nFigure 14. The relationship between the traffic conditions and the performance of NDT-based graph SLAM. The x-axis indicates the traffic condition (including normal traffic and dense traffic). The y-axis on the left side represents the value of positioning error and the y-axis on the right side indicates the positioning error gradient.\n\nFigure 15. The relationship between the degree of urbanization and the performance of LiDAR-based positioning. The x-axis indicates the degree of urbanization. The y-axis on the left side represents the value of positioning error and the y-axis on the right side indicates the positioning error gradient.\n\nTable 1. Definition of the degree of urbanization based on ℶ u r b a n .\n\nSparse AreaSub-urban AreaDense Urban Area ℶ u r b a n 0 ° ~ 15 ° 15 ° ~ 46 ° > 46 °\n\nTable 2. Experiment 1: Performance of NDT-based graph SLAM in a sparse area with dense traffic condition.\n\nErrorLateral (m)Longitudinal (m)Altitude (m)Reliability (m)2D (m)2D Gradient (m/s)3D (m)3D Gradient (m/s)Mean3.443.193.057.526.640.0179.690.024Std1.881.791.022.753.290.0084.120.010\n\nTable 3. Experiment 2: Performance of NDT-based graph SLAM in a sparse area with dense traffic condition.\n\nErrorLateral (m)Longitudinal (m)Altitude (m)Reliability (m)2D (m)2D Gradient (m/s)3D (m)3D Gradient (m/s)Mean6.314.910.775.9311.210.02811.990.03Std5.264.360.842.875.180.0135.600.014\n\nTable 4. Experiment 3: Performance of NDT-based graph SLAM in a dense urban area with normal traffic condition.\n\nErrorLateral (m)Longitudinal (m)Altitude (m)Reliability (m)2D (m)2D Gradient (m/s)3D (m)3D Gradient (m/s)Mean6.734.8111.918.911.540.09414.850.121Std4.392.319.019.616.010.0499.750.079\n\nTable 5. Experiment 4: Performance of NDT-based graph SLAM in dense urban area with dense traffic condition.\n\nErrorLateral (m)Longitudinal (m)Altitude (m)Reliability (m)2D (m)2D Gradient (m/s)3D (m)3D Gradient (m/s)Mean11.252.7719.0714.3814.02 0.11423.22 0.189Std5.092.069.6010.254.80 0.03910.25 0.083\n\n© 2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n\nShare and Cite\n\nMDPI and ACS Style\n\nWen, W.; Hsu, L.-T.; Zhang, G. Performance Analysis of NDT-based Graph SLAM for Autonomous Vehicle in Diverse Typical Driving Scenarios of Hong Kong. Sensors 2018, 18, 3928. https://doi.org/10.3390/s18113928\n\nAMA Style\n\nWen W, Hsu L-T, Zhang G. Performance Analysis of NDT-based Graph SLAM for Autonomous Vehicle in Diverse Typical Driving Scenarios of Hong Kong. Sensors. 2018; 18(11):3928. https://doi.org/10.3390/s18113928\n\nChicago/Turabian Style\n\nWen, Weisong, Li-Ta Hsu, and Guohao Zhang. 2018. \"Performance Analysis of NDT-based Graph SLAM for Autonomous Vehicle in Diverse Typical Driving Scenarios of Hong Kong\" Sensors 18, no. 11: 3928. https://doi.org/10.3390/s18113928\n\nNote that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here.\n\nArticle Metrics\n\nNo\n\nNo\n\nArticle Access Statistics\n\nFor more information on the journal statistics, click here.\n\nMultiple requests from the same IP address are counted as one view."
    }
}