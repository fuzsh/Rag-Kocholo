{
    "id": "correct_foundationPlace_00104_2",
    "rank": 77,
    "data": {
        "url": "https://techcommunity.microsoft.com/t5/azure-architecture-blog/leveraging-knowledge-graphs-with-azure-openai/ba-p/4093233",
        "read_more_link": "",
        "language": "en",
        "title": "Leveraging Knowledge Graphs with Azure OpenAI",
        "top_image": "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563708iE8352903EE383D98/image-size/original?v=v2&px=-1",
        "meta_img": "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563708iE8352903EE383D98/image-size/original?v=v2&px=-1",
        "images": [
            "https://techcommunity.microsoft.com/html/@583B3F561C4171F565A5431E573FCDA4/assets/Content/Images/GlobalHeader/MicrosoftLogo.png",
            "https://techcommunity.microsoft.com/t5/image/serverpage/avatar-name/default-avatar/avatar-theme/candy/avatar-collection/Microsoft/avatar-display-size/profile/version/2?xdesc=1.0",
            "https://techcommunity.microsoft.com/t5/image/serverpage/avatar-name/default-avatar/avatar-theme/candy/avatar-collection/Microsoft/avatar-display-size/message/version/2?xdesc=1.0",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563708iE8352903EE383D98/image-size/medium?v=v2&px=400",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563709i89F694CFE560F8B4/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563710iA82F378A93106B23/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563711i6033355989D8BE0C/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563713i372F2E761A1E8E28/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563712iCC368F42E6F36FCC/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563715iEF17C252BDBB66D5/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/image-id/563714iF4F1B86C60150A51/image-size/large?v=v2&px=999",
            "https://techcommunity.microsoft.com/t5/image/serverpage/avatar-name/default-avatar/avatar-theme/candy/avatar-collection/Microsoft/avatar-display-size/message/version/2?xdesc=1.0",
            "https://techcommunity.microsoft.com/t5/image/serverpage/avatar-name/default-avatar/avatar-theme/candy/avatar-collection/Microsoft/avatar-display-size/message/version/2?xdesc=1.0",
            "https://www.facebook.com/tr?id=1770559986549030&ev=PageView&noscript=1"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "techcommunity.microsoft.com",
            "user-id"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "In many industries, information can be scattered across multiple documents, or across multiple pages in a very large document. Moreover, combining information across documents and sources is essential for day-to-day operations. Knowledge Graphs are a way of structuring and organizing information using/following a specific topology called an ontology. Knowledge Graphs represent a network of entities - I.e., objects, places, events, or concepts – and the relationships between these entities.  This is powerful as it allows extracting data across multiple unstructured and structured sources if they are tied to the same entity or relationship. Knowledge graphs compliment the RAG (Retrieval Augmented Generation) technique very well.\r\n\r\nBy transitioning from traditional databases, knowledge graphs can help enterprises use the power of LMMs, Natural Language Processing (NLP), and other tools to better leverage their data. Leveraging Knowledge graphs to store information and for question answering enables us to pack in the most relevant features of multiple documents into a concise format, thereby making best use of token sizes.\r\n\r\nGPTs models can help transform unstructured data into structured knowledge graphs with relationships for future querying. This submission goes over how to enhance knowledge graph tasks by using LLMs. We will:\r\n\r\n Showcase how to use Azure OpenAI's (AOAI) GPT-4 models to perform Name Entity Recognition (NER) on a corpus of documents, that will be used to extract entities and relationships to build the knowledge graph.\r\nPerform a Natural Language to Code (NL-to-Code) prompt engineering solution to generate a cypher query that will build that knowledge graph, and NL-to-Code for to perform question answering against the knowledge graph.\r\nAnswer retrieval from the knowledge graph fetch relevant information.\r\nPrompt engineering to leverage the search results to generate answers either by RAG or other prompt engineering methods.",
        "meta_lang": "en",
        "meta_favicon": "https://c.s-microsoft.com/favicon.ico?v2",
        "meta_site_name": "TECHCOMMUNITY.MICROSOFT.COM",
        "canonical_link": "https://techcommunity.microsoft.com/t5/azure-architecture-blog/leveraging-knowledge-graphs-with-azure-openai/ba-p/4093233",
        "text": "Introduction\n\nIn many industries, information can be scattered across multiple documents, or across multiple pages in a very large document. Moreover, combining information across documents and sources is essential for day-to-day operations. In many industries (Legal, Insurance, Medical), information is spread across the documents in the form of Names Entities (E.g. - Address, Phone number, Policy Name etc.) that can be linked to each other through “Relationships”. Manually identifying entities and relationships across thousands of documents can be costly and time intensive. In this document, we go through the process of automating named entity recognition and identifying relationships through knowledge graphs.\n\nKnowledge Graphs are a way of structuring and organizing information using/following a specific topology called an ontology. Knowledge Graphs represent a network of entities - I.e., objects, places, events, or concepts – and the relationships between these entities. This is powerful as it allows extracting data across multiple unstructured and structured sources as long as they are tied to the same entity or relationship.\n\nKnowledge Graphs provide multiple key benefits that compel enterprise companies to use them. Listed below are a subset of key benefits:\n\nCombined data sources that may have been siloed previously.\n\nCombine structured and unstructured data.\n\nSummarize relationships efficiently.\n\nGather effective insights.\n\nVisualize relationships and flow of information across multiple sources.\n\nBy transitioning from traditional databases, knowledge graphs can help enterprises use the power of Large Multimodal Models (LMMs), Natural Language Processing (NLP), and other tools to better leverage their data. Leveraging knowledge graphs to store information and for question answering enables us to pack in the most relevant features of multiple documents into a concise format, thereby making best use of token sizes.\n\nGPTs models can help transform unstructured data into structured knowledge graphs with relationships for future querying. This notebook goes over how to enhance knowledge graph tasks by using LLMs. We will:\n\nShowcase how to use Azure OpenAI's (AOAI) GPT-4 models to perform Name Entity Recognition (NER) on a corpus of documents, that will be used to extract entities and relationships to build the knowledge graph.\n\nPerform a Natural Language to Code (NL-to-Code) prompt engineering solution to generate a cypher query that will build that knowledge graph, and NL-to-Code for to perform question answering against the knowledge graph.\n\nAnswer retrieval from the knowledge graph the fetch relevant information.\n\nPrompt engineering to leverage the search results to generate answers either by RAG or other prompt engineering methods.\n\nCovered Concepts\n\nThe notebook will be divided into the main components below:\n\nIntroduction to Knowledge Graphs\n\nUse Cases\n\nDataset overview\n\nOntologies\n\nMethod\n\nEntity Extraction (NER)\n\nGenerate Knowledge Graph (NL-to-Code)\n\nQuery Knowledge Graph (NL-to-Code)\n\nAlternate out-of-the-box solutions\n\nEvaluation\n\nUse Case Overview\n\nThis notebook will cover two use cases for knowledge graphs: an auto insurance company and another, technology company. Both cases have a pre-defined ontology, outlined in more detail later in the document. There can be other cases where organizations do not have an ontology but would like to use knowledge graphs for question answering. In this case, you could either use out of box solutions (as described in later sections). Lang-chain extracts \"knowledge triples\" to create its knowledge graph from documents. Another alternative is to build out entities and relations that are important for the organization to extract and use that as a starting point.\n\nUse Case 1: Auto Insurance Company\n\nAuto insurance firms receive hundreds of insurance claims every day. Within these claims, the user is often required to describe the events in as much detail as they can provide. Since this information is free-form, the detail and style in which users provide information can be highly variable. Insurance companies are often looking to get specific details from these narratives quickly, so that the process of filing claims can move faster.\n\nUse Case 2: Technology Company\n\nChatbots are an increasingly popular way to interact with customers to answer commonly asked questions about products. In the technology industry, information can come from unstructured (pdfs, txt) and structures (data base) like data sources that are required to be combined to answer questions. By first converting unstructured data into an offline knowledge graph structure, chatbots can reduce inference latency by extracting only the relevant nodes and edges. This can increase the customer response rate and increase satisfaction for the customers.\n\nDataset Breakdown\n\nUse Case 1: Auto Insurance Company\n\nWe have 5 different sample claims (text files) filed by policyholders. The information is scattered in easily identifiable entities (Policyholder, Claim Date, Claim Number etc.) and also within narratives provided by the policyholders.\n\nHere is an example of an insurance claim:\n\nClaim Report\n\nPolicyholder: Jennifer Thompson\n\nClaim Number: 123456789\n\nDate of Loss: 08/01/2021\n\nPolicy Type: Comprehensive Auto Insurance\n\nProduct: All-Inclusive Auto Insurance Package\n\nDescription of Loss:\n\nOn August 1, 2021, at approximately 4:00 PM, Jennifer Thompson was driving her 2015 Honda Civic, which is covered under our All-Inclusive Auto Insurance Package. Jennifer's partner, Michael Thompson, and their child, Emily Thompson, were also in the vehicle at the time of the accident. The accident occurred when Jennifer, who was driving at a moderate speed, failed to notice a stop sign and collided with another vehicle at the intersection.\n\nThe collision resulted in significant damage to Jennifer's Honda Civic and the other vehicle involved. The front bumper, headlights, and hood of Jennifer's car were severely damaged. The airbags deployed, and the windshield cracked. The other vehicle, a 2017 Toyota Corolla, sustained significant damage to its side doors and panels.\n\nJennifer sustained minor injuries, including bruises and whiplash, as a result of the accident. Her partner, Michael, and their child, Emily, were fortunately unharmed. The driver of the other vehicle, a 30-year-old male named David Johnson, complained of neck pain and was transported to a nearby hospital for further examination.\n\nCoverage:\n\nJennifer's All-Inclusive Auto Insurance Package provides coverage for the damages sustained in this accident. The package contains comprehensive collision coverage, which covers the damages to her 2015 Honda Civic. Additionally, personal injury protection (PIP) is included in her policy, covering Jennifer's medical expenses related to her minor injuries. Furthermore, liability coverage is provided in the package, which will cover the damages to the 2017 Toyota Corolla and any medical expenses incurred by David Johnson.\n\nConclusion:\n\nBased on the information provided, it is determined that Jennifer Thompson caused the accident by failing to stop at the stop sign. The risk/event involved her Honda Civic and led to damages affecting both her vehicle and the Toyota Corolla. Jennifer's All-Inclusive Auto Insurance Package contains the necessary coverage to address the damages and injuries sustained in this accident. Our claims department will process the claim and coordinate with the involved parties to ensure a smooth resolution.\n\nOur next step is to identify the named entities found in the ontology above and extract them along with corresponding relationships.\n\nWe have used documentation that is available online about Surface devices (e.g., Surface Pro 9, Surface Go 3, Surface Laptop 5, etc.) as a dataset for this use case. The webpages have been converted into pdf’s that are about 1000 pages. The text from these pages is extracted using Form Recognizer and then named entities and relationships that we are looking for are extracted from those texts.\n\nBelow is an example image of the online documentation used:\n\nOntologies\n\nFor knowledge graphs, an ontology is a description of the data structure that will be translated into the graph. A knowledge graph is created when you apply an ontology to a set of data points The ontology will outline the entities and relationships and may be used as a schema to ensure consistency. An ontology outlines the entities and relationships that will make up our knowledge graph.\n\nThe ontology describes basic entities and how they are connected to each other. Ontologies are expected to be a more structured representation of how various elements are connected to each other.\n\nLater in the document, we will demonstrate how to use the ontologies to generate a knowledge graph though perform entity extraction.\n\nUse Case 1: Auto Insurance Company Ontology\n\nFor our insurance use case, our ontology is defined as such below. We will use this ontology to construct and query our knowledge graph.\n\nGiven this ontology, we will show how to generate the corresponding knowledge graph further in the notebook. As we can see above, the ontology describes basic entities and how they are connected to each other. Ontologies are expected to be a more structured representation of how various elements are connected to each other (e.g. - the event involves an object).\n\nBelow is a snippet of the generated knowledge graph from the ontology given above. As you can see, the circular elements represent the entities (such as a person, coverage, object) as described in the ontology above as gray rectangles. Then there are arrows connecting the different entities which represent the relationships between the entities, shown as the arrows between the entities above. We see “Car accident” (entity “Event”) involves (relationship “involves”) “2018 Toyota Camry” (Entity “Object”).\n\nUse Case 2: Technology Company Ontology\n\nFor the technology company use case, the ontology is defined below as entities and relationships.\n\nEntity types:\n\n- Surface (the central node connecting to all devices belonging to the Surface family)\n\n- Surface device (name of a Surface device), e.g. Surface Pro 6, Surface Pro X, Surface Slim Pen 2\n\n- Features, e.g. Inking feedback, Windows Fax and Scan\n\n- Accessories\n\n- Operating system, e.g. Windows 11 ARM, Windows 10\n\n- Technical specifications\n\nRelationships:\n\n- [Surface], specific device, [Surface device]\n\n- [Surface device], has feature, [Feature]\n\n- [Surface device], has accessories, [Accessory]\n\n- [Surface device], has operating system, [Operating system]\n\n- [Surface device], has technical specifications, [Technical specification]\n\nBelow is a snippet of the generated knowledge graph from the ontology given above. As you can see, the circular elements represent the entities (such as a feature, accessory, operating system) as described in the ontology above as gray rectangles. Then there are arrows connecting the different entities which represent the relationships between the entities, shown as the arrows between the entities above. We see Surface Hub (entity “surface device”) has operating system (relationship “has operating system”) Windows 10 (entity “operating system “).\n\nWe will be performing the following steps for both use cases:\n\nPerform Name Entity Recognition (NER) with GPT-4 to find the relationships and entities to form the Knowledge Graph (using a given ontology).\n\nUse GPT-4 to generate the code to build the Knowledge Graph (NL to Code).\n\nPopulate the Knowledge Graph with unstructured data present within the insurance claims.\n\nQuery the Knowledge Graph to find relevant information.\n\nNER with Azure OpenAI\n\nName Entity Recognition (NER) is a common natural language processing task. NER extracts information from text and places it in a predetermined category. Given the ontology defined above, we can perform NER using Azure OpenAI GPT-4 models through prompt engineering.\n\nSpecifically, we can instruct GPT on how to extract entities that fit our ontology. We craft two prompts: a system prompt and user prompt. The system message is included at the beginning of the prompt and used to prime the model for the general context, instructions, or other information relevant to the use case. The user prompt can reinforce specific instructions for the task at hand and provide instructions for output format.\n\nWe pass in our original data sources and perform NER using a few-shot approach by providing examples of what the desired outcome should mirror. Additionally, a temperature of 0 because we want to curb creativity. See more details on NER with AOAI.\n\nUse Case 1 (Auto Insurance) Prompts:\n\nSystem Prompt:\n\n'''Assistant is a Named Entity Recognition (NER) expert. The assistant can identify named entities such as a person, place, or thing. The assistant can also identify entity relationships, which describe how entities relate to each other (eg: married to, located in, held by). Identify the named entities and the entity relationships present in the text by returning comma separated list of tuples representing the relationship between two entities in the format (entity, relationship, entity). Only generate tuples from the list of entities and the possible entity relationships listed below. Return only generated tuples in a comma separated tuple separated by a new line for each tuple.\n\nEntities:\n\n- Person\n\n- Object\n\n- Damage\n\n- Coverage\n\n- Product\n\n- Risk/Event\n\nRelationships:\n\n- [PERSON],has_partner,[PERSON]\n\n- [PERSON],has_child,[PERSON]\n\n- [PERSON],causes,[RISK/EVENT]\n\n- [PERSON],owns,[OBJECT]\n\n- [PERSON],uses,[OBJECT]\n\n- [DAMAGE],affects,[PERSON]\n\n- [DAMAGE],affects,[OBJECT]\n\n- [RISK/EVENT],involves,[OBJECT]\n\n- [RISK/EVENT],leads_to,[DAMAGE]\n\n- [COVERAGE],covers,[DAMAGE]\n\n- [PRODUCT],contains,[COVERAGE]\n\nExample output:\n\nMichael, has_partner, Emily\n\nMichael, has_child, Josh\n\nMichael, owns, Toyota Prus\n\nExtracted Entities:\n\nUser Prompt:\n\n\"Identify the named entities and entity relationships in the insurance claim text above. Return the entities and entity relationships in a tuple separated by commas. Return only generated tuples in a comma separated tuple separated by a new line for each tuple.\n\nText:”\n\nUse Case 2 (Technology) Prompts:\n\nSystem Prompt:\n\n'''Assistant is a Named Entity Recognition (NER) expert. The assistant can identify named entities such as a person, place, or thing. The assistant can also identify entity relationships, which describe how entities are associated or connected with each other (eg: married to, located in, held by). Identify the named entities and the entity relationships present in the text by returning comma separated list of tuples representing the relationship between two entities in the format (entity, relationship, entity). Only generate tuples from the list of entities and the possible entity relationships listed below. Return only generated tuples in a comma separated tuple separated by a new line for each tuple.\n\nEntities:\n\n- Surface device\n\n- Features\n\n- Accessories\n\n- Operating system\n\n- Technical specifications\n\n- Release date\n\nRelationships:\n\n- [SURFACE_DEVICE], has feature, [FEATURES]\n\n- [SURFACE_DEVICE], has accessories, [ACCESSORIES]\n\n- [SURFACE_DEVICE], has operating system, [OPERATING_SYSTEM]\n\n- [SURFACE_DEVICE], has technical specifications, [TECHNICAL_SPECIFICATIONS]\n\n- [SURFACE_DEVICE], released on, [RELEASE_DATE]\n\nExample output:\n\n(Surface Pro 9, has feature, Battery life up to 15.5 hrs)\n\n(Surface Laptop Go 2, released on, June 7 2022)\n\nUser Prompt\n\n\"Identify the named entities and entity relationships in the technology documentation text above. Return the entities and entity relationships in a tuple separated by commas. Return only generated tuples in a comma separated tuple separated by a new line for each tuple.\n\nText:”\n\nGenerating a Knowledge Graph with Azure OpenAI\n\nIn this section we will utilize Neo4j to visualize and store our knowledge graph. Neo4j is a native graph database that implements a true graph model all the way down to a storage level. It is highly scalable and schema free. Neo4j stores data as nodes, edges connecting them, and attributes of nodes and edges. It uses a declarative language known as Cypher.\n\nFirst, we must generate a graph database that we can query against. To do this, we will first convert our entity outputs into a csv, that will be used as input to our GPT4 prompt. We then ask GPT to generate the Cypher query to create the knowledge graph in Neo4j. Here we will show how GPT4 can generate a cypher query that will create all the nodes and relationships found during entity extraction.\n\nTo generate the cypher query, we perform a type of prompt engineering called Natural Language (NL) to Code. We input into the prompt our instructions in natural language and craft our instructions to specify the output in code.\n\nThe prompts used are shown below. Note that both prompts were the same across Use Case 1 and Use Case 2 for this portion.\n\nSystem Prompt:\n\n'''Assistant is an expert in Neo4j Cypher development. Create a cypher query to generate a graph using the data points provided.Data:'''\n\nUser Prompt:\"Generate a cypher query to create new nodes and their relationships given the data provided. Return only the cypher query.Cypher query: \"\n\nBy specifying what coding language in the instructions and providing a spot for the output, we are reinforcing the idea of what language and format for the expected output.\n\nThe result is a cypher query that can directly copied and pasted in Neo4j, and the knowledge graph is now ready to be queried.\n\nQuerying a Knowledge Graph with Azure OpenAI\n\nNow that we have our knowledge graph, we can leverage it to retrieve answers quickly. Based on the format of the answer the prompt-completion problem can be NL-to-NL (for text answers) or NL-to-Code (for graph answers in Neo4j). In the section below, we describe NL-to-Code question answering. Knowledge graphs concisely represent all entities relevant to the use case.\n\nUsing Knowledge graphs as an input to be answering questions might help reduce the number of hops/API calls one has to make to retrieve answers from unstructured data sources.\n\nLike the previous section, we input instructions in the system prompt, and pass the question as our user prompt. We ask for GPT to return a Cypher query which when executed, gives us the answer to our question.\n\nNote that to query the knowledge graph with the method shown above, a predefined ontology is required and must be passed into the prompt to generate meaningful queries. The prompt must specific the naming conventions used in the graph as this is being converted to cypher query programming language, and therefore to find a match in the graph it must use the correct naming convention and existing relationships.\n\nFor the user message, you can provide the query you wish to answer based on the graph.\n\nUse Case 1 (Auto Insurance) Prompt and Example Output:\n\nSystem Prompt:\n\n'''Assistant is an expert in Neo4j Cypher development. Only return a cypher query based on the user query. The cypher graph has the following schema:\n\nNodes: Accident, Car, Coverage, Damage, Insurance, Person\n\nEntity Properties:\n\n- Damage.description\n\n- Accident.type\n\n- Car.model\n\n- Coverage.type\n\n- Insurance.type\n\n- Person.name\n\nRelationships:\n\n- Insurance -> CONTAINS -> Coverage\n\n- Accident -> LEADS_TO -> Damage\n\n- Accident -> INVOLVES -> Car\n\n- Coverage -> COVERS -> Damage\n\n- Damage -> AFFECTS -> Car\n\n- Damage -> AFFECTS -> Person\n\n- Person -> USES -> Car\n\n- Person -> OWNS -> Car\n\n- Person -> HAS_CHILD -> Person\n\n- Person -> HAS_PARTNER -> Person\n\n- Person -> CAUSES -> Accident”\n\nExample questions and output:\n\nQuestion: Find all people who have caused an accident and the type of accident they caused. MATCH (p:Person)-[:CAUSES]->(a:Accident) RETURN p.name as Person, a.type as Accident_Type\n\nQuestion: What types of insurance contain specific coverages? MATCH (i:Insurance)-[:CONTAINS]->(c:Coverage) RETURN i.type, c.type\n\nQuestion: What types of insurance coverages cover specific damages? MATCH (c:Coverage)-[:COVERS]->(d:Damage) RETURN c.type, d.description\n\nQuestion: Find all coverages that cover a specific damage type and the insurance they belong to. MATCH (cov:Coverage)-[:COVERS]->(d:Damage {description: 'bruises'}), (i:Insurance)-[:CONTAINS]->(cov)RETURN cov.type as Coverage_Type, i.type as Insurance_Type\n\nQuestion: Find the person who caused the accident and what damage occurred and to who. MATCH (p:Person)-[:CAUSES]->(a:Accident), (a)-[:LEADS_TO]->(d:Damage), (d)-[:AFFECTS]->(i:Person)RETURN p.name as Person, i.name as Victim, d as Damage\n\nQuestion: Given a model of car, find the car owner and the damages occurred to the car. MATCH (a:Accident)-[:INVOLVES]->(c:Car {model: '2015 Honda Accord'}), (a)-[:LEADS_TO]->(d:Damage), (p:Person)-[:OWNS]->(c)RETURN p.name as Car_Owner, d.description as Damage_Description\n\nUse Case 2 (Technology Company) Prompt and Example Output:\n\nSystem Prompt:\n\n'''Assistant is an expert in Neo4j Cypher development. Only return a cypher query based on the user query. The cypher graph has the following schema:\n\nNodes: Surface, Device, Feature, OS, Spec\n\nRelationships:\n\n- Surface -> SPECIFIC_DEVICE -> Device\n\n- Device -> HAS_FEATURE -> Feature\n\n- Device -> HAS_OS -> OS\n\n- Device -> HAS_SPEC -> Spec\n\nSurface node does not accept any value for name.”\n\nExample questions and output:\n\nQuestion: What are some of the features of Surface Go 3 for Business? MATCH (s:Surface)-[:SPECIFIC_DEVICE]->(d:Device {name: 'Surface Go 3 for Business'})-[:HAS_FEATURE]->(f:Feature) RETURN f.name\n\nQuestion: Give me all the devices that have 11 hours of battery. MATCH (d:Device)-[:HAS_SPEC]->(s:Spec) WHERE s.battery = '11 hours' RETURN d\n\nQuestion: What are the features and usable operating systems of Surface Go 3 for Business? MATCH (s:Surface)-[:SPECIFIC_DEVICE]->(d:Device {name: 'Surface Go 3 for Business'})-[:HAS_FEATURE]->(f:Feature) WITH collect(f.name) as Features MATCH (s:Surface)-[:SPECIFIC_DEVICE]->(d:Device {name: 'Surface Go 3 for Business'})-[:HAS_OS]->(o:OS) RETURN Features, collect(o.name) as OperatingSystems\n\nQuestion: Give me all Surface devices and their supported OS's. MATCH (s:Surface)-[:SPECIFIC_DEVICE]->(d:Device)-[:HAS_OS]->(o:OS) RETURN s, d, o\n\nQuestion: Give me all Surface devices and their technical specifications. MATCH (s:Surface)-[:SPECIFIC_DEVICE]->(d:Device)-[:HAS_SPEC]->(sp:Spec) RETURN s, d, sp\n\nQuestion: Find all Surface devices that support a specific OS and the technical specifications of those devices. MATCH (s:Surface)-[:SPECIFIC_DEVICE]->(d:Device)-[:HAS_OS]->(o:OS {name: 'YourSpecificOSName'}), (d)-[:HAS_SPEC]->(sp:Spec) RETURN s, d, o, sp\n\nAlternate Methods for Knowledge Graphs\n\nThe sections above assume that the organization already has a pre-defined ontology they would like to work with. However, if the organization does not have a pre-defined ontology, below are some out-of-box recommendations for Question Answering using knowledge graphs:\n\n1. Langchain - GraphQA goes over question answering using a graph structure. GraphQA takes text as input and uses \"knowledge triplets\" for entity extraction and graph creation. A knowledge triple is a clause that contains a subject, a predicate, and an object. It then uses this graph to answer questions. Prompts for GraphQA are pre-built, but can be customized as required for the use case. Visit https://python.langchain.com/docs/modules/chains/additional/graph_qa for more details.\n\n2. OntoGPT - OntoGPT framework and SPIRES tool offer a more structured method of extracting knowledge from unstructured text for integration into KGs. This object-oriented approach, while working within the constraints of LLMs, can handle complex, nested relationships and has a special focus on consistency, quality control and ontology alignment. Visit https://apex974.com/articles/ontogpt-for-schema-based-knowledge-extraction for more details.\n\nEvaluation\n\nIn this notebook we discussed two major use cases for using LLMs: Name Entity Extraction (NER) and Natural Language-to-Code (NL-to-Code). Each of these cases can be evaluated independently during the development cycle. This section will elaborate on evaluation methods for each use case.\n\nNER\n\nTo evaluate NER tasks, a text document and corresponding ground-truth entities for the document is required. After running the NER task and generating a list of entities and relationships, one can compute the precision, recall, and accuracy of the task through a confusion matrix by comparing the generated classification to the ground truth classification through a binary classification evaluation method.\n\nWhile evaluating NER, it is recommended to go over fuzzy matched ground truth-GPT4 extracted entities to make sure that the required entities have been extracted and mapped correctly.\n\nRefer to this documentation for more information regarding confusion matrices for binary classification: sklearn.metrics.confusion_matrix — scikit-learn 1.3.0 documentation\n\nUse Case 1 (Auto Insurance) NER Evaluation:\n\nThe image above shows an example evaluation for the first claim in the data folder. It has ground truth relationships mapped from the ontologies and then GPT4 NER results. It correctly classified 16/20 entities. This can be improved with prompt engineering effort by incorporating few-shot learning or finetuning.\n\nUse Case 2 (Technology) NER Evaluation:\n\nFor Use Case 2, the image below shows evaluation based on 3 different online PDFs for technical support for Surface Devices. GPT4 correctly classified 19/23 entities.\n\nNL-to-Code\n\nTo evaluate NL-to-Code tasks, it is essential that a domain expert is involved in human in the loop to check the accuracy and viability of the generate code. Multiple metrics can be used to evaluate NL-to-Code tasks such as code readability, does the code sample run, and accuracy of results. Specifically for knowledge graphs, we also should check that all the entities and relationships identified in the previous step also are found in the knowledge graph.\n\nAll these metrics require human expertise in the domain to provide iterative feedback to the prompts to improve on the results. With code, the same functionality can be written in many ways but yield the same result. Therefore, an evaluation dataset can be the query and the expected outcome which can be evaluated in a binary classification fashion.\n\nThe first NL-to-Code task was to convert the extracted entities and generate a cypher query that will be used to populate the knowledge graph. The next NL-to-Code task was answering a question against the knowledge graph. Here an expert is required to know the ontology of the knowledge graph to be asked grounded questions. To mimic this, we propose five questions for each use case and validate for code completions (did the query run) and correct response (was the response accurate).\n\nUse Case 1 (Auto Insurance) NL-to-Code Evaluation:\n\nFor Use Case 1, GPT-4 extracted 16 entity-relationships tuples from the NER step above. It then correctly mapped 16/16 extracted entities in the cypher query. This was evaluated by checking the nodes that were created and ensuring the mapping between entities and relationships is reflected in the cypher query.\n\nFor the next NL-to-Code task of question answering, we evaluated 5 out of the 5 queries measured correctly for both code completeness and response accuracy.\n\nUse Case 2 (Technology) NL-to-Code Evaluation:\n\nFor Use Case 2, GPT-4 extracted 19 entity-relationships tuples from the NER step above. It then correctly mapped 19/19 extracted entities in the cypher query. This was evaluated by checking the nodes that were created and ensuring the mapping between entities and relationships is reflected in the cypher query.\n\nFor the next NL-to-Code task of question answering, we evaluated 5 out of the 5 queries measured correctly for both code completeness and response accuracy.\n\nConclusion\n\nIn conclusion, we have shown how to leverage Azure OpenAI GPT models with the power of knowledge graph while leveraging Neo4j. We found that the combination of AOAI and Neo4j to generate and query knowledge graphs is extremely powerful. This methodology can be applied to many technical use cases such as NER, NL-to-SQL, etc across different industries."
    }
}