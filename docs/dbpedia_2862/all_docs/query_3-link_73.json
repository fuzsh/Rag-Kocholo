{
    "id": "dbpedia_2862_3",
    "rank": 73,
    "data": {
        "url": "https://www.mdpi.com/journal/entropy",
        "read_more_link": "",
        "language": "en",
        "title": "Entropy",
        "top_image": "https://pub.mdpi-res.com/img/journals/entropy-logo-social.png?8600e93ff98dbf14",
        "meta_img": "https://pub.mdpi-res.com/img/journals/entropy-logo-social.png?8600e93ff98dbf14",
        "images": [
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1723472589",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-black-small1.svg?da3a8dcae975a41c?1723472589",
            "https://pub.mdpi-res.com/img/journal_indexing_logos/CS_no_number.svg?62107aae53c39662?1723472589",
            "https://pub.mdpi-res.com/img/journal_indexing_logos/PM.svg?d6a69b922515dcf5?1723472589",
            "https://pub.mdpi-res.com/img/journal_indexing_logos/IF_no_number.svg?af8a884fb765d812?1723472589",
            "https://pub.mdpi-res.com/title_story/title_story_17183588043998.jpg?1723472589",
            "https://pub.mdpi-res.com/title_story/title_story_17183587596005.jpg?1723472589",
            "https://pub.mdpi-res.com/title_story/title_story_17183585943071.jpg?1723472589",
            "https://pub.mdpi-res.com/entropy/entropy-26-00680/article_deploy/html/images/entropy-26-00680-g001-550.jpg?1723446297",
            "https://pub.mdpi-res.com/entropy/entropy-26-00679/article_deploy/html/images/entropy-26-00679-g001-550.jpg?1723461029",
            "https://pub.mdpi-res.com/entropy/entropy-26-00678/article_deploy/html/images/entropy-26-00678-g001-550.jpg?1723446297",
            "https://pub.mdpi-res.com/entropy/entropy-26-00676/article_deploy/html/images/entropy-26-00676-g001-550.jpg?1723261167",
            "https://pub.mdpi-res.com/entropy/entropy-26-00675/article_deploy/html/images/entropy-26-00675-g001-550.jpg?1723195697",
            "https://pub.mdpi-res.com/entropy/entropy-26-00673/article_deploy/html/images/entropy-26-00673-g001-550.jpg?1723110047",
            "https://pub.mdpi-res.com/entropy/entropy-26-00672/article_deploy/html/images/entropy-26-00672-g001-550.jpg?1723105899",
            "https://pub.mdpi-res.com/entropy/entropy-26-00671/article_deploy/html/images/entropy-26-00671-g001-550.jpg?1723025689",
            "https://pub.mdpi-res.com/entropy/entropy-26-00670/article_deploy/html/images/entropy-26-00670-g001-550.jpg?1723227244",
            "https://pub.mdpi-res.com/entropy/entropy-26-00669/article_deploy/html/images/entropy-26-00669-g001-550.jpg?1722934625",
            "https://pub.mdpi-res.com/entropy/entropy-26-00668/article_deploy/html/images/entropy-26-00668-g001-550.jpg?1722934131",
            "https://pub.mdpi-res.com/entropy/entropy-26-00667/article_deploy/html/images/entropy-26-00667-g001-550.jpg?1722936640",
            "https://pub.mdpi-res.com/entropy/entropy-26-00666/article_deploy/html/images/entropy-26-00666-g001-550.jpg?1722850606",
            "https://pub.mdpi-res.com/entropy/entropy-26-00665/article_deploy/html/images/entropy-26-00665-g001-550.jpg?1722849549",
            "https://pub.mdpi-res.com/entropy/entropy-26-00664/article_deploy/html/images/entropy-26-00664-g001-550.jpg?1722837774",
            "https://pub.mdpi-res.com/entropy/entropy-26-00662/article_deploy/html/images/entropy-26-00662-g001-550.jpg?1722932860",
            "https://pub.mdpi-res.com/entropy/entropy-26-00661/article_deploy/html/images/entropy-26-00661-g001-550.jpg?1722671590",
            "https://pub.mdpi-res.com/img/journals/entropy-logo.png?8600e93ff98dbf14",
            "https://pub.mdpi-res.com/img/design/books_logo_new.svg?76e680e5363e99ba?1723472589",
            "https://pub.mdpi-res.com/img/loading_circle.gif?9a82694213036313?1723472589",
            "https://pub.mdpi-res.com/img/misc/event_1723609124730.jpg?1723472589",
            "https://pub.mdpi-res.com/img/misc/event_1721081652890.jpg?1723472589",
            "https://pub.mdpi-res.com/img/misc/event_1721095762478.jpg?1723472589",
            "https://pub.mdpi-res.com/img/design/mdpi-pub-logo-white-small.png?71d18e5f805839ab?1723472589"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Entropy, an international, peer-reviewed Open Access journal.",
        "meta_lang": "en",
        "meta_favicon": "https://pub.mdpi-res.com/img/mask-icon-128.svg?c1c7eca266cd7013?1723472589",
        "meta_site_name": "",
        "canonical_link": "https://www.mdpi.com/journal/entropy",
        "text": "45 pages, 4378 KiB\n\nOpen AccessArticle\n\nGAD-PVI: A General Accelerated Dynamic-Weight Particle-Based Variational Inference Framework\n\nby Fangyikang Wang, Huminhao Zhu, Chao Zhang, Hanbin Zhao and Hui Qian\n\nEntropy 2024, 26(8), 679; https://doi.org/10.3390/e26080679 - 11 Aug 2024\n\nAbstract\n\nParticle-based Variational Inference (ParVI) methods have been widely adopted in deep Bayesian inference tasks such as Bayesian neural networks or Gaussian Processes, owing to their efficiency in generating high-quality samples given the score of the target distribution. Typically, ParVI methods evolve a weighted-particle [...] Read more.\n\nParticle-based Variational Inference (ParVI) methods have been widely adopted in deep Bayesian inference tasks such as Bayesian neural networks or Gaussian Processes, owing to their efficiency in generating high-quality samples given the score of the target distribution. Typically, ParVI methods evolve a weighted-particle system by approximating the first-order Wasserstein gradient flow to reduce the dissimilarity between the particle system’s empirical distribution and the target distribution. Recent advancements in ParVI have explored sophisticated gradient flows to obtain refined particle systems with either accelerated position updates or dynamic weight adjustments. In this paper, we introduce the semi-Hamiltonian gradient flow on a novel Information–Fisher–Rao space, known as the SHIFR flow, and propose the first ParVI framework that possesses both accelerated position update and dynamical weight adjustment simultaneously, named the General Accelerated Dynamic-Weight Particle-based Variational Inference (GAD-PVI) framework. GAD-PVI is compatible with different dissimilarities between the empirical distribution and the target distribution, as well as different approximation approaches to gradient flow. Moreover, when the appropriate dissimilarity is selected, GAD-PVI is also suitable for obtaining high-quality samples even when analytical scores cannot be obtained. Experiments conducted under both the score-based tasks and sample-based tasks demonstrate the faster convergence and reduced approximation error of GAD-PVI methods over the state-of-the-art. Full article\n\n(This article belongs to the Section Information Theory, Probability and Statistics)\n\n►▼ Show Figures\n\n22 pages, 3992 KiB\n\nOpen AccessArticle\n\nBayesian Modeling for Nonstationary Spatial Point Process via Spatial Deformations\n\nby Dani Gamerman, Marcel de Souza Borges Quintana and Mariane Branco Alves\n\nEntropy 2024, 26(8), 678; https://doi.org/10.3390/e26080678 - 11 Aug 2024\n\nAbstract\n\nMany techniques have been proposed to model space-varying observation processes with a nonstationary spatial covariance structure and/or anisotropy, usually on a geostatistical framework. Nevertheless, there is an increasing interest in point process applications, and methodologies that take nonstationarity into account are welcomed. In [...] Read more.\n\nMany techniques have been proposed to model space-varying observation processes with a nonstationary spatial covariance structure and/or anisotropy, usually on a geostatistical framework. Nevertheless, there is an increasing interest in point process applications, and methodologies that take nonstationarity into account are welcomed. In this sense, this work proposes an extension of a class of spatial Cox process using spatial deformation. The proposed method enables the deformation behavior to be data-driven, through a multivariate latent Gaussian process. Inference leads to intractable posterior distributions that are approximated via MCMC. The convergence of algorithms based on the Metropolis–Hastings steps proved to be slow, and the computational efficiency of the Bayesian updating scheme was improved by adopting Hamiltonian Monte Carlo (HMC) methods. Our proposal was also compared against an alternative anisotropic formulation. Studies based on synthetic data provided empirical evidence of the benefit brought by the adoption of nonstationarity through our anisotropic structure. A real data application was conducted on the spatial spread of the Spodoptera frugiperda pest in a corn-producing agricultural area in southern Brazil. Once again, the proposed method demonstrated its benefit over alternatives. Full article\n\n(This article belongs to the Special Issue Bayesianism)\n\n►▼ Show Figures\n\n18 pages, 264 KiB\n\nOpen AccessArticle\n\nHacking the Predictive Mind\n\nby Andy Clark\n\nEntropy 2024, 26(8), 677; https://doi.org/10.3390/e26080677 - 10 Aug 2024\n\nAbstract\n\nAccording to active inference, constantly running prediction engines in our brain play a large role in delivering all human experience. These predictions help deliver everything we see, hear, touch, and feel. In this paper, I pursue one apparent consequence of this increasingly well-supported [...] Read more.\n\nAccording to active inference, constantly running prediction engines in our brain play a large role in delivering all human experience. These predictions help deliver everything we see, hear, touch, and feel. In this paper, I pursue one apparent consequence of this increasingly well-supported view. Given the constant influence of hidden predictions on human experience, can we leverage the power of prediction in the service of human flourishing? Can we learn to hack our own predictive regimes in ways that better serve our needs and purposes? Asking this question rapidly reveals a landscape that is at once familiar and new. It is also challenging, suggesting important questions about scope and dangers while casting further doubt (as if any was needed) on old assumptions about a firm mind/body divide. I review a range of possible hacks, starting with the careful use of placebos, moving on to look at chronic pain and functional disorders, and ending with some speculations concerning the complex role of genetic influences on the predictive brain. Full article\n\n19 pages, 6004 KiB\n\nOpen AccessArticle\n\nAn Evaluation Model for Node Influence Based on Heuristic Spatiotemporal Features\n\nby Sheng Jin, Yuzhi Xiao, Jiaxin Han and Tao Huang\n\nEntropy 2024, 26(8), 676; https://doi.org/10.3390/e26080676 - 10 Aug 2024\n\nAbstract\n\nThe accurate assessment of node influence is of vital significance for enhancing system stability. Given the structural redundancy problem triggered by the network topology deviation when an empirical network is copied, as well as the dynamic characteristics of the empirical network itself, it [...] Read more.\n\nThe accurate assessment of node influence is of vital significance for enhancing system stability. Given the structural redundancy problem triggered by the network topology deviation when an empirical network is copied, as well as the dynamic characteristics of the empirical network itself, it is difficult for traditional static assessment methods to effectively capture the dynamic evolution of node influence. Therefore, we propose a heuristic-based spatiotemporal feature node influence assessment model (HEIST). First, the zero-model method is applied to optimize the network-copying process and reduce the noise interference caused by network structure redundancy. Second, the copied network is divided into subnets, and feature modeling is performed to enhance the node influence differentiation. Third, node influence is quantified based on the spatiotemporal depth-perception module, which has a built-in local and global two-layer structure. At the local level, a graph convolutional neural network (GCN) is used to improve the spatial perception of node influence; it fuses the feature changes of the nodes in the subnetwork variation, combining this method with a long- and short-term memory network (LSTM) to enhance its ability to capture the depth evolution of node influence and improve the robustness of the assessment. Finally, a heuristic assessment algorithm is used to jointly optimize the influence strength of the nodes at different stages and quantify the node influence via a nonlinear optimization function. The experiments show that the Kendall coefficients exceed 90% in multiple datasets, proving that the model has good generalization performance in empirical networks. Full article\n\n(This article belongs to the Special Issue Advances in Complex Networks and Their Applications, from COMPLEX NETWORKS 2023)\n\n►▼ Show Figures\n\n17 pages, 6945 KiB\n\nOpen AccessArticle\n\nIntelligent Fault Diagnosis Method for Rotating Machinery Based on Recurrence Binary Plot and DSD-CNN\n\nby Yuxin Shi, Hongwei Wang, Wenlei Sun and Ruoyang Bai\n\nEntropy 2024, 26(8), 675; https://doi.org/10.3390/e26080675 - 9 Aug 2024\n\nAbstract\n\nTo tackle the issue of the traditional intelligent diagnostic algorithm’s insufficient utilization of correlation characteristics within the time series of fault signals and to meet the challenges of accuracy and computational complexity in rotating machinery fault diagnosis, a novel approach based on a [...] Read more.\n\nTo tackle the issue of the traditional intelligent diagnostic algorithm’s insufficient utilization of correlation characteristics within the time series of fault signals and to meet the challenges of accuracy and computational complexity in rotating machinery fault diagnosis, a novel approach based on a recurrence binary plot (RBP) and a lightweight, deep, separable, dilated convolutional neural network (DSD-CNN) is proposed. Firstly, a recursive encoding method is used to convert the fault vibration signals of rotating machinery into two-dimensional texture images, extracting feature information from the internal structure of the fault signals as the input for the model. Subsequently, leveraging the excellent feature extraction capabilities of a lightweight convolutional neural network embedded with attention modules, the fault diagnosis of rotating machinery is carried out. The experimental results using different datasets demonstrate that the proposed model achieves excellent diagnostic accuracy and computational efficiency. Additionally, compared with other representative fault diagnosis methods, this model shows better anti-noise performance under different noise test data, and it provides a reliable and efficient reference solution for rotating machinery fault-classification tasks. Full article\n\n(This article belongs to the Section Signal and Data Analysis)\n\n►▼ Show Figures\n\n11 pages, 252 KiB\n\nOpen AccessArticle\n\nFurstenberg Family and Chaos for Time-Varying Discrete Dynamical Systems\n\nby Risong Li, Yongjiang Li, Tianxiu Lu, Jiazheng Zhao and Jing Su\n\nEntropy 2024, 26(8), 674; https://doi.org/10.3390/e26080674 - 9 Aug 2024\n\nAbstract\n\nAssume that (Y,ρ) is a nontrivial complete metric space, and that (Y,g1,∞) is a time-varying discrete dynamical system (T-VDDS), which is given by sequences (gl)l=1∞ [...] Read more.\n\nAssume that (Y,ρ) is a nontrivial complete metric space, and that (Y,g1,∞) is a time-varying discrete dynamical system (T-VDDS), which is given by sequences (gl)l=1∞ of continuous selfmaps gl:Y→Y. In this paper, for a given Furstenberg family G and a given T-VDDS (Y,g1,∞), G-scrambled pairs of points of the system (Y,g1,∞) (which contains the well-known scrambled pairs) are provided. Some properties of the set of G-scrambled pairs of a given T-VDDS (Y,g1,∞) are studied. Moreover, the generically G-chaotic T-VDDS and the generically strongly G-chaotic T-VDDS are defined. A sufficient condition for a given T-VDDS to be generically strongly G-chaotic is also presented. Full article\n\n(This article belongs to the Section Complexity)\n\n18 pages, 4026 KiB\n\nOpen AccessArticle\n\nGeneralized Kinetic Equations with Fractional Time-Derivative and Nonlinear Diffusion: H-Theorem and Entropy\n\nby Ervin K. Lenzi, Michely P. Rosseto, Derik W. Gryczak, Luiz R. Evangelista, Luciano R. da Silva, Marcelo K. Lenzi and Rafael S. Zola\n\nEntropy 2024, 26(8), 673; https://doi.org/10.3390/e26080673 - 8 Aug 2024\n\nAbstract\n\nWe investigate the H-theorem for a class of generalized kinetic equations with fractional time-derivative, hyperbolic term, and nonlinear diffusion. When the H-theorem is satisfied, we demonstrate that different entropic forms may emerge due to the equation’s nonlinearity. We obtain the entropy production related [...] Read more.\n\nWe investigate the H-theorem for a class of generalized kinetic equations with fractional time-derivative, hyperbolic term, and nonlinear diffusion. When the H-theorem is satisfied, we demonstrate that different entropic forms may emerge due to the equation’s nonlinearity. We obtain the entropy production related to these entropies and show that its form remains invariant. Furthermore, we investigate some behaviors for these equations from both numerical and analytical perspectives, showing a large class of behaviors connected with anomalous diffusion and their effects on entropy. Full article\n\n(This article belongs to the Special Issue Theory and Applications of Hyperbolic Diffusion and Shannon Entropy)\n\n►▼ Show Figures\n\n23 pages, 1900 KiB\n\nOpen AccessReview\n\nNonlinear Charge Transport and Excitable Phenomena in Semiconductor Superlattices\n\nby Luis L. Bonilla, Manuel Carretero and Emanuel Mompó\n\nEntropy 2024, 26(8), 672; https://doi.org/10.3390/e26080672 - 8 Aug 2024\n\nAbstract\n\nSemiconductor superlattices are periodic nanostructures consisting of epitaxially grown quantum wells and barriers. For thick barriers, the quantum wells are weakly coupled and the main transport mechanism is a sequential resonant tunneling of electrons between wells. We review quantum transport in these materials, [...] Read more.\n\nSemiconductor superlattices are periodic nanostructures consisting of epitaxially grown quantum wells and barriers. For thick barriers, the quantum wells are weakly coupled and the main transport mechanism is a sequential resonant tunneling of electrons between wells. We review quantum transport in these materials, and the rate equations for electron densities, currents, and the self-consistent electric potential or field. Depending on superlattice configuration, doping density, temperature, voltage bias, and other parameters, superlattices behave as excitable systems, and can respond to abrupt dc bias changes by large transients involving charge density waves before arriving at a stable stationary state. For other parameters, the superlattices may have self-sustained oscillations of the current through them. These oscillations are due to repeated triggering and recycling of charge density waves, and can be periodic in time, quasiperiodic, and chaotic. Modifying the superlattice configuration, it is possible to attain robust chaos due to wave dynamics. External noise of appropriate strength can generate time-periodic current oscillations when the superlattice is in a stable stationary state without noise, which is called the coherence resonance. In turn, these oscillations can resonate with a periodic signal in the presence of sufficient noise, thereby displaying a stochastic resonance. These properties can be exploited to design and build many devices. Here, we describe detectors of weak signals by using coherence and stochastic resonance and fast generators of true random sequences useful for safe communications and storage. Full article\n\n(This article belongs to the Special Issue Quantum Transport in Molecular Nanostructures)\n\n►▼ Show Figures\n\n18 pages, 22304 KiB\n\nOpen AccessArticle\n\nA High-Performance FPGA PRNG Based on Multiple Deep-Dynamic Transformations\n\nby Shouliang Li, Zichen Lin, Yi Yang and Ruixuan Ning\n\nEntropy 2024, 26(8), 671; https://doi.org/10.3390/e26080671 - 7 Aug 2024\n\nAbstract\n\nPseudo-random number generators (PRNGs) are important cornerstones of many fields, such as statistical analysis and cryptography, and the need for PRNGs for information security (in fields such as blockchain, big data, and artificial intelligence) is becoming increasingly prominent, resulting in a steadily growing [...] Read more.\n\nPseudo-random number generators (PRNGs) are important cornerstones of many fields, such as statistical analysis and cryptography, and the need for PRNGs for information security (in fields such as blockchain, big data, and artificial intelligence) is becoming increasingly prominent, resulting in a steadily growing demand for high-speed, high-quality random number generators. To meet this demand, the multiple deep-dynamic transformation (MDDT) algorithm is innovatively developed. This algorithm is incorporated into the skewed tent map, endowing it with more complex dynamical properties. The improved one-dimensional discrete chaotic mapping method is effectively realized on a field-programmable gate array (FPGA), specifically the Xilinx xc7k325tffg900-2 model. The proposed pseudo-random number generator (PRNG) successfully passes all evaluations of the National Institute of Standards and Technology (NIST) SP800-22, diehard, and TestU01 test suites. Additional experimental results show that the PRNG, possessing high novelty performance, operates efficiently at a clock frequency of 150 MHz, achieving a maximum throughput of 14.4 Gbps. This performance not only surpasses that of most related studies but also makes it exceptionally suitable for embedded applications. Full article\n\n(This article belongs to the Section Multidisciplinary Applications)\n\n►▼ Show Figures\n\n21 pages, 359 KiB\n\nOpen AccessArticle\n\nRevisiting Possibilistic Fuzzy C-Means Clustering Using the Majorization-Minimization Method\n\nby Yuxue Chen and Shuisheng Zhou\n\nEntropy 2024, 26(8), 670; https://doi.org/10.3390/e26080670 - 6 Aug 2024\n\nAbstract\n\nPossibilistic fuzzy c-means (PFCM) clustering is a kind of hybrid clustering method based on fuzzy c-means (FCM) and possibilistic c-means (PCM), which not only has the stability of FCM but also partly inherits the robustness of PCM. However, as an extension of FCM [...] Read more.\n\nPossibilistic fuzzy c-means (PFCM) clustering is a kind of hybrid clustering method based on fuzzy c-means (FCM) and possibilistic c-means (PCM), which not only has the stability of FCM but also partly inherits the robustness of PCM. However, as an extension of FCM on the objective function, PFCM tends to find a suboptimal local minimum, which affects its performance. In this paper, we rederive PFCM using the majorization-minimization (MM) method, which is a new derivation approach not seen in other studies. In addition, we propose an effective optimization method to solve the above problem, called MMPFCM. Firstly, by eliminating the variable V∈Rp×c, the original optimization problem is transformed into a simplified model with fewer variables but a proportional term. Therefore, we introduce a new intermediate variable s∈Rc to convert the model with the proportional term into an easily solvable equivalent form. Subsequently, we design an iterative sub-problem using the MM method. The complexity analysis indicates that MMPFCM and PFCM share the same computational complexity. However, MMPFCM requires less memory per iteration. Extensive experiments, including objective function value comparison and clustering performance comparison, demonstrate that MMPFCM converges to a better local minimum compared to PFCM. Full article\n\n(This article belongs to the Section Information Theory, Probability and Statistics)\n\n►▼ Show Figures\n\n18 pages, 662 KiB\n\nOpen AccessArticle\n\nBilateral Matching Method for Business Resources Based on Synergy Effects and Incomplete Data\n\nby Shuhai Wang, Linfu Sun and Yang Yu\n\nEntropy 2024, 26(8), 669; https://doi.org/10.3390/e26080669 - 6 Aug 2024\n\nAbstract\n\nOn the third-party cloud platform, to help enterprises accurately obtain high-quality and valuable business resources from the massive information resources, a bilateral matching method for business resources, based on synergy effects and incomplete data, is proposed. The method first utilizes a k-nearest neighbor [...] Read more.\n\nOn the third-party cloud platform, to help enterprises accurately obtain high-quality and valuable business resources from the massive information resources, a bilateral matching method for business resources, based on synergy effects and incomplete data, is proposed. The method first utilizes a k-nearest neighbor imputation algorithm, based on comprehensive similarity, to fill in missing values. Then, it constructs a satisfaction evaluation index system for business resource suppliers and demanders, and the weights of the satisfaction evaluation indices are determined, based on the fuzzy analytic hierarchy process (FAHP) and the entropy weighting method (EWM). On this basis, a bilateral matching model is constructed with the objectives of maximizing the satisfaction of both the supplier and the demander, as well as achieving the synergy effect. Finally, the model is solved using the linear weighting method to obtain the most satisfactory business resources for both supply and demand. The effectiveness of the method is verified through a practical application and comparative experiments. Full article\n\n(This article belongs to the Special Issue Entropy Method for Decision Making with Uncertainty)\n\n►▼ Show Figures\n\n19 pages, 991 KiB\n\nOpen AccessArticle\n\nEffect of Pure Dephasing Quantum Noise in the Quantum Search Algorithm Using Atos Quantum Assembly\n\nby Maria Heloísa Fraga da Silva, Gleydson Fernandes de Jesus and Clebson Cruz\n\nEntropy 2024, 26(8), 668; https://doi.org/10.3390/e26080668 - 6 Aug 2024\n\nAbstract\n\nQuantum computing is tipped to lead the future of global technological progress. However, the obstacles related to quantum software development are an actual challenge to overcome. In this scenario, this work presents an implementation of the quantum search algorithm in Atos Quantum Assembly [...] Read more.\n\nQuantum computing is tipped to lead the future of global technological progress. However, the obstacles related to quantum software development are an actual challenge to overcome. In this scenario, this work presents an implementation of the quantum search algorithm in Atos Quantum Assembly Language (AQASM) using the quantum software stack my Quantum Learning Machine (myQLM) and the programming development platform Quantum Learning Machine (QLM). We present the creation of a virtual quantum processor whose configurable architecture allows the analysis of induced quantum noise effects on the quantum algorithms. The codes are available throughout the manuscript so that readers can replicate them and apply the methods discussed in this article to solve their own quantum computing projects. The presented results are consistent with theoretical predictions and demonstrate that AQASM and QLM are powerful tools for building, implementing, and simulating quantum hardware. Full article\n\n(This article belongs to the Special Issue Quantum Computing in the NISQ Era)\n\n►▼ Show Figures\n\n27 pages, 456 KiB\n\nOpen AccessArticle\n\nA Higher Performance Data Backup Scheme Based on Multi-Factor Authentication\n\nby Lingfeng Wu, Yunhua Wen and Jinghai Yi\n\nEntropy 2024, 26(8), 667; https://doi.org/10.3390/e26080667 - 5 Aug 2024\n\nAbstract\n\nRemote data backup technology avoids the risk of data loss and tampering, and has higher security compared to local data backup solutions. However, the data transmission channel for remote data backup is not secure, and the backup server cannot be fully trusted, so [...] Read more.\n\nRemote data backup technology avoids the risk of data loss and tampering, and has higher security compared to local data backup solutions. However, the data transmission channel for remote data backup is not secure, and the backup server cannot be fully trusted, so users usually encrypt the data before uploading it to the remote server. As a result, how to protect this encryption key is crucial. We design a User-Centric Design (UCD) data backup scheme based on multi-factor authentication to protect this encryption key. Our scheme utilizes a secret sharing scheme to divide the encryption key into three parts, which are stored in the laptop, the smart card, and the server. The encryption key can be easily reconstructed from any two parts with user’s private information password, identity and biometrics. As long as the biometrics has enough entropy, our scheme can resist replay attacks, impersonation user attacks, impersonation server attacks, malicious servers and offline password guessing attacks. Full article\n\n(This article belongs to the Special Issue Information Security and Data Privacy)\n\n►▼ Show Figures\n\n24 pages, 4949 KiB\n\nOpen AccessArticle\n\nAssessment of Fractal Synchronization during an Epileptic Seizure\n\nby Oleg Gorshkov and Hernando Ombao\n\nEntropy 2024, 26(8), 666; https://doi.org/10.3390/e26080666 - 5 Aug 2024\n\nAbstract\n\nIn this paper, we define fractal synchronization (FS) based on the idea of stochastic synchronization and propose a mathematical apparatus for estimating FS. One major advantage of our proposed approach is that fractal synchronization makes it possible to estimate the [...] Read more.\n\nIn this paper, we define fractal synchronization (FS) based on the idea of stochastic synchronization and propose a mathematical apparatus for estimating FS. One major advantage of our proposed approach is that fractal synchronization makes it possible to estimate the aggregate strength of the connection on multiple time scales between two projections of the attractor, which are time series with a fractal structure. We believe that one of the promising uses of FS is the assessment of the interdependence of encephalograms. To demonstrate this approach in evaluating the cross-dependence between channels in a network of electroencephalograms, we evaluated the FS of encephalograms during an epileptic seizure. Fractal synchronization demonstrates the presence of desynchronization during an epileptic seizure. Full article\n\n(This article belongs to the Special Issue Fractal and Multifractal Analysis of Complex Networks II)\n\n►▼ Show Figures\n\n19 pages, 2444 KiB\n\nOpen AccessArticle\n\nFractional Telegrapher’s Equation under Resetting: Non-Equilibrium Stationary States and First-Passage Times\n\nby Katarzyna Górska, Francisco J. Sevilla, Guillermo Chacón-Acosta and Trifce Sandev\n\nEntropy 2024, 26(8), 665; https://doi.org/10.3390/e26080665 - 5 Aug 2024\n\nAbstract\n\nWe consider two different time fractional telegrapher’s equations under stochastic resetting. Using the integral decomposition method, we found the probability density functions and the mean squared displacements. In the long-time limit, the system approaches non-equilibrium stationary states, while the mean squared displacement saturates [...] Read more.\n\nWe consider two different time fractional telegrapher’s equations under stochastic resetting. Using the integral decomposition method, we found the probability density functions and the mean squared displacements. In the long-time limit, the system approaches non-equilibrium stationary states, while the mean squared displacement saturates due to the resetting mechanism. We also obtain the fractional telegraph process as a subordinated telegraph process by introducing operational time such that the physical time is considered as a Lévy stable process whose characteristic function is the Lévy stable distribution. We also analyzed the survival probability for the first-passage time problem and found the optimal resetting rate for which the corresponding mean first-passage time is minimal. Full article\n\n(This article belongs to the Special Issue Theory and Applications of Hyperbolic Diffusion and Shannon Entropy)\n\n►▼ Show Figures\n\n14 pages, 605 KiB\n\nOpen AccessArticle\n\nA Hierarchical Multi-Task Learning Framework for Semantic Annotation in Tabular Data\n\nby Jie Wu and Mengshu Hou\n\nEntropy 2024, 26(8), 664; https://doi.org/10.3390/e26080664 - 4 Aug 2024\n\nAbstract\n\nTo optimize the utilization and analysis of tables, it is essential to recognize and understand their semantics comprehensively. This requirement is especially critical given that many tables lack explicit annotations, necessitating the identification of column types and inter-column relationships. Such identification can significantly [...] Read more.\n\nTo optimize the utilization and analysis of tables, it is essential to recognize and understand their semantics comprehensively. This requirement is especially critical given that many tables lack explicit annotations, necessitating the identification of column types and inter-column relationships. Such identification can significantly augment data quality, streamline data integration, and support data analysis and mining. Current table annotation models often address each subtask independently, which may result in the neglect of constraints and contextual information, causing relational ambiguities and inference errors. To address this issue, we propose a unified multi-task learning framework capable of concurrently handling multiple tasks within a single model, including column named entity recognition, column type identification, and inter-column relationship detection. By integrating these tasks, the framework exploits their interrelations, facilitating the exchange of shallow features and the sharing of representations. Their cooperation enables each task to leverage insights from the others, thereby improving the performance of individual subtasks and enhancing the model’s overall generalization capabilities. Notably, our model is designed to employ only the internal information of tabular data, avoiding reliance on external context or knowledge graphs. This design ensures robust performance even with limited input information. Extensive experiments demonstrate the superior performance of our model across various tasks, validating the effectiveness of unified multi-task learning framework in the recognition and comprehension of table semantics. Full article\n\n(This article belongs to the Special Issue Natural Language Processing and Data Mining)\n\n►▼ Show Figures\n\n29 pages, 374 KiB\n\nOpen AccessArticle\n\nExact Expressions for Kullback–Leibler Divergence for Multivariate and Matrix-Variate Distributions\n\nby Victor Nawa and Saralees Nadarajah\n\nEntropy 2024, 26(8), 663; https://doi.org/10.3390/e26080663 - 4 Aug 2024\n\nAbstract\n\nThe Kullback–Leibler divergence is a measure of the divergence between two probability distributions, often used in statistics and information theory. However, exact expressions for it are not known for multivariate or matrix-variate distributions apart from a few cases. In this paper, exact expressions [...] Read more.\n\nThe Kullback–Leibler divergence is a measure of the divergence between two probability distributions, often used in statistics and information theory. However, exact expressions for it are not known for multivariate or matrix-variate distributions apart from a few cases. In this paper, exact expressions for the Kullback–Leibler divergence are derived for over twenty multivariate and matrix-variate distributions. The expressions involve various special functions. Full article\n\n(This article belongs to the Section Information Theory, Probability and Statistics)\n\n10 pages, 3306 KiB\n\nOpen AccessArticle\n\nModified Gravity in the Presence of Matter Creation: Scenario for the Late Universe\n\nby Giovanni Montani, Nakia Carlevaro and Mariaveronica De Angelis\n\nEntropy 2024, 26(8), 662; https://doi.org/10.3390/e26080662 - 4 Aug 2024\n\nAbstract\n\nWe consider a dynamic scenario for characterizing the late Universe evolution, aiming to mitigate the Hubble tension. Specifically, we consider a metric f(R) gravity in the Jordan frame which is implemented to the dynamics of a flat isotropic Universe. This [...] Read more.\n\nWe consider a dynamic scenario for characterizing the late Universe evolution, aiming to mitigate the Hubble tension. Specifically, we consider a metric f(R) gravity in the Jordan frame which is implemented to the dynamics of a flat isotropic Universe. This cosmological model incorporates a matter creation process, due to the time variation of the cosmological gravitational field. We model particle creation by representing the isotropic Universe (specifically, a given fiducial volume) as an open thermodynamic system. The resulting dynamical model involves four unknowns: the Hubble parameter, the non-minimally coupled scalar field, its potential, and the energy density of the matter component. We impose suitable conditions to derive a closed system for these functions of the redshift. In this model, the vacuum energy density of the present Universe is determined by the scalar field potential, in line with the modified gravity scenario. Hence, we construct a viable model, determining the form of the f(R) theory a posteriori and appropriately constraining the phenomenological parameters of the matter creation process to eliminate tachyon modes. Finally, by analyzing the allowed parameter space, we demonstrate that the Planck evolution of the Hubble parameter can be reconciled with the late Universe dynamics, thus alleviating the Hubble tension. Full article\n\n(This article belongs to the Special Issue Modified Gravity: From Black Holes Entropy to Current Cosmology IV)\n\n►▼ Show Figures"
    }
}