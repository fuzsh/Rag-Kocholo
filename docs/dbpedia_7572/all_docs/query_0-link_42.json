{
    "id": "dbpedia_7572_0",
    "rank": 42,
    "data": {
        "url": "https://asr.copernicus.org/articles/16/223/2019/",
        "read_more_link": "",
        "language": "en",
        "title": "Observation Preprocessing System for RC LACE (OPLACE)",
        "top_image": "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-avatar-web.png",
        "meta_img": "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-avatar-web.png",
        "images": [
            "https://contentmanager.copernicus.org/1575306/28/ssl",
            "https://contentmanager.copernicus.org/1575306/28/ssl",
            "https://www.advances-in-science-and-research.net/licenceSVG_16.svg",
            "https://www.advances-in-science-and-research.net/licenceSVG_16.svg",
            "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-avatar-thumb150.png",
            "https://www.advances-in-science-and-research.net/mendeley.png",
            "https://www.advances-in-science-and-research.net/reddit.png",
            "https://www.advances-in-science-and-research.net/twitter.png",
            "https://www.advances-in-science-and-research.net/facebook.png",
            "https://www.advances-in-science-and-research.net/linkedin.png",
            "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-f01-thumb.png",
            "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-f02-thumb.png",
            "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-t01-thumb.png",
            "https://asr.copernicus.org/articles/16/223/2019/asr-16-223-2019-f03-thumb.png",
            "https://www.advances-in-science-and-research.net/mendeley.png",
            "https://www.advances-in-science-and-research.net/reddit.png",
            "https://www.advances-in-science-and-research.net/twitter.png",
            "https://www.advances-in-science-and-research.net/facebook.png",
            "https://www.advances-in-science-and-research.net/linkedin.png",
            "https://contentmanager.copernicus.org/319376/28/ssl"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "TrojÃ¡kovÃ¡",
            "MÃ¡tÃ©"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Abstract. Meteorological observations are indispensable for the initialization of numerical weather prediction (NWP) forecast.\nTo enable the application of observations in NWP models a technical preprocessing is necessary.\nWithin the framework of RC LACE\n(Regional Cooperation for Limited Area modelling in Central Europe) consortium,\na common observation preprocessing system (OPLACE) has been built up to deliver\nmeteorological observations in an appropriate format for data assimilation in the NWP system ALADIN (Air LimiteÃ©e Adaptation Dynamique DÃ©veloppment International)\nThe purpose of this paper is to document the OPLACE data sources, preprocessing steps\nand means to make preprocessed observations available.\nFurthermore, it describes an exchange of dense national surface synoptic measurements and high-resolution aircraft data in real-time among RC LACE national meteorological services (NMS) of Austria, Croatia, the Czech Republic, Hungary, Romania, Slovakia, and Slovenia.",
        "meta_lang": "en",
        "meta_favicon": "https://www.advances-in-science-and-research.net/favicon_copernicus_16x16_.ico",
        "meta_site_name": "",
        "canonical_link": "https://asr.copernicus.org/articles/16/223/2019/",
        "text": "Numerical weather prediction (NWP) is an initial-value problem where numerical forecast is obtained by integration of the governing equations of geophysical fluid dynamics from initial values of the meteorological fields (Morel,Â 1981). Information about the state of the atmosphere is given by meteorological observations, such as surface observations from land and ship stations, upper-air observations from radiosondes and aircraft, and remote sensing observations from satellites and weather radars. Despite of many data sources, the observations are not available in sufficent quantity and with sufficient accuracy. The observations have to be combined with a NWP forecast through the process of data assimilation to provide the initial values for NWP (Kalnay,Â 2003; Rabier,Â 2005).\n\nThe World Meteorological Organization (WMO) World Weather Watch (WWW) programme ensures the provision and exchange of meteorological observations to support research and operational work in area of weather forecasting. A large variety of observation platforms involves various data formats (WMO,Â 2015), such as Traditional Alphanumeric Codes (TAC), Binary Universal Form for the Representation of meteorological data (BUFR), and General Representation of fields In Binary (GRIB). In order to facilitate the use of observations in operational NWP, a preprocessing step is needed to treat the measured data. The preprocessing step usually consists of a real time data acquisition and decoding. There might be further steps involved, such as data storage, quality control, and additional format conversions.\n\nNWP is time-critical and computationally demanding. Preprocessing a maximum number of observations is a vital precondition for data assimilation. Therefore, a maximum number of observations should be acquired and transformed to NWP suitable formats, as quickly as possible.\n\nDespite of a long and fruitful collaboration on limited-area NWP within the Regional Cooperation for Limited Area modelling in Central Europe (RC LACE; Wang et al.,Â 2018) the observation preprocessing was originally a responsibility of each National Meteorogical Service (NMS). Consequently data assimilation was implemented rather slowly, e.g. the three-dimensional variational data assimilation (3D-Var; BÃ¶lÃ¶ni,Â 2006) became operational in Hungary in 2005, surface analysis based on optimal interpolation was implemented in Czech Republic and Hungary in 2006 and 2008, respectively. In order to support operational data assimilation within RC LACE Programme, an internal project was proposed in 2008. The core component was a development of a common system to preprocess meteorological observations for RC LACE (OPLACE). The OPLACE system has been aimed to:\n\nuse limited staff resources efficiently and to reduce computational and network communication costs;\n\nto provide preprocessed meteorological observations in an appropriate format for data assimilation in ALADIN system (Termonia et al.,Â 2018). Historically the ALADIN system supported a single proprietary ASCII format (OBSOUL). Other formats such as BUFR and GRIB has been implemented progressively;\n\nto provide a platform for exchange of high-resolution observations, such as dense synoptic networks, and radar data, which are not covered by existing WMO programmes. Such observations will be referred to as the local observations hereafter.\n\nFinally it turned out that OPLACE was a key ingredient for the successful implementation of the data assimilation in local NWP suites of RC LACE countries (Fig.Â 1) and it has ensured a reliable base for operational NWP purposes.\n\nThis paper is organized as follows. The OPLACE system, its data sources, processing techniques, and outputs will be described in Sect.Â 2. SectionÂ 2.4 is dedicated to the real time exchange of the local observations. Finally conclusions and a short outlook will be given in Sect.Â 3.\n\nThe OPLACE system has been hosted by Hungarian Meteorological Service (HMS) since 2009. It was based on already existing infrastructure of HMS, e.g. data acquisition, databases of conventional observations, and satellite data processing. The observations are acquired from different sources and are subject to decoding, format conversions, eventually a simple quality control.\n\n2.1âData source and inputs\n\nAt the time of writing OPLACE provides observations primarily over Europe which has been the area of interest for RC LACE. Conventional observations, e.g., surface synoptic data from land (SYNOP) and ships (SHIP), moored and drifting buoys (BUOY), upper-air sounding (TEMP), wind profiler (E-PROFILE), and aircraft (AMDAR, ACARS) observations, are received via WMO Global Telecommunication System (GTS) in the standard WMO data formats (TAC and BUFR).\n\nRemote sensing data, such as microwave and infrared observations, atmospheric motion vectors, and scatterometer retrievals, are collected by EUMETSATâs dissemination mechanism for the near real-time delivery of data (EUMETCast) from geostationary Meteorological Satellite (Meteosat), from polar orbiting Meteorological Operational (MetOp) and National Oceanic and Atmospheric Administration (NOAA) satellites. The data provided by EUMETCast are processed up to different levels before their distribution (WMO,Â 2019):\n\nSEVIRI data are retrieved as Level 1.5, i.e., instrument data (digital counts) with geolocation and calibration information;\n\nAMSU-A/B, MHS, HIRS, ATMS, and IASI data are retrieved as Level 1c, i.e., instrument data with geolocation information and converted to brightness temperature or reflectance factor;\n\nASCAT scatterometer retrievals as Level 2, i.e., instrument data converted to geophysical quantity (ocean winds).\n\nMost of satellite data are fetched in BUFR format except for SEVIRI data which are retrieved in High Rate Information Transmission (HRIT) standard used by satellite operators for the dissemination of data to users via direct broadcast.\n\n2.2âProcessing technique\n\nA level of processing may differ for a given observation or a group of observations. The central task of the preprocessing is the data conversion to appropriate format for data assimilation in the ALADIN system. Particularities of various observation types are discussed and a short description of general processing tasks is given.\n\n2.2.1âConventional observations\n\nThe conventional observations (except for wind profiler data) are decoded by HMS observation team using locally developed decoders. Selected information is stored in local Network Common Data Form (netCDF) databases. These databases are not used by OPLACE exclusively but serve as inputs for other tools and local applications at HMS, e.g., visualization and verification. Incoming GTS data, in particular SYNOP and TEMP, may be delayed, repeated or corrected. The observations should be processed correspondingly, e.g. the corrections overwrite previous values in the databases.\n\nDespite of a good progress in the WMO migration (WMO,Â 2002) from the TAC to the Table Driven Code Forms (TDCF) many SYNOP and TEMP data are still received in both TAC and BUFR formats. Both streams are considered in the processing and duplications are eliminated.\n\nThe data conversion to appropriate format for data assimilation in the ALADIN system is performed by the OULAN program developed at MÃ©tÃ©o France. The program has been designed to read observations from a local database and to write the data in the proprietary ASCII format called OBSOUL. Originally all observation types were processed by the OULAN program, but progressively more data formats, e.g., BUFR, netCDF, are supported by the ALADIN system so the OULAN may become obsolete in the future.\n\nThe OULAN program has been adapted at HMS to use the local netCDF databases of conventional data. A very simple quality control is performed within the OULAN program. The program rejects observations with undefined identification, date or altitude, when position is missing or out of sphere and when wind components cannot be deduced from reported wind speed and direction (in case of a weak and variable wind). Additionally, the relative and specific humidity are computed from temperature and dew point temperature (if not available in the original report). The OULAN program supports a possibility to employ an additional data rejection based on external quality controls flags, but this has not been used within OPLACE implementation. The processing chain of SYNOP data is illustrated in Fig.Â 2a.\n\n2.2.2âRemote sensing observations\n\nHistorically remote sensing observations were processed by the OULAN as well, and there was an additional preprocessing step of EUMETSAT ATOVS and AVHRR Pre-processing Package (AAPP) involved in format conversions. Currently there is no specific preprocessing of AMSU-A/B, MHS, HIRS, ATMS, and IASI Level 1c data which can be handled by the ALADIN system directly as well as ASCAT LevelÂ 2 data.\n\nAtmospheric motion vectors (AMV), derived by tracking the motion of clouds and other atmospheric constituents, can be obtained either as a final product (GEOWIND) from Meteosat Second Generation (MSG) satellites via EUMETCast (EUMETSAT,Â 2015), or a more high-resolution set of AMVs from MSG (HRWIND) can be obtained by EUMETSAT Satellite Application Facility on support to Nowcasting and Very short range forecasting (NWC SAF; EUMETSAT,Â 2013). The NWC SAF version 2013 has been used for production of HRWIND observations. Both AMVs products are in BUFR format supported by the ALADIN system, and AMVs do not require any additional format conversion.\n\nThe SEVIRI data are processed specifically to allow assimilation of selected channels in clear sky conditions or above very low or mid-level clouds (Montmerle et al.,Â 2007). The cloud-type product developed by CMS (Centre de MÃ©tÃ©orologie Spatiale, Lannion, France) in the framework of NWC SAF has been used to derive cloud type information (Derrien et al.,Â 2005). The preprocessing comprises the conversion of selected infrared and water vapour channels from SEVIRI instrument to brightness temperatures and the format conversion from HRIT to GRIB format. The SEVIRI data and auxiliary NWP data, e.g. 3âh forecast from European Centre for Medium-Range Weather Forecasts (ECMWF), serve as input to NWC SAF to determine cloud mask and geolocation information. Furthermore, a dedicated program is necessary to generate date and time information from the beginning of the scan. All intermediate information is finally converted into a single GRIB file (Fig.Â 2b).\n\n2.2.3âGeneral processing\n\nApart from observation specific procedures and format conversions described above there are general tasks, such as data handling (fetching, partition, uploading) and monitoring. Processed observations are split in hourly time-slots (defined as Â±30âmin interval of the given hour) and separated by observation type and file format. The separation gives users a flexibility to get data according their needs. Taking into account various inputs and processing techniques it is important to carefully monitor the whole processing chain. Processing steps are traced in log files and missing data or any issue is reported via e-mail.\n\n2.3âOutput and data availability technique\n\nA File Transfer Protocol (FTP) server is used to facilitate the transfer of data. Processed observations are organized in a directory structure corresponding to the separation by hourly time-slots, observation type, and file format. The outputs are kept on the server for 6âd to enable a restart of operational applications in case of a short hardware or software malfunction. An archive is not part of the system and it is up to the users to store the data permanently. The OPLACE system runs regularly (as of today every twenty minutes) to update fresh or delayed observations to the FTP server. TableÂ 1 presents an actual overview of available observations and file formats.\n\n2.4âExchange of the local observations\n\nHigh-resolution observations are important for initialization of NWP at convection-permitting scales but they are not always covered by existing WMO programmes. For example modern air traffic surveillance systems (Mode-S radars) have received substantial attention in recent years due to its capability to provide not only an accurate knowledge of the position of the aircraft, but also meteorological information (de Haan,Â 2011; Strajnar,Â 2012). Another substantial number of local observations exists in dense regional synoptic or geodetic networks.\n\nAn extension of OPLACE was proposed to support the exchange of the local observations for operational NWP. Given that acquisition and preprocessing of the local observations can be very complex, see de Haan (2011) for Mode-S data, we have proposed to exchange data that have already been preprocessed as much as possible. The OPLACE system then provides a platform (FTP server) for the exchange, but it can eventually perform format conversions and the splitting into hourly time-slots.\n\nDense national surface synoptic measurements have been exchanged within RC LACE since 2014, recently the national synoptic data from Poland were added (Fig.Â 3a). The exchange of high-resolution aircraft Mode-S MRAR (Meteorological Routine Air Report) data from Slovenia became operational in 2015 and has been extended by Mode-S EHS (Enhanced Surveillance) from the Royal Netherlands Meteorological Institute (KNMI) in 2016. Further extension by Mode-S MRAR data from Czech Republic is under preparation (Fig.Â 3b).\n\nThe aim of this paper was to describe the OPLACE system which delivers observations in an appropriate format for data assimilation in the NWP system ALADIN. Details of data acquisition and processing techniques were given to demonstrate the complexity of such observation preprocessing. OPLACE has been developed within the RC LACE consortium and is a good example how NMSs can work together in an effective way and save manpower. Furthermore, OPLACE provides a platform for exchange of the local observations not available in the GTS, such as high-resolution surface synoptic and aircraft Mode-S measurements.\n\nIn the near future, OPLACE will add observations from new satellite sensors such as CrIS. Other data sources, such as GNSS zenith total delay, radar data, and further Mode-S data are under evaluation and might become available through the OPLACE local observation exchange in the future.\n\nFurthermore, more observations bring increasing data volumes and complexity. The first concept of the OPLACE system from 2008 comprised only a limited number of processing tasks which run sequentially from the KornShell script. Over the years the performance has become an issue, in particular the sequential execution. Therefore a redesign of the system was initiated to allow a parallel execution in a controlled state-of-the-art working environment and to improve the system operations and monitoring."
    }
}