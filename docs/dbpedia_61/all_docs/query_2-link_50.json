{
    "id": "dbpedia_61_2",
    "rank": 50,
    "data": {
        "url": "https://profiles.stanford.edu/steven-goodman",
        "read_more_link": "",
        "language": "en",
        "title": "Steven Goodman's Profile",
        "top_image": "https://profiles.stanford.edu/images/favicon.ico;jsessionid=BD927542CA7B44F4667D24BB6834F283.cap-su-capappprd97?r=10.8.0",
        "meta_img": "https://profiles.stanford.edu/images/favicon.ico;jsessionid=BD927542CA7B44F4667D24BB6834F283.cap-su-capappprd97?r=10.8.0",
        "images": [
            "https://profiles.stanford.edu/proxy/api/cap/profiles/23410/resources/profilephoto/350x350.1573844406919.jpg",
            "https://profiles.stanford.edu/images/orcid_32x32.png",
            "https://profiles.stanford.edu/images/orcid_32x32.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "Steven Goodman is part of Stanford Profiles, official site for faculty, postdocs, students and staff information (Expertise, Bio, Research, Publications, and more). The site facilitates research and collaboration in academic endeavors.",
        "meta_lang": "en",
        "meta_favicon": "/images/favicon.ico;jsessionid=BD927542CA7B44F4667D24BB6834F283.cap-su-capappprd97?r=10.8.0",
        "meta_site_name": "",
        "canonical_link": "https://profiles.stanford.edu/steven-goodman;jsessionid=BD927542CA7B44F4667D24BB6834F283.cap-su-capappprd97",
        "text": "Abstract\n\nWe use information derived from over 40K trials in the Cochrane Collaboration database of systematic reviews (CDSR) to compute the replication probability, or predictive power of an experiment given its observed (two-sided) P $$ P $$ -value. We find that an exact replication of a marginally significant result with P = . 05 $$ P=.05 $$ has less than 30% chance of again reaching significance. Moreover, the replication of a result with P = . 005 $$ P=.005 $$ still has only 50% chance of significance. We also compute the probability that the direction (sign) of the estimated effect is correct, which is closely related to the type S error of Gelman and Tuerlinckx. We find that if an estimated effect has P = . 05 $$ P=.05 $$ , there is a 93% probability that its sign is correct. If P = . 005 $$ P=.005 $$ , then that probability is 99%. Finally, we compute the required sample size for a replication study to achieve some specified power conditional on the p $$ p $$ -value of the original study. We find that the replication of a result with P = . 05 $$ P=.05 $$ requires a sample size more than 16 times larger than the original study to achieve 80% power, while P = . 005 $$ P=.005 $$ requires at least 3.5 times larger sample size. These findings confirm that failure to replicate the statistical significance of a trial does not necessarily indicate that the original result was a fluke.\n\nView details for DOI 10.1002/sim.9406\n\nView details for PubMedID 35396714\n\nAbstract\n\nImportance: Infection with COVID-19 has been associated with long-term symptoms, but the frequency, variety, and severity of these complications are not well understood. Many published commentaries have proposed plans for pandemic control that are primarily based on mortality rates among older individuals without considering long-term morbidity among individuals of all ages. Reliable estimates of such morbidity are important for patient care, prognosis, and development of public health policy.Objective: To conduct a systematic review of studies examining the frequency and variety of persistent symptoms after COVID-19 infection.Evidence Review: A search of PubMed and Web of Science was conducted to identify studies published from January 1, 2020, to March 11, 2021, that examined persistent symptoms after COVID-19 infection. Persistent symptoms were defined as those persisting for at least 60 days after diagnosis, symptom onset, or hospitalization or at least 30 days after recovery from the acute illness or hospital discharge. Search terms included COVID-19, SARS-CoV-2, coronavirus, 2019-nCoV, long-term, after recovery, long-haul, persistent, outcome, symptom, follow-up, and longitudinal. All English-language articles that presented primary data from cohort studies that reported the prevalence of persistent symptoms among individuals with SARS-CoV-2 infection and that had clearly defined and sufficient follow-up were included. Case reports, case series, and studies that described symptoms only at the time of infection and/or hospitalization were excluded. A structured framework was applied to appraise study quality.Findings: A total of 1974 records were identified; of those, 1247 article titles and abstracts were screened. After removal of duplicates and exclusions, 92 full-text articles were assessed for eligibility; 47 studies were deemed eligible, and 45 studies reporting 84 clinical signs or symptoms were included in the systematic review. Of 9751 total participants, 5266 (54.0%) were male; 30 of 45 studies reported mean or median ages younger than 60 years. Among 16 studies, most of which comprised participants who were previously hospitalized, the median proportion of individuals experiencing at least 1 persistent symptom was 72.5% (interquartile range [IQR], 55.0%-80.0%). Individual symptoms occurring most frequently included shortness of breath or dyspnea (26 studies; median frequency, 36.0%; IQR, 27.6%-50.0%), fatigue or exhaustion (25 studies; median frequency, 40.0%; IQR, 31.0%-57.0%), and sleep disorders or insomnia (8 studies; median 29.4%, IQR, 24.4%-33.0%). There were wide variations in the design and quality of the studies, which had implications for interpretation and often limited direct comparability and combinability. Major design differences included patient populations, definitions of time zero (ie, the beginning of the follow-up interval), follow-up lengths, and outcome definitions, including definitions of illness severity.Conclusions and Relevance: This systematic review found that COVID-19 symptoms commonly persisted beyond the acute phase of infection, with implications for health-associated functioning and quality of life. Current studies of symptom persistence are highly heterogeneous, and future studies need longer follow-up, improved quality, and more standardized designs to reliably quantify risks.\n\nView details for DOI 10.1001/jamanetworkopen.2021.11417\n\nView details for PubMedID 34037731\n\nAbstract\n\nSubstantial COVID-19 research investment has been allocated to randomized clinical trials (RCTs) on hydroxychloroquine/chloroquine, which currently face recruitment challenges or early discontinuation. We aim to estimate the effects of hydroxychloroquine and chloroquine on survival in COVID-19 from all currently available RCT evidence, published and unpublished. We present a rapid meta-analysis of ongoing, completed, or discontinued RCTs on hydroxychloroquine or chloroquine treatment for any COVID-19 patients (protocol: https://osf.io/QESV4/ ). We systematically identified unpublished RCTs (ClinicalTrials.gov, WHO International Clinical Trials Registry Platform, Cochrane COVID-registry up to June 11, 2020), and published RCTs (PubMed, medRxiv and bioRxiv up to October 16, 2020). All-cause mortality has been extracted (publications/preprints) or requested from investigators and combined in random-effects meta-analyses, calculating odds ratios (ORs) with 95% confidence intervals (CIs), separately for hydroxychloroquine and chloroquine. Prespecified subgroup analyses include patient setting, diagnostic confirmation, control type, and publication status. Sixty-three trials were potentially eligible. We included 14 unpublished trials (1308 patients) and 14 publications/preprints (9011 patients). Results for hydroxychloroquine are dominated by RECOVERY and WHO SOLIDARITY, two highly pragmatic trials, which employed relatively high doses and included 4716 and 1853 patients, respectively (67% of the total sample size). The combined OR on all-cause mortality for hydroxychloroquine is1.11 (95% CI: 1.02, 1.20; I=0%; 26 trials; 10,012 patients) and for chloroquine 1.77 (95%CI: 0.15, 21.13, I=0%; 4 trials; 307 patients). We identified no subgroup effects. We found that treatment with hydroxychloroquine is associated with increased mortality in COVID-19 patients, and there is no benefit of chloroquine. Findings have unclear generalizability to outpatients, children, pregnant women, and people with comorbidities.\n\nView details for DOI 10.1038/s41467-021-22446-z\n\nView details for PubMedID 33859192\n\nAbstract\n\nThe U.S. Food and Drug Administration (FDA) has substantial flexibility in its approval criteria in the context of life-threatening disease and unmet therapeutic need.To understand the FDA's evidentiary standards when flexible criteria are employed.Case series.Applications submitted between 2013 and 2018 that went through multiple review cycles because the evidence for clinical efficacy was initially deemed insufficient.Information was obtained from the approval package (available on Drugs@FDA), including advisory committee minutes, FDA reviews, and complete response letters.Of 912 applications reviewed, 117 went through multiple review cycles; only 22 of these faced additional review primarily because of issues related to clinical efficacy. Concerns about the end point, the clinical meaningfulness of the observed effect, and inconsistent results were common bases for initial rejection. In 7 of the 22 cases, the approval did not require new evidence but rather new interpretations of the original evidence. No FDA decisions cited reasoning used in previous decisions.The conclusions rely on the authors' interpretation of the FDA statements and on a series of \"close calls.\"The FDA has no mechanism to find or tradition to cite similar cases when weighing evidence for approvals, resulting in standalone, bespoke decisions. These decisions show highly variable criteria for \"substantial evidence\" when flexible evidential criteria are used, highlighted by the recent approval of aducanumab. A precedential tradition and suitable information system are required for the FDA to improve institutional memory and build upon past decisions. These would increase the FDA's decisional transparency, consistency, and predictability, which are critical to preserving the FDA's most valuable asset, the public's trust.U.S. Food and Drug Administration.\n\nView details for DOI 10.7326/M21-2918\n\nView details for PubMedID 34543584\n\nAbstract\n\nMost research manuscripts are not accepted for publication on first submission. A major part of the resubmission process is reformatting to another journal's specific requirements, a process separate from revising the scientific content. There has been little research to understand the magnitude of the burden imposed by the current resubmission process.We analyzed original research article submission requirements from twelve randomly selected journals in each of eight scientific and clinical focus areas from the InCites Journal Citation Reports database. From the 96 journals selected, we randomly identified three recently published manuscripts and sent surveys to those first and/or corresponding authors (288 total) to solicit information on time spent reformatting resubmissions and opinions on the process.There was significant variation in manuscript submission requirements for journals within the same scientific focus and only 4% of journals offered a fully format-free initial submission. Of 203 authors responding (71.5% response rate), only 11.8% expressed satisfaction with the resubmission process and 91% desired reforming the current system. Time spent on reformatting delays most publications by at least two weeks and by over three months in about 20% of manuscripts. The effort to comply with submission requirements has significant global economic burden, estimated at over $1.1 billion dollars annually when accounting for a research team's time.We demonstrate that there is significant resource utilization associated with resubmitting manuscripts, heretofore not properly quantified. The vast majority of authors are not satisfied with the current process. Addressing these issues by reconciling reformatting requirements among journals or adopting a universal format-free initial submission policy would help resolve a major subject for the scientific research community and provide more efficient dissemination of findings.\n\nView details for DOI 10.1371/journal.pone.0223976\n\nView details for PubMedID 31665156\n\nAbstract\n\nAssessment of researchers is necessary for decisions of hiring, promotion, and tenure. A burgeoning number of scientific leaders believe the current system of faculty incentives and rewards is misaligned with the needs of society and disconnected from the evidence about the causes of the reproducibility crisis and suboptimal quality of the scientific publication record. To address this issue, particularly for the clinical and life sciences, we convened a 22-member expert panel workshop in Washington, DC, in January 2017. Twenty-two academic leaders, funders, and scientists participated in the meeting. As background for the meeting, we completed a selective literature review of 22 key documents critiquing the current incentive system. From each document, we extracted how the authors perceived the problems of assessing science and scientists, the unintended consequences of maintaining the status quo for assessing scientists, and details of their proposed solutions. The resulting table was used as a seed for participant discussion. This resulted in six principles for assessing scientists and associated research and policy implications. We hope the content of this paper will serve as a basis for establishing best practices and redesigning the current approaches to assessing scientists by the many players involved in that process.\n\nView details for PubMedID 29596415\n\nAbstract\n\nCausal inference has a central role in public health; the determination that an association is causal indicates the possibility for intervention. We review and comment on the long-used guidelines for interpreting evidence as supporting a causal association and contrast them with the potential outcomes framework that encourages thinking in terms of causes that are interventions. We argue that in public health this framework is more suitable, providing an estimate of an action's consequences rather than the less precise notion of a risk factor's causal effect. A variety of modern statistical methods adopt this approach. When an intervention cannot be specified, causal relations can still exist, but how to intervene to change the outcome will be unclear. In application, the often-complex structure of causal processes needs to be acknowledged and appropriate data collected to study them. These newer approaches need to be brought to bear on the increasingly complex public health challenges of our globalized world.\n\nView details for DOI 10.1146/annurev-publhealth-031811-124606\n\nView details for PubMedID 23297653\n\nAbstract\n\nComparative effectiveness research (CER) is still an evolving framework for which much needs to be done to improve the ability of randomized controlled trials (RCTs) to supply the necessary evidence. Perhaps, most important is to start with a clearly specified decision and decision maker in mind when the RCTs are designed. Second is to initiate RCTs with clinically relevant outcomes and comparators earlier in the evaluation process. Third is to specify and measure factors that might modify the intervention's effect, subject to logistical constraints of complexity and cost, so the trial is maximally informative, about how and to whom the intervention should be administered. It will be necessary to borrow observational methodologies and approaches to extract meaningful causal and subgroup inferences from such trials. Process variables should be seen as potentially part of that framework of effect-modifying factors, perhaps amenable to embedded experimental assessment with a trial. Perhaps most importantly, we need to improve the nationwide CER infrastructure to allow for rapid initiation and accrual for CER trials to reduce the trade-off that often exists between the speed of evidence development and its quality.\n\nView details for DOI 10.1177/1740774511433285\n\nView details for PubMedID 22334465\n\nAbstract\n\nThis review describes methods used in comparative effectiveness research (CER). The aim of CER is to improve decisions that affect medical care at the levels of both policy and the individual. The key elements of CER are (a) head-to-head comparisons of active treatments, (b) study populations typical of day-to-day clinical practice, and (c) a focus on evidence to inform care tailored to the characteristics of individual patients. These requirements will stress the principal methods of CER: observational research, randomized trials, and decision analysis. Observational studies are especially vulnerable because they use data that directly reflect the decisions made in usual practice. CER will challenge researchers and policy makers to think deeply about how to extract more actionable information from the vast enterprise of the daily practice of medicine. Fortunately, the methods are largely applicable to research in the public health system, which should therefore benefit from the intense interest in CER.\n\nView details for DOI 10.1146/annurev-publhealth-031811-124610\n\nView details for Web of Science ID 000304202700026\n\nView details for PubMedID 22224891\n\nAbstract\n\nThe P value is a measure of statistical evidence that appears in virtually all medical research papers. Its interpretation is made extraordinarily difficult because it is not part of any formal system of statistical inference. As a result, the P value's inferential meaning is widely and often wildly misconstrued, a fact that has been pointed out in innumerable papers and books appearing since at least the 1940s. This commentary reviews a dozen of these common misinterpretations and explains why each is wrong. It also reviews the possible consequences of these improper understandings or representations of its meaning. Finally, it contrasts the P value with its Bayesian counterpart, the Bayes' factor, which has virtually all of the desirable properties of an evidential measure that the P value lacks, most notably interpretability. The most serious consequence of this array of P-value misconceptions is the false belief that the probability of a conclusion being in error can be calculated from the data in a single experiment without reference to external evidence or the plausibility of the underlying mechanism.\n\nView details for DOI 10.1053/j.seminhematol.2008.04.003\n\nView details for Web of Science ID 000257501600002\n\nView details for PubMedID 18582619\n\nAbstract\n\nA community of scientists arrives at the truth by independently verifying new observations. In this time-honored process, journals serve 2 principal functions: evaluative and editorial. In their evaluative function, they winnow out research that is unlikely to stand up to independent verification; this task is accomplished by peer review. In their editorial function, they try to ensure transparent (by which we mean clear, complete, and unambiguous) and objective descriptions of the research. Both the evaluative and editorial functions go largely unnoticed by the public--the former only draws public attention when a journal publishes fraudulent research. However, both play a critical role in the progress of science. This paper is about both functions. We describe the evaluative processes we use and announce a new policy to help the scientific community evaluate, and build upon, the research findings that we publish.\n\nView details for Web of Science ID 000245192200007\n\nView details for PubMedID 17339612\n\nAbstract\n\nBayesian inference is a formal method to combine evidence external to a study, represented by a prior probability curve, with the evidence generated by the study, represented by a likelihood function. Because Bayes theorem provides a proper way to measure and to combine study evidence, Bayesian methods can be viewed as a calculus of evidence, not just belief. In this introduction, we explore the properties and consequences of using the Bayesian measure of evidence, the Bayes factor (in its simplest form, the likelihood ratio). The Bayes factor compares the relative support given to two hypotheses by the data, in contrast to the P-value, which is calculated with reference only to the null hypothesis. This comparative property of the Bayes factor, combined with the need to explicitly predefine the alternative hypothesis, produces a different assessment of the strength of evidence against the null hypothesis than does the P-value, and it gives Bayesian procedures attractive frequency properties. However, the most important contribution of Bayesian methods is the way in which they affect both who participates in a scientific dialogue, and what is discussed. With the emphasis moved from \"error rates\" to evidence, content experts have an opportunity for their input to be meaningfully incorporated, making it easier for regulatory decisions to be made correctly.\n\nView details for DOI 10.1191/1740774505cn098oa\n\nView details for Web of Science ID 000232648100004\n\nView details for PubMedID 16281426\n\nAbstract\n\nGuillain-Barré syndrome (GBS) is a rare neurologic disease that occurs at all ages, causing a progressive, ascending paralysis that usually resolves over weeks or months. The disease appears to be identical in children and adults, except that children recover more quickly, with fewer residua. For patients who lose the ability to walk independently, the main treatment options are plasmapheresis or intravenous immune globulin (IVIg), treatments that have shown to have identical effectiveness in adults in two large RCTs involving 388 patients. The effectiveness of the treatments in children has only been studied in small, poorly controlled studies. If one could capture all eligible patients in the United States, only about 100-300 children would be available for a trial annually.The goal of this case was to demonstrate how Bayesian methods could be used to incorporate prior information on treatment efficacy from adults to design a randomized noninferiority trial of IVIg versus plasmapheresis in children. A Bayesian normal-normal model on the hazard ratio of time to independent walking was implemented.An evidence-based prior was constructed that was equivalent to 72 children showing exact equivalence between the therapies. A design was constructed based on a Bayesian normal-normal model on the hazard ratio, yielding a sample size of 160 children, with a preposterior analysis demonstrating a \"Type I\" error rate of 5% and a power of 77%.This case study illustrates a rational approach to constructing an evidence-based prior that would allow information from adults to formally augment data from children to minimize unnecessary pediatric experimentation. The frequentist properties of a Bayesian design can be evaluated and reported as they would be for a standard design. Discussion of the appropriate prior for such designs is both a necessary and desirable feature of Bayesian trials.\n\nView details for DOI 10.1191/1740774505cn102oa\n\nView details for Web of Science ID 000232648100008\n\nView details for PubMedID 16281429\n\nAbstract\n\nBayesian inference is usually presented as a method for determining how scientific belief should be modified by data. Although Bayesian methodology has been one of the most active areas of statistical development in the past 20 years, medical researchers have been reluctant to embrace what they perceive as a subjective approach to data analysis. It is little understood that Bayesian methods have a data-based core, which can be used as a calculus of evidence. This core is the Bayes factor, which in its simplest form is also called a likelihood ratio. The minimum Bayes factor is objective and can be used in lieu of the P value as a measure of the evidential strength. Unlike P values, Bayes factors have a sound theoretical foundation and an interpretation that allows their use in both inference and decision making. Bayes factors show that P values greatly overstate the evidence against the null hypothesis. Most important, Bayes factors require the addition of background knowledge to be transformed into inferences--probabilities that a given conclusion is right or wrong. They make the distinction clear between experimental evidence and inferential conclusions while providing a framework in which to combine prior with current evidence.\n\nView details for Web of Science ID 000080894700008\n\nView details for PubMedID 10383350\n\nAbstract\n\nAn important problem exists in the interpretation of modern medical research data: Biological understanding and previous research play little formal role in the interpretation of quantitative results. This phenomenon is manifest in the discussion sections of research articles and ultimately can affect the reliability of conclusions. The standard statistical approach has created this situation by promoting the illusion that conclusions can be produced with certain \"error rates,\" without consideration of information from outside the experiment. This statistical approach, the key components of which are P values and hypothesis tests, is widely perceived as a mathematically coherent approach to inference. There is little appreciation in the medical community that the methodology is an amalgam of incompatible elements, whose utility for scientific inference has been the subject of intense debate among statisticians for almost 70 years. This article introduces some of the key elements of that debate and traces the appeal and adverse impact of this methodology to the P value fallacy, the mistaken idea that a single number can capture both the long-run outcomes of an experiment and the evidential meaning of a single result. This argument is made as a prelude to the suggestion that another measure of evidence should be used--the Bayes factor, which properly separates issues of long-run behavior from evidential strength and allows the integration of background knowledge with statistical findings.\n\nView details for Web of Science ID 000080894700007\n\nView details for PubMedID 10383371\n\nAbstract\n\nThe Continual Reassessment Method (CRM) is a Bayesian phase I design whose purpose is to estimate the maximum tolerated dose of a drug that will be used in subsequent phase II and III studies. Its acceptance has been hindered by the greater duration of CRM designs compared to standard methods, as well as by concerns with excessive experimentation at high dosage levels, and with more frequent and severe toxicity. This paper presents the results of a simulation study in which one assigns more than one subject at a time to each dose level, and each dose increase is limited to one level. We show that these modifications address all of the most serious criticisms of the CRM, reducing the duration of the trial by 50-67 per cent, reducing toxicity incidence by 20-35 per cent, and lowering toxicity severity. These are achieved with minimal effects on accuracy. Most important, based on our experience at our institution, such modifications make the CRM acceptable to clinical investigators.\n\nView details for Web of Science ID A1995RE49200001\n\nView details for PubMedID 7667557\n\nAbstract\n\nAlthough epidemiologic studies have long associated tobacco and alcohol use with the development of squamous-cell carcinoma of the head and neck, the molecular targets of these carcinogens have yet to be identified. We performed a molecular analysis to determine the pattern of mutations in the p53 gene in neoplasms from patients with squamous-cell carcinoma of the head and neck and a history of tobacco or alcohol use.Sequence analysis of the conserved regions of the p53 gene was performed in tumor samples from 129 patients with primary squamous-cell carcinoma of the head and neck. We then used statistical analysis to identify any patient characteristics associated with mutation of the p53 gene.We found p53 mutations in 42 percent of the patients (54 of 129). Fifty-eight percent of the patients who smoked cigarettes and used alcohol (37 of 64; 95 percent confidence interval, 45 to 70 percent), 33 percent of the patients who smoked but abstained from alcohol (13 of 39; 95 percent confidence interval, 19 to 50 percent), and 17 percent of the patients who neither smoked nor drank alcohol (4 of 24, 95 percent confidence interval, 5 to 37 percent) had p53 mutations (P = 0.001). (Two patients used alcohol but did not smoke, and neither had a p53 mutation.) Furthermore, 100 percent of the mutations in the patients who neither drank nor smoked occurred at sites containing cytidine phosphate guanosine dinucleotides (potentially representing endogenous mutations) within the p53 gene (5 of 5 mutations; 95 percent confidence interval, 48 to 100 percent), whereas only 23 percent of those in cigarette smokers consisted of such changes (12 of 53 mutations; 95 percent confidence interval, 12 to 36 percent; P = 0.001).In our study, a history of tobacco and alcohol use was associated with a high frequency of p53 mutations in patients with squamous-cell carcinoma of the head and neck. Preliminary evidence linked cigarette smoking to p53 mutations at nonendogenous mutation sites. Our findings suggest a role for tobacco in the molecular progression of squamous-cell carcinoma of the head and neck and support the epidemiologic evidence that abstinence from smoking is important to prevent head and neck cancer.\n\nView details for Web of Science ID A1995QL78800004\n\nView details for PubMedID 7854378\n\nAbstract\n\nIt is not generally appreciated that the p value, as conceived by R. A. Fisher, is not compatible with the Neyman-Pearson hypothesis test in which it has become embedded. The p value was meant to be a flexible inferential measure, whereas the hypothesis test was a rule for behavior, not inference. The combination of the two methods has led to a reinterpretation of the p value simultaneously as an \"observed error rate\" and as a measure of evidence. Both of these interpretations are problematic, and their combination has obscured the important differences between Neyman and Fisher on the nature of the scientific method and inhibited our understanding of the philosophic implications of the basic methods in use today. An analysis using another method promoted by Fisher, mathematical likelihood, shows that the p value substantially overstates the evidence against the null hypothesis. Likelihood makes clearer the distinction between error rates and inferential evidence and is a quantitative tool for expressing evidential strength that is more appropriate for the purposes of epidemiology than the p value.\n\nView details for Web of Science ID A1993KX52900001\n\nView details for PubMedID 8465801\n\nAbstract\n\nThis commentary reviews the arguments for and against the use of p-values put forward in the Journal and other forums, and shows that they are all missing both a measure and concept of \"evidence.\" The mathematics and logic of evidential theory are presented, with the log-likelihood ratio used as the measure of evidence. The profoundly different philosophy behind evidential methods (as compared to traditional ones) is presented, as well as a comparative example showing the difference between the two approaches. The reasons why we mistakenly ascribe evidential meaning to p-values and related measures are discussed. Unfamiliarity with the technology and philosophy of evidence is seen as the main reason why certain arguments about p-values persist, and why they are frequently contradictory and confusing.\n\nView details for Web of Science ID A1988R635700013\n\nView details for PubMedID 3189634\n\nAbstract\n\nIn 2002, heterozygous suppressor of fused variants (SUFU+/- ) in the germline were described to have a tumor suppressor role in the development of pediatric medulloblastoma (MB). Other neoplasms associated with pathologic germline SUFU+/- variants have also been described among patients with basal cell nevus syndrome (BCNS; BCNS is also known as Gorlin syndrome, nevoid basal cell carcinoma [BCC] syndrome or Gorlin-Goltz syndrome; OMIM 109400), an autosomal-dominant cancer predisposition syndrome. The phenotype of patients with germline SUFU+/- variants is very poorly characterized due to a paucity of large studies with long-term follow-up. As such, there is a clinical need to better characterize the spectrum of neoplasms among patients with germline SUFU+/- variants so that clinicians can provide accurate counseling and optimize tumor surveillance strategies. The objective of this study is to perform a scoping review to map the evidence on the rate of medulloblastoma and to describe the spectrum of other neoplasms among patients with germline SUFU+/- variants. A review of all published literature in PubMed (MEDLINE), EMBASE, Cochrane, and Web of Science were searched from the beginning of each respective database until October 9, 2021. Studies of pediatric and adult patients with a confirmed germline SUFU+/- variant who were evaluated for the presence of any neoplasm (benign or malignant) were included. There were 176 patients (N = 30 studies) identified with a confirmed germline SUFU+/- variant who met inclusion criteria. Data were extracted from two cohort studies, two case-control studies, 18 case series, and eight case reports. The median age at diagnosis of a germline SUFU+/- variant was 4.5 years where 44.4% identified as female and 13.4% of variants were de novo. There were 34 different neoplasms (benign and malignant) documented among patients with confirmed germline SUFU+/- variants, and the most common were medulloblastoma (N = 59 patients), BCC (N = 21 patients), and meningioma (N = 19 patients). The median age at medulloblastoma diagnosis was 1.42 years (range 0.083-3; interquartile range 1.2). When data were available for these three most frequent neoplasms (N = 95 patients), 31 patients (32.6%) had neither MB, BCC nor meningioma; 51 patients (53.7%) had one of medulloblastoma or BCC or meningioma; eight patients (8.4%) had two of medulloblastoma or BCC or meningioma, and five patients (5.3%) had medulloblastoma and BCC and meningioma. This is the first study to synthesize the data on the frequency and spectrum of neoplasms specifically among patients with a confirmed germline SUFU+/- variant. This scoping review is a necessary step forward in optimizing evidence-based tumor surveillance strategies for medulloblastoma and estimating the risk of other neoplasms that could impact patient outcomes.\n\nView details for DOI 10.1002/ajmg.a.63496\n\nView details for PubMedID 38282294\n\nAbstract\n\nSARS-CoV-2 infection can result in ongoing, relapsing, or new symptoms or other health effects after the acute phase of infection; termed post-acute sequelae of SARS-CoV-2 infection (PASC), or long COVID. The characteristics, prevalence, trajectory and mechanisms of PASC are ill-defined. The objectives of the Researching COVID to Enhance Recovery (RECOVER) Multi-site Observational Study of PASC in Adults (RECOVER-Adult) are to: (1) characterize PASC prevalence; (2) characterize the symptoms, organ dysfunction, natural history, and distinct phenotypes of PASC; (3) identify demographic, social and clinical risk factors for PASC onset and recovery; and (4) define the biological mechanisms underlying PASC pathogenesis.RECOVER-Adult is a combined prospective/retrospective cohort currently planned to enroll 14,880 adults aged ≥18 years. Eligible participants either must meet WHO criteria for suspected, probable, or confirmed infection; or must have evidence of no prior infection. Recruitment occurs at 86 sites in 33 U.S. states, Washington, DC and Puerto Rico, via facility- and community-based outreach. Participants complete quarterly questionnaires about symptoms, social determinants, vaccination status, and interim SARS-CoV-2 infections. In addition, participants contribute biospecimens and undergo physical and laboratory examinations at approximately 0, 90 and 180 days from infection or negative test date, and yearly thereafter. Some participants undergo additional testing based on specific criteria or random sampling. Patient representatives provide input on all study processes. The primary study outcome is onset of PASC, measured by signs and symptoms. A paradigm for identifying PASC cases will be defined and updated using supervised and unsupervised learning approaches with cross-validation. Logistic regression and proportional hazards regression will be conducted to investigate associations between risk factors, onset, and resolution of PASC symptoms.RECOVER-Adult is the first national, prospective, longitudinal cohort of PASC among US adults. Results of this study are intended to inform public health, spur clinical trials, and expand treatment options.NCT05172024.\n\nView details for DOI 10.1371/journal.pone.0286297\n\nView details for PubMedID 37352211\n\nView details for PubMedCentralID PMC10289397\n\nAbstract\n\nBACKGROUND AND OBJECTIVES: Representative enrollment of racial and ethnic minoritized populations in biomedical research ensures the generalizability of results and equitable access to novel therapies. Previous studies on pediatric clinical trial diversity are limited to subsets of journals or disciplines. We aimed to evaluate race and ethnicity reporting and representation in all US pediatric clinical trials on ClinicalTrials.gov.METHODS: We performed a cross-sectional study of US-based clinical trials registered on ClinicalTrials.gov that enrolled participants aged <18 years old between October 2007 and March 2020. We used descriptive statistics, compound annual growth rates, and multivariable logistic regression for data analysis. Estimates of US population statistics and disease burden were calculated with the US Census, Kids' Inpatient Database, and National Survey of Children's Health.RESULTS: Among 1183 trials encompassing 405376 participants, race and ethnicity reporting significantly increased from 27% in 2007 to 87% in 2018 (P < .001). The median proportional enrollment of Asian American children was 0.6% (interquartile range [IQR], 0%-3.7%); American Indian, 0% (IQR, 0%-0%); Black, 12% (IQR, 2.9%-28.4%); Hispanic, 7.1% (IQR, 0%-18.6%); and white 66.4% (IQR, 41.5%-81.6%). Asian American, Black, and Hispanic participants were underrepresented relative to US population demographics. Compared with expected proportions based on disease prevalence and hospitalizations, Asian American and Hispanic participants were most consistently underrepresented across diagnoses.CONCLUSIONS: While race and ethnicity reporting in pediatric clinical trials has improved, the representative enrollment of minoritized participants remains an ongoing challenge. Evidence-based and policy solutions are needed to address these disparities to advance biomedical innovation for all children.\n\nView details for DOI 10.1542/peds.2022-058552\n\nView details for PubMedID 36916197\n\nAbstract\n\nBACKGROUND: Most medical educational programs emphasize clinical observation or clinical skill acquisition, fewer focus upon research. The Danish-American Research Exchange (DARE) program, sponsored by the Lundbeck Foundation, is unique in that the medical student initiates biomedical research collaboration between Danish and US medical institutions. To achieve this, Danish medical students (DARE students) conduct binational mentored research projects while based in the United States for 10months. In addition, DARE students are introduced to interdisciplinary thinking about how to develop ultra-low-cost healthcare interventions through the '$10 Challenge'.METHODS: We conducted a cross-sectional study of DARE alumni over five consecutive years (2015-2020, n=24). Research metrics included completion of a research project, primary authorship, and co-authorship of publications. The number of publications, prior to and after the DARE program were enumerated. For the first four cohorts, graduation from medical school and acceptance or intention to enter a joint MD-PhD program also were assessed. Two focus groups were conducted using constructivist grounded theory. Discussions were transcribed, redacted, and coded using Dedoose software.RESULTS: DARE Medical students were 31.2years (range 24-35), the majority were women (67%;16/24). The majority (17/24;71%) completed a first author publication in a peer-reviewed journal with a median of 3.9 per DARE alumnus. DARE alumnus reported increased proficiency in biostatistics, epidemiology, coding and public speaking as well as stronger research qualities in creativity, critical thinking, comfort in approaching scientist in both the US and Denmark (p<0.001 for all). Qualitative key themes included: increased confidence, a deepening of research inquiry and linkage to a research network.CONCLUSIONS: Preliminarily, this study suggests that medical students can initiate binational collaboration in medicine. Benefits include research productivity, intention to pursue academic medical careers, as well as positive impacts on motivation. This medical student-initiated research model lays the groundwork for using this model across other country pairs to promote binational collaboration.\n\nView details for DOI 10.1186/s12909-023-04002-z\n\nView details for PubMedID 36747167\n\nAbstract\n\nImportance: SARS-CoV-2 infection is associated with persistent, relapsing, or new symptoms or other health effects occurring after acute infection, termed postacute sequelae of SARS-CoV-2 infection (PASC), also known as long COVID. Characterizing PASC requires analysis of prospectively and uniformly collected data from diverse uninfected and infected individuals.Objective: To develop a definition of PASC using self-reported symptoms and describe PASC frequencies across cohorts, vaccination status, and number of infections.Design, Setting, and Participants: Prospective observational cohort study of adults with and without SARS-CoV-2 infection at 85 enrolling sites (hospitals, health centers, community organizations) located in 33 states plus Washington, DC, and Puerto Rico. Participants who were enrolled in the RECOVER adult cohort before April 10, 2023, completed a symptom survey 6 months or more after acute symptom onset or test date. Selection included population-based, volunteer, and convenience sampling.Exposure: SARS-CoV-2 infection.Main Outcomes and Measures: PASC and 44 participant-reported symptoms (with severity thresholds).Results: A total of 9764 participants (89% SARS-CoV-2 infected; 71% female; 16% Hispanic/Latino; 15% non-Hispanic Black; median age, 47 years [IQR, 35-60]) met selection criteria. Adjusted odds ratios were 1.5 or greater (infected vs uninfected participants) for 37 symptoms. Symptoms contributing to PASC score included postexertional malaise, fatigue, brain fog, dizziness, gastrointestinal symptoms, palpitations, changes in sexual desire or capacity, loss of or change in smell or taste, thirst, chronic cough, chest pain, and abnormal movements. Among 2231 participants first infected on or after December 1, 2021, and enrolled within 30 days of infection, 224 (10% [95% CI, 8.8%-11%]) were PASC positive at 6 months.Conclusions and Relevance: A definition of PASC was developed based on symptoms in a prospective cohort study. As a first step to providing a framework for other investigations, iterative refinement that further incorporates other clinical features is needed to support actionable definitions of PASC.\n\nView details for DOI 10.1001/jama.2023.8823\n\nView details for PubMedID 37278994\n\nAbstract\n\nGOAL: The aim was to investigate the short-term impact of time restricted feeding on patients with suspected gastroesophageal reflux disease (GERD).BACKGROUND: Lifestyle modifications are often suggested, but the role of diet in GERD is unclear. Intermittent fasting is popular in the media and has demonstrated potential benefits with weight loss and inflammatory conditions as well as alterations in gastrointestinal hormones.STUDY: Patients who were referred for 96-hour ambulatory wireless pH monitoring off proton pump inhibitor to investigate GERD symptoms were screened for eligibility. Patients were instructed to maintain their baseline diet for the first 2 days of pH monitoring and switch to an intermittent fasting regimen (16 consecutive hour fast and 8h eating window) for the second 2 days. Objective measures of reflux and GERD symptom severity were collected and analyzed.RESULTS: A total of 25 participants were analyzed. 9/25 (36%) fully adhered to the intermittent fasting regimen, with 21/25 (84%) demonstrating at least partial compliance. Mean acid exposure time on fasting days was 3.5% versus 4.3% on nonfasting days. Intermittent fasting was associated with a 0.64 reduction in acid exposure time (95% CI: -2.32, 1.05). There was a reduction in GERD symptom scores of heartburn and regurgitation during periods of intermittent fasting (14.3 vs. 9.9; difference of -4.46, 95% CI: -7.6,-1.32).CONCLUSIONS: Initial adherence to time restricted eating may be difficult for patients. There is weak statistical evidence to suggest that intermittent fasting mildly reduces acid exposure. Our data show that short-term intermittent fasting improves symptoms of both regurgitation and heartburn.\n\nView details for DOI 10.1097/MCG.0000000000001788\n\nView details for PubMedID 36730832\n\nAbstract\n\nTo systematically assess the robustness of reported postacute SARS-CoV-2 infection health outcomes in children.A search on PubMed and Web of Science was conducted to identify studies published up to 22 January 2022 that reported on postacute SARS-CoV-2 infection health outcomes in children (<18 years) with follow-up of ≥2 months since detection of infection or ≥1 month since recovery from acute illness. We assessed the consideration of confounding bias and causality, as well as the risk of bias.21 studies including 81 896 children reported up to 97 symptoms with follow-up periods of 2.0-11.5 months. Fifteen studies had no control group. The reported proportion of children with post-COVID syndrome was between 0% and 66.5% in children with SARS-CoV-2 infection (n=16 986) and between 2.0% and 53.3% in children without SARS-CoV-2 infection (n=64 910). Only two studies made a clear causal interpretation of an association between SARS-CoV-2 infection and the main outcome of 'post-COVID syndrome' and provided recommendations regarding prevention measures. The robustness of all 21 studies was seriously limited due to an overall critical risk of bias.The robustness of reported postacute SARS-CoV-2 infection health outcomes in children is seriously limited, at least in all the published articles we could identify. None of the studies provided evidence with reasonable certainty on whether SARS-CoV-2 infection has an impact on postacute health outcomes, let alone to what extent. Children and their families urgently need much more reliable and methodologically robust evidence to address their concerns and improve care.\n\nView details for DOI 10.1136/archdischild-2022-324455\n\nView details for PubMedID 36719840\n\nAbstract\n\nBACKGROUND AND OBJECTIVES: Unique ethical, epidemiological, and economic factors are barriers to performing research in children. The landscape of pediatric clinical trials, including drivers of completion and timely dissemination of results, is not well understood. We aimed to characterize the prevalence of and factors associated with early discontinuation, results reporting, and publication of pediatric clinical trials registered at ClinicalTrials.gov.METHODS: Cross-sectional analysis of clinical trials enrolling participants <18 years old registered at ClinicalTrials.gov from October 2007 to March 2020. Multivariable logistic regressions were performed to assess the association between trial characteristics and primary outcomes. Publication data were obtained through PubMed, ClinicalTrials.gov, Embase, and Scopus.RESULTS: Overall, 11.1% trials were stopped early, with recruitment failure being the predominant reason for discontinuation. Only 23.5% of completed trials reported results, and 38.8% were published within 3 years of completion. Rates of discontinuation and publication significantly improved over the study period. Among funding sources, government-sponsored trials (adjusted odds ratio [aOR], 0.72; 95% CI, 0.47-0.97) and academic trials (aOR, 0.64; 95% CI, 0.50-0.82) had lower odds of discontinuation compared with industry trials and were more likely to be published (government: aOR, 1.94 [95% CI, 1.52-2.48] academic: aOR, 1.61 [95% CI, 1.35-1.92). Academic trial investigators were the least likely to report results (aOR, 0.34; 95% CI, 0.31-0.52).CONCLUSIONS: Early discontinuation and nonreporting/nonpublication of findings remain common in registered pediatric clinical trials and were associated with funding source and other trial features. Targeted efforts are needed to support trial completion and timely results dissemination toward strengthening evidence-based pediatric medicine.\n\nView details for DOI 10.1542/peds.2021-052557\n\nView details for PubMedID 35314864\n\nAbstract\n\nBACKGROUND: Convalescent plasma has been widely used to treat COVID-19 and is under investigation in numerous randomized clinical trials, but results are publicly available only for a small number of trials. The objective of this study was to assess the benefits of convalescent plasma treatment compared to placebo or no treatment and all-cause mortality in patients with COVID-19, using data from all available randomized clinical trials, including unpublished and ongoing trials (Open Science Framework, https://doi.org/10.17605/OSF.IO/GEHFX ).METHODS: In this collaborative systematic review and meta-analysis, clinical trial registries (ClinicalTrials.gov, WHO International Clinical Trials Registry Platform), the Cochrane COVID-19 register, the LOVE database, and PubMed were searched until April 8, 2021. Investigators of trials registered by March 1, 2021, without published results were contacted via email. Eligible were ongoing, discontinued and completed randomized clinical trials that compared convalescent plasma with placebo or no treatment in COVID-19 patients, regardless of setting or treatment schedule. Aggregated mortality data were extracted from publications or provided by investigators of unpublished trials and combined using the Hartung-Knapp-Sidik-Jonkman random effects model. We investigated the contribution of unpublished trials to the overall evidence.RESULTS: A total of 16,477 patients were included in 33 trials (20 unpublished with 3190 patients, 13 published with 13,287 patients). 32 trials enrolled only hospitalized patients (including 3 with only intensive care unit patients). Risk of bias was low for 29/33 trials. Of 8495 patients who received convalescent plasma, 1997 died (23%), and of 7982 control patients, 1952 died (24%). The combined risk ratio for all-cause mortality was 0.97 (95% confidence interval: 0.92; 1.02) with between-study heterogeneity not beyond chance (I2=0%). The RECOVERY trial had 69.8% and the unpublished evidence 25.3% of the weight in the meta-analysis.CONCLUSIONS: Convalescent plasma treatment of patients with COVID-19 did not reduce all-cause mortality. These results provide strong evidence that convalescent plasma treatment for patients with COVID-19 should not be used outside of randomized trials. Evidence synthesis from collaborations among trial investigators can inform both evidence generation and evidence application in patient care.\n\nView details for DOI 10.1186/s12879-021-06829-7\n\nView details for PubMedID 34800996\n\nAbstract\n\nImportance: Convalescent plasma is a proposed treatment for COVID-19.Objective: To assess clinical outcomes with convalescent plasma treatment vs placebo or standard of care in peer-reviewed and preprint publications or press releases of randomized clinical trials (RCTs).Data Sources: PubMed, the Cochrane COVID-19 trial registry, and the Living Overview of Evidence platform were searched until January 29, 2021.Study Selection: The RCTs selected compared any type of convalescent plasma vs placebo or standard of care for patients with confirmed or suspected COVID-19 in any treatment setting.Data Extraction and Synthesis: Two reviewers independently extracted data on relevant clinical outcomes, trial characteristics, and patient characteristics and used the Cochrane Risk of Bias Assessment Tool. The primary analysis included peer-reviewed publications of RCTs only, whereas the secondary analysis included all publicly available RCT data (peer-reviewed publications, preprints, and press releases). Inverse variance-weighted meta-analyses were conducted to summarize the treatment effects. The certainty of the evidence was assessed using the Grading of Recommendations Assessment, Development, and Evaluation.Main Outcomes and Measures: All-cause mortality, length of hospital stay, clinical improvement, clinical deterioration, mechanical ventilation use, and serious adverse events.Results: A total of 1060 patients from 4 peer-reviewed RCTs and 10 722 patients from 6 other publicly available RCTs were included. The summary risk ratio (RR) for all-cause mortality with convalescent plasma in the 4 peer-reviewed RCTs was 0.93 (95% CI, 0.63 to 1.38), the absolute risk difference was -1.21% (95% CI, -5.29% to 2.88%), and there was low certainty of the evidence due to imprecision. Across all 10 RCTs, the summary RR was 1.02 (95% CI, 0.92 to 1.12) and there was moderate certainty of the evidence due to inclusion of unpublished data. Among the peer-reviewed RCTs, the summary hazard ratio was 1.17 (95% CI, 0.07 to 20.34) for length of hospital stay, the summary RR was 0.76 (95% CI, 0.20 to 2.87) for mechanical ventilation use (the absolute risk difference for mechanical ventilation use was -2.56% [95% CI, -13.16% to 8.05%]), and there was low certainty of the evidence due to imprecision for both outcomes. Limited data on clinical improvement, clinical deterioration, and serious adverse events showed no significant differences.Conclusions and Relevance: Treatment with convalescent plasma compared with placebo or standard of care was not significantly associated with a decrease in all-cause mortality or with any benefit for other clinical outcomes. The certainty of the evidence was low to moderate for all-cause mortality and low for other outcomes.\n\nView details for DOI 10.1001/jama.2021.2747\n\nView details for PubMedID 33635310\n\nAbstract\n\nImportance: Rapid eye movement (REM) sleep has been linked with health outcomes, but little is known about the relationship between REM sleep and mortality.Objective: To investigate whether REM sleep is associated with greater risk of mortality in 2 independent cohorts and to explore whether another sleep stage could be driving the findings.Design, Setting, and Participants: This multicenter population-based cross-sectional study used data from the Outcomes of Sleep Disorders in Older Men (MrOS) Sleep Study and Wisconsin Sleep Cohort (WSC). MrOS participants were recruited from December 2003 to March 2005, and WSC began in 1988. MrOS and WSC participants who had REM sleep and mortality data were included. Analysis began May 2018 and ended December 2019.Main Outcomes and Measures: All-cause and cause-specific mortality confirmed with death certificates.Results: The MrOS cohort included 2675 individuals (2675 men [100%]; mean [SD] age, 76.3[5.5] years) and was followed up for a median (interquartile range) of 12.1 (7.8-13.2) years. The WSC cohort included 1386 individuals (753 men [54.3%]; mean [SD] age, 51.5[8.5] years) and was followed up for a median (interquartile range) of 20.8 (17.9-22.4) years. MrOS participants had a 13% higher mortality rate for every 5% reduction in REM sleep (percentage REM sleep SD=6.6%) after adjusting for multiple demographic, sleep, and health covariates (age-adjusted hazard ratio,1.12; fully adjusted hazard ratio,1.13; 95% CI, 1.08-1.19). Results were similar for cardiovascular and other causes of death. Possible threshold effects were seen on the Kaplan-Meier curves, particularly for cancer; individuals with less than 15% REM sleep had a higher mortality rate compared with individuals with 15% or more for each mortality outcome with odds ratios ranging from 1.20 to 1.35. Findings were replicated in the WSC cohort despite younger age, inclusion of women, and longer follow-up (hazard ratio,1.13; 95% CI, 1.08-1.19). A random forest model identified REM sleep as the most important sleep stage associated with survival.Conclusions and Relevance: Decreased percentage REM sleep was associated with greater risk of all-cause, cardiovascular, and other noncancer-related mortality in 2 independent cohorts.\n\nView details for DOI 10.1001/jamaneurol.2020.2108\n\nView details for PubMedID 32628261\n\nAbstract\n\nThe PATH (Predictive Approaches to Treatment effect Heterogeneity) Statement was developed to promote the conduct of, and provide guidance for, predictive analyses of heterogeneity of treatment effects (HTE) in clinical trials. The goal of predictive HTE analysis is to provide patient-centered estimates of outcome risk with versus without the intervention, taking into account all relevant patient attributes simultaneously, to support more personalized clinical decision making than can be made on the basis of only an overall average treatment effect. The authors distinguished 2 categories of predictive HTE approaches (a \"risk-modeling\" and an \"effect-modeling\" approach) and developed 4 sets of guidance statements: criteria to determine when risk-modeling approaches are likely to identify clinically meaningful HTE, methodological aspects of risk-modeling methods, considerations for translation to clinical practice, and considerations and caveats in the use of effect-modeling approaches. They discuss limitations of these methods and enumerate research priorities for advancing methods designed to generate more personalized evidence. This explanation and elaboration document describes the intent and rationale of each recommendation and discusses related analytic considerations, caveats, and reservations.\n\nView details for DOI 10.7326/M18-3668\n\nView details for Web of Science ID 000506650200002\n\nView details for PubMedID 31711094\n\nAbstract\n\nScientific claims in biomedical research are typically derived from statistical analyses. However, misuse or misunderstanding of statistical procedures and results permeate the biomedical literature, affecting the validity of those claims. One approach journals have taken to address this issue is to enlist expert statistical reviewers. How many journals do this, how statistical review is incorporated, and how its value is perceived by editors is of interest. Here we report an expanded version of a survey conducted more than 20 years ago by Goodman and colleagues (1998) with the intention of characterizing contemporary statistical review policies at leading biomedical journals. We received eligible responses from 107 of 364 (28%) journals surveyed, across 57 fields, mostly from editors in chief. 34% (36/107) rarely or never use specialized statistical review, 34% (36/107) used it for 10-50% of their articles and 23% used it for all articles. These numbers have changed little since 1998 in spite of dramatically increased concern about research validity. The vast majority of editors regarded statistical review as having substantial incremental value beyond regular peer review and expressed comparatively little concern about the potential increase in reviewing time, cost, and difficulty identifying suitable statistical reviewers. Improved statistical education of researchers and different ways of employing statistical expertise are needed. Several proposals are discussed.\n\nView details for DOI 10.1371/journal.pone.0239598\n\nView details for PubMedID 33002031\n\nAbstract\n\nBackground: Never before have clinical trials drawn as much public attention as those testing interventions for COVID-19. We aimed to describe the worldwide COVID-19 clinical research response and its evolution over the first 100 days of the pandemic. Methods: Descriptive analysis of planned, ongoing or completed trials by April 9, 2020 testing any intervention to treat or prevent COVID-19, systematically identified in trial registries, preprint servers, and literature databases. A survey was conducted of all trials to assess their recruitment status up to July 6, 2020. Results: Most of the 689 trials (overall target sample size 396,366) were small (median sample size 120; interquartile range [IQR] 60-300) but randomized (75.8%; n=522) and were often conducted in China (51.1%; n=352) or the USA (11%; n=76). 525 trials (76.2%) planned to include 155,571 hospitalized patients, and 25 (3.6%) planned to include 96,821 health-care workers. Treatments were evaluated in 607 trials (88.1%), frequently antivirals (n=144) or antimalarials (n=112); 78 trials (11.3%) focused on prevention, including 14 vaccine trials. No trial investigated social distancing. Interventions tested in 11 trials with >5,000 participants were also tested in 169 smaller trials (median sample size 273; IQR 90-700). Hydroxychloroquine alone was investigated in 110 trials. While 414 trials (60.0%) expected completion in 2020, only 35 trials (4.1%; 3,071 participants) were completed by July 6. Of 112 trials with detailed recruitment information, 55 had recruited <20% of the targeted sample; 27 between 20-50%; and 30 over 50% (median 14.8% [IQR 2.0-62.0%]). Conclusions: The size and speed of the COVID-19 clinical trials agenda is unprecedented. However, most trials were small investigating a small fraction of treatment options. The feasibility of this research agenda is questionable, and many trials may end in futility, wasting research resources. Much better coordination is needed to respond to global health threats.\n\nView details for DOI 10.12688/f1000research.26707.1\n\nView details for PubMedID 33082937\n\nAbstract\n\nAIMS: To identify the clinical and urodynamic factors associated with the large capacity bladder and incomplete bladder emptying after prolapse repair.METHODS: We identified 592 women who underwent anterior and/or apical prolapse repair at our institution from 2009 to 2015. Women were stratified by urodynamic capacity. The primary outcome was incomplete emptying at the longest follow-up (postvoid residual [PVR]>200mL). Data were analyzed in the Statistical Analysis System software.RESULTS: Two hundred and sixty-six women (mean age, 61 years) had preoperative urodynamic tracings available for review. After surgery, there were 519 PVRs in 239 women recorded at up to 2949 days (mean, 396) and nine time points (median, 2; IQR, 1-3). The receiver operator curve for predicted probability of longest follow-up PVR greater than 200mL (area under curve=0.67) identified the 600mL cutpoint which defined large capacity bladder. Large capacity bladders (capacity, >600mL [n=79] vs ≤600mL, [n=160]) had a mean: detrusor pressure at maximum flow (21 vs 22cm H2 O; P=0.717), maximum flow rate (19 vs 17mL/s; P=0.148), significantly elevated PVR (202 vs 73mL; P<0.001), and significantly lower voiding efficiency (VE) (74 vs 82%, P<0.05). Following prolapse repair, elevated PVR was associated with large capacity (PVR 101 vs 49mL, P<0.05). Large bladders had a two- to three-fold risk of longest follow-up PVR greater than 200mL (14.3%-20.3% [capacity, >600mL] vs 4.1%-7.0% [capacity, ≤600mL]). VE was similar after surgery regardless of the capacity (87% vs 88%, P=0.772).CONCLUSIONS: The decision to pursue prolapse repair should be individualized and take into account, the bladder capacity and goals for PVR improvement after surgery.\n\nView details for PubMedID 30912192\n\nAbstract\n\nHeterogeneity of treatment effect (HTE) refers to the nonrandom variation in the magnitude or direction of a treatment effect across levels of a covariate, as measured on a selected scale, against a clinical outcome. In randomized controlled trials (RCTs), HTE is typically examined through a subgroup analysis that contrasts effects in groups of patients defined \"1 variable at a time\" (for example, male vs. female or old vs. young). The authors of this statement present guidance on an alternative approach to HTE analysis, \"predictive HTE analysis.\" The goal of predictive HTE analysis is to provide patient-centered estimates of outcome risks with versus without the intervention, taking into account all relevant patient attributes simultaneously. The PATH (Predictive Approaches to Treatment effect Heterogeneity) Statement was developed using a multidisciplinary technical expert panel, targeted literature reviews, simulations to characterize potential problems with predictive approaches, and a deliberative process engaging the expert panel. The authors distinguish 2 categories of predictive HTE approaches: a \"risk-modeling\" approach, wherein a multivariable model predicts the risk for an outcome and is applied to disaggregate patients within RCTs to define risk-based variation in benefit, and an \"effect-modeling\" approach, wherein a model is developed on RCT data by incorporating a term for treatment assignment and interactions between treatment and baseline covariates. Both approaches can be used to predict differential absolute treatment effects, the most relevant scale for clinical decision making. The authors developed 4 sets of guidance: criteria to determine when risk-modeling approaches are likely to identify clinically important HTE, methodological aspects of risk-modeling methods, considerations for translation to clinical practice, and considerations and caveats in the use of effect-modeling approaches. The PATH Statement, together with its explanation and elaboration document, may guide future analyses and reporting of RCTs.\n\nView details for DOI 10.7326/M18-3667\n\nView details for PubMedID 31711134\n\nAbstract\n\nRich literatures across multiple disciplines document the association between increased educational attainment and improved health. While quasi-experimental studies have exploited variation in educational policies to more rigorously estimate the health effects of education, there remains disagreement about whether education and health are causally linked. The aim of this study was to conduct a systematic review and meta-analysis to characterize this literature, with a focus on quasi-experimental studies of compulsory schooling laws (CSLs). Articles from 1990 to 2015 were obtained through electronic searches and manual searches of reference lists. We searched for English-language studies and included manuscripts if: (1) they involved original data analysis; (2) outcomes were health-related; and (3) the primary predictor utilized variation in CSLs. We identified 89 articles in 25 countries examining over 25 health outcomes, with over 600 individual point estimates. We systematically characterized heterogeneity on key study design features and conducted a meta-analysis of studies with comparable health outcome and exposure variables. Within countries, studies differed in terms of birth cohorts included, the measurement of health outcomes within a given category, and the type of CSL variation examined. Over 90% of manuscripts included multiple analytic techniques, such as econometric and standard regression methods, with as many as 31 \"primary\" models in a single study. A qualitative synthesis of study findings indicated that educational attainment has an effect on the majority of health outcomes-most beneficial, some negative-while the meta-analysis demonstrated small beneficial effects for mortality, smoking, and obesity. Future work could focus on inconsistent findings identified by this study, or review the health effects of other types of educational policies.\n\nView details for PubMedID 30036767\n\nAbstract\n\nBACKGROUND: Patients suffering from non-convulsive seizures experience delays in diagnosis and treatment due to limitations in acquiring and interpreting electroencephalography (EEG) data. The Ceribell EEG System offers rapid EEG acquisition and conversion of EEG signals to sound (sonification) using a proprietary algorithm. This study was designed to test the performance of this EEG system in an intensive care unit (ICU) setting and measure its impact on clinician treatment decision.METHODS: Encephalopathic ICU patients at Stanford University Hospital were enrolled if clinical suspicion for seizures warranted EEG monitoring. Treating physicians rated suspicion for seizure and decided if the patient needed antiepileptic drug (AED) treatment at the time of bedside evaluation. After listening to 30s of EEG from each hemisphere in each patient, they reevaluated their suspicion for seizure and decision for additional treatment. The EEG waveforms recorded with Ceribell EEG were subsequently analyzed by three blinded epileptologists to assess the presence or absence of seizures within and outside the sonification window. Study outcomes were EEG set up time, ease of use of the device, change in clinician seizure suspicion, and change in decision to treat with AED before and after sonification.RESULTS: Thirty-five cases of EEG sonification were performed. Mean EEG setup time was 6±3min, and time to obtain sonified EEG was significantly faster than conventional EEG (p<0.001). One patient had non-convulsive seizure during sonification and another had rhythmic activity that was followed by seizure shortly after sonification. Change in treatment decision after sonification occurred in approximately 40% of patients and resulted in a significant net reduction in unnecessary additional treatments (p=0.01). Ceribell EEG System was consistently rated easy to use.CONCLUSION: The Ceribell EEG System enabled rapid acquisition of EEG in patients at risk for non-convulsive seizures and aided clinicians in their evaluation of encephalopathic ICU patients. The ease of use and speed of EEG acquisition and interpretation by EEG-untrained individuals has the potential to improve emergent clinical decision making by quickly detecting non-convulsive seizures in the ICU.\n\nView details for PubMedID 29923167\n\nAbstract\n\nBackground Sharing of participant-level clinical trial data has potential benefits, but concerns about potential harms to research participants have led some pharmaceutical sponsors and investigators to urge caution. Little is known about clinical trial participants' perceptions of the risks of data sharing. Methods We conducted a structured survey of 771 current and recent participants from a diverse sample of clinical trials at three academic medical centers in the United States. Surveys were distributed by mail (350 completed surveys) and in clinic waiting rooms (421 completed surveys) (overall response rate, 79%). Results Less than 8% of respondents felt that the potential negative consequences of data sharing outweighed the benefits. A total of 93% were very or somewhat likely to allow their own data to be shared with university scientists, and 82% were very or somewhat likely to share with scientists in for-profit companies. Willingness to share data did not vary appreciably with the purpose for which the data would be used, with the exception that fewer participants were willing to share their data for use in litigation. The respondents' greatest concerns were that data sharing might make others less willing to enroll in clinical trials (37% very or somewhat concerned), that data would be used for marketing purposes (34%), or that data could be stolen (30%). Less concern was expressed about discrimination (22%) and exploitation of data for profit (20%). Conclusions In our study, few clinical trial participants had strong concerns about the risks of data sharing. Provided that adequate security safeguards were in place, most participants were willing to share their data for a wide range of uses. (Funded by the Greenwall Foundation.).\n\nView details for PubMedID 29874542\n\nAbstract\n\nDespite the wide use of the design with statistical stopping guidelines to stop a randomized clinical trial early for efficacy, there are unsettled debates of potential harmful consequences of such designs. These concerns include the possible over-estimation of treatment effects in early stopped trials and a newer argument of a \"freezing effect\" that will halt future randomized clinical trials on the same comparison since an early stopped trial represents an effective declaration that randomization to the unfavored arm is unethical. The purpose of this study is to determine the degree of bias in designs that allow for early stopping and to assess the impact on estimation if indeed future experimentation is \"frozen\" by an early stopped trial.We perform simulations to study the effect of early stopping. We simulate a collection of trials and contrast the treatment-effect estimates (risk differences and ratios) with the simulation truth. Simulations consider various scenarios of between-study variation, including an empirically derived distribution of effects from the clinical literature.Across the trials whose true effects are sampled from a uniform distribution, estimates from trials that stop early for efficacy deviate minimally from the simulation truth (median bias of the estimate of risk difference is 0.005). Over-estimation becomes appreciable only when the true effect is close to the null value 0 (median bias of the risk difference estimate is 0.04) or when stopping happens with 40% information or less; however, stopping under these situations is rare. We also find slight reverse bias of the estimated treatment effect (median bias of the risk difference estimate is -0.002) among trials that do not cross the early stopping boundaries but continue to the final analysis. Similar results occur with relative risk estimates. In contrast, Bayesian estimation of the treatment effect shrinks the estimate from trials stopping early and pulls back under-estimation from completed trials, largely rectifying any over-estimation among trials that terminate early. Regarding the so-called freezing effect, the pooled effects from meta-analyses that include truncated randomized clinical trials show an unimportant deviation from the true value, even when no subsequent trials are conducted after a truncated randomized clinical trial.Group sequential designs with stopping rules seek to minimize exposure of patients to a disfavored therapy and speed dissemination of results, and such designs do not lead to materially biased estimates. The likelihood and magnitude of a \"freezing effect\" is minimal. Superiority demonstrated in a randomized clinical trial stopping early and designed with appropriate statistical stopping rules is likely a valid inference, even if the estimate may be slightly inflated.\n\nView details for DOI 10.1177/1740774516649595\n\nView details for PubMedID 27271682\n\nAbstract\n\nMisinterpretation and abuse of statistical tests, confidence intervals, and statistical power have been decried for decades, yet remain rampant. A key problem is that there are no interpretations of these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously so-and yet these misinterpretations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statistics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.\n\nView details for DOI 10.1007/s10654-016-0149-3\n\nView details for PubMedID 27209009\n\nAbstract\n\nIn any clinical trial, it is essential to monitor the accumulating data to be sure that the trial continues to be safe for participants and that the trial is being conducted properly. Data monitoring committees, independent expert panels who undertake regular reviews of the data as the trial progresses, serve an important role in safeguarding the interests of research participants and ensuring trial integrity in many trials. Many pragmatic clinical trials, which aim to inform healthcare decisions by comparing alternate interventions in heterogeneous healthcare delivery settings, will warrant review by an independent data monitoring committee due to their potential impact on clinical practice. However, the very features that make a trial \"pragmatic\" may pose challenges in terms of which aspects of a trial to monitor and when it is appropriate for a data monitoring committee to intervene. Using the Pragmatic-Explanatory Continuum Indicator Summary tool that draws distinctions between pragmatic and explanatory clinical trials, we review characteristics of pragmatic clinical trials that may have implications for data monitoring committees and interim monitoring plans. These include broad eligibility criteria, a focus on subjective patient-centered outcomes, and in some cases a lack of standardized follow-up procedures across study sites. Additionally, protocol adherence is often purposefully not addressed in pragmatic trials in order to accurately represent the clinical practice setting and maintain practicability of implementation; there are differing viewpoints as to whether adherence should be assessed and acted upon by data monitoring committees in these trials. Some other issues not specifically related to the Pragmatic-Explanatory Continuum Indicator Summary criteria may also merit special consideration in pragmatic trials. Thresholds for early termination of a pragmatic clinical trial might be controversial. The distinguishing features of pragmatic clinical trials require careful consideration when developing interim data monitoring plans, and trial sponsors, investigators, and data monitoring committees should agree on a plan before trial inception. Finally, special expertise, such as an informatics, may be helpful on data monitoring committees for some pragmatic clinical trials. Patient representatives may provide particularly valuable insights in the monitoring process.\n\nView details for PubMedID 26374679\n\nAbstract\n\nThis article has an additional interactive example appended as a Supplement. Please visit the Supplement tab on this page to access the presentation. A primary goal of meta-analysis is to improve the estimation of treatment effects by pooling results of similar studies. This article explains how the most widely used method for pooling heterogeneous studies-the DerSimonian-Laird (DL) estimator-can produce biased estimates with falsely high precision. A classic example is presented to show that use of the DL estimator can lead to erroneous conclusions. Particular problems with the DL estimator are discussed, and several alternative methods for summarizing heterogeneous evidence are presented. The authors support replacing universal use of the DL estimator with analyses based on a critical synthesis that recognizes the uncertainty in the evidence, focuses on describing and explaining the probable sources of variation in the evidence, and uses random-effects estimates that provide more accurate confidence limits than the DL estimator.\n\nView details for DOI 10.7326/M13-2886\n\nView details for PubMedID 24727843\n\nAbstract\n\nAcknowledgment of all serious limitations to research evidence is important for patient care and scientific progress. Formal research on how biomedical authors acknowledge limitations is scarce.To assess the extent to which limitations are acknowledged in biomedical publications explicitly, and implicitly by investigating the use of phrases that express uncertainty, so-called hedges; to assess the association between industry support and the extent of hedging.We analyzed reporting of limitations and use of hedges in 300 biomedical publications published in 30 high and medium -ranked journals in 2007. Hedges were assessed using linguistic software that assigned weights between 1 and 5 to each expression of uncertainty.Twenty-seven percent of publications (81/300) did not mention any limitations, while 73% acknowledged a median of 3 (range 1-8) limitations. Five percent mentioned a limitation in the abstract. After controlling for confounders, publications on industry-supported studies used significantly fewer hedges than publications not so supported (p = 0.028).Detection and classification of limitations was--to some extent--subjective. The weighting scheme used by the hedging detection software has subjective elements.Reporting of limitations in biomedical publications is probably very incomplete. Transparent reporting of limitations may protect clinicians and guideline committees against overly confident beliefs and decisions and support scientific progress through better design, conduct or analysis of new studies.\n\nView details for DOI 10.1371/journal.pone.0073623\n\nView details for Web of Science ID 000327313100002\n\nView details for PubMedID 24324540\n\nView details for PubMedCentralID PMC3854521\n\nAbstract\n\nThe sensitivity of only a few tumors to anti-epidermal growth factor receptor EGFR tyrosine kinase inhibitors (TKIs) can be explained by the presence of EGFR tyrosine kinase (TK) domain mutations. In addition, such mutations were rarely found in tumor types other than lung, such as pancreatic and head and neck cancer. In this study we sought to elucidate mechanisms of resistance to EGFR-targeted therapies in tumors that do not harbor TK sensitizing mutations in order to identify markers capable of guiding the decision to incorporate these drugs into chemotherapeutic regimens. Here we show that EGFR activity was markedly decreased during the evolution of resistance to the EGFR tyrosine kinase inhibitor (TKI) erlotinib, with a concomitant increase of mitogen-inducible gene 6 (Mig6), a negative regulator of EGFR through the upregulation of the PI3K-AKT pathway. EGFR activity, which was more accurately predicted by the ratio of Mig6/EGFR, highly correlated with erlotinib sensitivity in panels of cancer cell lines of different tissue origins. Blinded testing and analysis in a prospectively followed cohort of lung cancer patients treated with gefitinib alone demonstrated higher response rates and a marked increased in progression free survival for patients with a low Mig6/EGFR ratio (approximately 100 days, P = 0.01).\n\nView details for DOI 10.1371/journal.pone.0068966\n\nView details for Web of Science ID 000322633700014\n\nView details for PubMedID 23935914\n\nView details for PubMedCentralID PMC3729565\n\nAbstract\n\n\"First they ignore you, then they laugh at you, then they fight you, then you win,\" a saying reportedly misattributed to Mahatma Ghandi(1), might apply to the use of Bayesian statistics in medical research. The idea that Bayesian approaches might be used to \"affirm\" findings derived from conventional methods, and thereby be regarded as more authoritative, is a dramatic turnabout from an era not very long ago when those embracing Bayesian ideas were considered barbarians at the gate. I remember my own initiation into the Bayesian fold, reading with a mixture of astonishment and subversive pleasure one of George Diamond's early pieces taking aim at conventional interpretations of large cardiovascular trials of the early 80's.(2) It is gratifying to see that the Bayesian approach, which saw negligible application in biomedical research in the 80's and began to get traction in the 90's, is now not just a respectable alternative to standard methods, but sometimes might be regarded as preferable. That said, it is premature to declare a \"win,\" and the statistical lingua franca of biomedical research is still firmly frequentist, with P-values, confidence intervals and Type I and II errors dominating the journal landscape. It is helpful to use the thoughtful and thorough Bayesian exercise of Bittl et al.(3) to reflect on what Bayesian approaches give us, and what they don't.\n\nView details for DOI 10.1161/CIRCULATIONAHA.113.003193\n\nView details for PubMedID 23674396\n\nAbstract\n\nOur aim was to comprehensively analyze promoter hypermethylation of a panel of novel and known methylation markers for thyroid neoplasms and to establish their relationship with BRAF mutation and clinicopathologic parameters of thyroid cancer. A cohort of thyroid tumors, consisting of 44 cancers and 44 benign thyroid lesions, as well as 15 samples of adjacent normal thyroid tissue, was evaluated for BRAF mutation and promoter hypermethylation. Genes for quantitative methylation specific PCR (QMSP) were selected by a candidate gene approach. Twenty-two genes were tested: TSHR, RASSF1A, RARβ2, DAPK, hMLH1, ATM, S100, p16, CTNNB1, GSTP1, CALCA, TIMP3, TGFßR2, THBS1, MINT1, CTNNB1, MT1G, PAK3, NISCH, DCC, AIM1 and KIF1A. The PCR-based \"mutector assay\" was used to detect BRAF mutation. All p values reported are two sided. Considerable overlap was seen in the methylation markers among the different tissue groups. Significantly higher methylation frequency and level were observed for KIF1A and RARß2 in cancer samples compared with benign tumors. A negative correlation between BRAF mutation and RASSF1A methylation, and a positive correlation with RARß2 methylation were observed in accordance with previous results. In addition, positive correlation with TIMP3 and a marginal correlation with DCC methylation were observed. The present study constitutes a comprehensive promoter methylation profile of thyroid neoplasia and shows that results must be analyzed in a tissue-specific manner to identify clinically useful methylation markers. Integration of genetic and epigenetic changes in thyroid cancer will help identify relevant biologic pathways that drive its development.\n\nView details for DOI 10.4161/epi.205248\n\nView details for Web of Science ID 000306291900007\n\nView details for PubMedID 22694820\n\nAbstract\n\nRigorous methodological standards help to ensure that medical research produces information that is valid and generalizable, and are essential in patient-centered outcomes research (PCOR). Patient-centeredness refers to the extent to which the preferences, decision-making needs, and characteristics of patients are addressed, and is the key characteristic differentiating PCOR from comparative effectiveness research. The Patient Protection and Affordable Care Act signed into law in 2010 created the Patient-Centered Outcomes Research Institute (PCORI), which includes an independent, federally appointed Methodology Committee. The Methodology Committee is charged to develop methodological standards for PCOR. The 4 general areas identified by the committee in which standards will be developed are (1) prioritizing research questions, (2) using appropriate study designs and analyses, (3) incorporating patient perspectives throughout the research continuum, and (4) fostering efficient dissemination and implementation of results. A Congressionally mandated PCORI methodology report (to be issued in its first iteration in May 2012) will begin to provide standards in each of these areas, and will inform future PCORI funding announcements and review criteria. The work of the Methodology Committee is intended to enable generation of information that is relevant and trustworthy for patients, and to enable decisions that improve patient-centered outcomes.\n\nView details for Web of Science ID 000302896100026\n\nAbstract\n\nThe optimal blood pressure level to minimize the risk of ischemic stroke (IS) in older adults is undetermined. Cerebral white matter lesions (WML), prevalent in older adults, may be a marker for vulnerability to IS. We aimed at determining the relationship between diastolic blood pressure (DBP) levels and IS in the presence of WML.The Cardiovascular Health Study population (N = 3,345, age ≥ 65 years, N = 3,345) was followed between 1989 and 2002 for IS incidence. Survival analysis included quintiles of DBP analyzed within WML levels controlling for age and cardiovascular disease.DBP had no effect on IS incidence in low WML levels but had a marginally significant J-curve relationship with IS in high WML levels: the adjusted hazard ratio for IS in the lowest (<63 mmHg) and highest (≥ 80) DBP quintiles compared with the third (nadir, 69-73 mmHg) was 1.64 (95% confidence interval: 0.93-2.9) and 1.83 (95% confidence interval: 1.06-3.15), respectively.In older adults with low-grade WML, low DBP may not pose a risk for IS. However, in high-grade WML, IS risk may increase in DBP less than 69 mmHg but is highest more than 80 mmHg. People with high-grade WML may be at risk of IS in high and low DBP.\n\nView details for DOI 10.1093/gerona/glq166\n\nView details for Web of Science ID 000286655300011\n\nView details for PubMedID 21030465\n\nAbstract\n\nOverwhelming evidence shows the quality of reporting of randomised controlled trials (RCTs) is not optimal. Without transparent reporting, readers cannot judge the reliability and validity of trial findings nor extract information for systematic reviews. Recent methodological analyses indicate that inadequate reporting and design are associated with biased estimates of treatment effects. Such systematic error is seriously damaging to RCTs, which are considered the gold standard for evaluating interventions because of their ability to minimise or avoid bias. A group of scientists and editors developed the CONSORT (Consolidated Standards of Reporting Trials) statement to improve the quality of reporting of RCTs. It was first published in 1996 and updated in 2001. The statement consists of a checklist and flow diagram that authors can use for reporting an RCT. Many leading medical journals and major international editorial groups have endorsed the CONSORT statement. The statement facilitates critical appraisal and interpretation of RCTs. During the 2001 CONSORT revision, it became clear that explanation and elaboration of the principles underlying the CONSORT statement would help investigators and others to write or appraise trial reports. A CONSORT explanation and elaboration article was published in 2001 alongside the 2001 version of the CONSORT statement. After an expert meeting in January 2007, the CONSORT statement has been further revised and is published as the CONSORT 2010 Statement. This update improves the wording and clarity of the previous checklist and incorporates recommendations related to topics that have only recently received recognition, such as selective outcome reporting bias. This explanatory and elaboration document-intended to enhance the use, understanding, and dissemination of the CONSORT statement-has also been extensively revised. It presents the meaning and rationale for each new and updated checklist item providing examples of good reporting and, where possible, references to relevant empirical studies. Several examples of flow diagrams are included. The CONSORT 2010 Statement, this revised explanatory and elaboration document, and the associated website (www.consort-statement.org) should be helpful resources to improve reporting of randomised trials.\n\nView details for DOI 10.1016/j.jclinepi.2010.03.004\n\nView details for PubMedID 20346624\n\nAbstract\n\nBecause of its potent immunosuppressive yet stem cell-sparing activity, high-dose cyclophosphamide was tested as sole prophylaxis of graft-versus-host disease (GVHD) after myeloablative allogeneic bone marrow transplantation (alloBMT). We treated 117 patients (median age, 50 years; range, 21-66 years) with advanced hematologic malignancies; 78 had human leukocyte antigen (HLA)-matched related donors and 39 had HLA-matched unrelated donors. All patients received conventional myeloablation with busulfan/cyclophosphamide (BuCy) and T cell-replete bone marrow followed by 50 mg/kg/d of cyclophosphamide on days 3 and 4 after transplantation. The incidences of acute grades II through IV and grades III through IV GVHD for all patients were 43% and 10%, respectively. The nonrelapse mortality at day 100 and 2 years after transplantation were 9% and 17%, respectively. The actuarial overall survival and event-free survivals at 2 years after transplantation were 55% and 39%, respectively, for all patients and 63% and 54%, respectively, for patients who underwent transplantation while in remission. With a median follow-up of 26.3 months among surviving patients, the cumulative incidence of chronic GVHD is 10%. These results suggest that high-dose posttransplantation cyclophosphamide is an effective single-agent prophylaxis of acute and chronic GVHD after BuCy conditioning and HLA-matched BMT (clinicaltrials.gov no. NCT00134017).\n\nView details for DOI 10.1182/blood-2009-11-251595\n\nView details for Web of Science ID 000276956500008\n\nView details for PubMedID 20124511\n\nAbstract\n\nDespite over 80 years of use, the ketogenic diet (KD) has never been tested in a blinded manner. Twenty children with intractable Lennox-Gastaut syndrome (LGS) were fasted 36 h and then randomized to receive the classic KD in conjunction with a solution containing either 60 g/day of glucose or saccharin. Parents and physicians were blinded to both the solution composition and level of ketosis. A crossover to the KD with the alternate solution occurred following the sixth day and a repeat fast. A 24-h electroencephalography (EEG) was obtained at baseline and after each arm. After administration of the solution, there was moderate evidence of a reduction in parent-reported seizures between the glucose and saccharin arms, with a median difference of 1.5 seizures per day (p = 0.07). There was no reduction in the number of EEG-identified events, with a median reduction of 7 events per day (p = 0.33). Ketosis was not completely eliminated in the glucose-added arm.\n\nView details for DOI 10.1111/j.1528-1167.2008.01740.x\n\nView details for Web of Science ID 000262781800018\n\nView details for PubMedID 18717710\n\nAbstract\n\nSomatic mutations provide uniquely specific markers for the early detection of neoplasia that can be detected in DNA purified from plasma or stool of patients with colorectal cancer. The primary purpose of the present investigation was to determine the parameters that were critical for detecting mutations using a quantitative assay. A secondary purpose was to compare the results of plasma and stool DNA testing using the same technology.We examined DNA purified from the stool of 25 patients with colorectal cancers before surgery. In 16 of these cases, plasma samples also were available. Mutations in stool or plasma were assessed with an improved version of the BEAMing technology.Of the 25 stool DNA samples analyzed, 23 (92%) contained mutations that were present in the corresponding tumors from the same patients. In contrast, only 8 of the 16 (50%) plasma DNA samples analyzed had detectable levels of mutated DNA. We found that the DNA fragments containing mutations in both stool and plasma DNA typically were smaller than 150 bases in size. The sensitivity of the new method was superior to a widely used technique for detecting mutations, using single base extension and sequencing, when assessed on the same samples (92% vs 60%; P = .008, exact McNemar test).When assessed with sufficiently sensitive methods, mutant DNA fragments are detectable in the stool of more than 90% of colorectal cancer patients. DNA purified from stool provides a better template for mutation testing than plasma.\n\nView details for DOI 10.1053/j.gastro.2008.05.039\n\nView details for Web of Science ID 000258439900026\n\nView details for PubMedID 18602395\n\nAbstract\n\nThree gene expression-based prognostic breast cancer tests have been licensed for use.To summarize evidence on the validity and utility of 3 gene expression-based prognostic breast cancer tests: Oncotype DX (Genomic Health, Redwood City, California), MammaPrint (Agendia BV, Amsterdam, the Netherlands), and H/I (AvariaDX, Carlsbad, California).MEDLINE, EMBASE, and Cochrane databases (from 1990 through January 2007), Web sites of test manufacturers, and discussion with the manufacturers.Original data studies published in English that addressed prognostic accuracy and discrimination or treatment benefit prediction of any of the 3 tests in women with breast cancer.Information was extracted about the clinical characteristics of the study population (particularly clinical and therapeutic homogeneity), tumor characteristics, and whether the marketed test or underlying signature was evaluated.The tests are based on distinct gene lists, using 2 different technologies. Overall, the body of evidence showed that this new generation of tests may improve prognostic and therapeutic prediction, but the tests are at different stages of development. Evidence shows that the tests offer clinically relevant, improved risk stratification over standard predictors. Oncotype DX has the strongest evidence, closely followed by MammaPrint and H/I (which is still maturing).For all tests, the relationship of predicted to observed risk in different populations and their incremental contribution over conventional predictors, optimal implementation, and relevance to patients receiving current therapies need further study.Gene expression technologies show great promise to improve predictions of prognosis and treatment benefit for women with early-stage breast cancer. More information is needed on the extent of improvement in prediction, characteristics of women in whom the tests should be used, and how best to incorporate test results into decision making about breast cancer treatment.\n\nView details for Web of Science ID 000253600800005\n\nView details for PubMedID 18252678\n\nAbstract\n\nTIMP-3 (tissue inhibitor of metalloproteinases-3) is 1 of 4 members of a family of proteins that were originally classified according to their ability to inhibit matrix metalloproteinases. We analyzed TIMP-3 methylation in 175 urine sediment DNA samples from patients with bladder cancer with well characterized clinicopathological parameters, including patient outcome.We examined urine sediment DNA for aberrant methylation of 9 genes, including TIMP-3, by quantitative fluorogenic real-time polymerase chain reaction.Using an optimal cutoff value by TaqMan(R) quantitation we found that the risk of death was statistically significantly higher in patients with higher TIMP-3 and ARF methylation (HR 1.99, 95% CI 1.12 to 3.27, p = 0.01 and HR 1.66, 95% CI 1.00 to 2.76, p = 0.05, respectively) than in patients without/lower TIMP3 and ARF methylation in urine. A significant correlation was also seen between the risk of death and stage 3 tumor (HR 2.73, 95% CI 1.58 to 4.72, p = 0.003) and metastasis (HR 3.32, 95% CI 1.98 to 5.57, p = 0.0001). Multivariate analysis subsequently revealed that TIMP-3 methylation was an independent prognostic factor for bladder cancer survival with stage and metastasis (p = 0.001 and 0.02, respectively).These results suggest that TIMP-3 promoter methylation could be a clinically applicable marker for bladder cancer progression.\n\nView details for DOI 10.1016/j.juro.2007.09.019\n\nView details for Web of Science ID 000252369600091\n\nView details for PubMedID 18082200\n\nAbstract\n\nTo assess the evidence that three marketed gene expression-based assays improve prognostic accuracy, treatment choice, and health outcomes in women diagnosed with early stage breast cancer.We evaluated the evidence for three gene expression assays on the market; Oncotype DX, MammaPrint and the Breast Cancer Profiling (BCP or H/I ratio) test, and for gene expression signatures underlying the assays. We sought evidence on: analytic performance of tests, clinical validity (i.e., prognostic accuracy and discrimination), clinical utility (i.e., prediction of treatment benefit), harms, impact on clinical decision making and health care costs.Few papers were found on the analytic validity of the Oncotype DX and MammaPrint tests, but these showed reasonable within-laboratory replicability. Pre-analytic issues related to sample storage and preparation may play a larger role than within-laboratory variation. For clinical validity, studies differed according to whether they examined the actual test that is currently being offered to pati"
    }
}