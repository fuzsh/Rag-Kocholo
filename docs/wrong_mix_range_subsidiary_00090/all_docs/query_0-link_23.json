{
    "id": "wrong_mix_range_subsidiary_00090_0",
    "rank": 23,
    "data": {
        "url": "https://theagileadmin.com/tag/odata/",
        "read_more_link": "",
        "language": "en",
        "title": "the agile admin",
        "top_image": "https://s0.wp.com/i/blank.jpg",
        "meta_img": "https://s0.wp.com/i/blank.jpg",
        "images": [
            "https://theagileadmin.com/wp-content/uploads/2020/09/cropped-austin1-1024x435-2.jpg",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://pixel.wp.com/b.gif?v=noscript"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Ernest Mueller"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Posts about odata written by Ernest Mueller",
        "meta_lang": "en",
        "meta_favicon": "https://s1.wp.com/i/favicon.ico",
        "meta_site_name": "the agile admin",
        "canonical_link": "https://theagileadmin.com/tag/odata/",
        "text": "This month’s ACUG meeting was cooler than usual – instead of having one speaker talk on a cloud-related topic, we had multiple group members do short presentation on what they’re actually doing in the cloud. I love talks like that, it’s where you get real rubber meets the road takeaways.\n\nI thought I’d share my notes on the presentations. I’ll write up the one we did separately, but I got a lot out of these:\n\nOData to the Cloud, by Craig Vyal from Pervasive Software\n\nMoving your SaaS from Colo to Cloud, by Josh Arnold from Arnold Marziani (previously of PeopleAdmin)\n\nDevOps and the Cloud, by Chris Hilton from Thoughtworks\n\nMoving Software from On Premise to SaaS, by John Mikula from Pervasive Software\n\nThe Programmable Infrastructure Environment, by Peco Karayanev and Ernest Mueller from National Instruments (see next post!)\n\nMy editorial comments are in italics. Slides are linked into the headers where available.\n\nOData to the Cloud\n\nOData was started by Microsoft (“but don’t hold that against it”) under the Open Specification Promise. Craig did an implementation of it at Pervasive.\n\nIt’s a RESTful protocol for CRUDdy GET/POST/DELETE of data. Uses AtomPub-based feeds and returns XML or JSON. You get the schema and the data in the result.\n\nYou can create an OData producer of a data source, consume OData from places that support it, and view it via stuff like iPhone/Android apps.\n\nCurrent producers – Sharepoint, SQL Azure, Netflix, eBay, twitpic, Open Gov’t Data Initiative, Stack Overflow\n\nCurrent consumers – PowerPivot in Excel, Sesame, Tableau. Libraries for Java (OData4J), .NET 4.0/Silverlight 4, OData SDK for PHP\n\nIt is easier for “business user” to consume than SOAP or REST. Craig used OData4J to create a producer for the Pervasive product.\n\nQuestions from the crowd:\n\nCompression/caching? Nothing built in. Though normal HTTP level compression would work I’d think. It does “page” long lists of results and can send a section of n results at a time.\n\nAuth? Your problem. Some people use Oauth. He wrote a custom glassfish basic HTTP auth portal.\n\nCompetition? Gdata is kinda like this.\n\nSeems to me it’s one part REST, one part “making you have a DTD for your XML”. Which is good! We’re very interested in OData for our data centric services coming up.\n\nMoving your SaaS from Colo to Cloud\n\nJosh Arnold was from PeopleAdmin, now he’s a tech recruiter, but can speak to what they did before he left. PeopleAdmin was a Sungard type colo setup. Had a “rotting” out of country DR site.\n\nThey were rewriting their stack from java/mssql to ruby/linux.\n\nAt the time they were spending $15k/mo on the colo (not including the cost of their HW). Amazon estimated cost was 1/3 that but really they found out after moving it’s 1/2. What was the surprise cost? Lower than expected perf (disk io) forced more instances than physical boxes of equivalent “size.”\n\nFlexible provisioning and autoscaling was great, the colo couldn’t scale fast enough. How do you scale?\n\nThe cloud made having an out of country DR site easy, and not have it rot and get old.\n\nQuestion: What did you lose in the move? We were prepared for mental “control issues” so didn’t have those. There’s definitely advanced functionality (e.g. with firewalls) and native hardware performance you lose, but that wasn’t much.\n\nThey evalled Rackspace and Amazon (cursory eval). They had some F5s they wanted to use and the ability to mix in real hardware was tempting but they mainly went straight to Amazon. Drivers were the community around it and their leadership in the space.\n\nTimeline was 2 years (rewrite app, slowly migrate customers). It’ll be more like 3-4 before it’s done. There were issues where they were glad they didn’t mass migrate everyone at once.\n\nTechnical challenges:\n\nPerformance was a little lax (disk performance, they think) and they ended up needing more servers. Used tricks like RAIDed EBSes to try to get the most io they could (mainly for the databases).\n\nEvery customer had a SSL cert, and they had 600 of them to mess with. That was a problem because of the 5 Elastic IP limit. Went to certs that allow subsidiary domains – Digicert allowed 100 per cert (other CAs limit to much less) so they could get 100 per IP.\n\nApp servers did outbound LDAP conns to customer premise for auth integration and they usually tried to allow those in via IP rules in their corporate firewalls, but now on Amazon outbound IPs are dynamic. They set up a proxy with a static (elastic) Ip to route all that through.\n\nRightscale – they used it. They like it.\n\nThey used nginx for the load balancing, SSL termination. Was a single point of failure though.\n\nRemember that many of the implementations you are hearing about now were started back before Rackspace had an API, before Amazon had load balancers, etc.\n\nIn discussion about hybrid clouds, the point was brought up a lot of providers talk about it – gogrid, opsource, rackspace – but often there are gotchas.\n\nDevOps and the Cloud\n\nChris Hilton from Thoughtworks is all about the DevOps, and works on stuff like continuous deployment for a living.\n\nDevOps is:\n\ncollaboration between devs and operations staff\n\nagile sysadmin, using agile dev tools\n\ndev/ops/qa integration to achieve business goals\n\nWhy DevOps?\n\nSilos. agile dev broke down the wall between dev/qa (and biz).\n\ndevs are usually incentivized for change, and ops are incentivized for stability, which creates an innate conflict.\n\nbut if both are incentivized to deliver business value instead…\n\nDevOps Practices\n\nversion control!\n\nautomated provisioning and deployment (Puppet/chef/rPath)\n\nself healing\n\nmonitoring infra and apps\n\nidentical environments dev/test/prod\n\nautomated db mgmt\n\nWhy DevOps In The Cloud?\n\ncloud requires automation, devops provides automation\n\nReferences\n\n“Continuous Delivery” Humble and Farley\n\nRapid and Reliable Releases InfoQ\n\nRefactoring Databases by Ambler and Sadalage\n\nAnother tidbit: they’re writing puppet lite in powershell to fill the tool gap – some tool suppliers are starting, but the general degree of tool support for people who use both Windows and Linux is shameful.\n\nMoving Software from On Premise to SaaS\n\nJohn Mikula of Pervasive tells us about the Pervasive Data Cloud. They wanted to take their on premise “Data Integrator” product, basically a command line tool ($, devs needed to implement), to a wider audience.\n\nStarted 4 years ago. They realized that the data sources they’re connecting to and pumping to, like Quickbooks Online, Salesforce, etc are all SaaS from the get go. “Well, let’s make our middle part the same!”\n\nThey wrote a Java EE wrapper, put it on Rackspace colo initally.\n\nIt gets a customer’s metadata, puts it on a queue, another system takes it off and process it. A very scaling-friendly architecture. And Rackspace (colo) wasn’t scaling fast enough, so they moved it to Amazon.\n\nTheir initial system had 2 glassfish front ends, 25 workers\n\nFor queuing, they tried Amazon SQS but it was limited, then went to Apache Zookeeper\n\nFirst effort was about “deploy a single app” – namely salesforce/quickbooks integration. Then they made a domain specific model and refactored and made an API to manage the domain specific entities so new apps could be created easily.\n\nRecommended approach – solve easy problems and work from there. That’s more than enough for people to buy in.\n\nTheir core engine’s not designed for multitenancy – have batches of workers for one guy’s code – so their code can be unsafe but it’s in its own bucket and doesn’t mess up anyone else.\n\nChanging internal business processes in a mature company was a challenge – moving from perm license model to per month just with accounting and whatnot was a big long hairy deal.\n\nMaking the API was rough. His estimate of a couple months grew to 6. Requirements gathering was a problem, very iterative. They weren’t agile enough – they only had one interim release and it wasn’t really usable; if they did it again they’d do the agile ‘right thing’ of putting out usable milestones more frequently to see what worked and what people really needed.\n\nIn Closing\n\nWhew! I found all the presentations really engaging and thank everyone for sharing the nuts and bolts of how they did it!"
    }
}