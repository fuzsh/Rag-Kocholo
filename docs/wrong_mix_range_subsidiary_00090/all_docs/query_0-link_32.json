{
    "id": "wrong_mix_range_subsidiary_00090_0",
    "rank": 32,
    "data": {
        "url": "https://theagileadmin.com/tag/cloud-computing/",
        "read_more_link": "",
        "language": "en",
        "title": "Cloud Computing",
        "top_image": "https://s0.wp.com/i/blank.jpg",
        "meta_img": "https://s0.wp.com/i/blank.jpg",
        "images": [
            "https://theagileadmin.com/wp-content/uploads/2020/09/cropped-austin1-1024x435-2.jpg",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://s2.wp.com/i/logo/wpcom-gray-white.png",
            "https://pixel.wp.com/b.gif?v=noscript"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Ernest Mueller"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Posts about Cloud Computing written by Ernest Mueller",
        "meta_lang": "en",
        "meta_favicon": "https://s1.wp.com/i/favicon.ico",
        "meta_site_name": "the agile admin",
        "canonical_link": "https://theagileadmin.com/tag/cloud-computing/",
        "text": "This monthâ€™s ACUG meeting was cooler than usual â€“ instead of having one speaker talk on a cloud-related topic, we had multiple group members do short presentation on what theyâ€™re actually doing in the cloud. I love talks like that, itâ€™s where you get real rubber meets the road takeaways.\n\nI thought Iâ€™d share my notes on the presentations. Iâ€™ll write up the one we did separately, but I got a lot out of these:\n\nOData to the Cloud, by Craig Vyal from Pervasive Software\n\nMoving your SaaS from Colo to Cloud, by Josh Arnold from Arnold Marziani (previously of PeopleAdmin)\n\nDevOps and the Cloud, by Chris Hilton from Thoughtworks\n\nMoving Software from On Premise to SaaS, by John Mikula from Pervasive Software\n\nThe Programmable Infrastructure Environment, by Peco Karayanev and Ernest Mueller from National Instruments (see next post!)\n\nMy editorial comments are in italics. Slides are linked into the headers where available.\n\nOData to the Cloud\n\nOData was started by Microsoft (â€œbut donâ€™t hold that against itâ€) under the Open Specification Promise. Craig did an implementation of it at Pervasive.\n\nItâ€™s a RESTful protocol for CRUDdy GET/POST/DELETE of data. Uses AtomPub-based feeds and returns XML or JSON. You get the schema and the data in the result.\n\nYou can create an OData producer of a data source, consume OData from places that support it, and view it via stuff like iPhone/Android apps.\n\nCurrent producers â€“ Sharepoint, SQL Azure, Netflix, eBay, twitpic, Open Govâ€™t Data Initiative, Stack Overflow\n\nCurrent consumers â€“ PowerPivot in Excel, Sesame, Tableau. Libraries for Java (OData4J), .NET 4.0/Silverlight 4, OData SDK for PHP\n\nIt is easier for â€œbusiness userâ€ to consume than SOAP or REST. Craig used OData4J to create a producer for the Pervasive product.\n\nQuestions from the crowd:\n\nCompression/caching? Nothing built in. Though normal HTTP level compression would work Iâ€™d think. It does â€œpageâ€ long lists of results and can send a section of n results at a time.\n\nAuth? Your problem. Some people use Oauth. He wrote a custom glassfish basic HTTP auth portal.\n\nCompetition? Gdata is kinda like this.\n\nSeems to me itâ€™s one part REST, one part â€œmaking you have a DTD for your XMLâ€. Which is good! Weâ€™re very interested in OData for our data centric services coming up.\n\nMoving your SaaS from Colo to Cloud\n\nJosh Arnold was from PeopleAdmin, now heâ€™s a tech recruiter, but can speak to what they did before he left. PeopleAdmin was a Sungard type colo setup. Had a â€œrottingâ€ out of country DR site.\n\nThey were rewriting their stack from java/mssql to ruby/linux.\n\nAt the time they were spending $15k/mo on the colo (not including the cost of their HW). Amazon estimated cost was 1/3 that but really they found out after moving itâ€™s 1/2. What was the surprise cost? Lower than expected perf (disk io) forced more instances than physical boxes of equivalent â€œsize.â€\n\nFlexible provisioning and autoscaling was great, the colo couldnâ€™t scale fast enough. How do you scale?\n\nThe cloud made having an out of country DR site easy, and not have it rot and get old.\n\nQuestion: What did you lose in the move? We were prepared for mental â€œcontrol issuesâ€ so didnâ€™t have those. Thereâ€™s definitely advanced functionality (e.g. with firewalls) and native hardware performance you lose, but that wasnâ€™t much.\n\nThey evalled Rackspace and Amazon (cursory eval). They had some F5s they wanted to use and the ability to mix in real hardware was tempting but they mainly went straight to Amazon. Drivers were the community around it and their leadership in the space.\n\nTimeline was 2 years (rewrite app, slowly migrate customers). Itâ€™ll be more like 3-4 before itâ€™s done. There were issues where they were glad they didnâ€™t mass migrate everyone at once.\n\nTechnical challenges:\n\nPerformance was a little lax (disk performance, they think) and they ended up needing more servers. Used tricks like RAIDed EBSes to try to get the most io they could (mainly for the databases).\n\nEvery customer had a SSL cert, and they had 600 of them to mess with. That was a problem because of the 5 Elastic IP limit. Went to certs that allow subsidiary domains â€“ Digicert allowed 100 per cert (other CAs limit to much less) so they could get 100 per IP.\n\nApp servers did outbound LDAP conns to customer premise for auth integration and they usually tried to allow those in via IP rules in their corporate firewalls, but now on Amazon outbound IPs are dynamic. They set up a proxy with a static (elastic) Ip to route all that through.\n\nRightscale â€“ they used it. They like it.\n\nThey used nginx for the load balancing, SSL termination. Was a single point of failure though.\n\nRemember that many of the implementations you are hearing about now were started back before Rackspace had an API, before Amazon had load balancers, etc.\n\nIn discussion about hybrid clouds, the point was brought up a lot of providers talk about it â€“ gogrid, opsource, rackspace â€“ but often there are gotchas.\n\nDevOps and the Cloud\n\nChris Hilton from Thoughtworks is all about the DevOps, and works on stuff like continuous deployment for a living.\n\nDevOps is:\n\ncollaboration between devs and operations staff\n\nagile sysadmin, using agile dev tools\n\ndev/ops/qa integration to achieve business goals\n\nWhy DevOps?\n\nSilos. agile dev broke down the wall between dev/qa (and biz).\n\ndevs are usually incentivized for change, and ops are incentivized for stability, which creates an innate conflict.\n\nbut if both are incentivized to deliver business value insteadâ€¦\n\nDevOps Practices\n\nversion control!\n\nautomated provisioning and deployment (Puppet/chef/rPath)\n\nself healing\n\nmonitoring infra and apps\n\nidentical environments dev/test/prod\n\nautomated db mgmt\n\nWhy DevOps In The Cloud?\n\ncloud requires automation, devops provides automation\n\nReferences\n\nâ€œContinuous Deliveryâ€ Humble and Farley\n\nRapid and Reliable Releases InfoQ\n\nRefactoring Databases by Ambler and Sadalage\n\nAnother tidbit: theyâ€™re writing puppet lite in powershell to fill the tool gap â€“ some tool suppliers are starting, but the general degree of tool support for people who use both Windows and Linux is shameful.\n\nMoving Software from On Premise to SaaS\n\nJohn Mikula of Pervasive tells us about the Pervasive Data Cloud. They wanted to take their on premise â€œData Integratorâ€ product, basically a command line tool ($, devs needed to implement), to a wider audience.\n\nStarted 4 years ago. They realized that the data sources theyâ€™re connecting to and pumping to, like Quickbooks Online, Salesforce, etc are all SaaS from the get go. â€œWell, letâ€™s make our middle part the same!â€\n\nThey wrote a Java EE wrapper, put it on Rackspace colo initally.\n\nIt gets a customerâ€™s metadata, puts it on a queue, another system takes it off and process it. A very scaling-friendly architecture. And Rackspace (colo) wasnâ€™t scaling fast enough, so they moved it to Amazon.\n\nTheir initial system had 2 glassfish front ends, 25 workers\n\nFor queuing, they tried Amazon SQS but it was limited, then went to Apache Zookeeper\n\nFirst effort was about â€œdeploy a single appâ€ â€“ namely salesforce/quickbooks integration. Then they made a domain specific model and refactored and made an API to manage the domain specific entities so new apps could be created easily.\n\nRecommended approach â€“ solve easy problems and work from there. Thatâ€™s more than enough for people to buy in.\n\nTheir core engineâ€™s not designed for multitenancy â€“ have batches of workers for one guyâ€™s code â€“ so their code can be unsafe but itâ€™s in its own bucket and doesnâ€™t mess up anyone else.\n\nChanging internal business processes in a mature company was a challenge â€“ moving from perm license model to per month just with accounting and whatnot was a big long hairy deal.\n\nMaking the API was rough. His estimate of a couple months grew to 6. Requirements gathering was a problem, very iterative. They werenâ€™t agile enough â€“ they only had one interim release and it wasnâ€™t really usable; if they did it again theyâ€™d do the agile â€˜right thingâ€™ of putting out usable milestones more frequently to see what worked and what people really needed.\n\nIn Closing\n\nWhew! I found all the presentations really engaging and thank everyone for sharing the nuts and bolts of how they did it!\n\nTwo cloud systems management suppliers talk about their bidness! My comments in italics.\n\nCloud Autoscaling in Enterprise Computing by George Reese (enStratus Networks LLC)\n\nHow the Top Social Games Scale on the Cloud by Michael Crandell (RightScale, Inc)\n\nI am more familiar with RightScale, but just read Reeseâ€™s great Cloud Application Architectures book on the plane here. Whose cuisine will reign supreme?\n\nenStratus\n\nReese starts talking about â€œnaive autoscalingâ€ being a problem. The cloud isnâ€™t magic; you have to be careful. He defines â€œenterpriseâ€ autoscaling as scaling that is cognizant of financial constraints and not this hippy VC-funded twitter type nonsense.\n\nReactive autoscaling is done when the systemâ€™s resource requirements exceed demand. Proactive autoscaling is done in response to capacity planning â€“ â€œrun more during the day.â€\n\nProactive requires planning. And automation needs strict governors in place.\n\nIn our PIE autoscaling, we have built limits like that into the model â€“ kinda like any connection pool. Min, max, rate of increase, etc.\n\nHe says your controls shouldnâ€™t be all â€œnumber of servers,â€ but be â€œbudgetâ€ based. Hmmm. Thatâ€™s ideal but is it too ideal? And so what do you do, shut down all your servers if you get to the 28th of the month and you run out of cash?\n\nCPU is not a scaling metric. Have better metrics tied to things that matter like TPS/response time. Completely agree there; scaling just based on CPU/memory/disk is primitive in the extreme.\n\nEfficiency is a key cloud metric. Get your utilization high.\n\nHereâ€™s where I kinda disagree â€“ it can often be penny wise and pound foolish. In the name of â€œefficiencyâ€ Iâ€™ve seen people put a bunch of unrelated apps on one server and cause severe availability problems. Screw utilization. Or use a cloud provider that uses a different charging model â€“ I forget which one it was, but we had a conf call with one cloud provider that only charged on CPU used, not â€œservers provisioned.â€\n\nOf course you donâ€™t have to take it to an extreme, just roll down to your minimum safe redundancy number on a given tier when you can.\n\nSecurity â€“ well, you tend not to do some centralized management things (like add to Active Directory) in the cloud. It makes user management hard. Or just makes you use LDAP, like God intended.\n\nCloud bursting â€“ scaling from on premise into the cloud.\n\nCase study â€“ a diaper company. Had a loyalty program. It exceeded capacity within an hour of launch. Humans made a scaling decision to scale at the load balancing tier, and enStratus executed the auto-scale change. They checked it was valid traffic and all first.\n\nBut is this too fiddly for many cases? If you are working with a â€œlarger than 5 boxesâ€ kind of scale donâ€™t you really want some more active automation?\n\nRightScale\n\nThe RightScale blog is full of good info!\n\nThey run 1.2 million cloud servers! hey see things like 600k concurrent users, 100x scaling in 4 days, 15k instances, 1:2000 management ratioâ€¦\n\nNow about gaming and social apps. They power the top 10 Facebook apps. They are an open management environment that lives atop the cloud suppliersâ€™ APIs.\n\nGames have a natural lifecycle where they start small, maybe take off, get big, eventually taper off. Itâ€™s not a flat demand curve, so flat supply is â€˜tarded.\n\nDuring the early phase, game publishers need a cheap, fast solution that can scale. They use Chef and other stuff in server templates for dynamic boot-time configuration.\n\nTypically, game server side tech looks like normal Web stuff! Apache+HAproxy LB, app servers, db cache (memcached), db (sharded mySQL master/slave pairs). Plus search, queues, admin, logs.\n\nInstance types â€“ you start to see a lot of larger instances â€“ large and extra large. Is this because of legacy comfort issues? Is it RAM needs?\n\nCentOS5 dominates! Generic images, configured at boot. One company rebundles for faster autoscale. Not much ubuntu or Windows. To be agile you need to do that realtime config.\n\nA lot of the boxes are used for databases. Web/app and load balancing significant too. Thereâ€™s a RightScale paper showing a 100k packets per second LB limit with Amazon.\n\nPeople use autoscaling a lot, but mainly for web app tier. Not LBs because the DNS changing is a pain. And people donâ€™t autoscale their DBs.\n\nThey claim a lot lower human need on average for management on RightScale vs using the APIs â€œor the consoles.â€ Thatâ€™s a big or. One of our biggest gripes with RightScale is that they consume all those lovely cloud APIs and then just give you a GUI and not an API. Thatâ€™s lame. It does a lot of good stuff but then it â€œterminatesâ€ the programmatic relationship. [Edit: Apparently they have a beta API now, added since we looked at them.]\n\nHe disagrees with Reese â€“ the problem isnâ€™t that there is too much autoscaling, itâ€™s that it has never existed. I tend to agree. Dynamic elasticity is key to these kind of business models.\n\nIf your whole DB fits into memcache, what is mySQL for? Writes sometimes? NoSQL sounds cool but in the meantime use memcache!!!\n\nThe cloud has enabled things to exist that wouldnâ€™t have been able to before. Higher agility, lower cost, improved performance with control, anew levels of resiliency and automation, and full lifecycle support.\n\nWhat Is Microsoft Azure?\n\nIâ€™m going to attempt to explain Microsoft Azure in â€œnormal Web personâ€ language. Like many of you, I am more familiar with Linux/open source type solutions, and like many of you, my first forays into cloud computing have been with Amazon Web Services. It can often be hard for people not steeped in Redmondese to understand exactly what the heck theyâ€™re talking about when Microsoft people try to explain their offerings. (I remember a time some years ago I was trying to get a guy to explain some new Microsoft data access thing with the usual three letter acronym name. I asked, â€œIs it a library? A language? A protocol? A daemon? Branding? What exactly is this thing youâ€™re trying to get me to uptake?â€ The reply was invariably â€œItâ€™s an innovative new way to access data!â€ Sigh. I never did get an answer and concluded â€œNever mind.â€)\n\nMicrosoft has released their new cloud offering, Azure. Our company is a close Microsoft partner since we use a lot of their technologies in developing our companyâ€™s desktop software products, so as â€œcloud guyâ€ Iâ€™ve gotten some in depth briefings and even went to PDC this year to learn more (some of my friends who have known me over the course of my 15 years of UNIX administration were horrified). â€œCloud computingâ€ is an overloaded enough term that itâ€™s not highly descriptive and it took a while to cut through the explanations to understand what Azure really is. Let me break it down for you and explain the deal.\n\nPoint of Comparison: Amazon (IaaS)\n\nIn Amazon EC2, as hopefully everyone knows by now, you are basically given entire dynamically-provisioned, hourly-billed virtual machines that you load OSes on and install software and all that. â€œLike servers, but somewhere out in the ether.â€ Those kinds of cloud offerings (e.g. Amazon, Rackspace, most of them really) are called Infrastructure As A Service (IaaS). Youâ€™re responsible for everything you normally would be, except for the data center work. Azure is not an IaaS offering but still bears a lot of similarities to Amazon; Iâ€™ll get into details later.\n\nPoint of Comparison: Google App Engine (PaaS)\n\nTake Googleâ€™s App Engine as another point of comparison. There, you just upload your Python or Java application to their portal and â€œit runs on the Web.â€ You donâ€™t have access to the server or OS or disk or anything. And it â€œmagicallyâ€ scales for you. This approach is called Platform as a Service (PaaS). They provide the full platform stack, you only provide the end application. On the one hand, you donâ€™t have to mess with OS level stuff â€“ if you are just a Java programmer, you donâ€™t have to know a single UNIX (or Windows) command to transition your app from â€œBut it works in Eclipse!â€ to running on a Web server on the Internet. On the other hand, that comes with a lot of limitations that the PaaS providers have to establish to make everything play together nicely. One of our early App Engine experiences was sad â€“ one of our developers wrote a Java app that used a free XML library to parse some XML. Well, that library had functionality in it (that we werenâ€™t using) that could write XML to disk. You canâ€™t write to disk in App Engine, so its response was to disallow the entire library. The app didnâ€™t work and had to be heavily rewritten. So itâ€™s pretty good for code that you are writing EVERY SINGLE LINE OF YOURSELF. Azure isnâ€™t quite as restrictive as App Engine, but it has some of that flavor.\n\nAzureâ€™s Model\n\nWindows Azure falls between the two. First of all, Azure is a real â€œhosted cloudâ€ like Amazon Web Services, like most of us really think about when we think cloud computing; itâ€™s not one of these on premise things that companies are branding as â€œcloudâ€ just for kicks. Thatâ€™s important to say because it seems like nowadays the larger the company, the more they are deliberately diluting the term â€œcloudâ€ to stick their products under its aegis. Microsoft isnâ€™t doing that, this is a â€œcloud offeringâ€ in the classical (where classical means 2008, I guess) sense.\n\nHowever, in a number of important ways itâ€™s not like Amazon. Iâ€™d definitely classify it as a PaaS offering. You upload your code to â€œRolesâ€ which are basically containers that run your application in a Windows 2008(ish) environment. (There are two types â€“ a â€œWeb roleâ€ has a stripped down IIS provided on it, a â€œWorker roleâ€ doesnâ€™t â€“ the only real difference between the two.) You do not have raw OS access, and cannot do things like write to the registry. But, it is less restrictive than App Engine. You can bundle up other stuff to run in Azure â€“ even run Java apps using Apache Tomcat. You have to be able to install whatever you want to run â€œxcopy onlyâ€ â€“ in other words, no fancy installers, it needs to be something you could just copy the files to a Windows PC, without administrative privilege, and run a command from the command line and have it work. Luckily, Tomcat/Java fits that description. They have helper packs to facilitate doing this with Tomcat, memcached, and Apache/PHP/MediaWiki. At PDC they demoed Dominoâ€™s Pizza running their Java order app on it and a WordPress blog running on it. So itâ€™s not only for .NET programmers. Managed code is easier to deploy, but you can deploy and run about anything that fits the â€œcopy and run command lineâ€ model.\n\nI find this approach a little ironic actually. Itâ€™s been a lot easier for us to get the Java and open source (well, the ones with Windows ports) parts of our infrastructure running on Azure than Windows parts! Everybody provides Windows stuff with an installer, of course, and you canâ€™t run installers on Azure. Anyway, in its core computing model itâ€™s like Google App Engine â€“ itâ€™s more flexible than that (good) but it doesnâ€™t do automatic scaling (bad). If it did autoscaling Iâ€™d be willing to say â€œItâ€™s better than App Engine in every way.â€\n\nIn other ways, itâ€™s a lot like Amazon. They offer a variety of storage options â€“ blobs (like S3), tables (like SimpleDB), queues (like SQS), drives (like EBS), SQL Azure (like RDS). They have an integral CDN. They do hourly billing. Pricing is pretty similar to Amazon â€“ itâ€™s hard to totally equate apples to apples, but Azure compute is $0.12/hr and an Amazon small Windows image compute is $0.12/hr (Coincidence? I think not.). And you have to figure out scaling and provisioning yourself on Amazon too â€“ or pay a lot of scratch to one of the provisioning companies like RightScale.\n\nWhatâ€™s Unique and Different\n\nWell, the largest thing that Iâ€™ve already mentioned is the PaaS approach. If you need OS level access, youâ€™re out of luck; if you donâ€™t want to have to mess with OS management, youâ€™re in luck! So to the first order of magnitude, you can think of Azure as â€œlike Amazon Web Services, but the compute uses more of a Google App Engine model.â€\n\nBut wait, thereâ€™s more!\n\nOne of the biggest things that Azure brings to the table is that, using Visual Studio, you can run a local Azure â€œfabricâ€ on your PC, which means you can develop, test, and run cloud apps locally without having to upload to the cloud and incur usage charges. This is HUGE. One of the biggest pains about programming for Amazon, for instance, is that if you want to exercise any of their APIs, you have to do it â€œup there.â€ Also, you canâ€™t move images back and forth between Amazon and on premise. Now, there are efforts like EUCALYPTUS that try to overcome some of this problem but in the end you pretty much just have to throw in the towel and do all dev and test up in the cloud. Amazon and Eclipse (and maybe Xen) â€“ get together and make it happen!!!!\n\nHereâ€™s something else interesting. In a move that seems more like a decision from a typical cranky cult-of-personality open source project, they have decided that proper Web apps need to be asynchronous and message-driven, and by God thatâ€™s what youâ€™re going to do. Their load balancers wonâ€™t do sticky sessions (only round robin) and time out all connections between all tiers after 60 seconds without exception. If you need more than that, tough â€“ rewrite your app to use a multi-tier message queue/event listener model. Now on the one hand, itâ€™s hard for me to disagree with that â€“ Iâ€™ve been sweating our developers, telling them thatâ€™s the correct best-practice model for scalability on the Web. But again youâ€™re faced with the â€œWell what if Iâ€™m using some preexisting software and thatâ€™s not how itâ€™s architected?â€ problem. This is the typical PaaS pattern of â€œitâ€™s great, if youâ€™re writing every line of code yourself.â€\n\nIn many ways, Azure is meant to be very developer friendly. In a lot of ways thatâ€™s good. As a system admin, however, I wince every time they go on about â€œYou can deploy your app to Azure just by right clicking in Visual Studio!!!â€ Of course, thatâ€™s not how anyone with a responsibly controlled production environment would do it, but it certainly does make for fast easy adoption in development. The curve for a developer who is â€œjustâ€ a C++/Java/.NET/whatever wrangler to get up and going on an IaaS solution like Amazon is pretty large comparatively; here, itâ€™s â€œgo sign up for an account and then click to deploy from your IDE, and voila itâ€™s running on the Intertubes.â€ So itâ€™s a qualified good â€“ it puts more pressure on you as an ops person to go get the developers to understand why they need to utilize your services. (In a traditional server environment, they have to go through you to get their code deployed.) Often, for good or ill, we use the release process as a touchstone to also engage developers on other aspects of their code that need to be systems engineered better.\n\nNow, thatâ€™s my view of the major differences. I think the usual Azure sales pitch would say something different â€“ Iâ€™ve forgotten two of their huge differentiators, their service bus and access control components. They are branded under the name â€œAppFabric,â€ which as usual is a name Microsoft is also using for something else completely different (a new true app server for Windows Server, including projects formerly code named Dublin and Velocity â€“ think of it as a real WebLogic/WebSphere type app server plus memcache.)\n\nTheir service bus is an ESB. As alluded to above, youâ€™re going to want to use it to do messaging. You can also use Azure Queues, which is a little confusing because the ESB is also a message queue â€“ Iâ€™m not clear on their intended differentiation really. You can of course just load up an ESB yourself in any other IaaS cloud solution too, so if you really want one you could do e.g. Apache ServiceMix hosted on Amazon. But, they are managing this one for you which is a plus. You will need to use it to do many of the common things youâ€™d want to do.\n\nTheir access control â€“ is a mess. Sorry, Microsoft guys. The whole rest of the thing, Iâ€™ve managed to cut through the â€œMicrosoft acronyms versus the rest of the worldâ€™s terms and definitionsâ€ factor, but not here. â€œYou see, you use ACSâ€™s WIF STS to generate a SWT,â€ says our Microsoft rep with a straight face. They seem to be excited that it will use peopleâ€™s Microsoft Live IDs, so if you want people to have logins to your site and you donâ€™t want to manage any of that, it is probably nice. It takes SAML tokens too, I think, though Iâ€™m not sure if the caveats around that end up equating to â€œWell, not really.â€ Anyway, their explanations have been incoherent so far and Iâ€™m not smelling anything Iâ€™m really interested in behind it. But thereâ€™s nothing to prevent you from just using LDAP and your own Internet SSO/federation solution. I donâ€™t count this against Microsoft because no one else provides anything like this, so even if I ignore the Azure one it doesnâ€™t put it behind any other solution.\n\nThe Future\n\nMicrosoft has said they plan to add on some kind of VM/IaaS offering eventually because of the demand. For us, the PaaS approach is a bit of a drawback â€“ we want to do all kinds of things like â€œvirus scan uploaded files,â€ â€œrun a good load balancer,â€ â€œrun an LDAP serverâ€, and other things that basically require more full OS access. I think we may have an LDAP direction with the all-Java OpenDS, but itâ€™s a pain point in general.\n\nI think a lot of their decisions that are a short term pain in the ass (no installs, no synchronous) are actually good in the long term. If all developers knew how to develop async and did it by default, and if all software vendors, even Windows based ones, provided their product in a form that could just be â€œcopy and run without admin privsâ€ to install, the world would be a better place. Thatâ€™s interesting in that â€œSure itâ€™s hard to use now but itâ€™ll make the world better eventuallyâ€ is usually heard from the other side of the aisle.\n\nConclusion\n\nAzureâ€™s a pretty legit offering! And Iâ€™m very impressed by their velocity. I think itâ€™s fair to say that overall Azure isnâ€™t quite as good as Amazon except for specific use cases (youâ€™re writing it all in .NET by hand in Visual Studio) â€“ but no one else is as good as Amazon either (believe me, I evaluated them) and Amazon has years of head start; Azure is brand new but already at about 80%! That puts them into the top 5 out of the gate.\n\nWithout an IaaS component, you still canâ€™t do everything under the sun in Azure. But if youâ€™re not depending on much in the way of big third party software chunks, itâ€™s feasible; if youâ€™re doing .NET programming, itâ€™s very compelling.\n\nDo note that I havenâ€™t focused too much on the attributes and limitations of cloud computing in general here â€“ thatâ€™s another topic â€“ this article is meant to compare and contrast Azure to other cloud offerings so that people can understand its architecture.\n\nI hope that was clear. Feel free and ask questions in the comments and Iâ€™ll try to clarify!\n\nI went to OpsCamp this last weekend here in Austin, a get-together for Web operations folks specifically focusing on the cloud, and it was a great time! Hereâ€™s my after action report.\n\nThe event invite said it was in the Spider House, a cool local coffee bar/normal bar. I hadnâ€™t been there before, but other people that had said â€œThatâ€™s insane! Theyâ€™ll never fit that many people! Thereâ€™s outside seating but itâ€™s freezing out!â€ That gave me some degree of trepidation, but I still racked out in time to get downtown by 8 AM on a Saturday (sigh!). Happily, it turned out that the event was really in the adjacent music/whatnot venue also owned by Spider House, the United States Art Authority, which they kindly allowed us to use for free! There were a lot of people there; we werenâ€™t overfilling the place but it was definitely at capacity, there were near 100 people in attendance.\n\nI had just heard of OpsCamp through word of mouth, and figured it was just going to be a gathering of local Austin Web ops types. Which would be entertaining enough, certainly. But as I looked around the room I started recognizing a lot of guys from Velocity and other major shows; CEOs and other high ranked guys from various Web ops related tool companies. Sponsors included John Willis and Adam Jacob (creator of Chef) from Opscode , Luke Kanies from Reductive Labs (creator of Puppet), Damon Edwards and Alex Honor from DTO Solutions (formerly ControlTier), Mark Hinkle and Matt Ray from Zenoss, Dave Nielsen (CloudCamp), Michael CotÃ© (Redmonk), Bitnami, Spiceworks, and Rackspace Cloud. Other than that, there were a lot of random Austinites and some guys from big local outfits (Dell, IBM).\n\nYou can read all the tweets about the event if you swing that way.\n\nOpsCamp kinda grew out of an earlier thing, BarCampESM, also in Austin two years ago. I never heard about that, wish I had.\n\nHow It Went\n\nI had never been to an â€œunconferenceâ€ before. Basically thereâ€™s no set agenda, itâ€™s self-emergent. It worked pretty well. Iâ€™ll describe the process a bit for other noobs.\n\nFirst, there was a round of lightning talks. Brett from Rackspace noted that â€œsize matters,â€ Bill from Zenoss said â€œmonitoring is important,â€ and Luke from Reductive claimed that â€œin 2-4 years â€˜cloudâ€™ wonâ€™t be a big deal, itâ€™ll just be how people are doing things â€“ unless youâ€™re a jackass.â€\n\nThen it was time for sessions. People got up and wrote a proposed session name on a piece of paper and then went in front of the group and pitched it, a hand-count of â€œhow many people find this interestingâ€ was taken.\n\nCandidates included:\n\nservice level to resolution\n\nphysical access to your cloud assets\n\nautodiscovery of systems\n\ndecompose monitoring into tool chain\n\ntool chain for automatic provisioning\n\nmonitoring from the cloud\n\nmonitoring in the cloud â€“ widely dispersed components\n\nagent based monitoring evolution\n\ndevops is the debil â€“ change to the role of sysadmins\n\nAnd more\n\nWe decided that so many of these touched on two major topics that we should do group discussions on them before going to sessions. They were:\n\nmonitoring in the cloud\n\nconfig mgmt in the cloud\n\nThis seemed like a good idea; these are indeed the two major areas of concern when trying to move to the cloud.\n\nSadly, the whole-group discussions, especially the monitoring one, were unfruitful. For a long ass time people threw out brilliant quips about â€œWhy would you bother monitoring a server anywayâ€ and other such high-theory wonkery. I got zero value out of these, which was sad because the topics were crucially interesting â€“ just too unfocused; you had people coming at the problem 100 different ways in sound bytes. The only note I bothered to write down was that â€œmonitoring pornâ€ (too many metrics) makes it hard to do correlation. We had that problem here, and invested in a (horrors) non open-source tool, Opnet Panorama, that has an advanced analytics and correlation engine that can make some sense of tens of thousands of metrics for exactly that reason.\n\nSessions\n\nThere were three sessions. I didnâ€™t take many notes in the first one because, being a Web ops guy, I was having to work a release simultaneously with attending OpsCamp ğŸ˜›\n\nContinue reading â†’"
    }
}