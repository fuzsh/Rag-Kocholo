{
    "id": "dbpedia_2104_3",
    "rank": 42,
    "data": {
        "url": "https://gmd.copernicus.org/articles/15/251/2022/",
        "read_more_link": "",
        "language": "en",
        "title": "Convolutional conditional neural processes for local climate downscaling",
        "top_image": "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-avatar-web.png",
        "meta_img": "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-avatar-web.png",
        "images": [
            "https://contentmanager.copernicus.org/800952/365/ssl",
            "https://contentmanager.copernicus.org/800952/365/ssl",
            "https://www.geoscientific-model-development.net/licenceSVG_16.svg",
            "https://www.geoscientific-model-development.net/licenceSVG_16.svg",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-avatar-thumb150.png",
            "https://www.geoscientific-model-development.net/mendeley.png",
            "https://www.geoscientific-model-development.net/reddit.png",
            "https://www.geoscientific-model-development.net/twitter.png",
            "https://www.geoscientific-model-development.net/facebook.png",
            "https://www.geoscientific-model-development.net/linkedin.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f01-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f02-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f03-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f04-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f05-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-t01-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-t02-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f06-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f07-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f08-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f09-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f10-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f11-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-f12-thumb.png",
            "https://gmd.copernicus.org/articles/15/251/2022/gmd-15-251-2022-t03-thumb.png",
            "https://www.geoscientific-model-development.net/mendeley.png",
            "https://www.geoscientific-model-development.net/reddit.png",
            "https://www.geoscientific-model-development.net/twitter.png",
            "https://www.geoscientific-model-development.net/facebook.png",
            "https://www.geoscientific-model-development.net/linkedin.png",
            "https://contentmanager.copernicus.org/319373/365/ssl",
            "https://contentmanager.copernicus.org/319376/365/ssl"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "J. Scott",
            "Richard E"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Abstract. A new model is presented for multisite statistical downscaling of temperature and precipitation using convolutional conditional neural processes\n(convCNPs). ConvCNPs are a recently developed class of models that allow deep-learning techniques to be applied to off-the-grid spatio-temporal\ndata. In contrast to existing methods that map from low-resolution model output to high-resolution predictions at a discrete set of locations, this\nmodel outputs a stochastic process that can be queried at an arbitrary latitudeâlongitude coordinate. The convCNP model is shown to outperform an\nensemble of existing downscaling techniques over Europe for both temperature and precipitation taken from the VALUE intercomparison project. The\nmodel also outperforms an approach that uses Gaussian processes to interpolate single-site downscaling models at unseen locations. Importantly,\nsubstantial improvement is seen in the representation of extreme precipitation events. These results indicate that the convCNP is a robust\ndownscaling model suitable for generating localised projections for use in climate impact studies.",
        "meta_lang": "en",
        "meta_favicon": "https://www.geoscientific-model-development.net/favicon_copernicus_16x16_.ico",
        "meta_site_name": "",
        "canonical_link": "https://gmd.copernicus.org/articles/15/251/2022/",
        "text": "Statistical downscaling methods are vital tools in translating global and regional climate model output to actionable guidance for climate impact studies. General circulation models (GCMs) and regional climate models (RCMs) are used to provide projections of future climate scenarios; however, coarse resolution and systematic biases result in unrealistic behaviour, particularly for extreme events (Allen etÂ al.,Â 2016; Maraun etÂ al.,Â 2017). In recognition of these limitations, downscaling is routinely performed to correct raw GCM and RCM outputs. This is achieved either by dynamical downscaling, running a nested high-resolution simulation or via statistical methods. Comparisons of statistical and dynamical downscaling suggest that neither group of methods is clearly superior (Ayar etÂ al.,Â 2016; Casanueva etÂ al.,Â 2016); however, in practice computationally cheaper statistical methods are widely used.\n\nMajor classes of statistical downscaling methods are model output statistics (MOS) and perfect prognosis (PP; Maraun etÂ al.,Â 2010). MOS methods explicitly adjust the simulated distribution of a given variable to the observed distribution using variations of quantile mapping (Teutschbein and Seibert,Â 2012; Piani etÂ al.,Â 2010; Cannon etÂ al.,Â 2020). Though these methods are widely applied in impact studies, they struggle to downscale extreme values and artificially alter trends (Maraun,Â 2013; Maraun etÂ al.,Â 2017). In contrast, in PP downscaling, the aim is to learn a transfer functionÂ f such that\n\n(1) y ^ = f ( x , Z ) ,\n\nwhere y^ is the downscaled prediction of a given climate variable whose true value isÂ y at locationÂ x and ZÂ is a set of predictors from the climate model (Maraun and Widmann,Â 2018). This is based on the assumption that while sub-grid-scale and parameterised processes are poorly represented in GCMs, the large-scale flow is generally better resolved (Maraun and Widmann,Â 2018).\n\nMultiple different models have been trialled for parameterising f. Traditional statistical methods used for this purpose include multiple linear regression (GutiÃ©rrez etÂ al.,Â 2013; Hertig and Jacobeit,Â 2013), generalised linear models (San-MartÃ­n etÂ al.,Â 2017) and analogue techniques (Hatfield and Prueger,Â 2015; Ayar etÂ al.,Â 2016). More recently, there has been considerable interest in applying advances in machine learning to this problem, including relevance vector machines (Ghosh and Mujumdar,Â 2008), artificial neural networks (Sachindra etÂ al.,Â 2018), auto-encoders (Vandal etÂ al.,Â 2019), recurrent neural networks (Bhardwaj etÂ al.,Â 2018; Misra etÂ al.,Â 2018), generative adversarial networks (White etÂ al.,Â 2019) and convolutional neural networks (Vandal etÂ al.,Â 2017, 2018; Pan etÂ al.,Â 2019; BaÃ±o-Medina etÂ al.,Â 2020; HÃ¶hlein etÂ al.,Â 2020; Liu etÂ al.,Â 2020). These models are trained in a supervised framework by learning a mapping from low-resolution predictors to downscaled values at a particular set of locations for which observations are available. Unsupervised downscaling using normalising flows has also been proposed (Groenke etÂ al.,Â 2020).\n\nLimitations remain in these models. In many climate applications it is desirable to make projections that are both (i) consistent over multiple locations and (ii) specific to an arbitrary locality. The problem of multi-site downscaling has been widely studied, with two classes of approaches emerging. Traditional methods take analogues or principal components of the coarse-resolution field as predictors. The spatial dependence is then explicitly modelled for a given set of sites, using observations at those locations to train the model (Maraun and Widmann,Â 2018; Cannon,Â 2008; Bevacqua etÂ al.,Â 2017; Mehrotra and Sharma,Â 2005). More recent work has sought to leverage advances in machine learning, for example convolutional neural networks (CNNs), for feature extraction (Vandal etÂ al.,Â 2017; Bhardwaj etÂ al.,Â 2018; Misra etÂ al.,Â 2018; BaÃ±o-Medina etÂ al.,Â 2020; HÃ¶hlein etÂ al.,Â 2020). These methods take in a grid of low-resolution predictors and output downscaled predictions either on a fixed grid or at a pre-determined list of sites. The question naturally arises as to how we can generate predictions at new locations at test time. Models trained in one location can be applied in another using transfer learning (Wang etÂ al.,Â 2021). In this case, however, the output predictions are still at the resolution or list of sites determined at training time (i.e. a CNN model trained on 0.1â resolution will output 0.1â resolution predictions, regardless of where it is applied). To make predictions on a grid with a different resolution or at a new set of locations requires interpolation of model predictions or taking the closest location.\n\nIn this study we propose a new approach to statistical downscaling using a convolutional conditional neural process model (convCNP; Gordon etÂ al.,Â 2019), a state-of-the-art probabilistic machine learning method combining ideas from Gaussian processes (GPs) and deep neural networks. This model learns a mapping between a gridded set of low-resolution predictors and a continuous stochastic process over longitude and latitude representing the downscaled prediction of the required variable. In contrast to previous work where discrete predictions are made at a list of locations determined at training time, the stochastic process output from the convCNP can be queried at any location where a prediction is required. Although to our knowledge this is the first application of such a model in downscaling, similar work has demonstrated the advantages of learning a mapping from discrete input data to continuous prediction fields in modelling idealised fluid flow (Li etÂ al.,Â 2020b, a; Lu etÂ al.,Â 2019).\n\nThe specific aims of this study are as follows.\n\nDevelop a new statistical model for downscaling GCM output capable of generating a stochastic process as a prediction that can be queried at an arbitrary site.\n\nCompare the performance of the statistical model to existing strong baselines.\n\nCompare the performance of the statistical model at locations outside of the training set to existing interpolation methods.\n\nQuantify the impact of including sub-grid-scale topography on model predictions.\n\nSectionÂ 2 outlines the development of the downscaling model and presents the experimental setup used to address aimsÂ 2â4. SectionÂ 3 compares the performance of the statistical model to an ensemble of baselines. SectionsÂ 4 andÂ 5 explore model performance at unseen locations and the impact of including local topographic data. Finally, Sect.Â 6 presents a discussion of these results and suggestions for further applications.\n\nThe convCNP model outperforms the GP-baseline at unseen stations. Results for MAE, Spearman correlation and mean bias are shown in Fig.Â 6. For maximum temperature, the convCNP model gives small improvements over the baseline model, with Spearman correlations of 0.99 (0.98) and MAE of 1.19ââC (1.35ââC) for the convCNP (GP baseline). Importantly, large outliers (>â10ââC) in the baseline MAE are not observed in the convCNP predictions. FigureÂ 7 shows the spatial distribution of MAE for the convCNP and GP-baseline together with the difference in MAE between the two models. This demonstrates that stations with high MAE in the convCNP model are primarily concentrated in the complex topography of the European Alps. The GP-baseline model displays large MAE not only in the Alps but also at other locations, for example in Spain and France. The convCNP improves predictions at 82 out of the 86Â stations.\n\nRepeating this analysis for precipitation, the convCNP model gives substantial improvement over the baseline for MAE and Spearman correlation. Spearman correlations are 0.57 (0.20) and MAE 2.10âmm (2.71âmm) for convCNP (GP-baseline). In contrast to maximum temperature, there is no clear link between topography and MAE, though again convCNP predictions have large MAE for multiple stations located in the Alps. The convCNP model improves on baseline predictions at 80 out of 86Â stations.\n\nComparisons between models for extreme metrics are shown in Fig.Â 8. For maximum temperature, the convCNP has slightly lower absolute 98th percentile bias than the baseline. For precipitation, errors are substantially lower, with median absolute 98th percentile bias of 4.90âmm for convCNP compared to 22.92âmm for GP-baseline. The spatial distributions of 98th percentile bias for maximum temperature and precipitation predictions together with the difference in absolute bias are shown in Fig.Â 9. For maximum temperature, the convCNP does not improve on the baseline at all stations. The GP-baseline exhibits uniformly positive biases, while the convCNP model has both positive and negative biases. Improvements are seen through central and eastern Europe, while the convCNP performs comparatively poorly in southern Europe and the British Isles. For precipitation, predictions have low biases across much of Europe for the convCNP, with the exception of in the complex terrain of the Alps. GP-baseline biases are negative throughout the domain. For this case, convCNP predictions have lower bias at 84 of the 86Â validation stations.\n\nA limitation to the analysis of the standard climate metrics in TableÂ 2 is that these only assess certain aspects of the predicted distribution. To assess the calibration of the models, we next examine the probability integral transform (PIT) values. The PIT value for a given prediction is defined as the cumulative density function (CDF) of the distribution predicted by the convCNP model evaluated at the true observed value. These values can be used to determine whether the model is calibrated by evaluating the PIT for every model prediction at the true observation, and plotting their distribution. If the model is properly calibrated, it is both necessary and sufficient for this distribution to be uniform (Gneiting etÂ al.,Â 2007). PIT distributions for maximum temperature and wet-day precipitation are shown in Fig.Â 10. For temperature, the model is well calibrated overall, although the predicted distributions are often too narrow, as demonstrated by the peaks around zero and one indicating that the observed value falls outside the predicted normal distribution. Calibration of the precipitation model is poorer overall. The peak in PIT mass around zero indicates that this model often over-predicts rainfall accumulation. Performance varies between individual stations for both temperature and precipitation, with examples of PIT distributions for both well-calibrated and poorly calibrated stations shown in Fig.Â 10.\n\nThis study demonstrated the successful application of convCNPs to statistical downscaling of temperature and precipitation. The convCNP model performs well compared to strong baselines from the VALUE ensemble on both mean and extreme metrics. For both variables the convCNP model outperforms an interpolation-based baseline. Inclusion of sub-grid-scale topographic information is shown to improve model performance for mean and extreme metrics for maximum temperature and mean metrics for precipitation. The convCNP model has a significant advantage over these baselines in that the output prediction is a continuous function, allowing predictions to be made at an arbitrary (longitude, latitude, elevation) location. Although only temperature and precipitation are considered in this study, the model is easily applied to any climate variable with available station observations, for example wind speed.\n\nSeveral areas remain for future work, both within the convCNP model and in comparison to other downscaling methods. In the convCNP predictions, representation of certain metrics, notably precipitation extremes requires further improvement, particularly in areas with complex topography. The topography ablation experiments demonstrate that the convCNP P98 bias increases in regions with complex topography. Dynamically, this is likely due to local flow effects such as FÃ¶hn winds (Gaffin,Â 2007; Basist etÂ al.,Â 1994), which depend on the incident angle of the background flow. A possible explanation for this is that the MLP is insufficient to model these effects. Further experimentation with adding a second CNN to capture the sub-grid-scale processes and possibly conditioning predictions of this model on local flow is left as a topic for future research. Another avenue for improving model performance would be to change the distribution predicted by the convCNP. Model calibration results presented in Sect.Â 4 indicate that the temperature downscaling model could be improved using a distribution with heavier tails. Precipitation model calibration requires improvement, with the model frequently under-predicting wet-day accumulations. A possible explanation for this is that the left-hand tail of the gamma distribution decays rapidly. For cases where the mode of the predicted distribution is greater than zero, small observed accumulations are heavily penalised. Previous work has acknowledged that the Bernoulliâgamma distribution used in this study is not realistic for all sites (VlÄek and Huth,Â 2009) and suggested that representation of precipitation extremes can be improved using a Bernoulliâgammaâgeneralised Pareto distribution (BenÂ Alaya etÂ al.,Â 2015; Volosciuk etÂ al.,Â 2017). Future work will explore improving the calibration of the downscaling models using mixture distributions and normalising flows (Rezende and Mohamed,Â 2015) to improve the calibration of the model. A further possibility for extending the convCNP model would be to explicitly incorporate time by building recurrence into the model (Qin etÂ al.,Â 2019; Singh etÂ al.,Â 2019).\n\nFuture work will also focus on developing a standardised framework to compare the convCNP model to a variety of deep-learning baselines, building on the work of (Vandal etÂ al.,Â 2019). Although some studies have indicated that in certain cases deep-learning models offer little advantage over widely used statistical methods such as those included in the VALUE ensemble (BaÃ±o-Medina etÂ al.,Â 2020; Vandal etÂ al.,Â 2019), others suggest that deep-learning methods offer improved performance (White etÂ al.,Â 2019; Vandal etÂ al.,Â 2017; HÃ¶hlein etÂ al.,Â 2020; Liu etÂ al.,Â 2020; Sachindra etÂ al.,Â 2018; Misra etÂ al.,Â 2018). Further work is required both to rigorously compare the convCNP model to other machine learning models for downscaling and to generate a standardised intercomparison of models more broadly. Examination of a larger set of metrics, particularly for precipitation, would also be beneficial.\n\nThe final aspect to consider is extending these promising results downscaling reanalysis data to apply to future climate simulations from GCMs. An in depth analysis of the convCNP model performance on seasonal and annual metrics would be beneficial in informing application to impact scenarios. A limitation in all PP downscaling techniques is that applying a transfer function trained on reanalysis data to a GCM makes the assumption that the predictors included in the context set are realistically simulated in the GCM (Maraun and Widmann,Â 2018). Future work will aim to address this issue through training a convCNP model directly on RCM or GCM hindcasts available through projects such as EURO-CORDEX (Jacob etÂ al.,Â 2014).\n\nAllen, S., Boschung, J., Nauels, A., Xia, Y., Bex, V., and Midgley, P.: Climate change 2013: the physical science basis. Contribution of working groupÂ I to the fifth assessment report of the Intergovernmental Panel on Climate Change, Cambridge University Press, Cambridge, UK, 2016.âa\n\nAyar, P.Â V., Vrac, M., Bastin, S., Carreau, J., DÃ©quÃ©, M., and Gallardo, C.: Intercomparison of statistical and dynamical downscaling models under the EURO-and MED-CORDEX initiative framework: present climate evaluations, Clim. Dynam., 46, 1301â1329, 2016.âa, b, c, d\n\nBaÃ±o-Medina, J., Manzanas, R., and GutiÃ©rrez, J. M.: Configuration and intercomparison of deep learning neural models for statistical downscaling, Geosci. Model Dev., 13, 2109â2124, https://doi.org/10.5194/gmd-13-2109-2020, 2020.âa, b, c\n\nBasist, A., Bell, G.Â D., and Meentemeyer, V.: Statistical relationships between topography and precipitation patterns, J. Climate, 7, 1305â1315, 1994.âa\n\nBenÂ Alaya, M.Â A., Chebana, F., and Ouarda, T.Â B.: Probabilistic multisite statistical downscaling for daily precipitation using a Bernoulliâgeneralized pareto multivariate autoregressive model, J. Climate, 28, 2349â2364, 2015.âa\n\nBenestad, R.Â E., Chen, D., Mezghani, A., Fan, L., and Parding, K.: On using principal components to represent stations in empiricalâstatistical downscaling, Tellus A, 67, 28326, https://doi.org/10.3402/tellusa.v67.28326, 2015.âa, b, c\n\nBevacqua, E., Maraun, D., HobÃ¦k Haff, I., Widmann, M., and Vrac, M.: Multivariate statistical modelling of compound events via pair-copula constructions: analysis of floods in Ravenna (Italy), Hydrol. Earth Syst. Sci., 21, 2701â2723, https://doi.org/10.5194/hess-21-2701-2017, 2017.âa\n\nBhardwaj, A., Misra, V., Mishra, A., Wootten, A., Boyles, R., Bowden, J., and Terando, A.Â J.: Downscaling future climate change projections over Puerto Rico using a non-hydrostatic atmospheric model, Climatic Change, 147, 133â147, 2018.âa, b\n\nCannon, A.Â J.: Probabilistic multisite precipitation downscaling by an expanded BernoulliâGamma density network, J. Hydrometeorol., 9, 1284â1300, 2008.âa, b\n\nCannon, A.Â J., Piani, C., and Sippel, S.: Bias correction of climate model output for impact models, chap.Â 5, in: Climate Extremes and Their Implications for Impact and Risk Assessment, edited by: Sillmann, J., Sippel, S., and Russo, S., Elsevier, 77â104, https://doi.org/10.1016/B978-0-12-814895-2.00005-7, 2020.âa\n\nCasanueva, A., Herrera, S., FernÃ¡ndez, J., and GutiÃ©rrez, J.Â M.: Towards a fair comparison of statistical and dynamical downscaling in the framework of the EURO-CORDEX initiative, Climatic Change, 137, 411â426, 2016.âa\n\nChollet, F.: Xception: Deep learning with depthwise separable convolutions, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 1251â1258, 2017.âa\n\nDanielson, J. J. and Gesch, D. B.: Global multi-resolution terrain elevation data 2010 (GMTED2010), U.S. Geological Survey Open-File Report 2011-1073, 26Â pp., available at: https://developers.google.com/earth-engine/datasets/catalog/USGS_GMTED2010 (last access: 8Â December 2020), 2011.âa, b\n\nDee, D. P., Uppala, S. M., Simmons, A. J., Berrisford, P., Poli, P., Kobayashi, S., Andrae, U., Balmaseda, M. A., Balsamo, G., Bauer, P., Bechtold, P., Beljaars, A. C. M., van de Berg, L., Bidlot, J., Bormann, N., Delsol, C., Dragani, R., Fuentes, M., Geer, A. J., Haimberger, L., Healy, S. B., Hersbach, H., HÃ³lm, E. V., Isaksen, L., KÃ¥llberg, P., KÃ¶hler, M., Matricardi, M., McNally, A. P., Monge-Sanz, B. M., Morcrette, J.-J., Park, B.-K., Peubey, C., de R osnay, P., Tavolato, C., ThÃ©paut, J.-N., and Vitart, F.: The ERA-Interim reanalysis: Configuration and performance of the data assimilation system, Q. J. Roy. Meteor. Soc., 137, 553â597, https://doi.org/10.1002/qj.828, 2011 (data available at: https://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/, last access: 7Â December 2020).âa, b\n\nDubois, Y., Gordon, J., and Foong, A.Â Y.: Neural Process Family, available at: http://yanndubs.github.io/Neural-Process-Family/, last access: 10Â December 2020.âa\n\nGaffin, D.Â M.: Foehn winds that produced large temperature differences near the southern Appalachian Mountains, Weather Forecast., 22, 145â159, 2007.âa\n\nGarnelo, M., Rosenbaum, D., Maddison, C.Â J., Ramalho, T., Saxton, D., Shanahan, M., Teh, Y.Â W., Rezende, D.Â J., and Eslami, S.: Conditional neural processes, arXiv [preprint], arXiv:1807.01613, 2018.âa, b\n\nGhosh, S. and Mujumdar, P.Â P.: Statistical downscaling of GCM simulations to streamflow using relevance vector machine, Adv. Water Resour., 31, 132â146, 2008.âa\n\nGneiting, T., Balabdaoui, F., and Raftery, A.Â E.: Probabilistic forecasts, calibration and sharpness, J. R. Stat. Soc. B, 69, 243â268, 2007.âa\n\nGordon, J., Bruinsma, W.Â P., Foong, A.Â Y., Requeima, J., Dubois, Y., and Turner, R.Â E.: Convolutional conditional neural processes, arXiv [preprint], arXiv:1910.13556, 2019.âa, b, c\n\nGroenke, B., Madaus, L., and Monteleoni, C.: ClimAlign: Unsupervised statistical downscaling of climate variables via normalizing flows, in: Proceedings of the 10th International Conference on Climate Informatics, 60â66, 2020.âa\n\nGutiÃ©rrez, J.Â M., San-MartÃ­n, D., Brands, S., Manzanas, R., and Herrera, S.: Reassessing statistical downscaling techniques for their robust application under climate change conditions, J. Climate, 26, 171â188, 2013.âa, b, c, d, e, f\n\nGutiÃ©rrez, J.Â M., Maraun, D., Widmann, M., Huth, R., Hertig, E., Benestad, R., RÃ¶ssler, O., Wibig, J., Wilcke, R., Kotlarski, S., and San Martin, D.: An intercomparison of a large ensemble of statistical downscaling methods over Europe: Results from the VALUE perfect predictor cross-validation experiment, Int. J. Climatol., 39, 3750â3785, 2019.âa, b, c, d, e\n\nHatfield, J.Â L. and Prueger, J.Â H.: Temperature extremes: Effect on plant growth and development, Weather and Climate Extremes, 10, 4â10, 2015.âa\n\nHaylock, M., Hofstra, N., KleinÂ Tank, A., Klok, E., Jones, P., and New, M.: A European daily high-resolution gridded data set of surface temperature and precipitation for 1950â2006, J. Geophys. Res.-Atmos., 113, D20119, https://doi.org/10.1029/2008JD010201, 2008.âa\n\nHe, K., Zhang, X., Ren, S., and Sun, J.: Deep residual learning for image recognition, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 770â778, 2016.âa\n\nHertig, E. and Jacobeit, J.: A novel approach to statistical downscaling considering nonstationarities: application to daily precipitation in the Mediterranean area, J. Geophys. Res.-Atmos., 118, 520â533, 2013.âa\n\nHertig, E., Maraun, D., Bartholy, J., Pongracz, R., Vrac, M., Mares, I., GutiÃ©rrez, J.Â M., Wibig, J., Casanueva, A., and Soares, P.Â M.: Comparison of statistical downscaling methods with respect to extreme events over Europe: Validation results from the perfect predictor experiment of the COST Action VALUE, Int. J. Climatol., 39, 3846â3867, 2019.âa, b\n\nHÃ¶hlein, K., Kern, M., Hewson, T., and Westermann, R.: A Comparative Study of Convolutional Neural Network Models for Wind Field Downscaling, arXiv [preprint], arXiv:2008.12257, 2020.âa, b, c\n\nHuth, R., MikÅ¡ovská»³, J., Å tÄpÃ¡nek, P., Belda, M., Farda, A., ChlÃ¡dovÃ¡, Z., and PiÅ¡oft, P.: Comparative validation of statistical and dynamical downscaling models on a dense grid in central Europe: temperature, Theor. Appl. Climatol., 120, 533â553, 2015.âa, b, c, d, e, f, g\n\nJacob, D., Petersen, J., Eggert, B., Alias, A., Christensen, O.Â B., Bouwer, L.Â M., Braun, A., Colette, A., DÃ©quÃ©, M., Georgievski, G., and Georgopoulou, E.: EURO-CORDEX: new high-resolution climate change projections for European impact research, Reg. Environ. Change, 14, 563â578, 2014.âa\n\nJacobeit, J., Hertig, E., Seubert, S., and Lutz, K.: Statistical downscaling for climate change projections in the Mediterranean region: methods and results, Reg. Environ. Change, 14, 1891â1906, 2014.âa\n\nKatz, R.Â W. and Brown, B.Â G.: Extreme events in a changing climate: variability is more important than averages, Climatic Change, 21, 289â302, 1992.âa\n\nKingma, D.Â P. and Ba, J.: Adam: A method for stochastic optimization, arXiv [preprint], arXiv:1412.6980, 2014.âa\n\nKlein Tank, A. M. G., Wijngaard, J. B., KÃ¶nnen, G. P., BÃ¶hm, R., DemarÃ©e, G., Gocheva, A., Mileta, M., Pashiardis, S., Hejkrlik, L., KernâHansen, C., and Heino, R.: Daily dataset of 20th-century surface air temperature and precipitation series for the European Climate Assessment, Int. J. Climatol., 22, 1441â1453, https://doi.org/10.1002/joc.773, 2002 (data available at: https://www.ecad.eu/dailydata/index.php, last access: 8Â December 2020).âa, b\n\nLi, Z., Kovachki, N., Azizzadenesheli, K., Liu, B., Bhattacharya, K., Stuart, A., and Anandkumar, A.: Fourier neural operator for parametric partial differential equations, arXiv [preprint], arXiv:2010.08895, 2020a.âa\n\nLi, Z., Kovachki, N., Azizzadenesheli, K., Liu, B., Bhattacharya, K., Stuart, A., and Anandkumar, A.: Neural operator: Graph kernel network for partial differential equations, arXiv [preprint], arXiv:2003.03485, 2020b.âa\n\nLiu, Y., Ganguly, A.Â R., and Dy, J.: Climate Downscaling Using YNet: A Deep Convolutional Network with Skip Connections and Fusion, in: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 3145â3153, 2020.âa, b\n\nLu, L., Jin, P., and Karniadakis, G.Â E.: Deeponet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators, arXiv [preprint], arXiv:1910.03193, 2019.âa\n\nMaraun, D.: Bias correction, quantile mapping, and downscaling: Revisiting the inflation issue, J. Climate, 26, 2137â2143, 2013.âa\n\nMaraun, D. and Widmann, M.: Statistical downscaling and bias correction for climate research, Cambridge University Press, Cambridge, UK, 2018.âa, b, c, d, e\n\nMaraun, D., Wetterhall, F., Ireson, A. M., Chandler, R. E., Kendon, E. J., Widmann, M., Brienen, S., Rust, H. W., Sauter, T., ThemeÃl, M., and Venema, V. K. C.: Precipitation downscaling under climate change: Recent developments to bridge the gap between dynamical models and the end user, Rev. Geophys., 48, RG3003, https://doi.org/10.1029/2009RG000314, 2010.âa\n\nMaraun, D., Widmann, M., GutiÃ©rrez, J.Â M., Kotlarski, S., Chandler, R.Â E., Hertig, E., Wibig, J., Huth, R., and Wilcke, R.Â A.: VALUE: A framework to validate downscaling approaches for climate change studies, Earths Future, 3, 1â14, 2015.âa\n\nMaraun, D., Shepherd, T.Â G., Widmann, M., Zappa, G., Walton, D., GutiÃ©rrez, J.Â M., Hagemann, S., Richter, I., Soares, P.Â M., Hall, A., and Mearns, L. O.: Towards process-informed bias correction of climate change simulations, Nat. Clim. Change, 7, 764â773, 2017.âa, b\n\nMaraun, D., Huth, R., GutiÃ©rrez, J.Â M., MartÃ­n, D.Â S., Dubrovsky, M., Fischer, A., Hertig, E., Soares, P.Â M., Bartholy, J., PongrÃ¡cz, R., and Widmann, M.: The VALUE perfect predictor experiment: evaluation of temporal variability, Int. J. Climatol., 39, 3786â3818, 2019.âa\n\nMehrotra, R. and Sharma, A.: A nonparametric nonhomogeneous hidden Markov model for downscaling of multisite daily rainfall occurrences, J. Geophys. Res.-Atmos., 110, D16108, https://doi.org/10.1029/2004JD005677, 2005.âa\n\nMisra, S., Sarkar, S., and Mitra, P.: Statistical downscaling of precipitation using long short-term memory recurrent neural networks, Theor. Appl. Climatol., 134, 1179â1196, 2018.âa, b, c\n\nPan, B., Hsu, K., AghaKouchak, A., and Sorooshian, S.: Improving precipitation estimation using convolutional neural network, Water Resour. Res., 55, 2301â2321, 2019.âa\n\nPiani, C., Haerter, J., and Coppola, E.: Statistical bias correction for daily precipitation in regional climate models over Europe, Theor. Appl. Climatol., 99, 187â192, 2010.âa\n\nQin, S., Zhu, J., Qin, J., Wang, W., and Zhao, D.: Recurrent attentive neural process for sequential data, arXiv [preprint], arXiv:1910.09323, 2019.âa\n\nRaynaud, D., Hingray, B., Zin, I., Anquetin, S., Debionne, S., and Vautard, R.: Atmospheric analogues for physically consistent scenarios of surface weather in Europe and Maghreb, Int. J. Climatol., 37, 2160â2176, 2017.âa, b\n\nRezende, D.Â J. and Mohamed, S.: Variational inference with normalizing flows, arXiv [preprint], arXiv:1505.05770, 2015.âa\n\nRibalaygua, J., Torres, L., PÃ³rtoles, J., Monjo, R., GaitÃ¡n, E., and Pino, M.: Description and validation of a two-step analogue/regression downscaling method, Theor. Appl. Climatol., 114, 253â269, 2013.âa, b\n\nSachindra, D., Ahmed, K., Rashid, M.Â M., Shahid, S., and Perera, B.: Statistical downscaling of precipitation using machine learning techniques, Atmos. Res., 212, 240â258, 2018.âa, b\n\nSan-MartÃ­n, D., Manzanas, R., Brands, S., Herrera, S., and GutiÃ©rrez, J.Â M.: Reassessing model uncertainty for regional projections of precipitation with an ensemble of statistical downscaling methods, J. Climate, 30, 203â223, 2017.âa, b, c, d, e\n\nSingh, G., Yoon, J., Son, Y., and Ahn, S.: Sequential Neural Processes, arXiv [preprint], arXiv:1906.10264, 27Â October 2019.âa\n\nTeutschbein, C. and Seibert, J.: Bias correction of regional climate model simulations for hydrological climate-change impact studies: Review and evaluation of different methods, J. Hydrol., 456, 12â29, 2012. âa\n\nTheobald, D.Â M., Harrison-Atlas, D., Monahan, W.Â B., and Albano, C.Â M.: Ecologically-relevant maps of landforms and physiographic diversity for climate adaptation planning, PLoS One, 10, e0143619, https://doi.org/10.1371/journal.pone.0143619, 2015 (data available at: https://developers.google.com/earth-engine/datasets/catalog/CSP_ERGo_1_0_Global_ALOS_mTPI, last access: 9Â December 2020).âa, b\n\nVandal, T., Kodra, E., Ganguly, S., Michaelis, A., Nemani, R., and Ganguly, A.Â R.: Deepsd: Generating high resolution climate change projections through single image super-resolution, in: Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining, 1663â1672, 2017.âa, b, c\n\nVandal, T., Kodra, E., Dy, J., Ganguly, S., Nemani, R., and Ganguly, A.Â R.: Quantifying uncertainty in discrete-continuous and skewed data with Bayesian deep learning, in: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2377â2386, 2018.âa\n\nVandal, T., Kodra, E., and Ganguly, A.Â R.: Intercomparison of machine learning methods for statistical downscaling: the case of daily and extreme precipitation, Theor. Appl. Climatol., 137, 557â570, 2019.âa, b, c\n\nVaughan, A.: annavaughan/convCNPClimate: First release (v1.0.0), Zenodo [code], https://doi.org/10.5281/zenodo.4554603, 2021.âa\n\nVlÄek, O. and Huth, R.: Is daily precipitation Gamma-distributed?: Adverse effects of an incorrect use of the KolmogorovâSmirnov test, Atmos. Res., 93, 759â766, 2009.âa\n\nVolosciuk, C., Maraun, D., Vrac, M., and Widmann, M.: A combined statistical bias correction and stochastic downscaling method for precipitation, Hydrol. Earth Syst. Sci., 21, 1693â1719, https://doi.org/10.5194/hess-21-1693-2017, 2017.âa\n\nWang, F., Tian, D., Lowe, L., Kalin, L., and Lehrter, J.: Deep Learning for Daily Precipitation and Temperature Downscaling, Water Resour. Res., 57, e2020WR029308, https://doi.org/10.1029/2020WR029308, 2021.âa\n\nWhite, B., Singh, A., and Albert, A.: Downscaling Numerical Weather Models with GANs, in: AGU Fall Meeting Abstracts, vol. 2019, GC43Dâ1357, 2019.âa, b\n\nWidmann, M., Bedia, J., GutiÃ©rrez, J.Â M., Bosshard, T., Hertig, E., Maraun, D., Casado, M.Â J., Ramos, P., Cardoso, R.Â M., Soares, P.Â M., and Ribalaygua, J.: Validation of spatial variability in downscaling results from the VALUE perfect predictor experiment, Int. J. Climatol., 39, 3819â3845, 2019.âa\n\nWilby, R.Â L., Dawson, C.Â W., and Barrow, E.Â M.: SDSM?a decision support tool for the assessment of regional climate change impacts, Environ. Modell. Softw., 17, 145â157, 2002.âa\n\nWilks, D.Â S.: Stochastic weather generators for climate-change downscaling, partÂ II: multivariable and spatially coherent multisite downscaling, WIREs Clim. Change, 3, 267â278, 2012.âa\n\nZerenner, T., Venema, V., Friederichs, P., and Simmer, C.: Downscaling near-surface atmospheric fields with multi-objective Genetic Programming, Environ. Modell. Softw., 84, 85â98, 2016.âa"
    }
}