{
    "id": "dbpedia_705_0",
    "rank": 39,
    "data": {
        "url": "https://www.nature.com/articles/s41593-024-01672-w",
        "read_more_link": "",
        "language": "en",
        "title": "Cognitive control training with domain-general response inhibition does not change children’s brains or behavior",
        "top_image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig1_HTML.png",
        "meta_img": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig1_HTML.png",
        "images": [
            "https://pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&sz=728x90&c=933040152&t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-024-01672-w%26doi%3D10.1038/s41593-024-01672-w%26techmeta%3D36,57,59%26subjmeta%3D1310,2150,2649,378,477,631%26kwrd%3DAttention,Cognitive+control,Psychology",
            "https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41539-022-00146-7/MediaObjects/41539_2022_146_Fig1_HTML.png",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-022-17695-x/MediaObjects/41598_2022_17695_Fig1_HTML.png",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-021-04152-4/MediaObjects/41598_2021_4152_Fig1_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig1_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig2_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig3_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig4_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig5_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-024-01672-w/MediaObjects/41593_2024_1672_Fig6_HTML.png",
            "https://pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&sz=300x250&c=-99517963&t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-024-01672-w%26doi%3D10.1038/s41593-024-01672-w%26techmeta%3D36,57,59%26subjmeta%3D1310,2150,2649,378,477,631%26kwrd%3DAttention,Cognitive+control,Psychology",
            "https://www.nature.com/static/images/logos/sn-logo-white-ea63208b81.svg",
            "https://www.nature.com/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg",
            "https://verify.nature.com/verify/nature.png",
            "https://www.nature.com/j0xe4gg7/article/s41593-024-01672-w"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Claire R",
            "Boris C",
            "Nico U. F"
        ],
        "publish_date": "2024-06-04T00:00:00",
        "summary": "",
        "meta_description": "Cognitive control is required to organize thoughts and actions and is critical for the pursuit of long-term goals. Childhood cognitive control relates to other domains of cognitive functioning and predicts later-life success and well-being. In this study, we used a randomized controlled trial to test whether cognitive control can be improved through a pre-registered 8-week intervention in 235 children aged 6–13 years targeting response inhibition and whether this leads to changes in multiple behavioral and neural outcomes compared to a response speed training. We show long-lasting improvements of closely related measures of cognitive control at the 1-year follow-up; however, training had no impact on any behavioral outcomes (decision-making, academic achievement, mental health, fluid reasoning and creativity) or neural outcomes (task-dependent and intrinsic brain function and gray and white matter structure). Bayesian analyses provide strong evidence of absent training effects. We conclude that targeted training of response inhibition does little to change children’s brains or their behavior. Cognitive control is important for later-life success and is often targeted for interventions. Here the authors show that response inhibition training in a large sample of children over 8 weeks did not change their brains or behavior in the short or long term.",
        "meta_lang": "en",
        "meta_favicon": "/static/images/favicons/nature/apple-touch-icon-f39cb19454.png",
        "meta_site_name": "Nature",
        "canonical_link": "https://www.nature.com/articles/s41593-024-01672-w",
        "text": "Associations between cognitive control and outcome measures\n\nWe first tested how cognitive control performance was associated with each of our outcome measures. To remove task-related variance specific to any assessment of cognitive control, we obtained a single factor of cognitive control derived from multiple cognitive control measures (Methods). We observed significant positive associations between cognitive control performance and several of the outcome measures in the expected direction (Extended Data Fig. 1): delay of gratification (that is, percentage of delayed choices in the intertemporal choice task; t (226) = 2.44, P = 0.015); academic achievement (t (217) = 2.53, P = 0.012); fluid reasoning (that is, Wechsler Abbreviated Scale of Intelligence (WASI) scores; t (216) = 2.27, P = 0.024); externalizing symptoms (t (184) = −2.15, P = 0.032) as well as mean diffusivity of right fronto-striatal tracts (t (145) = −2.81, P = 0.005). Cognitive control performance was, thus, correlated with a host of other outcomes, as commonly reported in the literature7,8,9,45.\n\nTraining indices\n\nTraining took place over an 8-week period. The motivation to train was high to begin with (Experimental Group = 5.30; Control Group = 5.30; out of 1–7) and decreased as training went on (F (6, 308.75) = 16.42, P < 0.001; Fig. 1a). No group differences were observed in overall motivation between groups (t (395.13) = −0.50, P = 0.61; BF10 = 0.23; Fig. 1a) nor an interaction between Session and Group (F (6,308.75) = 1.45, P = 0.194). Furthermore, on average, individuals in both groups trained a similar number of sessions (Experimental Group: n = 16.60 ± 8.35; Control Group: n = 16.99 ± 8.55). No significant difference was observed in the amount trained between both groups (t (205.33) = 0.33, P > 0.740; BF10 = 0.16; Fig. 1b). To assess whether each group improved on the trained cognitive function throughout the intervention, we examined changes over the training sessions in the stop-signal reaction time (SSRT; Experimental Group) and the ‘go-signal’ reaction time (Go RT; Control Group), respectively. For this, we looked at the slope of change in each trained cognitive function using a mixed model with training weeks added as a predictor. There was a main effect of Session where both groups improved on their trained cognitive functions over the training weeks (Experimental Group: F (1, 2292.60) = 121.30, P < 0.001, η2 = 0.05; Control Group: F (1, 3197.5) = 185.57, P < 0.001, η2 = 0.05; Fig. 1c). Thus, groups did not differ in training intensity or motivation and showed moderate improvements during training in the targeted processes.\n\nShort-term training-related changes\n\nNear transfer\n\nAs a primary measure of near transfer, we looked at the probability of successful stopping and response times to ‘go’ stimuli. The latter is of interest for both indexing training success for the response speed group as well as providing a measure of proactive slowing56 for the Experimental Group. A mixed model revealed a significant interaction between Session and Group in the probability of successful stopping in the SSRT (F (1,221.00) = 27.31, PFDRcorr < 0.001, η2 = 0.11; Fig. 2a). Follow-up paired t-tests comparing pre–post training scores revealed that the probability of successful stopping increased in the Experimental Group (t (215) = −5.96, P < 0.001). However, no significant change was found in the Control Group (t (218) = 1.43, P = 0.92). We also observed a significant interaction between Session and Group in Go RT (F (1, 227.28) = 31.75, PFDRcorr < 0.001, η2 = 0.12; Fig. 2b). Follow-up paired t-tests comparing pre–post training scores revealed that reaction times increased in the Experimental Group (t (228) = −5.02, P < 0.001) and decreased in the Control Group (t (228) = 2.94, P = 0.021).\n\nFar transfer—behavioral indices\n\nCognitive control\n\nTraining cognitive control was operationalized by targeting response inhibition. We assessed the impact of training response inhibition on other subprocesses associated with cognitive control (that is, inhibition as measured by tasks other than the SSRT, shifting and working memory). Given the potentially different impact of training on both speed and accuracy57, we performed factor analyses across all cognitive control tasks separately for error rates and reaction times (Methods). This yielded two factors for error rates (one jointly for inhibition and shifting and one for memory) and one single factor for reaction times. For error rates, there was a Session-by-Group interaction found with the inhibition/shifting factor (F (1, 215.68) = 10.678, PFDRcorr = 0.006, η2 = 0.05; Fig. 3a). Follow-up paired t-tests, however, revealed that neither group changed significantly from pre-training to post-training. For the memory factor, there was no Session-by-Group interaction (F (1, 212.72) = 0.090, P = 0.764, η2 < 0.001, BF10 = 0.188; Fig. 3b). For the reaction time factor, there was a significant Session-by-Group interaction (F (1,213.71) = 18.60, PFDRcorr < 0.001, η2 = 0.08; Fig. 3c). Pre–post t-test comparisons in the Experimental Group revealed an increase from pre-training to post-training (t (213) = −2.94, P = 0.022) and a decrease for the Control Group (t (212) = 3.16 P = 0.011).\n\nDecision-making\n\nFor the role of the proposer in the Dictator Game (DG) for coins shared, there was no significant Session-by-Group interaction (F (1, 199.18) = 0.144, P = 0.705, η2 < 0.001, BF10 = 0.201; Fig. 3d). For the role of the responder in the Ultimatum Game (UG) for offers accepted, there was no significant Session-by-Group interaction (F (1, 196.49) = 2.36, P = 0.126, η2 = 0.01, BF10 = 0.176; Fig. 3e). In the intertemporal choice task, there was no significant Session-by-Group interaction in the total percentage of delayed choices (F (1, 203.60) = 1.01, P = 0.317, η2 = 0.004, BF10 = 0.150; Fig. 3f).\n\nAcademic performance\n\nThere was no significant Session-by-Group interaction for total academic scores (F (1, 217.35) = 0.266, P = 0.606, η2 = 0.001, BF10 = 0.159; Fig. 3g).\n\nWASI\n\nThere was no significant Session-by-Group interaction found for WASI scores (F (1, 211.92) = 0.351, P = 0.554, η2 = 0.001, BF10 = 0.169; Fig. 3h).\n\nMental Health\n\nThere was no significant Session-by-Group interaction found for either internalizing problems (F (1, 125.47) = 4.10, P = 0.159, BF10 = 0.194; Fig. 3i) or externalizing problems (F (1, 123.94) = 0.972, P = 0.326, η2 = 0.007, BF10 = 0.228; Fig. 3j).\n\nCreativity\n\nThere was no significant Session-by-Group interaction for total creativity scores (a sum score of the five measures from Torrance Tests of Creative Thinking (TTCT); F (1, 209.32) = 3.373, P = 0.068, η2 = 0.02, BF10 = 0.448; Fig. 3k).\n\nFar transfer—neural indices\n\nFunctional magnetic resonance imaging\n\nAlthough we report brain regions classically implicated in inhibition during successful versus unsuccessful stop trials in our developmental sample (Supplementary Table 7), when looking at the whole brain, no significant interaction was observed between Session and Group for any voxel after correction for multiple comparisons. We also focussed our analysis on the right IFG, a core hub of cognitive control and response inhibition in particular49. For the region of interest (ROI) analysis, parameter estimates for each participant were extracted from the right IFG. A mixed model revealed a significant effect of Group (F (1, 271) = 11.43, P < 0.001, η2 = 0.04; higher activation overall for the Control Group compared to the Experimental Group) and no interaction between Session and Group (F (1, 271) = 3.87, P = 0.050, η2 = 0.01, BF10 = 1.105; Fig. 4a). Follow-up t-test showed no significant change in either group before or after training.\n\nCortical thickness\n\nTo assess potential training-related changes in cortical gray matter structure, we looked at the whole brain. There was no significant interaction between Session and Group for any voxel. We also obtained parameter estimates of cortical thickness for each participant extracted from the right IFG. A mixed model revealed no interaction between Session and Group (F (1, 139.85) = 0.016, P = 0.901, η2 < 0.001, BF10 = 0.200; Fig. 4b).\n\nResting-state connectivity\n\nWe looked at changes in connectivity profiles in circuits known to be implicated in cognitive control and response inhibition50, such as CON and FPN. Connectivity in the CON and FPN was extracted for each participant. Mixed models revealed no interaction between Session and Group in either of the two networks (CON: F (1, 141.34) = 0.053, P = 0.819, η2 < 0.001, BF10 = 0.180; Fig. 4c; FPN: F (1, 143.14) = 0.162, P = 0.688, η2 = 0.001, BF10 = 0.187; Fig. 4d).\n\nDiffusion tensor imaging\n\nFractional anisotropy and mean diffusivity, two measures of white matter microstructure, were extracted from connections between the frontal lobes and striatal areas of the right hemisphere, given their known role in cognitive control and response inhibition58. Mixed models revealed no significant interactions between Session and Group in either fractional anisotropy (F (1, 141.63) = 0.134, p = 0.715, η2 < 0.001, BF10 = 0.188; Fig. 4e) or mean diffusivity (F (1, 144.24) = 0.019, P = 0.891, η2 < 0.001, BF10 = 0.211; Fig. 4f) in the right frontal-striatal putamen.\n\nLong-term training-related changes\n\nNear transfer\n\nWe also tested if any training-related changes might persist or, indeed, emerge over time, as was asserted previously29, by comparing performance on outcome measures between training groups 1 year after training. For the probability of successful stopping in the SSRT, there was a significant interaction between Session and Group (F (1,227.16) = 8.68, PFDRcorr = 0.018, η2 = 0.04; Fig. 5a). Follow-up paired t-tests revealed that the probability of successful stopping remained increased in the Experimental Group (t (217) = −4.38, P = 0.001) after 1 year; however, no significant change was found in the Control Group (t (218) = −0.202, P = 1.000). For reaction time to the ‘go’ signal, there was a significant interaction between Session and Group (F (1, 235.94) = 13.32, PFDRcorr < 0.003, η2 = 0.05; Fig. 5b). Follow-up paired t-tests revealed that reaction times remained elevated in the Experimental Group (t (231) = −6.992, P < 0.001); however, no significant change was found in the Control Group (t (230) = −1.844, P = 0.399).\n\nFar transfer\n\nCognitive control\n\nNo significant changes remained in executive function tasks 1 year after training. These analyses were performed on a subset of tasks that were carried out at the follow-up due to COVID-19 restrictions. No Session-by-Group interaction was found in memory span in the Corsi task (F (1, 228.05) = 0.147, P = 0.702, η2 < 0.001, BF10 = 0.152; Fig. 6a); in proactive control, as measured by the AX-Continuous Performance Task (CPT) (F (1, 445) = 0.340, P = 0.560, η2 < 0.001, BF10 = 0.165; Fig. 6b); or in cognitive flexibility (F (1, 227.71) = 0.178, P = 0.183, η2 = 0.008, BF10 = 0.294; Fig. 6c).\n\nDecision-making\n\nThere was no significant Session-by-Group interaction for any of the decision-making measures (sharing in the DG: (F (1, 204.53) = 2.74, P = 0.099, η2 = 0.01, BF10 = 0.450; Fig. 6d)); for proportion of accepted offers in the UG (F (1, 198.66) = 0.385, P = 0.536, η2 = 0.002, BF10 = 0.174; Fig. 6e); or for percentage delayed choice in the intertemporal choice task (F (1, 202.89) = 0.116, P = 0.733, η2 < 0.001, BF10 = 0.166; Fig. 6f).\n\nMental health\n\nNo significant Session-by-Group interaction was found for internalizing problems (F (1, 154.70) = 2.23, P = 0.138, η2 = 0.01, BF10 = 0.207; Fig. 6g) or externalizing problems (F (1, 147.47) = 0.573, P = 0.450, η2 = 0.004, BF10 = 0.162; Fig. 6h).\n\nMediation of far transfer by near transfer\n\nA common argument in defense of the large heterogeneity within far transfer effects from training studies is that this depends crucially on whether near transfer is found51. We examined if changes in near transfer were in any way predictive of changes in far transfer. Our measure of near transfer was the probability of successful stopping. We found that near transfer was not predictive of performance change on any far transfer measure.\n\nTraining effect on mental health after COVID-19 lockdown\n\nMuch research has been dedicated to establishing that cognitive control might serve as a buffer to the onset of mental health problems47,52. Although our present sample was not at risk, data collection took place during COVID-19, which presented considerable challenges to mental health due to school closures and lockdowns59. We examined whether training cognitive control would buffer against any negative impact of COVID-19 measures on mental health. We studied apathy and mental health using the Apathy Evaluation Scale, clinical version (AES-C), and the Strengths & Difficulties Questionnaire (SDQ) for ages 4–17 years before and after the COVID-19 lockdown. We found that both groups were similar in terms of positive cases of COVID-19 as well as perceived stress (Supplementary Tables 5 and 6). Crucially, although we found a significant increase in apathy after the COVID-19 lockdown (F (1,178.29) = 29.82, P < 0.001; Extended Data Fig. 2a), this was not buffered by response inhibition training (F (1, 178.78) = 0.014, P = 0.905, η2 < 0.001, BF10 = 0.188; Extended Data Fig. 2a). There was no buffering effect of training on the strength and difficulties scores after the COVID-19 lockdown (F (1, 154.32) = 3.05, P = 0.083, η2 = 0.008, BF10 = 0.141; Extended Data Fig. 2b).\n\nControlling for socioeconomic status\n\nTo test for the robustness and generalizability of our effects, we re-ran all analyses of short-term and long-term near and far transfer effects while also controlling for socioeconomic status (SES). Controlling for SES did not change any of the outcomes.\n\nParticipants\n\nA total of 262 typically developing children were recruited for the study (6.03–13.31 years; mean age = 8.97 years; females = 52.84%) from schools within Greater London in the United Kingdom (data collection started in May 2019 and ended in May 2021). Sampling occurred by contacting over 2,000 schools in the Greater London area. Of those schools, 20 ended up participating from a diverse range of boroughs. Information material was disseminated among parents of participating schools, and only those children whose parents/carers had signed them up ended up taking part. Participants were excluded on the basis of formal diagnoses of neurodevelopmental disorders as well as a safety protocol for neuroimaging (for example, metal in the body and claustrophobia). After exclusion of incomplete data, our sample consisted of 235 children (6.03–13.31 years; mean age = 8.97 years; females = 51.91%). The ethnic composition of our sample was as follows: Asian = 14.65%; Black = 3.18%; Mixed/multiple ethnic groups = 17.20%; White = 64.33%; Other = 0.63%. SES was assessed based on employment and education of both parents72,73,74 (Supplementary Table 1). There was a positive skew in SES (mean = 1.64; on a scale of 1–5 where 1 is the highest score attainable). Children were randomly assigned to an experimental group training cognitive control (through inhibition) or to an active control group training response speed (Supplementary Figs. 1 and 2), with groups matched for gender and age, school and class based on mean matching. Matching was performed by an experimenter not involved in testing.\n\nThe University College London (UCL) ethics committee approved this study (protocol number: 12271/001). In accordance with this, written informed consent was obtained from parents, and assent was obtained from children after a description of the study was provided.\n\nStudy design\n\nThis study had four main phases. After an initial baseline data collection phase at pre-test, the 8-week computerized intervention was administered. This was followed by a post-test and, finally, a 1-year follow-up. Behavioral, questionnaire and neural data (that is, at pre-test, post-test and 1-year follow-up) were collected to examine independent near transfer and far transfer changes. Due to disruptions to in-person testing during the COVID-19 pandemic, no magnetic resonance imaging (MRI) was obtained at 1-year follow-up. Retention was 71.24% from pre-test to post-test and 99.40% from post-test to 1-year follow-up.\n\nTraining games\n\nTraining was programmed on Gorilla Experiment Builder (https://gorilla.sc/), a platform for running behavioral research online. Training was presented in the form of a computerized web-based Treasure Game. The training was designed to last 8 weeks, with four recommended sessions per week, one taking place at school and three at home. Each session was programmed to take approximately 15 min.\n\nBoth groups received identical training in terms of narrative, stimuli and intensity (Supplementary Fig. 2). The only difference between the groups was how participants were instructed to respond to the stop stimuli (that is, inhibit for the Experimental Group and respond for the Control Group; further details are provided in the Supplementary Information). Once every week, questions regarding children’s motivation were administered (Supplementary Information).\n\nExperimental Group: response inhibition training\n\nTo train response inhibition, a stop-signal response task was used. Participants were instructed to press the spacebar on presentation of a ‘go’ signal. On stop trials where a ‘stop’ signal appeared after the ‘go’ signal, participants were instructed to inhibit pressing the spacebar (however, see Supplementary Information Table 4 for specific descriptions of each training game and training mechanism). ‘Go’ and ‘stop’ signal stimuli and inhibition mechanism varied according to the game being played. The stop signal delay (SSD) was initially set at 200 ms. After successful inhibition, the SSD would decrease by 50 ms, and, after failed inhibition, it would increase by 50 ms75,76. This ensured that the training was adaptive. Stop trials occurred 26–47% for each training session. To ensure adaptiveness across training sessions, the SSD of each subsequent session was taken from the final ‘stop’ trial of the preceding session on that specific training game.\n\nControl Group: response speed training\n\nThe response speed training was identical to the experimental condition in all aspects except that a response was required for all signals. Participants were instructed to press the spacebar as quickly as possible. To ensure that training was adaptive for this group, participants had to respond within a time window that was set based on a rolling average of the response time of the previous 10 trials plus two standard deviations. This ensured that the training was adaptive while minimizing the effect of outliers on the response threshold.\n\nPre–post tasks\n\nBefore and after the training, three assessment timepoints took place onsite at the author’s laboratory: before the training (T0), after the training (T1) and 1-year follow-up (T2). Note that, due to the outbreak of the COVID-19 pandemic in March 2020, some participants completed one or more assessment timepoints online from home. The assessment battery included several child-friendly tasks measuring cognitive control and neural measurements as well as creativity, mental health and academic performance (Supplementary Fig. 1).\n\nCognitive control tasks\n\nA total of nine cognitive control tasks were administered, assessing different functions (that is, inhibition, shifting and working memory). For all tasks, participants were presented with practice trials, before main trials were administered, where they had to attain a criterion threshold for accuracy. Additionally, comprehension questions were employed to ensure participants understood the rules for each task (for example, ‘What button should you press if you see a bear on the screen?’). Rules were re-explained if participants answered incorrectly on any of the questions. The experimenter noted if the participant still failed to comprehend the task. All participants managed to pass these comprehension questions; therefore, no individual was excluded from the analysis. The task was presented using Presentation software (https://www.neurobs.com/, version 23). For remote testing during COVID-19, a subset of executive function tasks was administered online via Gorilla (https://gorilla.sc/)77,78.\n\nInhibition tasks\n\nSSRT task\n\nA measure of cognitive control was administered via a child-friendly version of the SSRT79. Ten practice trials were administered before 80 trials of the main task. Each trial started with the presentation of a fixation cross of 1,250 ms. During the task, participants were asked to press the left arrow key when seeing the ‘go’ signal (that is, a honey pot) on the left side of the screen and the down arrow key when the signal appeared on the right side. On 25% of the trials (that is, a ‘stop’ trial), a picture of bees was presented after the honey pot. This served as the ‘stop’ signal. The SSD started at 200 ms, decreased by 50 ms after a successful ‘stop’ trial and increased by 50 ms after an unsuccessful ‘stop’ trial. As a measure of inhibition, a mean SSRT (ms) was calculated using the integration method80. Several studies validated the SSRT as a measure of response inhibition81, and it is correlated with self-report measures of impulsive behaviors in young adults75.\n\nFlanker inhibition\n\nThe participants completed a child-friendly version of the Eriksen flanker inhibition task82. Children were presented with a row of fish on the screen. They were required to focus on the fish in the center (named Chloe) and indicate the direction in which it was swimming (that is, left key response required when the fish was facing left; down key response required when the fish was facing right). Participants were told to ignore the direction that other fish swim in and only indicate the direction that Chloe swam in. On congruent trials, all fish faced the same direction. On incongruent trials, surrounding fish faced the opposite direction to Chloe. Fish were presented for 700 ms before they disappeared. Participants were given a maximum of 2,500 ms to respond from stimulus onset. A total of 20 congruent trials and 20 incongruent trials were administered. This task was chosen because it is a child-friendly task for ages 6 years and up and was validated in several studies83,84. The difference in both reaction times and error rates between incongruent trials and congruent trials was calculated separately.\n\nStroop\n\nParticipants completed a child-friendly version of the Stroop task85. The task was introduced as the ‘Farm Animal’ game, where they were told to match animals to their homes (for example, dog to a kennel). They were presented with both auditory stimuli of an animal sound (for example, ‘bark’, ‘meow’ and ‘croak’ for dog, cat and frog, respectively) and visual stimuli of the animals. Crucially, participants were asked to match animals to where they live (for example, frog to a pond). They were told to listen carefully to an auditory cue indicating the animal type (for example, frog – ‘ribbit’) and not to pay attention to the visual cue of the animal presented on the screen. Trials lasted for 10,000 ms within which participants had to make a response. Although audio stimuli were presented for 600 ms, visual stimuli were presented until participants made a response (maximum of 1,000 ms). A blank screen with a ‘cross’ was presented between trials for 10,000 ms (inter-trial interval (ITI)). On congruent trials, both auditory and visual cues matched (for example, frog presented on screen and ‘ribbit’ tone played). On incongruent trials, auditory and visual cues did not match (that is, dog presented on screen and ‘ribbit’ tone played). Participants completed 72 trials in total, with 36 congruent and 36 incongruent trials. The differences in both reaction times and error rates between incongruent trials and congruent trials were calculated separately.\n\nMemory tasks\n\nN-back\n\nBoth the 1-back and 2-back tasks were administered to measure working memory86. The task was adapted to be child-friendly and introduced as the ‘Dino-Donut’ game, where participants were told that dinosaurs were lining up to eat some donuts. For the 1-back task, they were told to stop dinosaurs that tried to eat a donut twice in a row and to press the spacebar if they appeared consecutively to stop them. For the 2-back task, they were told that the dinosaurs became sneakier, and this time they should press the spacebar if the same dinosaur appeared two trials prior. Stimuli were shown for 500 ms followed by a 1,500-ms inter-stimulus-interval (ISI). Responses had to be made before the onset of the next stimulus presentation. Participants completed 80 trials in total, 40 for each N-back condition. As a measure of error rate, false alarm rate was calculated for both 1-back and 2-back tasks. Reaction times to make a correct response were also calculated.\n\nCorsi block-tapping task\n\nWorking memory span was assessed using the Corsi block-tapping task, which measures visuo-spatial working memory span with a higher value indicating a higher working memory span87. This task consisted of ‘Freddy the frog’ jumping between nine potential locations designed as lily pads. The participants followed the jumps by clicking on the lily pads in a forward sequence. Trials commenced with a countdown from 3 to 1 to alert participants to the start of a trial. Then, the stimulus of the frog jumping was shown for 600 ms for every jump. The ISI was fixed to 600 ms. Participants completed three practice trials with feedback, and there was a total of 14 main trials. Initially, participants had to remember and click on two lily pads. The task employed an adaptive staircase design where the working memory load (that is, number of lily pads to remember) increased by one when participants made two consecutive correct answers. The maximum working memory load attained was used as a working memory span measure.\n\nShifting tasks\n\nCognitive flexibility\n\nA child-friendly version of the cognitive flexibility task assessed participants’ ability for rule switching across dimensions (using sound cues: ‘animal’ or ‘size’). If a sound cue of ‘animal’ was played, participants had to indicate if the animal was a cat or a dog. If a sound cue of ‘size’ was played, participants had to indicate if the animal was big or small88. Participants had 10 s to respond, during which the stimuli remained on the screen before the trial timed out. Responses made before 200 ms after stimulus onset were not recorded. The ITI was jittered and ranged from 1,000 ms to 1,200 ms. Stay trials were preceded by a trial with the same rule (for example, deciding on the type of animal was presented twice in a row). During switch trials, the current trial was preceded by a trial in a different dimension (that is, participants had to first respond to the size of the animal and then to the type of animal that is presented). After a practice block, participants completed 40 trials (consisting of 28 stay trials and 12 switch trials). Participants completed 20 single-dimension trials in two blocks and 40 mixed trials in one block. The difference in both reaction times and error rates between switch trials and stay trials was calculated.\n\nFlanker shifting\n\nThe participants completed a child-friendly version of the Eriksen flanker shifting task88. Children were presented with a row of fish on the screen. They were told that all the fish swim in the same direction. However, two colors of fish would appear: orange and purple fish. When orange fish were presented, they were instructed to indicate the direction in which the fish swam (that is, left key response required when the fish faced left; down key response required when the fish faced right). When purple fish were presented, they were instructed to indicate the opposite direction in which the fish swam (that is, left key response required when the fish was facing right; down key response required when the fish was facing left). Fish were presented for 700 ms before they disappeared. Participants were given a maximum of 2,500 ms to respond from stimulus onset. Stay trials were defined as those where the rule for the previous trial was the same as the current trial (that is, purple trial after a purple trial; orange trial after an orange trial). Switch trials were defined as those where a rule change has occurred (that is, purple trial after an orange trial; orange trial after a purple trial). Based on this, there were 28 stay trials and 12 switch trials. The difference in both reaction times and error rates between switch trials and stay trials was calculated.\n\nComplex cognitive control tasks\n\nAX-CPT\n\nReactive and proactive control were measured using a child-friendly version of the AX-CPT paradigm89. The task was introduced as the ‘Fruit Island’ game. An ‘A’ or ‘B’ cue (that is, dog or cat) was presented in the middle of the screen for 500 ms, followed by an ISI of 750 ms and then a probe ‘X’ or ‘Y’ (that is, orange or apple) during which participants had to make their response. Participants were instructed to press the left key whenever an ‘X’ followed an ‘A’ (that is, AX trials) and to press the down arrow key for all other cue–probe combinations. Importantly, they were instructed to only respond once the probe had been presented and were alerted of this if they made a response before the probe was presented. Participants had a maximum of 6,000 ms to make a response. Responses were followed by an ITI of 1,500 ms. The proportions of the trial types were based on previous studies89,90 where 40% of trials were AX trials. All other trials (that is, AY, BX and BY trials) were presented 20% each. Trials were presented randomly. Ten practice trials were administered where feedback was provided, followed by 60 main trials. Proactive Behavioral Index (PBI) was calculated for error rates and reaction times separately91.\n\nDecision-making tasks\n\nParticipants were told that they would be playing a series of games where they could win monetary units (MUs) and exchange these for gifts at the end of the experiment. Participants were told that the more MUs they had at the end of all the games, the larger their gift would be. The reward was described in this abstract way to appeal to children of all ages and was previously found to be sufficiently motivating for children of this age and equally so across the age range92,93.\n\nDG\n\nParticipants were allocated six MUs, visually represented in the task as coins on a computer screen. In the offline sample, two boxes were presented, one for the child and one for their ‘partner’. Children were told that they were playing with another child from a different school; in reality, there was no other participant. They were instructed to first click on the MU and then the boxes to divide them, and they were informed that once they had put an MU in a box, they could not change their decision. Counters at the side of the boxes kept track of the number of MUs in either box. During the task, the instructor explicitly informed the participant that they would turn away and not look at the screen. There was no response time limit. The DG measures pro-social decision-making as indicated by how many MUs a participant decides to give to another unknown child. In the online version, children determined their chosen distribution by moving a slider. In this sense, the online task required just one move to distribute the MUs. As in the offline version, children were told that they were playing with another child from another school whom they did not know, when, in reality, there was no other participant. Unlike in the offline sample, however, children could change their minds about their preferred distributions indefinitely and submit their final decision by pressing the spacebars on their computers. Parents were instructed to be present in the room while testing, engaged in an activity such as reading a book and not to influence their children’s participation.\n\nUG\n\nThe UG consisted of the responder role. Children could accept or reject a single offer of an unfair distribution (1/6) of MUs made by another unknown child in the study. If they rejected the offer, the participant and the unknown other child who made the offer (a computer, in reality) would receive zero MUs. For this game, there was, again, no response limit for the participants.\n\nIntertemporal choice task\n\nIntertemporal decision-making was assessed using an intertemporal choice task. In the intertemporal choice task, participants made choices between immediate and delayed reward options. This task measured the extent to which participants discount rewards as a function of how delayed they are via their choices. Participants completed 18 trials (in a fixed order) where they were always presented with a choice between either an immediate or a delayed option. The unit of delay used was days, where every moon depicted indicated one additional day of waiting before the participant would receive their reward. The reward for the delayed option was always eight MUs, and the immediate reward option ranged among two, four and six MUs. For every immediate reward option, participants’ discounting was measured by calculating the percentage of total delayed choices.\n\nAcademic performance\n\nAcademic performance scores were collected retrospectively from schools in the form of English and Maths age-standardized scores. Depending on school, English tests included Progress in Reading Assessment, Progress Test in English, Suffolk Reading Test and/or New Group Reading Test, and Maths tests included Progress in Understanding Maths Assessment and/or Progress Test in Maths. As we did not have discipline-specific hypotheses, the main measure for overall academic performance was a composite age-standardized score computed for each participant as the average across all available English or Maths age-standardized scores for that participant; if participants had scores for one test or discipline only, that score was used as a measure of overall academic performance.\n\nCreativity\n\nCreativity was measured using the Torrence Test of Creative Thinking (TTCT)94. The TTCT is the most widely used test of creativity95,96,97. The TTCT consists of verbal and figural versions. In the present study, we used TTCT-Figural form A. Participants were provided with a pencil, an eraser and a printed Torrance activity sheet. Following a protocol, participants were instructed to use 10 min to complete the given stimuli with unique answers and to come up with interesting titles that described their drawings. In case participants finished in less than 10 min, they were encouraged to use the remaining time to add to their answers. It has high test–retest reliability and can predict creativity success98.\n\nFluid intelligence\n\nFluid intelligence was measured using WASI-II (ref. 99). The WASI consists of two parts: Matrix Reasoning and Vocabulary. WASI Matrix Reasoning measures non-verbal ability, which correlates well with fluid and visual intelligence, and the WASI verbal subtest measures verbal ability, which correlates well with verbal IQ and crystalized intelligence. For Matrix Reasoning, participants were provided with 30 visually depicted incomplete matrices and asked to choose one from the five options that logically follows the missing matrices. For the vocabulary part, participants were presented with 28 words, one at a time, and asked to verbally define or describe the word presented. WASI-II has high reliability and validity100 and provides a good estimate of intelligence.\n\nMental health\n\nSDQ\n\nThe parent-report version of the SDQ101 was used to measure internalizing and externalizing difficulties. The SDQ is a 25-item scale consisting of five subscales (emotional problems, conduct problems, peer relationship problems, prosocial behavior and hyperactivity/inattention), each of which includes five questions. Parents rate their child’s behavior over the previous 6 months. Each question has the following response options: 0 = not true, 1 = somewhat true and 2 = certainly true. For each scale, the responses can be summed to provide a total score for that scale. In non-clinical samples, such as are included in the present study, it has been recommended to combine the scales into two further subscales representing ‘internalizing’ and ‘externalizing’ problems102. The internalizing subscale is calculated by summing the emotional problems and peer relationship problems subscales, and the externalizing subscale is calculated by summing the hyperactivity/inattention and conduct problems subscales. We, therefore, used this approach in the present study. The SDQ has high validity and reliability103.\n\nChild and Adolescent Symptom Inventory-4R\n\nThe Child and Adolescent Symptom Inventory-4R (CASI-4R)104 is a parent-report rating scale that evaluates behaviors related to the disorders that are included in the Diagnostic and Statistical Manual of Mental Disorders in young people aged 5–18 years. In the present study, the CASI-4R subscales relating to attention-deficit/hyperactivity disorder (ADHD), generalized anxiety disorder, major depressive episode, depressive disorder, conduct disorder, social phobia and separation anxiety were included. Parents were asked to rate their child’s overall behavior. Each question has the following response options: 0 = never, 1 = sometimes, 2 = often and 3 = very often. Previous studies found that the CASI-4R has good test–retest reliability, validity and internal consistency105.\n\nApathy Evaluation Scale, informant version\n\nThe Apathy Evaluation Scale, informant version (AES-I), was used to assess apathy106. The AES-I includes 18 items relating to cognitive, behavioral and emotional apathy. We asked parents to rate their child’s behavior over the previous 4 weeks. Each question is rated on a four-point scale (not at all, slightly true, somewhat true and very true), with higher scores reflecting greater apathy.\n\nMRI measures\n\nMRI data were acquired with a standard whole-head coil on a 3.0-Tesla Siemens Prisma scanner at the Birkbeck-UCL Centre for Neuroimaging. To limit head motion, participants were asked to keep their heads as still as possible. Foam inserts were used between the head and the head coil to ensure a snug fit. Visual stimuli were projected onto a screen in the magnet bore that could be viewed via a mirror attached to the head coil. During the acquisition of the structural and diffusion tensor imaging (DTI) scan, participants watched cartoons without sound.\n\nTask-related functional MRI\n\nThe same SSRT task used outside of the scanner was employed where two runs (54 trials each, jittered ITI = 2,200–3,000 ms) were administered. Each run lasted approximately 5 min each and was acquired using T2-weighted echo planar imaging (EPI; TR = 1.25 s, TE = 35.2 ms, sequential acquisition, 60 slices of 2 × 2 × 2 mm3 voxels, field of view 1,696 × 1,696, 106 × 106 matrix, in-plane resolution = 2 mm). The task was presented using Presentation software (version 23).\n\nCortical thickness\n\nHigh-resolution T1-weighted images were acquired using a magnetization-prepared rapid gradient echo sequence (MP-RAGE; TR = 2.30 s TE = 2.98 ms, flip angle = 8°, slices = 1 × 1 × 1 mm3 voxels, field of view 256 × 256). A total of 208 slices per participant (voxel size = 1 × 1 × 1 mm3) were collected, and the acquisition matrix ranged 256 × 256.\n\nResting state\n\nParticipants completed one run lasting 5 min (212 EPI volumes, 60 slices per volume, voxel size 2 × 2 × 2 mm3, TR = 1,250 ms, TE = 35.2 ms, flip angle = 65°). Participants were instructed to observe a fixation cross presented on a screen. For spatial normalization and anatomical localization, a structural scan was obtained (see ‘Cortical thickness’ subsection above). Finally, to improve functional-to-anatomical co-registration, a field map scan was acquired (one EPI volume, 72 slices per volume, voxel size 2 × 2 × 2 mm3, TR = 8,000 ms, TE = 66 ms, flip angle = 90°).\n\nDTI\n\nDiffusion imaging was acquired while children were awake. A total of 72 contiguous near-axial slices were acquired for each volume, using an acquisition sequence fully optimized for clinical tractography, providing isotropic (2 × 2 × 2 mm) resolution and whole head coverage (matrix size 104 × 104 × 72, TR = 3,600 ms, TE = 92 ms). Then, 100 diffusion-weighted volumes (50 × b-value of 1,000 s mm−2, 50 × b-value of 2,000 s mm−2) and five volumes without diffusion gradient were acquired.\n\nPre-processing and statistical analysis\n\nOutliers were removed for all measures. Datapoints falling two standard deviations below or above the mean were excluded.\n\nCognitive control factors\n\nOutliers were removed from each cognitive control measure. Datapoints falling two standard deviations below or above the mean were excluded. Then, a confirmatory factor analysis (CFA) was performed using ‘lavaan’ in RStudio to create latent factors of executive functions107. For T0 data, multiple models were fit; however, the model failed to converge for most models, with some of them displaying negative variances, suggesting that models were mis-specified. Only two models converged: a model with a single factor encompassing all tasks and a model with three subfactors of inhibition, shifting and memory. There were no significant differences in model fits (Δχ2 (3) = 1.69, P = 0.638). The inhibition factor was extracted to examine correlations at T0 with the other domains. To examine training-related changes in executive functions, the factor analysis was conducted separately for error rate and reaction time data. This was done because a factor solution could not be found when composite measures of error rates and reaction times were used. For the error rate factor specifically, inclusion of flanker inhibition indices caused non-convergence of models and was excluded from analysis. Based on previous literature, factor loadings were constrained by timepoints to allow for pre–post comparisons establishing weak factorial invariance26. Values for each individual were extracted from this for further analysis. This was done separately for error rates and reaction times, where a larger value indicated a larger error rate or reaction time.\n\nCreativity\n\nThe TTCT responses were scored according to the Streamlined Scoring Guideline108. The responses were scored with respect to five norm-based creativity measures: fluency, originality, abstractness of titles, elaboration and resistance to premature closure. A higher score in any of the five subcategories indicates more unique answers and higher levels of creativity. In the present study, all responses were scored by a single scorer, and a sum score of all five categories was used for the analyses. To establish consistency, the scorer scored a random sample of 10 responses two times with 2 weeks in between. Eighty-six percent of the scores were consistent across the two separate scorings.\n\nMental health\n\nA CFA was performed using ‘lavaan’ in RStudio to create latent factors of mental health107. Based on previous literature, factor loadings were constrained by timepoints to allow for pre–post comparisons establishing weak factorial invariance26. Factors of externalizing problems and internalizing problems were created. Specifically, externalizing problems from the SDQ and CASI-ADHD problems loaded on the externalizing factor. Internalizing problems from the SDQ, CASI-social phobia, CASI-separation anxiety and CASI-depression loaded on the internalizing factor. Values for each individual were extracted from this for further analysis, where a larger value indicated greater mental health problems.\n\nMRI measures\n\nTask-related functional MRI\n\nEach individual’s functional scans were realigned to correct for head motion by initial realignment to first image and second realignment to mean image. The realigned scans were co-registered with anatomical T1-weighted images and spatially normalized to the standard Montreal Neurological Institute (MNI) space by resampling to a voxel size of 2 × 2 × 2 mm3. Normalized images were smoothed with an 8-mm Gaussian filter. Fixed statistical effects were calculated at the individual level by modeling each trial condition (‘stop’ successful, ‘stop’ unsuccessful, ‘go’ successful and ‘go’ unsuccessful) with a box car function convolved with the canonical hemodynamic response function. To reduce movement-related artifacts, six motion parameters were included as regressors as well as an additional regressor to model images that were corrupted due to head motion of more than 1.5 mm and were replaced by interpolations of adjacent images (<10% of participant’s data). To examine training-related changes from pre-test to post-test in ‘stop’ versus ‘go’ trial condition, the Sandwich Estimator Toolbox for Longitudinal and Repeated Measures Data version 2.1.0 was employed (SwE, toolbox for SPM, Guillaume et al.109). Repeated-measures ANOVA was conducted at the group level, with the ‘stop’ successful condition and ‘go’ successful condition entered as fixed effects and a subject factor entered as random effects. Family-wise error (FWE) corrections at P < 0.05 were applied to the data. Moreover, using the MarsBaR Toolbox110 implemented in SPM12, we extracted functional activity from the right IFG selected from the probabilistic Harvard-Oxford atlas111 (thresholded at 20%, center of mass: 51, 28, 8). Beta values for each ROI (that is, successful ‘stop’ trials versus successful ‘go’ trials) were extracted for further statistical analyses outside of SPM.\n\nCortical thickness\n\nAfter converting the DICOM files to NifTI using dcm2niix, structural MRI images were processed with FreeSurfer112 (version 6.0.0, http://surfer.nmr.mgh.harvard.edu) to label and segment cortex and white matter. All scans were then visually inspected for quality, and, if necessary, segmentation was manually corrected in FreeSurfer. Four independent inspectors conducted these checks, and one final inspector performed a final inspection of all scans. After corrections, scans were re-segmented using FreeSurfer. If the quality of scans was inadequate, they were excluded from the final analysis. Based on this, data were available from 141 participants. After pre-processing, sulcal and gyral features across individual participants were aligned by morphing each participant’s brain to an average spherical representation that accurately matches cortical thickness measurements across participants while minimizing metric distortion. A 10-mm Gaussian smoothing kernel was applied to the data to reduce measurement noise but preserve the capacity for anatomical localizations113,114. Cortical thickness data were analyzed using the SurfStat toolbox for MATLAB115 (https://www.math.mcgill.ca/keith/surfstat). Findings from the surface-based analyses were controlled for multiple comparisons using random field theory5,113,115. This reduced the chance of reporting an FWE. We ran whole-brain models looking at changes in cortical thickness after training by testing for a Session-by-Group interaction. Using the Desikan–Killiany atlas116, cortical thickness was extracted from the right IFG (comprising the right pars triangularis, the pars opercularis and the pars orbitalis) to look at the specific interaction within this region.\n\nResting state\n\nProcessing of resting-state functional connectivity (RSFC) data was completed with the ABCD-HCP pipeline (https://github.com/DCAN-Labs/abcd-hcp-pipeline), which is modified from the original HCP pipelines117. In brief, this pipeline consists of six stages. First, the PreFreeSurfer stage normalizes anatomical data. This normalization includes brain extraction, denoising and then bias field correction on anatomical T1-weighted and/or T2-weighted data. To improve output image quality, ANTs DenoiseImage attempts to remove scanner noise from T1 and T2 anatomical images by modeling scanner noise as a Rician distribution, and ANTs N4BiasFieldCorrection attempts to improve bias field correction. Second, the FreeSurfer stage constructs cortical surfaces from the normalized anatomical data. This stage also performs surface registration to a standard surface template, and surfaces are refined using the T2-weighted anatomical data. Third, the PostFreeSurfer stage transforms the volumes to a standard volume template space using ANTs nonlinear registration and the surfaces to the standard surface space via spherical registration. Fourth, the fMRIVolume stage performs processing of the functional data, including correction for functional distortions via reverse-phase encoding spin echo images, intensity normalization to a whole-brain-mode value of 1,000, within-run correction for head movement and registration to the standard template. Fifth, the fMRISurface stage maps the normalized functional volumes to the standard surface template. The BOLD functional MRI volumetric data were sampled to each participant’s original mid-thickness left and right hemisphere surfaces constrained by the gray matter ribbon. These surfaces were then combined with volumetric subcortical and cerebellar data into the CIFTI format using Connectome Workbench (https://www.humanconnectome.org/software/connectome-workbench), creating full brain timecourses excluding non-gray matter tissue. The resting-state timecourses were then smoothed with a 2-mm full-width at half-maximum kernel applied to geodesic distances on surface data and Euclidean distances on volumetric data. Finally, the DCANBOLDproc stage performs further denoising steps to reduce variance unlikely to reflect neuronal activity. These denoising steps include a respiratory filter to improve framewise displacement estimates, temporal masks to flag motion-contaminated frames with a filtered framewise displacement greater than 0.3 mm, demeaning, detrending, interpolation across censored frames and a band-pass filter (0.008 Hz < f < 0.1 Hz).\n\nAfter processing, time series of RSFC data were extracted using the Gordon-333 parcellation118, which includes 333 parcels (ROIs) that cover the whole cortical surface. These time series were further motion censored at a framewise displacement greater than 0.2 mm. Then, parcels were grouped for the networks of interest (FPN and CON), and Pearson correlations across parcels within each network were run. We then computed the mean z-score across all correlations within each network. Therefore, we obtained an RSFC value (z-score) for each network of interest, participant and timepoint.\n\nDTI\n\nThe data were initially visually inspected. Volumes with extreme artifacts or corruption were removed. Across the dataset, the average number of volumes removed was 0.27 (range = 0–5) at T0 and 0.97 (range = 0–10) at T1, accounting for 0.5% of the total number of volumes acquired. Data was then pre-processed using ExploreDTI (https://exploredti.com/). The data were corrected for head motion, eddy current distortions and EPI distortions, and the B-matrix was rotated119. Remaining outliers due to head motion and cardiac pulsation were excluded using REKINDLE. The tensor model was fitted to the data using a nonlinear least square fitting procedure. DTI scalar maps, including fractional anisotropy and mean diffusivity, were calculated and exported. A whole-brain tractography algorithm using Euler integration and the following settings was applied: step size = 0.5 mm, fractional anisotropy threshold ≥ 0.15 and angle threshold ≤ 35. Whole-brain tractography was exported to TrackVis (https://trackvis.org/) to perform virtual in vivo dissections for the right hemisphere. The connections were dissected in regions corresponding to the putamen and the frontal lobes, providing measures for the fronto-putamen connections. All dissections were completed after ensuring intra-rater reliability. This was tested with the use of 10 participants from the present study, dissected twice by the same dissector. Reliability was tested using a two-way mixed intra-class correlation coefficient (ICC)120. For all tracts, the ICC for single measures reached greater than 0.90. For each tract, fractional anisotropy and mean diffusivity were calculated. These measures reflect the structural integrity of the white matter connection and may indicate microstructural differences, such as myelination, axonal integrity and how compact fiber bundles are121. Fractional anisotropy is the degree of directionality of water motion within a particular voxel. Mean diffusivity is the average diffusion of water motion within a voxel.\n\nTraining-related changes\n\nMixed models were used to examine training-related changes using the ‘lme4’ package in R (version 4.3.1). In this model, the main effects of training group and session were examined as well as the interaction between Group and Session. Age and gender was added into the model as a covariate. Significant interaction effects between Session and Group were interpreted as presence of training-related changes and followed up with post hoc paired t-tests. In a subset of available tasks, maintenance of training-related changes was examined between pre-test (T0) and 1-year follow-up (T2). For evidence of null effects, we report the BF in favor of the null model (the model without a Group-by-Session interaction) over the training model (the model with a Group-by-Session interaction) for each measure of interest122. The prior is set to be the model with main effects of Group and Session. We isolate this particular interaction as our training effect of interest where BF10 < 1 suggested evidence for the null hypothesis (that is, no training-related changes).\n\nData imputation\n\nFor all measures (unless specified otherwise), multiple imputations by chained equations (MICE) was used to impute missing data (predictive mean matching; iterations = 20, n datasets = 100; Supplementary Fig. 4). A single imputed dataset was used, as this was necessary in conducting mixed models with post hoc tests and factor analysis. We ensured the replicability of these results by re-running the process multiple times and choosing a dataset at random. Missing data were imputed using the MICE package in R (50 datasets created, 50 maximum iterations), and quickpred was used to create the imputation model123. Factors of executive function (at T0) and mental health factors were imputed using full information maximum likelihood (FIML) in ‘lavaan’.\n\nCorrection for multiple comparisons\n\nThe Benjamini–Hochberg procedure55 was applied to mixed model analysis testing for training-related changes. We used the adjustment method BH with the function p.adjust in R. For the results that are significant, we report their adjusted P value after correction to control FDR with multiple testing.\n\nTest–retest reliability\n\nTo assess the reliability of outcome measures, we looked at both test–retest reliability and split-half reliability. To assess test–retest, ICCs were calculated using the ‘psych’ package in R. ICC(2,1) was chosen to allow different means at different timepoints using a two-way random-effects model. ICC was calculated on all available timepoints for each given measure. Percentage accuracy and mean reaction time for correct response were calculated for each participant per task for intra-class comparison (Supplementary Table 2). The data used for the reliability tests were not imputed. The Spearman–Brown coefficient was calculated using the ‘splithalfr’ package in R124. Percentage accuracy and mean reaction time for the first half and second half of the experiments were compared in the executive function tasks to test internal reliability (Supplementary Table 3). Mean percentage delayed choice was tested for Temporal Discounting Task. For questionnaires, Cronbach’s alpha was tested using the ‘psych’ package in R.\n\nReporting summary\n\nFurther information on research design is available in the Nature Portfolio Reporting Summary linked to this article."
    }
}