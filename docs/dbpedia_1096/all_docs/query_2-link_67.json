{
    "id": "dbpedia_1096_2",
    "rank": 67,
    "data": {
        "url": "https://academic.oup.com/mnras/article/521/2/1817/7055956",
        "read_more_link": "",
        "language": "en",
        "title": "On the functional form of the radial acceleration relation",
        "top_image": "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/521/2/10.1093_mnras_stad597/2/m_stad597fig1.jpeg?Expires=1786769009&Signature=nERpLWcvFv80R3GAg1BBBlEc6AinIaz-ylhgFKzzuLz53TMhnZ8xbmK23wFC~6eSfpVZ3sPbLQRsfrSywY3nOBY0rFgjCpXd0d1Bns8fg96MPJ2XxJfNPH5FShWGMZ-xMaJuZ~4fFoAejViml3dI5z55axy2u1qqshnEsJlovc5d55wheaZQIMrQxsY-BNa6HkEucFTdValUx5v8jExnFuqTcjoREsd9aMnPvFYV1JQ4GnKXiOi0umzFfKAgapYQsbk6xx51pSi4U4aNA-ibat5Q18kE71IP6MNm5MLRnERn9RBkxKV4lKNCMewg-j4A29Mzu-HM-hlhSqGTmSO~AA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
        "meta_img": "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/521/2/10.1093_mnras_stad597/2/m_stad597fig1.jpeg?Expires=1786769009&Signature=nERpLWcvFv80R3GAg1BBBlEc6AinIaz-ylhgFKzzuLz53TMhnZ8xbmK23wFC~6eSfpVZ3sPbLQRsfrSywY3nOBY0rFgjCpXd0d1Bns8fg96MPJ2XxJfNPH5FShWGMZ-xMaJuZ~4fFoAejViml3dI5z55axy2u1qqshnEsJlovc5d55wheaZQIMrQxsY-BNa6HkEucFTdValUx5v8jExnFuqTcjoREsd9aMnPvFYV1JQ4GnKXiOi0umzFfKAgapYQsbk6xx51pSi4U4aNA-ibat5Q18kE71IP6MNm5MLRnERn9RBkxKV4lKNCMewg-j4A29Mzu-HM-hlhSqGTmSO~AA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
        "images": [
            "https://oup.silverchair-cdn.com/UI/app/svg/umbrella/oxford-academic-logo.svg",
            "https://oup.silverchair-cdn.com/UI/app/svg/i.svg",
            "https://oup.silverchair-cdn.com/UI/app/svg/account.svg",
            "https://oup.silverchair-cdn.com/UI/app/svg/i.svg",
            "https://oup.silverchair-cdn.com/UI/app/svg/account.svg",
            "https://oup.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/mnras/mnras_title424221717.svg",
            "https://oup.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/mnras/mnras_h1-1266173020.svg",
            "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/Issue/521/2/17/m_cover.jpeg?Expires=1727709281&Signature=sKcYu0PpUmbjZXw9yWZeeXs6NbKfiKon1B9Z1ovC~DP6tO89in7PtfkEmQhBt1e7rDjDnuv7JvtLNR9rsCAOQXmsf-vDelNVZ74sTZ5BUj6GBA14OlEUvpkxoUOWAu4YV7cJVaGmKhh4v38L5f4QBMk1GKOUQ6i2F~xBrsijYv87keWd9P8SdZ-HpiFv5ayFCLyrxOxrA2LKrpbYiD2K5jfkkLwd~cRXUy4-BHgErhYE1z0ZsG-9WL8F6DboCmQ5rFJI-ZaeF8slnnxNQ0fKEsP7nBT6wEDFDxyx94fXjnGAIBMxqqEH8-dKq0p8OPdGTGs4MLB710jRCQGEfb-iYA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
            "https://oup.silverchair-cdn.com/Themes/Silver/app/img/mini-icon.png",
            "https://oup.silverchair-cdn.com/Themes/Silver/app/img/mini-icon.png",
            "https://oup.silverchair-cdn.com/UI/app/svg/pdf.svg",
            "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/521/2/10.1093_mnras_stad597/2/m_stad597fig1.jpeg?Expires=1726801431&Signature=umBhRnMcqsi6Pvxfgoz5mJniqX4HXnf~hYkRluFUmmhW07Rve8ppuYBA~WK3FIpwP6edyaFz4n4I8HHVXp0dMOQBThehSkvv5psn4aLtzUexwl2DQaZy4OT4Dh0ROamp5TZiQ182ZelZE4oT8Um5fPRE5L2r-RBCA-qps45GdXAVqVQPCxiNj6MI046Bc5Ay5qqr1Ru0fCMY55YrMSfvWZsDcIKUCRjFMf-6XFoc3egPa7QoRn~fh~w5qDjtAI1z0zJnGWlohonZVNJyxtvLAflDBS8mF0aa0Ny3TImrQvm~YngLSaWxm5SGydF2swlB5grCihHvH4RYHl9iMjew0A__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
            "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/521/2/10.1093_mnras_stad597/2/m_stad597fig2.jpeg?Expires=1726801431&Signature=EP5U2uhVNn379RlRZLsggqZgQQqkjXTPZZkO5xlCNVG6a0qBlv710rgjoesec0oEbrkcqlgTtCMXz1s2t3m9m0kLkBvIGsQDY~L4TSl-wUArls48lhV~oiHsOykz78uaHUmd3ikr-z8J-3FgRo2sgYdbWRbkNuiMek-qQcSgN7MPmqXKigsAwJ51vbdr36HJBNxWjvOaswvB3rrsaFxIdoZLu3Y0j9P~tTQeMakFK~uPwxArTQbc-azDZWS8WGUfBYXrbQmXXtx2FWbWSeQRhTzo1~Nt6iCXAV7m28OIH9GrYA3RmSCW2xUim4NsK1xBIZTELC~q09TGQoUKskIR9g__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
            "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/521/2/10.1093_mnras_stad597/2/m_stad597fig3.jpeg?Expires=1726801431&Signature=HRWfWAz6woYfkmHYRTioEUFCELY66lAe8zdq~8sXoEjTL0gWNUQKJ~xh5zkoEH2BcMB2NqZHMtK6s9sQZD3sCfdYZ5lwqZsoxpSxG0ErUSqww1Iy5pxNUc7kYBJq7bx12jAMcYhtb8dyjFnVETDjkNTgu66CiLytNQ5F-ZS8ykszvPTIn-Y4sqVlGJgCwLpYKjv6yhTJNx5A5jpY6rc4sJYzLz2GSONc0p-YnUKIL02TEMZo9NxzmSF99vaGqdBg4fIXuJXaCxFwfNmLJILcZqCpTAxuH6MP1NLndAoE4GgJDlBFEfbtgSkyVscOvoLfo1cfD7LtZMvQxSOLY4YdxQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
            "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/mnras/521/2/10.1093_mnras_stad597/2/m_stad597fig4.jpeg?Expires=1726801431&Signature=GNKYF13NZl73Cf4plau7xSp82OW5wwPTdLweECV~EwRzF7SY95isJAVWTXoO~iYBIuvz5YDYNU-4zEg0mwuD22FfpyGxuCt518CBtATOSuiyx-taJu1iEGuLA9-MryMP6rXp8wTvWDo52w-s9cwk6EEO0FHjoydkgtJ5BXLa1tnpB4kLMRML3~rTdE4X5mF8bizqyhKFH-uZi08LapLmw1vqXIqKwYSF5-18tpkZZS0CNhsj-NYwVl94YlVUNgnplsimt6XZGQTjeh44o8kEtxTqSdqbb6Gu4reZDmaFgIa-f7BnLTmVp4pzZPRvxO6PH7l5IMmitkRishrVOjMu5Q__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA",
            "https://oup.silverchair-cdn.com/UI/app/svg/i.svg",
            "https://oup.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/mnras/mnras_f11784595720.svg",
            "https://oup.silverchair-cdn.com/UI/app/svg/umbrella/oup-logo.svg",
            "https://ouptag.scholarlyiq.com/ntpagetag.gif?js=0"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Desmond, Harry",
            "Bartlett, Deaglan J",
            "Ferreira, Pedro G",
            "Deaglan J",
            "Pedro G"
        ],
        "publish_date": "2023-02-23T00:00:00",
        "summary": "",
        "meta_description": "ABSTRACT. We apply a new method for learning equations from data – Exhaustive Symbolic Regression (ESR) – to late-type galaxy dynamics as encapsulated in t",
        "meta_lang": "en",
        "meta_favicon": "//oup.silverchair-cdn.com/UI/app/img/v-638576256025047103/apple-touch-icon.png",
        "meta_site_name": "OUP Academic",
        "canonical_link": "https://academic.oup.com/mnras/article-abstract/521/2/1817/7055956",
        "text": "ABSTRACT\n\nWe apply a new method for learning equations from data – Exhaustive Symbolic Regression (ESR) – to late-type galaxy dynamics as encapsulated in the radial acceleration relation (RAR). Relating the centripetal acceleration due to baryons, gbar, to the total dynamical acceleration, gobs, the RAR has been claimed to manifest a new law of nature due to its regularity and tightness in agreement with Modified Newtonian Dynamics (MOND). Fits to this relation have been restricted by prior expectations to particular functional forms, while ESR affords an exhaustive and nearly prior-free search through functional parameter space to identify the equations optimally trading accuracy with simplicity. Working with the SPARC data, we find the best functions typically satisfy gobs ∝ gbar at high gbar, although the coefficient of proportionality is not clearly unity and the deep-MOND limit |$g_\\text{obs}\\propto \\sqrt{g_\\text{bar}}$| as gbar → 0 is little evident at all. By generating mock data according to MOND with or without the external field effect, we find that symbolic regression would not be expected to identify the generating function or reconstruct successfully the asymptotic slopes. We conclude that the limited dynamical range and significant uncertainties of the SPARC RAR preclude a definitive statement of its functional form, and hence that this data alone can neither demonstrate nor rule out law-like gravitational behaviour.\n\n1 INTRODUCTION\n\nKinematic measurements of galaxies relate their visible and dynamical masses, affording constraints on the distribution of dark matter and/or the behaviour of gravity. These measurements are simplest to perform for late-type galaxies supported predominantly by rotation, as the enclosed dynamical mass may be calculated from the centripetal acceleration and the law of gravity. Such studies have revealed a striking correlation between the enclosed baryonic and total dynamical mass assuming Newtonian gravity, dubbed the mass discrepancy–acceleration (Sanders 1990; McGaugh 2004) or radial acceleration relation (RAR; Lelli et al. 2017). It has been claimed that the RAR indicates that at high accelerations the Newtonian dynamical mass follows the baryonic mass (indicating little dark matter and the validity of Newtonian mechanics), while as acceleration drops below a new constant of nature g0 ≈ 10−10 m s−2, the dynamical mass increasingly exceeds the baryonic mass in a regular way.\n\nOne may attempt to understand these observations from either a dark matter or modified gravity perspective. In ΛCDM, the difference between the dynamical and baryonic mass is due to the dark matter that makes up most of the mass of the galaxy. The RAR must therefore be explained by the relative distributions of dark and visible mass established by the process of galaxy formation. Interactionless cold dark matter is influenced only gravitationally by the baryonic mass so the emergence of the RAR must be somewhat fortuitous; it is not established directly by a baryon–dark matter coupling (although see Blanchet & Le Tiec 2008; Berezhiani & Khoury 2015; Famaey, Khoury & Penco 2018 for alternative ideas). In contrast, the modified gravity (or modified inertia) interpretation posits a breakdown of Newtonian mechanics at low acceleration so that the dynamical mass inferred by a Newtonian analysis is not the true dynamical mass of the galaxy. The prototypical instantiation of this idea is Modified Newtonian Dynamics (MOND; Milgrom 1983a, c, b), in which the kinematic acceleration gobs follows the square root of the Newtonian acceleration gbar in the weak-field regime. This enables the total dynamical mass of the galaxy to remain equal to the baryonic mass across galaxies’ rotation curves, eliminating the need for dark matter in them. The MOND paradigm attempts to dispense with dark matter entirely, and has cosmologically viable relativistic extensions (most recently Skordis & Złośnik 2021). It is reviewed in Famaey & McGaugh (2012) and Banik & Zhao (2022).\n\nCentral to the dark matter–modified gravity debate in the context of galaxy dynamics is the functional form of the RAR. This is because MOND makes a very specific prediction (absent the external field effect: gobs = gbar in the high-acceleration ‘Newtonian regime’ and |$g_\\text{obs} \\propto g_\\text{bar}^{1/2}$| in the low-acceleration ‘deep-MOND regime’) while dark matter could accommodate a range of possibilities depending on the effect of galaxy formation on halo density profiles, which remains highly uncertain (e.g. Duffy et al. 2010; Macciò et al. 2012; Keller & Wadsley 2017; Ludlow et al. 2017; Navarro et al. 2017; Tenneti et al. 2018; Grudić et al. 2020). The only potentially unambiguous prediction is that the RAR tends to gobs = Ωm/Ωb gbar at radii sufficiently large to encompass the cosmic baryon fraction, but it is unclear where or even if this occurs in galaxies. Thus, while the ΛCDM prediction for the full RAR can be tested only by applying potentially restrictive priors on galaxy formation effects (Di Cintio & Lelli 2016; Desmond 2017; Paranjape & Sheth 2021), a more direct route towards informing the dark matter–modified gravity debate is to test the MOND prediction, specifically the limiting behaviour at g ≪ g0 and g ≫ g0, the small intrinsic scatter and the lack of residual correlations.\n\nHere, we focus on the asymptotic behaviour. This can be assessed to some extent by fitting a functional form with free power-law slopes at both ends (Lelli et al. 2017), but this assumes that the slope tends to a constant at each end and restricts to a specific part of the functional parameter space for which this is the case. These are in question when assessing the accuracy of the MOND prescription. A fully satisfactory fit should therefore make no such assumptions, eliminating potential confirmation bias and testing without any priors the assertion that the RAR implies no dynamically relevant dark matter at high g and the deep-MOND limit at low g. We accomplish this here by means of a novel regression algorithm dubbed Exhaustive Symbolic Regression (ESR; Bartlett, Desmond & Ferreira 2022b), and hence assess the degree to which the RAR supports the tenets of MOND. Within the MOND paradigm, this method also enables optimization of the ‘interpolating function’ (IF) |$g_\\text{obs}= \\mathcal {F}(g_\\text{bar})$| between the two stipulated limits.\n\nThe structure of the paper is as follows. In Section 2, we describe the RAR data that we use, and in Section 3, our algorithm for generating functions and assessing their aptitude for describing the data. Section 4 presents the results. In Section 5, we discuss the broader ramifications, potential remaining uncertainties and ways in which the programme could be furthered in the future. Section 6 concludes; full details on ESR are given in the companion paper Bartlett et al. (2022b). Units not explicitly given are 10−10 m s−2, and all logarithms are natural.\n\n2 OBSERVATIONAL DATA\n\nWe use the SPARC data set (Lelli, McGaugh & Schombert 2016),1 a compilation of 175 rotation curves from the literature combined with Spitzer|$3.6\\,{\\mu}{\\rm m}$| photometry. We apply the same quality cuts as the RAR study of Lelli et al. (2017), removing galaxies with quality flag 3 (indicating large asymmetries, non-circular motions and/or offsets between stellar and HI distributions), and those with inclinations |$i < 30^{\\circ}$| and points for which the quoted fractional uncertainty on the observed rotation velocity is greater than 10 per cent. This leaves 2696 points from 147 galaxies.\n\n3 METHOD\n\nWe describe our method for generating and assessing trial functions in Section 3.1, and our likelihood function in Section 3.2. In Section 3.3, we outline our criteria for assessing whether a function displays MOND-like behaviour.\n\n3.1 Exhaustive symbolic regression\n\nWhile algorithms for symbolic regression (SR) – the search for good functional descriptions of a data set – are becoming mature, they remain fallible (La Cava et al. 2021). Unless the generating function of the data is known at the outset (in which case SR is not required), it is not possible to determine whether any SR algorithm has uncovered the best function. This motivated us to develop ESR which, given a set of basis functions, produces and evaluates every possible function up to a given complexity of equation, defined here as the number of nodes in its tree representation. This enables a brute-force solution to relatively simple problems and provides a touchstone for assessing the results of stochastic algorithms at higher complexity. As shown in detail in Bartlett et al. (2022b), stochastic searches regularly fail to the best functions at even moderate complexity ∼6, so that we would not be confidant of obtaining the functional form of the RAR through any algorithm besides ESR.\n\nPresented in full in the companion paper, ESR has two main steps: i) generating, and optimising the parameters of, all functions up to a given complexity, and ii) ranking these functions using an information-theoretic metric combining accuracy and simplicity. For part i, the steps are:\n\nGenerate all possible trees containing a given number of nodes (equal to the complexity of functions considered).\n\nGenerate the complete set of such functions by decorating these trees with all permutations of the operators from the operator list specified in advance, utilising the constraints on the arity of the operator that can occupy a given node.\n\nSimplify the functions and remove duplicates. Variants of the same function (e.g. x(x + θ0) and x2 + θ0x) are however retained as these may have different model complexities (used in step ii, below). For each unique function the variant is retained that minimizes this.\n\nDetermine the values of the free parameters appearing in the functions that maximize the likelihood of the data (see Section 3.2).\n\nRepeat for all complexities under consideration.\n\nThe only degrees of freedom in this procedure are the maximum complexity considered (here set at 9 as higher complexity is computationally prohibitive) and the set of operators of which the functions are composed. Here we choose:2\n\nNullary: gbar, θ\n\nUnary: exp , sqrt, square, inv\n\nBinary: +, −, *, /, pow\n\nwhere θ is a free parameter. We implicitly take the absolute value of the argument of any square root or power.\n\nThe result of this procedure is a list of all functions up to the maximum complexity (of which there are 2.24 × 107), along with the parameter values that maximize the likelihood of the RAR data. As in regular regression, using the maximum likelihood as the model selection criterion would favour overfitting, whereby a function fits the data near-perfectly but generalizes or extrapolates poorly. To remedy this, SR typically uses two-objective optimization, where the second objective is the ‘simplicity’ of the function. In the absence of a metric for trading accuracy (the first objective) with complexity, optimal functions form a ‘Pareto front’ where accuracy cannot be increased without reducing simplicity and vice versa. Simplicity has been defined analogously to model complexity (the number of nodes in the tree representation; e.g. in PySR; Cranmer et al. 2020), among others, but such definitions are typically arbitrary and thus compromise the objectivity of the regression results.\n\nTo remedy this, part (ii) of ESR implements the minimum description length principle (MDL; Rissanen 1978; Grunwald 2007; Grünwald & Roos 2019) as a model selection criterion, which has an information-theoretic motivation and provides a natural framework for making commensurable the two objectives. MDL states that functions are preferred to the extent that they compress the data, i.e. minimize the number of bits required to communicate the data with the aid of the function. We implement this with a two-step code in which the description length (also called codelength) is comprised of a component describing the function and a component describing the residuals of the data around the function’s expectation. We use the Shannon–Fano coding scheme for the latter (Cover & Thomas 1991), and for the former include contributions both from the structure of the function (penalising those employing more operators) and from the free parameters (penalising more parameters, especially ones that must be specified to high precision to achieve a high likelihood). The overall codelength of the compressed data, L(D), is derived in section 3 of Bartlett et al. (2022b):\n\nwhere L is the description length, D the data set, H the hypothesis (i.e. function in question), |$\\mathcal {L}$| the likelihood, θ a free parameter of the function, k the number of nodes in the function’s tree representation, n the number of unique operators involved, p the total number of free parameters, I the Fisher information matrix of the parameters and cj any constant natural numbers generated by simplifications. A hat denotes evaluation at the maximum-likelihood point. With all logarithms natural, this is the number of nats required to communicate the data with the aid of the function. L(D) supports a probabilistic interpretation over function space that generalizes the likelihood: the relative probability of a function is exp (−L(D)) (Grunwald 2007).\n\nThe structure of the function alone determines the klog (n) term, but the remaining terms require the free parameters to be numerically optimized to maximize the likelihood (which we use interchangeably with minimising the loss).3 We now describe our choice of likelihood for the RAR data.\n\n3.2 Loss function\n\nAs is typical (e.g. Lelli et al. 2017), we assume that gbar, gobs and their uncertainties are uncorrelated across the data set. We further assume that the true gbar and gobs values, denoted |$g_\\text{bar}^\\text{t}$| and |$g_\\text{obs}^\\text{t}$|⁠, generate the observed values with lognormal probability distributions centred at the true values with widths given by their uncertainties δgbar and δgobs. Following Lelli et al. (2017), we fix the mass-to-light ratios Υgas = 1.33, Υdisc = 0.5, and Υbulge = 0.7, and assign them 10, 25, and 25 per cent uncertainties, respectively, summing these in quadrature to estimate δVbar and hence δgbar (assuming no uncertainty in radial position). We likewise assume the uncertainties on distance D and inclination i to be statistical and hence sum their contributions in quadrature with the quoted statistical uncertainty on Vobs according to Lelli et al. (2017, equation 2) to estimate δgbar.\n\nThe likelihood of an observation given the function in question, |$f(g_\\text{bar}^\\text{t})$|⁠, is then:\n\n(2)\n\nwhere\n\nThis is derived by keeping the leading-order term in the Taylor expansion of |$\\log (f(g_\\text{bar}^\\text{t}))$| around log (f(gbar)), and therefore assumes this to be small relative to the rate of change of f. An advantage of working in log (gbar) − log (gobs) space as opposed to gbar − gobs is that, the RAR being roughly a product of power-laws, this minimizes the error due to the first-order approximation. We find this to be good for all of the best functions. The likelihood is then the product over all data points. We discuss in Section A, the limitations of this likelihood model and how it could be improved.\n\n3.3 Assessing MOND\n\nThe core of the MOND paradigm is that gobs = gbar at g ≫ g0 and |$g_\\text{obs}= \\sqrt{g_\\text{bar}g_0}$| at g ≪ g0 (Milgrom 1983a, b, c). This implies\n\nCommon choices for the IF covering the intermediate region g ≈ g0 include\n\n‘Simple’:|$g_\\text{obs}= g_\\text{bar}/2 + \\sqrt{g_\\text{bar}^2/4 + g_\\text{bar}g_0}$| (Famaey & Binney 2005),\n\n‘Standard’:|$g_\\text{obs}= \\frac{1}{\\sqrt{2}} \\sqrt{g_\\text{bar}^2 + \\sqrt{g_\\text{bar}^2 (g_\\text{bar}^2 + 4g_0^2}})$| (Milgrom 1983c),\n\n‘RAR’:|$g_\\text{obs}= g_\\text{bar}/(1-\\exp (-\\sqrt{g_\\text{bar}/g_0}))$| (Lelli et al. 2017).\n\nFig. 1 plots these functions on top of the RAR data for the best-fitting values on the SPARC data (shown in the lower rows of Table 1 in Section 4.1). The Simple and RAR IFs are distinguished from the Standard IF principally by a more gradual transition between the Newtonian and deep-MOND regimes, although the Standard IF also prefers a significantly higher value of g0. While the basic MOND framework is not committed to any particular IF, it is committed to equation (4) providing an optimal description of the data. Our assessment of the theory will therefore be based on the extent to which the best functions (those with lowest description length) conform to these limits: any function that does so, in addition to possessing a coefficient of proportionality of unity in gobs ∝ gbar at high gbar, may be considered a new MOND IF (The low-gbar coefficient of proportionality is |$\\sqrt{g_0}$| but g0 is unknown a priori, so this does not supply an additional requirement.). Following Lelli et al. (2017), we will also consider a double power law fit:\n\n(5)\n\nwhich has limiting logarithmic slopes of θ3 and θ2, and plot the best-fit in Fig. 1. We define |$s_- \\equiv \\lim _{g_\\text{bar}\\rightarrow 0} s$| and |$s_+ \\equiv \\lim _{g_\\text{bar}\\rightarrow \\infty } s$|⁠.\n\nThe MOND interpretation of the RAR is complicated by the possibility of the external field effect (EFE), a breakdown of the strong equivalence principle due to the non-linear, acceleration-based modification to Newtonian mechanics (Milgrom 1983a). The EFE implies that otherwise identical galaxies in different external gravitational fields have different dynamics, which is a function of the external field strength gex relative to g0 and the internal field gin. In the quasi-Newtonian regime gin < gex < g0, Kepler’s laws are recovered with dynamical masses scaled by gex/g0, while in the external field-dominated regime gin < g0 < gex, Newtonian mechanics are fully recovered (Famaey & McGaugh 2012). This steepens the RAR at low gbar.\n\nThe precise effect of the EFE is difficult to calculate in general because it depends both on the underlying MOND theory, and on a galaxy’s morphology and orientation with respect to the external field direction. The most sophisticated fitting functions to MOND simulations are currently to be found in Zonoozi et al. (2021) for QUMOND (Milgrom 2010) and Chae & Milgrom (2022) for AQUAL (Bekenstein & Milgrom 1984). Chae et al. (2022) tested these expectations by fitting the SPARC rotation curves for the average external field strength, finding this to be in good agreement with independent estimates based on the baryonic mass surrounding the SPARC galaxies (Chae et al. 2021) for AQUAL, but less so for QUMOND. We will therefore use AQUAL to explore the effect of the EFE on the expected low-gbar slope and functional form more generally. Chae & Milgrom (2022) eq. 15 gives\n\n(6)\n\nThis allows for variable disc thickness and scale length, and is azimuthally averaged to reduce sensitivity to the orientation of the field relative to the disc axis. It recovers the Simple IF as eN ≡ gex/g0 → 0 and hence we refer to it as ‘Simple IF + EFE’.\n\nNote that, while some form of the EFE is generically predicted by MOND in modified inertia formulations, it may be very different (e.g. a function of the entire past trajectory of an object) or negligible (Milgrom 2011). While there is evidence for the EFE in many systems (McGaugh & Milgrom 2013; Haghi et al. 2019; Chae et al. 2020b), in others it appears conspicuously absent (Hernandez et al. 2019; Freundlich et al. 2022). The black curve in Fig. 1 shows the best fit to the data using equation (6).\n\n3.4 Mock data generation\n\nTo shed light on the significance of our results, we apply ESR also to two stacks of mock data sets. We generate each mock data set using exactly the same number of points as the SPARC data, and with identical log gbar, δ log gbar, and δ log gobs values, but with log gobs generated using a MONDian function. This assumes |$g_\\text{bar}^\\text{t}$| equal to the SPARC gbar (the maximum a priori estimate), log gbar for each mock realization drawn from |$\\mathcal {N}(\\log g_\\text{bar}^\\text{t}, \\delta \\log g_\\text{bar})$|⁠, and log gobs from |$\\mathcal {N}(\\mathcal {F}(\\log g_\\text{bar}^\\text{t}), \\delta \\log g_\\text{obs})$|⁠. To reduce the impact of noise in the mock data, we apply ESR to a stack of 10 independent realizations.4 The only terms in the description length that depend on the data set size are |$\\log (\\mathcal {L})$| and the Fisher matrix I, both of which scale linearly. To make the results compatible with the real data we therefore divide these terms by 10.\n\nThe two mock data set stacks differ in the generating function |$\\mathcal {F}$|⁠. For the first, we use the RAR IF with the best-fitting value on the data g0 = 1.127 (see Section 4). This function is already known to describe the RAR well (Lelli et al. 2017), and has low enough complexity to be included (as a special case of a more general function, see below) in our function list. Since equation (4) is satisfied by construction in this case, evaluating it on the best functions from ESR will address the question of whether the dynamic range of the data is sufficiently high – and the uncertainties sufficiently low – to pick out unambiguously a correctly MONDian solution, as only in this case could one expect to obtain such behaviour for the real data were it generated by MOND.\n\nThe second stack is created using equation (6). We adopt g0 = 1.2 and 〈gex〉 = 1.2 × 10−2 (eN = 0.01), corresponding roughly to maximal clustering of unobserved baryons (as expected in a MOND cosmology and maximising agreement with the rotation curve fits; Chae et al. 2021), and hence providing an upper bound on the impact of the EFE. This is similar to the value inferred in Chae (2022) and Chae et al. (2022) from fits to the SPARC rotation curves, and from our fit to the SPARC data in Table 1.5\n\n4 RESULTS\n\n4.1 SPARC data\n\nWe show in Table 1 the statistics of the best functions found by ESR on the SPARC data. We split the codelength of equation (1) into terms describing the residuals of the data around the functional expectation, the functional form, and the parameter values as shown in the table footnotes. Below the horizontal line we give the results of the three MOND IFs, for which the free parameter corresponds to g0, the double power law (equation (5)), and the Simple IF + EFE (equation 6). P(f) ≡ exp (−L(D))/∑(exp (− L(D))) is the probability of the function given its description length, where the sum is over all functions up to complexity 9. (Note that these values would be changed by low-L(D) functions at higher complexity.) For reference, L(D) for the raw data (corresponding to the hypothesis log gobs = 0) is 53471, showing that significant compression is possible.\n\nWe find the best-fitting g0 value for the RAR IF to be 1.13, somewhat lower than the 1.20 quoted by Lelli et al. (2017), although the data are the same. This is because Lelli et al. (2017) used scipy.odr to perform the optimization rather than using the full first-order likelihood equations (2)–(3), and also did the analysis in the log (gobs) − gbar rather than log (gbar) − log (gobs) plane (F. Lelli private communication). The double power law fit has much higher maximum likelihood than the MOND IFs, outweighing its increased codelength due to its four free parameters. Although the RAR IF has complexity 9, it is not explicitly produced by ESR due to the constant ‘1’ appearing,6 a generalized form in which this is replaced by a free parameter appears at rank 17, with a probability 4 × 1010 times lower than the top-ranked function (ΔL(D) = 24.5). When θ0 ≠ 0, the low-gbar logarithmic slope s− of this function is 1 rather than 1/2, so it does not function as a MOND IF. We refer to it as the ‘generalized RAR IF’.\n\nThe best ESR functions are clearly superior to the MOND functions or double power law. While the best metric for this is L(D) (or equivalently P(f)), other statistics lead to the same conclusion. There are many functions more accurate (lower |$-\\log (\\mathcal {L})$|⁠) than even the double power law. Although the functions at rank 1–9 have more free parameters than the IFs this is more than compensated for by their greater accuracy: as an alternative metric, the Bayesian Information Criterion (BIC) of the rank 1 function is 108 lower than the Simple IF, and even that of the rank 3 function with four free parameters is 94.5 lower, corresponding to a very strong preference. In agreement with Chae et al. (2020b), Chae et al. (2021), Chae et al. (2022) when fitting the Simple IF + EFE, we find that eN > 0 is clearly preferred and recovers a value around the large-scale structure expectation. Although this function is significantly more accurate than any IF on its own, more than compensating for its additional free parameter (ΔBIC = −35 compared to the Simple IF), it has a poor description length due to the large functional contribution. The complexity is 59 using our current basis set of operators, although this would fall to 45 if tanh were explicitly included. In general, the great improvement in accuracy and simplicity of the ESR functions demonstrates the advantage of this method over guessing functions ‘by eye’.\n\nIn the top panel of Fig. 2, we plot the best 20 functions on top of the SPARC data. The functions are colour-coded by P(f), with darker colouring indicating functions favoured by MDL. The top six functions have discontinuities in s at gbar ≈ 0.02. We have checked that this is not due to outlying points, does not invalidate the first-order approximation of equation (2), and does not appear to map onto any local feature of the data. Instead it is likely due to the relative simplicity (i.e. complexity ≤9) of the functions considered, as we discuss further in Section 5. While such behaviour could be excluded by requiring no discontinuity in the derivative within the range of the data (or more generally weighting functions with an s-dependent prior), we see no principled reason to do so. The first function without a discontinuity is at rank 7, which has the Newtonian limit and s− = 0.52 at maximum likelihood. Although this is 9.3 σ from s− = 1/2, and hence this equation cannot function as a pure-MOND IF, the EFE leads to the expectation that s > 1/2 at low gbar as discussed in more detail below. Several of the remaining highly ranked functions have similar quasi-MONDian behaviour.\n\nWhile some of the best functions have MONDian limits around gbar = 10±3 others do not, and in particular s− < 1/2 is common. To explore this further, we calculate s− and s+ analytically for the top 10 equations as a function of their free parameters, showing the results in Table B1. For each of the functions where s− and/or s+ depend on |$\\boldsymbol {\\theta }$| (i.e. are not fixed by the functional form alone), we perform a Markov Chain Monte Carlo (MCMC) inference using the numpyro sampler (Bingham et al. 2019; Phan, Pradhan & Jankowiak 2019) with broad flat priors to constrain the parameters, and hence derive the posterior predictive distributions of the limiting slopes. Fig. 3 (left-hand panel) shows the results for the top 10 functions, using a dot to indicate a limit fixed by the functional form, a bar to show the 95 per cent confidence interval in cases where the slope depends on the parameters, and an arrowhead to indicate a limit outside of the plotting range (including ±∞). In many cases, the 95 per cent confidence interval is extremely narrow.\n\nAlthough it is s− and s+ that directly relate to the MOND hypothesis, they require extrapolation far beyond the range of the data. To understand how the slopes behave near the limits of the SPARC data, we also calculate s at the minimum, gbar, min = 8.32 × 10−13 m s−2, and maximum, gbar, max = 6.54 × 10−9 m s−2, measured baryonic accelerations. These are plotted in cyan and magenta respectively in Fig. 3. At gbar, max, the logarithmic slope is ≲1 for almost all functions, as expected for the Newtonian limit as only at gbar → ∞ does s become 1. However, we find that the gbar, min slopes of the top five functions are not ∼1/2 but actually <0 due to the aforementioned discontinuity. The remaining top functions have low-acceleration slopes typically slightly larger than 1/2.\n\nThese results show that the SPARC data do not unambiguously favour s− = 1/2 and s+ = 1. The requirement for an interpolating function to be MONDian is in fact even more stringent than this, since the coefficient of proportionality in the limiting high-gbar power-law relation must be unity, i.e. gobs = gbar. We find that among the functions in the top 10 for which s+ = 1, four have such a coefficient (at rank 2, 4, 7, 10) while for the rank 1 function this is 0.84 ± 0.006 and at rank 8 it is 0.72 ± 0.01, where the uncertainties are obtained by fitting the functions with MCMC. At low gbar, the coefficient in |$g_\\text{obs}\\propto g_\\text{bar}^{1/2}$| should be |$\\sqrt{g_0}\\approx 1$|⁠. The only function with s− = 1/2 (rank 6) has the coefficient 1.12 (close to the 1.10 expected from the canonical g0 = 1.2) while those further down with sgbar, min ≈ 1/2 have a coefficient of 1. The relative simplicity of the functions we consider here should preference a coefficient of 1, and hence again it is not clear to what extent the data may be said to be MONDian. The double power law has the limits |$g_\\text{obs}=0.81\\:g_\\text{bar}^{1.03}$| at high gbar and |$g_\\text{obs}=1.57\\:g_\\text{bar}^{0.60}$| at low gbar.\n\nNext, we show in the left-hand panel of Fig. 4, the separate Pareto fronts of description length and negative log-likelihood, with the second (‘simplicity’) objective measured by functional complexity. Unlike the Pareto fronts produced by traditional SR algorithms, those of ESR are guaranteed to be optimal. L(D) and |$-\\log (\\mathcal {L})$| are minimized separately at each complexity, and have their minimum values over all complexity subtracted so that the globally best functions appear at 0. We show the MONDian functions and double power law as separate symbols, all of which we find to be strongly Pareto-dominated by the best ESR functions at lower complexity. Note that while the ‘knee’ of the Pareto front (where L(D) or |$-\\log (\\mathcal {L})$| turns over) would appear to be at complexity 6–7, there is a significant improvement in going from complexity 8 to 9. This cautions against automatically selecting functions at the knee (the default for example in PySR), and indicates that further improvement would likely be achievable by going beyond complexity 9. This is beyond the scope of the present work; we are content here to have discovered simple functional forms for the RAR surpassing any that have been considered heretofore.\n\n4.2 Mock data\n\nThe above results suggest a Newtonian limit (gobs → gbar as gbar → ∞) is somewhat favoured by the data while a deep-MOND limit (⁠|$g_\\text{obs}\\rightarrow \\sqrt{g_0\\:g_\\text{bar}}$| as gbar → 0) is questionable. However, given the limited dynamical range and significant uncertainties of the data, it is unclear to what extent we should expect to find these limits even if the generating function were MONDian. In addition, the EFE would imply s > 1/2 at low gbar. To investigate these issues we now apply ESR to the mock data of Section 3.4.\n\n4.2.1 RAR IF generating function\n\nTable 2 shows the best functions found by ESR for the RAR IF mock data, along with the results for the IFs and double power law. The RAR IF is, by construction, a good fit to this data, but there are 15 functions with lower L(D), including several at lower complexity. This indicates that the characteristics of the SPARC data (dynamic range and uncertainties) are insufficient to pick out the true generating function: ESR prefers simpler functions which may achieve slightly higher likelihoods. Since the |$-\\log (\\mathcal {L})$| term in L(D) becomes dominant at large data set size, simply increasing the number of (mock) observations with otherwise identical properties would not be sufficient to push the generating function to the top of the list. For this data set, we find that the generalized RAR IF, appearing at rank 41, has higher L(D) than the RAR IF despite slightly higher likelihood, a success of MDL’s penalization of more complex functions. Note that the best-fit generalized RAR IF is |$x/(0.995-\\exp (-\\sqrt{x/1.068}))$|⁠, somewhat offset from the ground-truth values {1, 1.127}. This results from a combination of the limited data set size (introducing random noise) and a small bias in the maximum-likelihood estimator which we discuss further in Appendix A. At rank 27, we find a close cousin of the RAR IF in which the ‘1’ is free and g0 is pinned to 1. This performs only slightly worse than the RAR IF itself because the true g0 is close to 1.\n\nThe highest ranked ESR function is better by ΔL(D) = 6.3 than the RAR IF. Although the relative probability between the best function and the best RAR-like function is smaller than in the observations (∼1600 compared to 4 × 1010), it is interesting that the best RAR-like function appears further up the list in the real data (rank 17 versus 27). The double power law is disfavoured relative to the RAR IF and many ESR functions despite having the highest likelihood shown in the table, another success of the complexity penalization. There are a few functions overall with lower |$-\\log (\\mathcal {L})$|⁠, the lowest being −2048.0 at rank 51 ((θ0 + |θ1 + θ2/x|1/2)−1, L(D) = −2018.4). Also as expected, the Simple IF + EFE has eN snapped to 0, and hence behaves identically to the Simple IF albeit with larger functional complexity.\n\nThe top 20 ESR functions for the RAR IF mock are overplotted on that data in the middle panel of Fig. 2. We find a slightly reduced spread in s at both the high-gbar and low-gbar ends compared to the real data, without any discontinuities within the data range. However, there is still significant uncertainty beyond the range of the data. This is quantified in the middle panel of Fig. 3, where the top 10 functions are all observed to have slopes of approximately 1/2 at gbar, min and 1 at gbar, max, although only in two cases is s− = 1/2: for the others it is lower. This indicates that constraining the slope to be near 1/2 at gbar, min is insufficient to conclude that s− takes a similar value, at least up to complexity 9. One would need to reduce the uncertainties, or, preferably, lower gbar, min. That this applies to a lesser extent at high-gbar is shown by the functions at rank 4 and 7 with s+ = ∞.\n\nAdding to the conclusion that the mock data characteristics are insufficient to pick out a MONDian generating function, we find that the coefficient in gobs ∝ gbar at high gbar is only unity for one of the top-10 functions for which s+ = 1 (at rank 6). For all the others, it is 0.64 with the exception of that at rank 1 where it is 0.63. These values have uncertainties ∼0.003 when constrained by MCMC, and vary by ∼0.02 over mock data sets differing only in the random seed. Thus the best functions almost always fail to recover the Newtonian limit even when it is the truth, presumably due to an insufficient gbar, max. The origin of 0.64 is unclear, but presumably results from the way the lower-gbar behaviour is filtered through the forms of the functions found to be optimal. In cases where s− = 1/2, the coefficient of proportionality is 1 (to be compared to |$\\sqrt{g_0}$| in MOND), and the double power law limits are |$g_\\text{obs}=1.20\\:g_\\text{bar}^{0.90}$| at high gbar and |$g_\\text{obs}=1.30\\:g_\\text{bar}^{0.54}$| at low gbar.\n\nThe middle panel of Fig. 4 shows the Pareto front for these data. We find more smooth behaviour than for the real data, with the optimum solution achieved already by complexity 8, reflecting the relatively simple nature of the generating function. This shows that if the RAR IF was generating the real data (and our likelihood and mock data generation method were accurate), we would have achieved the L(D) minimum on those data too. However, the MONDian functions (including the RAR IF itself) and double power law are Pareto-dominated by the ESR results even on these mock data, showing that one should not expect to be able to recover unambiguously even this simplest of MOND generating functions.\n\n4.2.2 Simple IF + EFE generating function\n\nAnalogous results for the mock data generated using the Simple IF with inclusion of the EFE are shown in Table 3 and the bottom/right-hand panels of Figs 2–4. This data set behaves more similarly to the real data in terms of the relative ordering of the IFs, double power law, and ESR functions, including the generalized RAR IF. Indeed, the best-fit parameters of all three non-EFE IFs are identical to the SPARC data to two decimal places, while those of the generalized RAR IF and the high-gbar slope of the double power law are the same to one. Here, the IFs provide a significantly worse compression of the data than the best ESR functions, and the double power law also performs relatively poorly due to the curvature at low gbar (see Fig. 1). There is again a small bias between the maximum-likelihood (1.19 and 8.56 × 10−3) and true (1.2 and 1 × 10−2) g0 and eN values for the Simple IF + EFE fit. Although this function has among the highest likelihoods achievable by ESR up to complexity 9, its functional complexity makes it a poor compression of its own SPARC-like mock data. This reinforces the conclusion that the characteristics of these data are insufficient to identify a MONDian generating function: this one in particular would require far more data than the RAR IF to be favoured by MDL.\n\nFor the Simple IF + EFE mock all top-10 functions have s+ = 1 and s(gbar, max) > 0.9. However, only six of them recover the true Newtonian limit gobs = gbar: the others find gobs = 0.71 gbar or gobs = 0.79 gbar, again with sub per cent uncertainty from MCMC. Thus under this model too one would not expect the Newtonian limit to be identified robustly. While s(gbar, min) > 1/2, indicating the significant impact of the EFE, s− is typically 0 as opposed to 1 as expected from equation (6). Thus gbar, min is too high to constrain s− reliably, although this may also be a reflection of the relative simplicity of the functions we consider. The double power law limits are |$g_\\text{obs}=0.96\\:g_\\text{bar}^{0.98}$| at high gbar and |$g_\\text{obs}=1.55\\:g_\\text{bar}^{0.60}$| at low gbar. The Pareto front indicates this data set to be somewhat more complex than the RAR IF mock, as L(D) continues to fall to complexity 9, although the smoothness shows it to be simpler than the real data.\n\nAll functions considered achieve considerably higher likelihood on the mock data sets than the real data, showing that the mocks are simpler. This could be because the data do not conform to the MOND expectation – one would expect any given gobs = f(gbar) to be relatively inaccurate in a chaotic ΛCDM galaxy formation scenario – or because the model for scattering the mock data points is overly simplistic. This is discussed further in Section 5. Relatedly, the P(f) values of the top functions are very closely spaced in the mock data sets, indicating that there is little to distinguish them. On the contrary, on the real data the integrated probability of all functions besides the top five is ≲10−8, suggesting that these functions perhaps ought not to be considered at all. The limiting slopes of the top 10 equations as a function of the parameters can be found in Tables B2 and B3 for the RAR and EFE mocks, respectively.\n\n5 DISCUSSION\n\nOur main conclusion is that the SPARC data are insufficient to determine robustly the limiting behaviour of the RAR, and hence cannot verify or refute the MOND hypothesis. This is reached by studying mock data generated by MOND; in particular, generating data according to the RAR IF, not only are we unable to identify that as the generating function, but, more seriously, we cannot reconstruct s− = 1/2. At the high-gbar end, the logarithmic slope of the Newtonian limit (s+ = 1) is typically well recovered, although the coefficient of proportionality in gobs ∝ gbar is not: in the RAR IF mock data this takes a values ∼0.64 far more often than 1.\n\nImproving this situation requires increasing the dynamical range of the RAR. At the low-gbar end, this may be achieved by studying ultra-diffuse galaxies (e.g. Freundlich et al. 2022), or local dwarf spheroidals (e.g. McGaugh & Wolf 2010; McGaugh & Milgrom 2013), some of which seem seem to indicate s− ≈ 0, as found by many of the best ESR functions (Lelli et al. 2017). Alternatively, one may attempt to probe the outer regions of galaxies including the Milky Way (e.g. Oman et al. 2020). Particularly promising for a large gain is to use stacked weak lensing to probe galaxy outskirts that would have insufficient signal to noise on an individual-object basis (Brouwer et al. 2021). This appears to indicate s− ≈ 1/2. Increasing gbar, max requires probing the central regions of high-mass ellipticals, as well as groups and clusters of galaxies (Chae et al. 2019, 2020a; Chan & Del Popolo 2020; Tian et al. 2020; Gopika & Desai 2021; Pradyumna & Desai 2021). Such data already exists and may readily be folded into our framework to increase its constraining power. A smaller information gain may be achieved by reducing the uncertainties in gbar and gobs: in the limit of no uncertainty, any generating function will be assigned P(f) = 1 by MDL. By generating mock data with different characteristics, one could ascertain the requirements for various features of the functional form to be unambiguously determined.\n\nIt is likely that there exist functions at higher complexity superior to those of Tables 1–3, especially for the real data where L(D) drops significantly from complexity 8 to 9. While uncovering lower-L(D) functions at complexity >9 may update the optimal limiting behaviours of the functional form of the RAR, and hence its compatibility with MOND, it cannot compromise our discovery of simpler and more accurate functions than the IFs and double power law. Indeed, the fact that the (or at least a) knee of the Pareto front is reached around complexity 7 in the left-hand panel of Fig. 4 shows that such functions already offer a powerful compression, and the commonalities between the top functions at complexity ≲9 suggests that similar features are likely to be present in more complex functions also.\n\nDiscovering such functions would likely be computationally prohibitive for the ESR algorithm, and thus a stochastic search (e.g. using a genetic algorithm) may be required. This search may be seeded by the ESR functions: the fact that many of the best-fitting functions have similar features (such as gobs ≈ 0.64 gbar as gbar → ∞ for the RAR IF mock) suggests these may be useful for higher-complexity functions also. Thus ESR may be used to validate the underlying assumption of stochastic searches that there exist features of functions responsible for their fitness, and the identification of these features may be useful for tuning hyperparameters. It would also be possible to combine ESR with deterministic symbolic regression algorithms (e.g. Worm & Chiu 2013; Rivero & Fernandez-Blanco 2022; Kammerer et al. 2020) to search systematically the neighbourhood of good functions towards higher complexity.\n\nOur best functions on the real data have a discontinuity in s around gbar = 0.02. This is likely due to the limited complexity of the equations we consider: a cusp is the simplest way of changing s sharply. It is probable that the optimal functions at higher complexity will have a smoothed form of this behaviour in which s does not become negative and may not tend to 0. We therefore doubt that the s− and s(gbar, min) values of the best functions in Table 1 are robust. One could attempt to construct more complex functions inspired by the ESR results with similar but not discontinuous behaviour and calculate their |$-\\log (\\mathcal {L})$| and L(D) separately, or feed them into a genetic algorithm as mentioned above. On the other hand, below complexity 9, there is only a single low description length function that is discontinuous, the third best function at complexity 8 (P(f) = 4.2 × 10−11). The best functions at lower complexity more frequently have s− = 1/2 and s+ = 1, although again they rarely satisfy gobs = gbar as gbar → ∞. For example, the top function at complexity 6 – marking the (first) knee of the L(D) Pareto front in Fig. 4 – is |$g_\\text{obs}=0.70\\:g_\\text{bar}+ \\sqrt{g_\\text{bar}}$|⁠, exhibiting similar high-gbar behaviour to the 1st- and 8th-ranked functions overall.\n\nTo generate the mock data, we assumed that all gbar values are uncorrelated. While this is likely true between galaxies, it is not within a single galaxy because the uncertainty in gbar is dominated by the mass-to-light ratio, a global galaxy parameter in the simplest approximation. This may be seen from the data in Fig. 1, where lines of points (e.g. scattering low around gbar = 2 or high around gbar = 10) are all from the same galaxy. A more robust procedure may be to generate Υ values for each mock galaxy by randomly drawing from their priors, use this to transform gbar, and then add any other random sources of noise (e.g. from the uncertainty in |$3.6\\,\\mu{\\rm m}$| luminosity). By enhancing inter-galaxy variations, this may increase the complexity of the mock data sets, moving their ESR results towards those of the SPARC data. Alternatively, one may fit each galaxy separately to assess compatibility of their individual RARs (analogously to Li et al. 2018 but not just for the RAR IF). The assumption of uncorrelated data points is also present in our likelihood, as discussed further in Appendix A. A complete analysis would infer D, i, L3.6, and Υ for each SPARC galaxy along with the parameters of the function being fitted.\n\nWe have assumed no intrinsic scatter in the RAR such that all deviations from the hypothetical functional expectation must come from the observational uncertainties. While this is expected in MOND, in ΛCDM the complex process of galaxy formation would lead to a significant and parameter-dependent effective intrinsic scatter (Desmond 2017). Even the EFE would introduce some scatter due to galaxy-by-galaxy variation in gex (Chae et al. 2021). It would be straightforward to add this (in some direction on the RAR plane) as an additional free parameter of all functions, which would alter the results. MDL naturally penalizes the addition of this parameter, allowing one to determine whether it is justified for any given function. This would provide further evidence concerning the optimality of MOND by assessing the extent to which the data implies law-like modified gravity behaviour.\n\nOur current implementation of MDL treats the parameter values as part of the model and chooses them to maximize the likelihood. An alternative would be to treat the hypothesis in equation (1) as the functional form alone, assigning codelengths and probabilities to functions regardless of their parameter values. In a Bayesian formulation, this corresponds to marginalizing over the parameters, and enables a simpler one-part coding scheme, where the description length is simply the negative logarithm of the model evidence including any functional prior. An even higher-level approach would be to group functions into sets with specific properties, e.g. limiting behaviour. This would enable calculation of the posterior predictive distribution of any feature of the functional representation of the data set, and hence enable model comparison at any level of generality.\n\nThe relative simplicity of the RAR and conformity to the Newtonian and deep-MOND limits are the key differences between the expectations of MOND and the more chaotic galaxy formation scenario of ΛCDM: it is only under the simpler scenario that one would expect to find a simple |$g_\\text{obs}= \\mathcal {F}(g_\\text{bar})$|⁠. While our results are therefore not particularly supportive of the MOND hypothesis, this is not to say either that data could not plausibly have been generated by MOND or that it could plausibly have been generated under another hypothesis, as only MOND currently has sufficient predictivity for a test of this precision. We look to future SR studies with more data to establish the functional form of the RAR – if it exists – definitively.\n\n6 CONCLUSION\n\nThe RAR has become central to debates about the mass discrepancy problem on astrophysical scales. Its tightness and regularity have been used to argue for a violation of Newtonian gravity in accordance with MOND, but the functions used to fit the data have been constructed to conform to this theory. As the first detailed application of the brand-new technique of ESR, we rank objectively all simple functions in terms of their aptitude for describing the SPARC RAR. We employ the minimum description length principle to trade accuracy with simplicity and hence perform model selection, and calibrate our method on mock MOND data generated both with and without the external field effect (EFE). Our conclusions are as follows:\n\nESR discovers functions which are better descriptions, in both accuracy and simplicity and for both observed and simulated data, than MOND functions or a double power law.\n\nWhile the majority of best-fitting functions on the SPARC data recover gobs ∝ gbar at high accelerations, not all have a best-fit coefficient of proportionality near unity. Thus the Newtonian limit is not clearly evidenced.\n\nThe SPARC data do not prefer functions with the deep-MOND limit of |$g_\\text{obs}\\propto \\sqrt{g_\\text{bar}}$| as gbar → 0. Instead, we find that functions with gbar → const typically compress the data more efficiently, albeit with considerable uncertainty.\n\nSPARC-like mock data generated assuming the MONDian RAR interpolating function do not unambiguously recover that function. Moreover, many of the best functions for those mock data have gobs ≈ 0.64 gbar rather than gobs = gbar at high gbar, and most do not have a deep-MOND limit at all.\n\nThe EFE in AQUAL greatly increases the logarithmic slope of the best-fitting functions at the low-gbar end of the data, but does not appreciably impact the limiting slope at gbar → 0. Incorporating the EFE in the mock data produces more generally similar results to the real data, so our analysis (within the MOND paradigm) hints at it.\n\nWe conclude that the data have too small a dynamic range (and too large uncertainties) to unambiguously favour MOND even if it is in fact generating the data. The SPARC RAR alone therefore does not supporting that theory unambiguously. The best prospect for improving this situation is to increase the acceleration range of the data, e.g. using stacked weak lensing at low gbar and groups and clusters at high gbar.\n\nOur results are a function of the maximum complexity of equation considered. Future symbolic regression algorithms – exhaustive or non-exhaustive – will reach the true description length minimum, and hence uncover the optimal functional representation of the RAR and determine whether the relation implies novel law-like gravitational behaviour.\n\nESR provides for the first time a guaranteed complete search through functional parameter space, making it the ideal tool to determine the analytic form of observed relations, extract physics from data theory-agnostically, and create fitting functions. We make the ESR and RAR codes, full function sets and the best 50 functions for each data set we consider publicly available to facilitate future applications.\n\nAcknowledgement\n\nWe thank Kyu-Hyun Chae, Andrei Constantin, Miles Cranmer, Mario Figueiredo, Gianluca Gregori, Thomas Harvey, Mark Kotanchek, Federico Lelli, Stacy McGaugh, Andre Lukas, Richard Stiskalek, and Tariq Yasin for useful inputs and discussion.\n\nHD is supported by a Royal Society University Research Fellowship (grant no. 211046). DJB is supported by the Simons Collaboration on ‘Learning the Universe’ and was supported by STFC and Oriel College Oxford. PGF acknowledges support from European Research Council Grant No: 693024 and the Beecroft Trust.\n\nThis project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No 693024).\n\nThis work used the DiRAC Complexity and DiRAC@Durham facilities, operated by the University of Leicester IT Services and Institute for Computational Cosmology, which form part of the STFC DiRAC HPC Facility (www.dirac.ac.uk). This equipment is funded by Business Innovation & Skills (BIS) National E-Infrastructure capital grants ST/K000373/1, ST/P002293/1, ST/R002371/1, and ST/S002502/1, STFC DiRAC Operations grant ST/K0003259/1, and Durham University and Science and Technology Facilities Council (STFC) operations grant ST/R000832/1. DiRAC is part of the National E-Infrastructure.\n\nFor the purpose of open access, the authors have applied a Creative Commons Attribution (CC BY) licence to any Author Accepted Manuscript version arising.\n\n7 DATA AVAILABILITY\n\nThe code and data associated with ESR and its application to the RAR are released at https://github.com/DeaglanBartlett/ESRand in Bartlett, Desmond & Ferreira (2022a). The SPARC data is available at http://astroweb.cwru.edu/SPARC. Other data may be shared on request to the corresponding authors.\n\nReferences\n\nAPPENDIX A: A NOTE ON LIKELIHOODS\n\nA1 Correlation of measurements and their uncertainties\n\nThe likelihood of Section 3.2 treats the uncertainties induced by Υ, D, and i as statistical and uncorrelated between points. This is clearly incorrect: a scattering up of Υ, for example, causes a coherent increase in gbar across the rotation curve, generating off-diagonal elements in the covariance matrix. A better approach is therefore to calculate the covariance matrix via Monte Carlo. For a given galaxy, one would independently sample Υgas, Υdisc, Υbulge, D, and i many times from their assumed-Gaussian prior distributions. One would then generate the corresponding |$\\mathbf {g_\\text{obs}}$| and |$\\mathbf {g_\\text{bar}}$| values (now vectors across the rotation curve of a given galaxy), scatter them by their statistical uncertainty (⁠|$\\mathbf {g_\\text{bar}}$| has only the small δL3.6 term), and calculate the covariance matrices |$\\mathbf {\\mathsf {\\Sigma }}_\\text{obs}$| and |$\\mathbf {\\mathsf {\\Sigma }}_\\text{bar}$|⁠.\n\nLet us define u ≡ log (gbar) and v ≡ log (gobs) such that |$\\boldsymbol {u}$| and |$\\boldsymbol {v}$| are vectors containing u and v for all galaxies at all measured points along the rotation curve. We denote the ‘true’ values with a superscript t and the observed values without a superscript. We assume that |$\\boldsymbol {u}^\\text{t}$| and |$\\boldsymbol {v}^\\text{t}$| are drawn from multivariate Gaussian distributions with covariance matrices |$\\mathsf {\\Sigma }_u$| and |$\\mathsf {\\Sigma }_v$|⁠, respectively. Since |$\\boldsymbol {u}^\\text{t}$| and |$\\boldsymbol {v}^\\text{t}$| are statistically independent random variables for fixed |$\\boldsymbol {u}$| and |$\\boldsymbol {v}$|⁠, the likelihood of a given set of points in the |$(\\boldsymbol {u}^\\text{t}, \\boldsymbol {v}^\\text{t})$| plane would then be\n\n(A1)\n\nThe equivalent of equation (2) for a vector-valued function |$\\boldsymbol {f}$|⁠, |$\\boldsymbol {v} = \\boldsymbol {f}\\left(\\boldsymbol {u} \\right)$|⁠, is then obtained by marginalising over |$\\boldsymbol {u}^\\text{t}$|⁠,\n\n(A2)\n\nTaylor expanding |$\\boldsymbol {f}\\left(\\boldsymbol {u}^\\text{t}\\right)$| about |$\\boldsymbol {u}$|⁠,\n\n(A3)\n\nwhere |$\\mathbf {\\mathsf {D}}_{ij} \\equiv \\partial _j \\mathbf {f}_i \\vert _{\\boldsymbol {u}}$|⁠, yields\n\n(A4)\n\nwhere |$\\mathbf {\\mathsf {\\Sigma _\\text{tot}}}$| is the total covariance matrix defined by\n\nThis is equivalent to equation (3) if |$\\boldsymbol {u}$| and |$\\boldsymbol {v}$| have only a single element.\n\nIn principle, the assumption that the joint probability distributions of |$\\boldsymbol {u}^\\text{t}$| and |$\\boldsymbol {v}^\\text{t}$| are a multivariate Gaussian is unnecessary as the full empirical distributions are generated by the Monte Carlo sampling described above. Using this directly would enable a loss function which, while still independent between galaxies, fully encapsulates the correlated, non-Gaussian structure of each galaxy’s measurements, and hence provides a more accurate description of the expected probability distributions of gbar and gobs. This model would also allow for more accurate mock data generation as discussed in Section 5.\n\nA2 Sampling nuisance parameters from their posteriors\n\nAll the methods described above sample Υ, D, and i, and the true gbar values |$\\boldsymbol {u}^\\text{t}$|⁠, from their priors, i.e. without adjusting them to maximize agreement with the function being fitted. In principle, the better procedure is to constrain these nuisance parameters jointly with any parameters of the function, assuming that function in the fit. Even the relatively simple case where |$\\boldsymbol {u}^\\text{t}$| is drawn from the prior but Υ, D, and i from the posterior is however impractical as it requires optimization in a parameter space of dimension 147 × 3 + p if the three Υs are coupled (or only one is varied), and 147 × 5 + p if they are varied separately, where p is the number of free parameters in the function. This would naturally account for correlations between the gbar and gobs measurements induced by variations in Υ, D, and i, and thus provides a more accurate but expensive alternative to the model of Section A1. This approach will be applied for the first time to the RAR, outside the context of SR, in upcoming work ( Desmond 2023, in prep).\n\nThe situation is complicated further by inference of |$\\boldsymbol {u}^\\text{t}$|⁠. At the top level of the hierarchical model for predicting |$\\boldsymbol {v}$| from |$\\boldsymbol {u}$| are both the parameters of the model, |$\\boldsymbol {\\theta }$|⁠, and |$\\boldsymbol {u}^\\text{t}$|⁠. If one wanted to find the true maximum likelihood point, one should maximize equation (A1) for |$\\boldsymbol {u}^\\text{t}$| as well as |$\\boldsymbol {\\theta }$|⁠, instead of equation (A2) for |$\\boldsymbol {\\theta }$| alone.\n\nTo do this, we start by noting that maximising the likelihood in equation (A1) is equivalent to minimising\n\n(A6)\n\nUsing equation (A3) and minimising h with respect to |$\\boldsymbol {u}^\\text{t}$|⁠, we find the maximum-likelihood point, |$\\hat{\\boldsymbol {u}}^\\text{t}$|⁠, to be\n\nand we must therefore maximize\n\n(A8)\n\nwhere |$\\mathbf {\\mathsf {\\Sigma }}_\\text{tot}^{-1}$| is defined in equation (A5). This will not yield the same result as maximising equation (A4) since equation (A8) does not contain the normalization term which penalizes large gradients. When applied to mock data generated assuming |$\\boldsymbol {v}^\\text{t}$| is linearly related to |$\\boldsymbol {u}^\\text{t}$|⁠, we find that equation (A4) (the commonly used expression, and the one we adopt in Section 3.2) induces a small bias that equation (A8) does not. This is the reason why the best-fit RAR and generalized RAR IFs do not precisely match the generating function in Table 2, or the Simple IF + EFE the generating function in Table 3. We should expect all best-fitting parameter values to be likewise slightly biased by the use of equation (2).\n\nIn practice, it is challenging to maximize equation (A1) since the lack of the gradient-penalizing determinant means that naïvely using equation (A8) can prefer functions with diverging gradients at at least one point in the domain of |$\\boldsymbol {u}$|⁠. This breaks the linearity assumption in equation (A3), making the result untrustworthy. Instead, one should numerically solve the full optimization problem without Taylor-expanding |$\\boldsymbol {f}$|⁠. This involves solving a root-finding problem for each trial |$\\boldsymbol {\\theta }$| during the optimization of the function’s parameters. Although feasible for a handful of functions, this is computationally impractical for the full set of ESR functions. We therefore use the simpler likelihood here, calibrating our results using mock data to measure the magnitude of the bias. We defer further discussion of this important issue to future work.\n\nAPPENDIX B: LIMITING SLOPES OF ESR FUNCTIONS\n\nHere we provide the analytic low-gbar (s−) and high-gbar (s+) logarithmic slopes of the top 10 functions generated using ESR up to complexity 9. We give the slopes for the observed SPARC data in Table B1, the mock data assuming the RAR IF in Table B2, and the mock data assuming the Simple IF with EFE in Table B3.\n\n© The Author(s) 2023. Published by Oxford University Press on behalf of Royal Astronomical Society"
    }
}