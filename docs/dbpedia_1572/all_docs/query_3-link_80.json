{
    "id": "dbpedia_1572_3",
    "rank": 80,
    "data": {
        "url": "https://link.springer.com/article/10.1007/s10064-020-01766-2",
        "read_more_link": "",
        "language": "en",
        "title": "The use of unmanned aerial vehicles (UAVs) for engineering geology applications",
        "top_image": "https://static-content.springer.com/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig1_HTML.jpg",
        "meta_img": "https://static-content.springer.com/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig1_HTML.jpg",
        "images": [
            "https://link.springer.com/oscar-static/images/darwin/header/img/logo-springerlink-39ee2a28d8.svg",
            "https://media.springernature.com/w72/springer-static/cover-hires/journal/10064?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-981-99-4362-3?as=webp",
            "https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-031-14623-7?as=webp",
            "https://media.springernature.com/w215h120/springer-static/image/art%3A10.3103%2FS0747923920050047/MediaObjects/11990_2020_2137_Fig1_HTML.gif",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig1_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig2_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig3_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig4_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig5_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig6_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig7_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig8_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig9_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig10_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig11_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig12_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig13_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig14_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig15_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig16_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig17_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig18_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig19_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig20_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig21_HTML.jpg",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig22_HTML.png",
            "https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10064-020-01766-2/MediaObjects/10064_2020_1766_Fig23_HTML.png",
            "https://link.springer.com/oscar-static/images/logo-springernature-white-19dd4ba190.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Marc S",
            "De Berardinis"
        ],
        "publish_date": "2020-04-01T00:00:00",
        "summary": "",
        "meta_description": "This paper represents the result of the IAEG C35 Commission “Monitoring methods and approaches in engineering geology applications” workgroup a",
        "meta_lang": "en",
        "meta_favicon": "/oscar-static/img/favicons/darwin/apple-touch-icon-92e819bf8a.png",
        "meta_site_name": "SpringerLink",
        "canonical_link": "https://link.springer.com/article/10.1007/s10064-020-01766-2",
        "text": "This paper represents the result of the IAEG C35 Commission “Monitoring methods and approaches in engineering geology applications” workgroup. The work of the Commission is aimed to present a general overview of UAVs and their potentiality in the field of engineering geology. The use of UAV has progressively increased in the last decade and nowadays started to be considered a standard research instrument for the acquisition of images and other information on demand over an area of interest. The possible field of activity of these systems has progressively expanded and now ranges from archaeological applications (Rinaudo et al. 2012; Nex and Remondino 2014; Nikolakopoulos et al. 2017b), to smart farming (Zhang and Kovacs 2012), to the management of natural hazards (Gomez and Purdie 2016; Giordan et al. 2018). It is possible to find different names or acronyms to describe the same object: an aerial drone. RPAS (remote pilot aircraft system), UAV (unmanned aerial vehicle), and UAS (unmanned aerial system) are the most common acronyms, but we have also to consider all national definition, where the name is translated in the national language. In this paper, we decided to use “UAV” to identify an unmanned aerial system, which is able to have an autonomous flight with or without an engine, to be remotely controlled, and to be able to collect some data. Usually, these systems are employed with imaging sensors but not only. Nowadays, UAV and drone are familiar words, and the commercial and smaller version can be found on the shelf, in all electronic shops or in a normal mall with a very low prices. Considering the low price and the very friendly use of the system, these systems are now considered suitable for an incredible number of potential application fields even where the users are not particularly skilled in aeronautics system such as geomatics, geology, cultural heritage, archaeology, survey, mining, environmental applications, and astronomy. In next sections, we will provide a more detailed description of the main characteristics of UAV, their main components, and the possibility to carry on a payload that can be constituted by a system able to acquire a specific dataset-like images, 3D point clouds, or other physical parameters like radiations or air quality. The paper is organized in the first part focused on the description of UAV, their main characteristics, and several best practice suggestion for a correct use, and a second part with a sequence of scenarios where the use of UAV can be considered very useful for engineering geology applications.\n\nRecent UAV developments\n\nThe first exemplar of modern UAV, in term of the aerial vehicle with the capability to have an autonomous flight even with long range and a wireless link to the ground station, has been developed in 1944, during the Second World War and it was the V-1 system. Traditionally, UAV systems were used for military goals and applications and only recently became system used for civilian use. Even though UAV systems were developed for military purposes (and this is still now a key topic), the availability of low-cost sensors and platforms has laid the foundations for an increasing interest also in the civil field (Juul 2015; NASA 2015). In geomatics, Przybilla and Wester-Ebbinghaus (1979) carried out the first application. Even if UAVs were not initially designed and realized for geomatics or other applications, commercial solutions have been progressively adapted to fulfill different geomatics fields of applications and operative requests (Piras et al. 2017a, b; Chiabrando et al. 2013; Aicardi et al. 2016a, b). Thanks to new technologies, innovative solutions and sensors have been recently developed even for civilian application, allowing to improve the flexibility (less restriction in term of sensor’s installation), performance (more duration, better aerodynamics profile, better navigation system), and planning tool (new tools have been developed for planning and control the UAV operations).\n\nFor civilian purposes, the most significant recent improvements are the development of low-cost flight controller systems (Chao et al. 2010), and the great diffusion of structure from motion (SfM) applications that allows the creation of a 3D model from a sequence of images captured from different points of view (Westoby et al. 2012).\n\nThese two recent signs of progress have pushed the great current diffusion of cheap systems that has exponentially increased the number of people that are using UAV also for professional purposes. Unfortunately, most of them do not have a proper background for their correct use. In particular, the acquisition of a photo sequence required by structure from motion applications seems to be a simple operation, but if the high accuracy (both in terms of geographic positioning and resolution) of the final model is required, the use of these systems cannot be managed as a black box without respecting few essential rules. On the other hand, one of the actual limitations is that these “friendly” systems give the impression that could be used without any specific competences creating a real risk of having poor results and working in un-safety conditions.\n\nUAVs classification\n\nIt is quite challenging to define a summary table about the UAV classification because each modern UAV is full of technology, and it is complicated to compare different systems between themselves. A possible tentative, considering some general factors as the duration of the flight, range, and payload, is shown in Table 1.\n\nOver the short-range category, there are other larger UAV systems, but they are rarely employed for civilian applications, and for this reason, they are not mentioned in Table 1.\n\nAnother possible classification could be made considering the weight with respect to the air propulsion system (with or without engines or propellers). Considering this approach, it is possible to distinguish several kinds of systems. Balloons, kites, and paraglides are systems without their own propulsion. On the opposite side, multirotors, fixed wings, airship, and helicopters are the UAV based on electric or combustion engine. In Table 2, the main characteristics of these categories are summarized and compared.\n\nAccording to recent development of UAV for civilian purposes, the most widespread applications for UAV are generally the following: (i) photogrammetry and remote sensing (Colomina and Molina 2014) to extract information from images and produce 3D data; (ii) 3D modeling (Wefelscheid et al. 2011) to reconstruct the 3D shape of buildings or areas; (iii) surveillance (Semsch et al. 2009), both in civil and military fields; (iv) inspection (Zhang et al. 2012), especially when human interventions can be dangerous; (v) disaster response and monitoring (Boccardo et al. 2015), to map the situation after catastrophic events or before an expected one and to provide new updated information. In this case, UAVs can be easily and quickly used; (vi) forest and agriculture and geological investigations (with thermal and multispectral sensors (Saari et al. 2011) are emerging fields that UAV can provide high-resolution and repetitive data fundamental for monitoring purposes. Another possible classification has been proposed by the NASA (2015) that divides the UAV missions into four different groups:\n\nLand management missions: these are performed to obtain geospatial information on specific areas for monitoring or management purposes. They can be particularly suitable in dangerous areas (for example, after disasters and emergencies) and their civil applications may include fields such as the following: agricultural forestry, firefighting, geological investigations, communication networks, surveying, and mapping. This kind of use is particularly suitable to have prior knowledge of some areas before building and construction projects and to provide updated digital terrain models (DTMs) and orthophoto data.\n\nCommercial: these type of missions are mostly related to precision agriculture since in this specific case, the use of UAVs can save time and cost to acquire a large amount of data. In particular, the capability to house thermal and near-infrared sensors onboard suggests that unmanned system will significantly modify the general perspective in the agriculture field. On the other hand, they can be flexible and repeatable tools to acquire environmental parameters about air pollution and quality;\n\nEarth science missions: the goal of these missions is to monitor some areas of the earth, measuring the geophysical processes associated with natural hazards on a larger scale than the land management one. The general idea is that these missions would replace the satellite observations in the future (for example, for earthquakes, landslide, and volcanoes);\n\nHomeland security: these missions concern the monitoring of restricted areas for security or surveillance operations and they are included under the category of “Non-Military Governmental.”\n\nTraditionally, in the more significant part of the activities done in the environmental field, the most used systems are fixed wings and multirotor thanks to their flight duration and operability. Unfortunately, there is not a unique system for all kind of practical problems and, in each case, it is fundamental a careful preventive evaluation of the mission characteristics aimed to define the best solution and sensors that should be installed on. Furthermore, in almost operations, it is fundamental to pay attention to the planning of data acquisition that represents a fundamental aspect to be considered in the definition of the survey. It is important to point out that when we consider a UAV, we have to know that the complete system is composed not only by the aerial vehicle but also by the ground control station (GCS). The GCS is very important and mandatory, in order to work in safe condition, and to verify in real-time the operative state of the UAV during the flight (e.g., telemetry, temperature of the battery, power, temperature of the propellers). One of most important actions that should be done before the flight is to verify the quality and the stability of the data link and the communication system, because it is fundamental to have always a good connection between UAV, pilot, and GCS.\n\nEven if almost recent UAVs are able to fly autonomously following a predefined mission plan, it is fundamental to remember that there is always the possibility that some element in the mission planner cannot work correctly. In this possible critical situation, the pilot has to take direct control of the UAV and land it in safety conditions. For this reason, the skill of the pilot is a fundamental element for the correct management of UAV operations.\n\nAs mentioned before, the most used UAV for non-military applications are mini- and micro-UAV (payload < 30 kg). Fixed wings and multirotors are the preferred solutions for their ease of use, low cost, transportability, and the capability of performing surveys in different areas. On the other hand, their small size requires specifically designed sensors that have to be both reliable and lightweight enough to respect the limits of the payload.\n\nThis section aims to provide the reader an overview of the essential components of conventional UAV. A more detailed analysis of possible payloads is presented in the “UAV payload sensors” section.\n\nPrincipal UAV components\n\nAerial vehicles are complex systems made by hardware and software structures. The improvement of electronics allowed the development of navigation and control systems more and more available on the market.\n\nThe main components of a UAV can be divided into three main categories: (i) the aerial platform, which includes the airframe, the navigation system, the power system, and the payload; (ii) the ground control station (GCS), which allows the human control from a remote emplacement; and (iii) the communication system, which supports the communication between the other two components.\n\nThe aerial platform is composed of different components whose purpose is to allow the flight and carry some sensors in the air for the data acquisition:\n\nThe airframe is the main structure of the UAV. Its structure has to consider the weight regarding, in particular the power and the communication and control systems onboard. Moreover, the airframe needs to be adequately designed to withstand the forces that can occur during the flight and not cause deformation and vibration. As presented in Fig. 1, fixed wings are mainly made of polystyrene or plastic; common multirotors airframes are made of aluminum or carbon fiber (in such a way as to be lightweight and resistant), and the number of arms is a function of the expected payload and the number of engines.\n\nThe navigation system is the main component of the avionics is the autopilot that allows autonomous or semi-autonomous flights through hardware and software components. The specification of the autopilot for a UAV can be summarized as reported in Table 3. The navigation system is composed of flight control, GPS/GNSS, and inertial system.\n\nThe flight control is the “core” of the navigation system. This board manages the flight planning and can verify in real-time the theoretical trajectory with respect the real one. It is possible to connect on this board several sensors, to synchronize the data acquisition using the GPS time. In some case, a small digital memory car is housing, with a purpose to collect and store several information as a trajectory (log file), telemetry, and images or another kind of data.\n\nThe GPS/GNSS board is another fundamental element of modern UAVs. Usually, a single-frequency and dual-constellation (GPS and GLONASS) system is installed onboard. In some configurations, even a dual-frequency multi-constellations receiver could be available. Traditionally, the receiver is only used to define the UAV position in stand-alone (st. dev. = 3–5 m), potentially with EGNOS or WAAS solution (st. dev. = 1–3 m). Raw data (pseudo-range and carrier phase) are not usually saved, but in some recent commercial systems, it is possible to do it, to realize a PPK (post-processing kinematic) positioning. Even RTK (real-time kinematic) positioning is allowed in some new commercial systems;\n\nThe inertial system is commonly the last component of the navigations system. Nowadays, a MEMS (micro-electro-mechanical systems) inertial measurement unit (IMU) is installed on board, with the purpose to control the UAV’s attitude. Usually, IMU is not able to collect the raw data, even in the most recent ones. The range of the precision in the estimation of the angle of common IMU used for mini or micro-UAV is around 1–4°.\n\nThe power system is another fundamental element of UAV aimed to provide energy to the system. According to the selected airframe, different power systems can be adopted: Wankel rotary engines, fuel cells, and electric solutions are the most common. With multirotor systems, the most adopted solution is lithium polymer (LiPo) batteries.\n\nThe payload is composed of sensors or instruments carried by the UAV and used to acquire some specific data or parameter (e.g., RGB/multispectral camera, video-camera, thermal or other kinds of sensors).\n\nThe other components of payload could be instruments needed for the onboard equipment and the device activation. Especially in the case of cameras, a fundamental component is a gimbal, a support that allows the rotation of the payload along one or more axes often equipped with servos that can adjust or stabilize the orientation of the sensor. According to the sensor, the gimbal can be fixed, stabilized, and controllable from the ground.\n\nThe ground control station (GCS) ensures a permanent and interactive remote control of the UAV informing the pilot about the progress of the autonomous flight. A computer or a tablet able to plan the flight and control its execution usually is the base configuration for a GCS. The pilot should be equipped with a remote control that can be used in emergency cases or to perform the takeoff and landing if the UAV is not entirely autonomous. One or more people are responsible for the management and control of UAV parameters during the flight. The major parts of commercial UAVs have their dedicated mission planner or it is possible to use open-source software developed by the scientific community. Mission planners are applications where it is possible to define a sequence of navigation waypoints or to set a photogrammetric flight defining the area of interest, the camera parameters, and other photogrammetric parameters (e.g., side and frontal overlap, ground sampling distance).\n\nThe last UAV component is the communication system that is the radio connection between the ground and the vehicle. To command and control a UAV, radio communication is mandatory also to assure a continuous link for emergency operations. Radio frequencies (RF) in the range of 30 MHz to 3 GHz are generally the RF bandwidth in which small multirotors operate.\n\nUAV navigational sensors\n\nNavigation systems have become widespread in recent years and adopted on vehicles, smartphones, and other numerous operative solutions. In most cases, these systems use not only one or more GNSS receivers but also an IMU that is necessary to provide the vehicle setup information for each epoch and to assist the GNSS system in estimating the position of the vehicle. The use of these sensors for UAV, however, requires the resolution of a series of problems linked for example to their synchronization and calibration. Typically, these problems can be solved by developing appropriate hardware and software tools, able to analyze and compensate systematic errors (bias) and sensor drift(s). The ultimate goal of this suite is a navigational solution sufficiently accurate about the type of final application of the system. The accuracy of the UAV position is not only an important element for the management of the flight but also a crucial point for the possible application of direct photogrammetry (Chiabrando et al. 2013).\n\nDifferent operative solutions can be available on UAV, mainly based on these possible configurations: (i) single/multi-frequency GPS/GNSS receivers; in this case there is often the possibility to improve the solution with the usage of the L2 frequency; (ii) single/multi-constellation antennas and GPS/GNSS receivers: the availability of more than one constellation can improve the final positioning solution; (iii) GPS/GNSS RTK (real-time kinematic) approach which allows the possibility of improving the position accuracy estimated in real-time with the correction from a master or a permanent station; (iv) integrated GNSS and IMU sensors; in this configuration, the GNSS position can be improved using the data from the inertial platform.\n\nThe market offers many low-cost GPS or GNSS receivers, often available as an OEM card. In other cases, some developer kits are available, as the u-blox receivers. u-blox can be considered an example of low-cost GNSS receiver capable of receiving four single-frequency GNSS constellations. Due to its limited cost, it can be considered an interesting solution with minimum overall dimensions and an easy interface. The presence of the communication port requires only preparing a data storage on micro PC and SD card (or similar) and the transfer of raw data to a processing center. Among the “medium-high” level receivers, some multi-frequency and multi-constellation OEM cards could be mentioned. These cards should be engineered and could constitute a low-cost solution but with centimeter precision suitable also for real-time. These receivers are usually set up for RTK acquisitions, and they may have options that are not always included in normal receivers such as 1PPS (pulse per second), to issue the recording command from the receiver to an external instrument, and “Event Marker” to record an external event (for example, the measurement time of another sensor) in the GNSS time scale.\n\nThe IMU consists of a set of sensors, generally accelerometers and gyroscopes, necessary to allow the estimation of all the navigation states at a high frequency. Since these are electro-mechanical sensors, the measurements carried out could often be affected by systematic errors like measurement bias, scaling factors or non-orthogonality of the sensor triplets, and accidental errors generally due to noise.\n\nIMU can be used for the following: (i) The estimation of the position often integrated with GNSS receivers. In this case, they can determine the displacement with a double integration while the orientation takes place with three gyroscopes on the three coordinate axes. (ii) The estimation of the attitude angles, by measuring the components on the three axes. Measurements can be static or dynamic.\n\nGNSS and IMU can be integrated into the navigation board of UAV or mounted as external sensors and connected to the navigation board.\n\nUAV navigation sensors evaluation tests\n\nIn order to understand the behavior of common UAV, the investigation of the main components of the navigation system is a crucial aspect. In particular, the performance of navigator sensors (IMU and GNSS) has a great impact on the final performance of the system. To define the system precision considering different possible configurations for better management of the missions, several tests of navigation sensors (onboard and external) have been carried on. The employed system was a hexacopter that weighs about 2.2 kg including batteries, and that can lift a payload of up to 1.5 kg.\n\nThe test of navigation sensors is based on reference data extracted from topographic measurements done using a total station (TS). Two different solutions, mainly based on the same kind of approach, are proposed: (i) positioning sensor’s evaluation, aimed to define the performance of GNSS sensors, is based on the use of a single prism and a total station; (ii) angle’s estimation, designed to the evaluation of IMU performance, is based on the use of two prisms and two total stations.\n\nThe first test is focused on positioning systems. For this test, a retro-reflector target composed by three small prisms was housed on board on the UAV under the gimbal. The retro-reflector target assures a continuous auto-tracking of the total motorized station that can follow the UAV flight paths and autonomously measure both distance and angles with accuracies of 2 mm and 1 s within an operative range of 1 km. The UAV is equipped with an onboard GPS and an external GNSS receiver that acquire simultaneously the position of the drone. The tested external GNSS receiver was a Novatel OEM 615 dual-frequency (L1 = 1575.42 MHz and L2 = 1227.60 MHz) equipped with the antenna ANTCOM ID L1L2 1215 A2, which can receive GPS, GLONASS, and Galileo constellations. The drone was manually piloted in a dedicated airfield where cross flights of 200 m were performed flying at a speed of 3 m/s.\n\nAfter the synchronization, to have comparable sets of data, the track extracted from the onboard and external positioning sensor can be compared with that one obtained from the data of the total station, considered as reference. The difference between the two sets of data is used to evaluate the reliability of positioning systems considering the accuracy of the proposed methodology based on total station measurements and the differences between the two sets of data.\n\nTables 4 and 5 show the result of the analysis of internal and external GNSS accuracy, in terms of minimum, maximum and mean values with the evaluation of the standard deviation (σ) which measures the dispersion of the data. For the internal GPS, Table 4 shows the comparison between the acquired track of GPS and of the total station. In particular, the south-north-south path was used to evaluate the accuracy in the X direction and the east-west-east path for the Y direction (Table 4). The same approach was used to analyze the vertical component.\n\nPresented results demonstrate that the performance of the internal GPS receiver is consistent with a low-cost single-frequency GPS receiver in stand-alone positioning using EGNOS correction, with an accuracy of few meters, with the vertical component four times worse than the horizontal one (Bulusu et al. 2000). Furthermore, the analysis of the standard deviation shows that the acquired data are very noisy and the sensor is not, therefore, reliable. For the significant part of the geomatic applications (photogrammetry, thermal analyses, radio-frequency measurements, etc.), centimetric positioning is required. For this reason, the introduction of an external GNSS receiver on the UAV was investigated to evaluate the eventual positive effect in positioning accuracy. The storage of the GNSS receiver raw data has been realized by making a direct connection between the GNSS OEM and a dedicated Ardulog data logger. The GNSS raw data (pseudo-range and carrier phase), were recorded in a text file using a sample rate of 5. For a protection of the system during the flights, a special box was realized with the 3D printer and housed below the airframe in the gimbal. The box also houses the battery for the GNSS receiver, and two switches allow to activate the receiver and the antenna. The entire system is shielded, and a LED light is mounted outside the box to signalize when the ambiguity phase is fixed as it is fundamental that the system is initialized before beginning the flight. The external antenna was mounted on a dedicated support designed to protect the system also against interferences, and the entire system was calibrated to know the lever arm.\n\nThe data recorded by the external receiver were processed with a PPK (Post Processed Kinematic) approach (Gao and Wojciechowski 2004; Stempfhuber and Buchholz 2011) to define the UAV positions respect to a master station on the ground. The accuracy and completeness of the positioning solution through the GNSS external receiver has been assessed using the total station as a reference. The UAV position was tracked two times along a rectangular path to evaluate the position accuracy, and then, the positions estimated from the external GNSS receiver during the same flight were processed with a PPK technique considering the master station on the ground and the receiver onboard as a moving point.\n\nObtained results (Table 5) demonstrate that estimated GNSS positions follow the total station trajectory and have an accuracy of few centimeters. This is an acceptable value according to the nominal precision of the PPK positioning.\n\nThe presented test shows the good performance of the external GNSS receiver. A more detailed analysis of obtained results pointed out that higher differences between GNSS results a TS measures are referred to the first part of the test (especially for the vertical component). The cause of these is the GNSS initialization phase, the time necessary to fix the phase ambiguity. To avoid this inconvenient, some recommendations can be proposed: (i) the receiver should be turned on about 2–3 min before starting the flight and it has to stay on the initial flight point; (ii) after takeoff, UAV must stay on air on the first waypoint for a few seconds; (iii) then, the flight can be performed with a maximum speed of about 5–7 m/s; (iv) finally it is important to wait 2–3 min on the ground after landing before turning off the receiver. This strategy allows having centimetric accuracies for the entire mission.\n\nAnother aspect that has been investigated is the reachable precision of the external receiver using different GNSS constellations (Pupillo et al. 2015) and, in particular, considering only GPS and GPS-GLONASS. Results (Table 6) demonstrated that the usage of the GLONASS constellation has a strong influence on the final solution. Without the GLONASS, the estimated precision is about 40 cm. On the contrary, the use of both constellations can improve the precision to 1–3 cm. Multi-constellation antennas are more and more available, and their dimension and weight are compatible with UAV. Since their cost is now quite acceptable, and the procedure to use their data to obtain precise position is well established, in precise positioning surveys, the use of multi-constellation antennas is recommended.\n\nThe second presented test is aimed to evaluate the performance of IMU. Using the same approach of the previous test, the onboard sensors data, and a reference solution acquired from the ground were obtained and compared. In this test, the adopted strategy involved the use of two total stations and two retro-reflector targets mounted on the UAV. The retro-reflector target consists of the combination of three smaller prisms. A bar with two retro-reflector targets was installed onboard to guarantee the acquisition of the UAV position and attitude. To track the flights, two total stations (Leica Image and Smart Station) were used in the position tracking mode. One of the used instruments can also be synchronized with the GPS time by using an external receiver that can be placed on the instrument and update the total station time according to the GPS. Finally, the same sampling rate of 0.2 s was used for the two instruments. During the flights, each total station can follow one prism because of the track mode of the instrument, and it is then possible to relate the two measurements. Using the same approach used for GNSS, the test of IMU considered internal and external solutions. The adopted external IMU was a low-cost Microstrain sensor, the 3DM-GX3-35 model.\n\nThe UAV attitude during the flight and the reliability of the recorded data from the internal sensors were evaluated by taking particular attention to the compass component. This is important to assess whether it is necessary to install an external IMU to have a precise compass component. For the internal IMU, different flights (especially linear and cross) were performed to test the recorded attitude of the UAV. During the linear path, the UAV flew along the direction between the two total stations (with an angle of about 35° respect to the North) instead during the cross path the chosen direction was 0°.\n\nThe flights were scheduled using a special application developed in MATLAB able to generate a text file that contains the waypoints positions that can be managed by the navigation software.\n\nThe test is based on the estimation of the UAV compass as an angle between the two measured prisms and its comparison with the data recorded from the UAV. The different sampling rates of the two total stations and their synchronization need to be considered during the processing step. Each total station has an internal clock, but the two times are not the same, and the acquisition interval was not the same. For this reason, a specific MATLAB script was developed to process these data. The developed code is partitioned in three main steps:\n\n1.\n\nangles estimation from the data of the two total stations:\n\na.\n\ntotal stations need to be previously mutually synchronized (also according to the GPS time);\n\nb.\n\nthe coordinates of each point recorded by the TSs have to be extracted;\n\nc.\n\nthe angles between two corresponding points can be estimated;\n\n2.\n\nangles extraction from the data recorded by the internal IMU platform (that is already synchronized with the GPS time);\n\n3.\n\ncomparison between the angles determined with the TSs data and that recorded by the internal UAV platform.\n\nHere it is reported an example of the performed tests, a cross path.\n\nThe first required step was the total stations synchronization and interpolation. The data acquired by the two TSs differ in:\n\nabsolute time;\n\ninterval step between two consecutive measurements\n\nIn an ideal case, the instruments synchronization should be the following: N1(t) + bN = N2(t) where bN is the bar length in the North direction between the two prisms; however in the real case, measurements estimation uncertainties are introduced: N1(t + Δt) + bN + ΔbN = N2(t)\n\nTo align the data, one TS was considered the reference, and the data from the other one were translated and interpolated to have the measurements at the same time and interval steps. Starting from an approximate offset time, an iterative procedure was used to obtain the best fit between the two sets of data. A linear interpolation was used at this step to have the same number of measurements.\n\nWhen the two set of data were finally synchronized, it was possible to estimate the compass as the angle between two measured targets (each one acquired from a TS). The calculated result is shown in Fig. 2 (red component).\n\nData acquired by the internal sensors of the UAV are stored in the microSD in a log file. A script (gpx reader) able to read these data was written in MATLAB, and it includes positioning (from the internal GPS) and attitude information (from the internal IMU). The same synchronization procedure was applied to overlap the UAV data recorded from the internal sensors with that acquired by the TS. The TS was adopted as a reference, and the UAV data were temporally translated and interpolated to have the same sampling rate. The compass component of the UAV can now be overlapped (Fig. 2) and compared with the TS measurements. To better understand the behavior, the difference between the two data was evaluated (magenta in Fig. 2), and some statistical values were also estimated:\n\nmean = − 0.022°\n\nstandard deviation = ± 0.910°\n\nmedian = − 0.073°\n\nThe obtained results have a mean value very close to the zero with a small standard deviation, and they demonstrated that, using this UAV, the angles could be estimated with precisions acceptable for our investigations.\n\nThe use of an external IMU was also evaluated to assess if it is possible and useful to improve accelerometers, magnetometers, and gyroscopes data to enhance positioning and attitude information housing on board an external IMU platform. We made some analyses using the low-cost sensor of Microstrain, the 3DM-GX3-35 model (Table 7) because of its low weight and size.\n\nThis sensor has an internal GNSS receiver (u-blox) that allows a row metrical position and performs the synchronization of the data including accelerometers, gyroscopes, and magnetometers that can be independently acquired by the instrument, but it is not able to retrieve an integrated solution based on the loosely coupled Kalman filter (Kalman 1960). The sensor was previously analyzed by the Geomatic’s group of the Politecnico di Torino (Piras and Dabove 2016) to assess its behavior.\n\nFor our implementation on the UAV, the IMU sensor was directly connected to a mini PC installable onboard, in particular, a PicoPc (Pico83016) with Windows operating system and with the possibility to directly install the management software of the Microstrain. The whole system was installed onboard, the IMU was housed directly on the gimbal, and the antenna has been locked on the top of the UAV. To evaluate the platform were performed two different tests with the UAV with the engines off and placed on the table and during a flight.\n\nFigure 3 shows the comparison of the data obtained in the two evaluated cases.\n\nDuring the flight test, the information acquired before the flight (before the red line) when the UAV engines were turned on is easily recognizable. For all the graphs, the same axis scale is used to read the data easily and different colors represent different directions (x, y, z). The recorded data in the three directions shows a significant noise for all the IMU components. The sensor betrays the UAV vibrations due to flight movement, and the magnetic component can have large interferences from the operation of the engine. A further test was done trying to filter out this noise. In particular, through the MATLAB Wavelet Analyzer, the signal was filtered with the Daubechies 3 level 7. In the case of the two sets of data (on the table and during the flight), the accelerometers, gyroscopes and magnetometers signals were filtered, but after the filter, it has remained a clear difference between the signal acquired in static and that recorded in dynamic.\n\nAccording to these tests, we can conclude that a detailed knowledge of the onboard available navigational sensors is crucial to understand UAVs behavior and to test their performance. This need has been investigated with the development of a specific methodology to evaluate GNSS and IMU platforms, and particular flights were adopted to analyze the performance of the sensors in comparison with well-established topographic techniques. The analysis strategy employed for the onboard navigation sensors (GNSS receiver and IMU) allowed to assess the metrical position achievable through the low-cost devices installed on board. On the other hand, it was demonstrated that, if a real-time knowledge of the precise position of the UAV during the flight is not required, it is possible to use an external GNSS receiver. The processing of the acquired data was also analyzed to obtain precise knowledge of the system position along with the flight. Considering these strategies, it is possible to reconstruct the UAV position with a centimeter-level of detail, which is the required level for precise geomatics analyses and direct photogrammetry scenarios.\n\nThe use of an external IMU platform was also investigated, but the used sensors suffered too much from vibrations and interference, and it was not possible to assess improvement in the definition of the angle since it must be very well shielded and protected from vibrations to work well. This means introducing other weights, but the limited payload carried by UAV usually hampers this possibility.\n\nThe use of mounted sensors exploits UAV potential. Their payload is, in fact, the core of the system that allows their user to collect various kinds of data for further processing and analyses (Pajares 2015). In addition to sensors, there is also accessory equipment allowing the correct positioning of the acquired datasets in three-dimensional spatial coordinates (De Agostino et al. 2010). These features are mandatory when UAV data are used in conjunction with other geocoded data, and when the investigated topics deal with earth science issues (Schulz 2007).\n\nFocusing the attention on UAV’s payload, various acquisition systems, and related supporting equipment like gimbals, can be mounted on board. These sensors can mainly include the following categories: (i) digital cameras, (ii) thermal detectors, (iii) multispectral cameras, (iv) LiDAR (light detection and ranging), (v) sensors for the air quality evaluation. In engineering geology applications, the first four categories are the most used, and for this reason, they are presented and discussed in this section. The acquired payload dataset can be merged with IMU and GNSS receivers installed on the UAV to measure its position and attitude, in real-time and post-processing, along with the flight for navigation and data processing purposes (Cramer 2001).\n\nDigital cameras\n\nThe most common use for UAV is acquisition of images and videos for monitoring (Gonzalez et al. 2016), photogrammetry (Eisenbeiß 2009), filming, security (Mademlis et al. 2018), and any kind of documentation (Nageli et al. 2017), also for geological applications (Bemis et al. 2014; Giordan et al. 2018). Different categories of cameras are now available for this kind of applications: professional, semi-professional, and action cams. For each category, the lens calibration is required to ensure the quality of the final result (Casella et al. 2004; Clarke and Fryer 1998; Hemayed 2003).\n\nOne of the most critical points in the use of RGB cameras is the identification and measurement of the shooting position to perform the image orientation (Remondino et al. 2012). Nowadays, many commercial navigation systems can manage the acquisition of image and store UAV’s position (GNSS) and attitude (IMU) simultaneously (Zongjian 2008; Carbonneau and Dietrich 2017). In the post-processing phase, the GNSS position can be stored in the EXIF file of the acquired image or coupled in dedicated software. Concerning the image processing phase, the most employed technique is the “structure from motion” (SfM) (Braunstein 1990; Clapuyt et al. 2016) which allows the three-dimensional reconstruction of the surveyed object for further processing and analyses. This approach has been satisfactorily applied in geosciences and engineering geology as well (Westoby et al. 2012; Lucieer et al. 2014; Mancini et al. 2013; Ryan et al. 2015).\n\nThermal detectors\n\nThermal detectors are a class of sensors capable of remotely measuring the object’s temperature. They provide, as a result, an image with temperature values stored in raster’s digital numbers (Cetas 1978). The process, defined as thermography, is based on the acquisition of the thermal infrared radiation of the electromagnetic spectrum (1.3–15 μm). Thermal imagery is then represented in grayscale, from white depicting areas emitting maximum radiation to black at the opposite end of the thermal scale. To ease image interpretation or highlight particular temperature intervals, false colors could be suddenly added.\n\nOften, thermal detectors are coupled with an RGB camera with the same field of view to allow a better interpretation of acquired imagery by adding the visible bands to the thermal one.\n\nThe uses of these sensors on UAV are various (Vasterling and Meyer 2013), ranging from search and rescue missions (e.g., Rudol and Doherty 2008) to precision agriculture (e.g., Turner et al. 2010) and earth science applications, as in Fig. 4, or volcanology (Nishar et al. 2016; Amici et al. 2013).\n\nConcerning currently available sensors, the following is a non-exhaustive list of manufacturers: DJI, FLIR Flytron, Thermoteknix, Yuneec, Workswell WIRIS. FLIR is a renowned manufacturer producing a vast array of thermal cameras, including UAV-borne ones—thermal or coupled with a visual one. They are also provided with preassembled kits, usually featuring DJI drones. Several companies offer this kind of products as DRONExpert or DSLRPros. DJI itself produced a dual sensor (thermal and RGB) featuring several advanced functions to maximize thermal survey productivity. Workswell WIRIS creates an integrated system composed by a thermal camera, RGB camera, and a built-in control unit.\n\nMoreover, the upper limit of measured temperature range could be extended, on request when purchased, to 1500 °C. Workswell also provides ready-to-fly kits composed by their system and a drone. Flytron manufactures, based on a FLIR sensor core, a compact and low-cost thermal sensor allowing small drones to include in their payload a thermal camera. Yuneec, on the other hand, proposes an integrated kit including, in addition to the thermal sensor, a low light visual camera and the gimbal. Lastly, Thermoteknix offers a compact, new generation thermal camera featuring a shutter-less technology allowing an uninterrupted view of the target and the removal of moving parts. Thanks to these characteristics, it is used in security applications, including counter UAV drones (C-UAV) as a part of the targeting equipment. Table 8 summarizes some features of the described sensors.\n\nMultispectral cameras\n\nIn addition to RGB cameras, multispectral ones can capture image data in the non-visible sector of the light spectrum. They are equipped with an array of sensors, each one acquiring a specific wavelength interval. In some cases, the intervals mimic those featured by well-known satellite missions mounting multispectral sensors. To perform multi-band analyses and indices computation also visible bands are acquired. If the camera is dedicated to a particular task, only part of the visible spectrum could be considered. On the other hand, general-purpose ones are capable of acquiring all of the visible bands (i.e., RGB).\n\nCameras are also connected to external components which allow the correct positioning of the acquired images, like GNSS antennas and calibration sensor detecting the incident solar radiation during image acquisition thus correcting each one, according to the sunlight influence. Concerning sensor calibration, cameras are often provided with a calibrated panel, which has to be scanned at the beginning and the end of the flight. The panel acquisition ensures a more accurate generation of the data by taking into account the incident light conditions during the UAV mission.\n\nThe result of a multispectral survey is exploited, particularly, by the computation of indices that are linear combinations of bands processed by raster algebra (Shapiro and Westervelt 1994). Among the various indices proposed in the literature, the most used is the NDVI (normalized difference vegetation index) obtained by calculating the ratio between the difference and the sum of NIR and red bands. NDRE (normalized difference red edge) is similar to the previous one, and the only difference is the Red Edge band use instead of the red band (Li et al. 2013). Both of them are used in order to spot differences in vegetation health status (Fig. 5) and soil water availability (Eitel et al. 2010), also for inferring slope failures and instability triggers as in satellite remote sensing application of the same methodologies (Fiorucci et al. 2011; Mondini et al. 2011; Guzzetti et al. 2012).\n\nManufacturers offer different sensors, featuring various characteristics and acquired bands. Sentera offers multiple solutions concerning multispectral cameras, the most advanced is the multiSPEC 4 with six bands (RGB + multispectral) and automatic computation of vegetation indices (NDVI, NDRE). Sentera also proposes a ready-to-use version of the sensor capable of yielding RGB and vegetation indices or only vegetation indices as results. The camera is provided as it is or included in a ready-to-fly kit compatible with various drones with fixed or rotary wings. Sequoia, manufactured by Parrot, is supplied with four bands and an RGB camera; it is also equipped with GPS, IMU, and magnetometer, so it is entirely autonomous and compatible with any drones. Tetracam produces the lighter sensor, called ADC Micro, allowing its deployment also on small UAVs. Its bands are equivalent to Landsat Thematic Mapper bands TM2, TM3, and TM4. MicaSense manufactures RedEdge sensor, which, in addition to the RGB bands, captures Red edge and near-IR. Lastly, AIRINOV multiSpec 4C acquires four different spectral bands: green, red, red edge, and NIR. They are corrected in real-time by an onboard lux meter; the recording of date, time, and position is available for each shot. Table 9 summarizes some technical characteristics of the listed sensors.\n\nLight detection and ranging\n\nLight detection and ranging (LiDAR) sensors are the most complex and also valid for the acquisition of a 3D model of the studied area. These devices can be very helpful during the night or in low light conditions, with clouds or shadows and especially in dense tree-covered areas. LiDAR is an active sensor that emits a signal to the target object; then, it measures the time of flight and the intensity of the returned signal (Baltsavias 1999; Wehr and Lohr 1999).\n\nThe system is not only composed by the laser emitter but also equipped with a receiver that detects the reflected energy of the pulse, and its positioning (IMU) and navigation (GNSS) systems. From the late 1990s (Miller and Amidi 1998), many different LiDAR sensors (firstly experimental and then for commercial purposes) specially designed for UAV applications were developed.\n\nPrimary limitations on these sensors are naturally represented by their weight, their dimensions, and power consumption. Nowadays, there are various LiDAR models commercially available for use on a UAV system having suitable load capacity in terms of payload and dimensions. The first applications of these sensors are forestry and vegetation mapping (Sankey et al. 2017; Sankey et al. 2018; Guo et al. 2017) but, according to “traditional” LiDAR potentialities (among others Lato et al. 2009; Dewitte et al. 2008) in engineering geology, also the UAV-borne version of LiDAR is expected to provide encouraging results.\n\nVarious systems/sensors are available with different features and capabilities. Leddar Tech provides a compact solution equipped with a solid-state fixed light source and eight independent detection elements allowing multi-object measurement. Velodyne, renowned for autonomous vehicle equipment, offers different lightweight rotating head sensors allowing 360° surveys. Riegl markets a long-range system allowing an operating flight altitude of up to 350 m AGL.\n\nIntegrated systems are also available, like the one provided by Routescene. It is a ready-to-use system, which combines LiDAR, RTK-GNSS, inertial sensors, and control components in a unique device. Velodyne LiDAR is also included in two other solutions like Yellowscan and Geodetics, and it is integrated, like the previous one, with GNSS, inertial, and control units. Table 10 shows the main features of six different examples of systems that can be adopted by UAV.\n\nAlthough similar in sizes and weight, scanning systems examined have different characteristics in terms of global performances, absolute ranging, and scanning rate. In particular, is it possible to divide them into two main categories: (i) compact sensors with approximate ranging between 40 and 100 and scan rate ranging between 50 and 300 KHz, weighting nearly 1 kg, and (ii) advanced sensors, with multi-pulse and full-waveform technology with a weight of 4–5 kg, ranging between 100 m (for corridor and power lines applications) and 900 m (aerial mapping).\n\nIn the second category, at the current date, is it possible to include only the RIEGL VUX, in the two versions: UAV (primary lower ranging and scan rate) and LR (long range). This sensor differs from those belonging to the first category from this concept project, comparable with a full-scale aerial LiDAR sensor, and mounted on an aerial vehicle with a pilot, but made compact and suitable for use with UAVs.\n\nHowever, the two main problems of this instrumentation are its weight, which in fact constrains the type of aerial platform that can be used, with not negligible consequences on flight regulations for this type of aircraft (in particular total takeoff weight); and its price, which is more than ten times higher than other solutions represented by the first category.\n\nIt is evident that this system has a higher level of performance in comparison with other types of solutions but it remains, at least from a psychological point of view, more than one doubt about safety and reliability factor for the installation of a payload of the cost 20 times greater than the aerial vector that carries it. This sensor results in almost all cases installed on a rotating blade manned vector.\n\nAt the moment, these systems have a strong limitation, represented by the UAV flight autonomy, usually represented by a multirotor, which have a fly range of no more than 25–30 min. A possible solution could be the use of fixed wing solution featuring a greater flight autonomy.\n\nIn this section, we present a synthesis of the best practice for an excellent acquisition of a photo sequence that can be processed using the structure from motion applications. The main goal of this section is the introduction of most essential aspects that can be considered for proper use of UAVs, in term of operative rules, regulation, data collection, and data processing.\n\nSometimes, users are often convinced that the use of UAV is quite easy, practically automatic and that the data collection strategy is secondary to obtain valid and precise photogrammetric products.\n\nIn the last 20 years, a major revolution has taken place in microelectronics, battery and camera technology, and global positioning, plus a quiet revolution in photogrammetric software and its availability, based on the theory of “close-range” photogrammetry (Cooper and Robson 2001). This recent evolution has fueled developments and enabled almost any type of UAV-mounted camera to achieve reliably accurate results in terms of 3D surface models and 4D monitoring. In practice, results from UAV photogrammetry can be spliced smoothly with LiDAR-based techniques, both terrestrial and airborne, and satellite-based techniques, and are increasingly used in tandem to produce DTM (Hobbs et al. 2013; Tong et al. 2015; Peppa et al. 2016; Wilkinson et al. 2016; Mateos et al. 2017). Of course, there are limitations to the use of UAV, primary among which are weather and legislation. The former is not exclusive to UAV surveys but the latter definitely. Regulation and law for UAV is not a subject that is covered in detail in this paper as it is complex, internationally varied, and ever-changing (Stöcker et al. 2017). Current technological improvements include greater endurance, payload and range, collision avoidance, and increased sophistication of onboard IMU (UST 2018). Context-based flight controls are also emerging; that is, the UAV use of elements of Artificial Intelligence (AI) to control flight parameters onboard according to changes in its environment. Terrain recognition, either from laser scanner or from photogrammetry, combined with IMU data, provides a form of “dead reckoning” navigation and safeguard against GPS outages. This is already available in some terrestrial laser scanner systems for indoor use, but will also be applied to confined or other UAV scenarios where GPS is absent. Some requirements of landslide surveys are summarized in Table 11 and the effects of some recent and (likely) future developments given in Tables 12 and 13.\n\nRegulation\n\nIn a built-up or air-trafficked area, a UAV survey is likely to be regulated internationally (International Civil Aviation Organisation, ICAO) and/or nationally (national aviation authority) (Stöcker et al. 2017) which might include, for example, a “Permission for Commercial Operations” (PfCO), a “Congested Area Operational Safety Case” (CAOSC), a “Private Impact Assessment” (PIA), and insurance cover. In any event, even where not mandatory, some form of site assessment is advisable and, where applicable, contact with air traffic control (ATC), police, emergency services, etc. Besides, an assessment of weather and likely flying conditions should be carried out. These levels of regulation tend to mitigate against rapid ad-hoc UAV surveying of the kind that might be deemed necessary to achieve an effective geohazard response, for example. However, for a routine survey, such preparations would be considered advisable and most government and commercial organizations carrying out geo-surveys will have formalized health & safety procedures covering all forms of fieldwork. At the moment, each country has a different regulation, but the European community is going to prepare a European Regulation. The goal is to have a “mandatory regulation” in June 2020.\n\nOperative rules and planning\n\nOne of the most crucial activities that should be considered before a survey is flight planning. Nex and Remondino (2014) listed several essential elements that compose the typical workflow for the acquisition and processing of images. The published workflow is dedicated in particular to the acquisition of photo sequence that can be processed using SfM algorithms. Similar approaches can be adopted for different acquisition processes.\n\nThe most important parameters considered in the workflow that is fundamental for a correct definition of the flight planning are as follows: (i) flight parameters: ground sample distance (GSD), area of interest, camera information, and flight goals; (ii) characteristics of the available UAV: UAV platform (batteries duration, maximum distance from the ground control station) and autopilot; (iii) additional parameters like camera calibration, and availability and distribution of ground control points (GCPs).\n\nThese elements contribute to the definition of the mission planning that is propaedeutic to the acquisition of images. After the acquisition of the photo sequence, a process of image triangulation allows the generation of the digital surface model (DSM) and other products like orthoimages, 3D modeling, and the extraction of features. James et al. (2017) made a detailed analysis of how it is possible to reduce the number of GCPs, which often requires a strong field survey effort and the importance of the proper choice camera concerning the final resolution and quality of the DSM.\n\nEven if the use of commercial UAV could seem very simple and quite friendly, it is fundamental to apply some primary mode of operation and to be able to realize correct planning of the flight, to avoid collecting useless dataset. First, it is mandatory to do an investigation of the site before the flight. Aerial or satellite images are not sufficient (and updated) to detect some critical points or elements. After the decision of the UAV survey, it is essential to select the best UAV typology. As previously mentioned, the two most diffused UAV categories are multirotor and fixed wings. As suggested by Giordan et al. (2015), the topography of the target is a good point for the identification of the best UAV configuration: for steep areas (like rock walls or infrastructures), the best solution is usually a multirotor coupled with oblique images acquisition; for gentle and more extensive slopes, the best solution is often a fixed wing with nadiral images acquisition. Once that the typology of UAV has been identified, it is fundamental to keep into account the actual condition of the site, and, in particular, it is mandatory to:\n\n1.\n\nVerify the possible authority restriction on this area (e.g., a location close to the airport), to ask permission (if it is possible) or not working there. Each country has different rules; therefore, it is fundamental to verify the specific one.\n\n2.\n\nVerify the presence of electric lines or pylons or other aerial furniture. In some case, it is impossible to estimate the height or the distance between this obstacle and UAV\n\n3.\n\nIdentify the correct surface where takeoff and land. This area depends a lot by the category of used UAV. If the selected UAV is a multirotor, the required space is limited, because it is possible to realize the VTOL (vertical takeoff and landing). Using a fixed wing, it needs a broader area (at least 20–25 m), including a free space about the runways, to have the takeoff and landing ramp.\n\n4.\n\nCheck the adequate GNSS visibility, both in the upper part of the flight and on the ground, to avoid to lose the GNSS signal during the landing (very critical condition) or in the takeoff (operability is not allowed);\n\n5.\n\nControl the presence of vegetation and other possible obstacles;\n\n6.\n\nVerify the presence of potential electromagnetic interferences, both for the GNSS signal and for the UAV communication system;\n\n7.\n\nCheck the morphology of the area to survey, considering possible high slope variation or other specific issues.\n\nAlso, a critical operative step is to verify the weather condition, and to have a continuous weather forecasting bulletin, avoiding being surprised by critical visibility condition (e.g., fog) or, in a worst-case, a rainstorm. Nowadays, there are a lot of APP for smartphone (e.g., Avia Weather - METAR & TAF), where the METAR (METeorological Air Report) is read and the main information is extracted, allowing working with the official meteorological report, generated by the Aeronautic Service. After that, it is possible to start the flight planning. This planning depends on the aim of the flight. In some case (e.g., indoor positioning or GPS not available), the flight is entirely manually made. In all other conditions (where the GPS is available), it is possible to realize an automatic flight. If the target of the flight is the acquisition of an image sequence for photogrammetry purposes, it is fundamental to shooting the images respecting the photogrammetric parameters imposed by the user. Knowing the proprieties of the digital camera (focal length, resolution, pixel size, etc.), it is possible to planning the flight, in order to respect the scale factor of the frame, the overlapping between the frames (longitudinal and transversal) and the GSD (ground sampling distance), that is the distance between two pixel in the object space. Using a traditional nadir acquisition, the schema of the flight is presented in Fig. 6. According to Fig. 6, the scale factor of the frame is defined as:\n\n$$ \\frac{H}{c}=\\frac{L}{l}={m}_{\\mathrm{b}} $$\n\nwhere B is the distance between two shooting; H, the relative flight height; c, the focal length; A, the distance between two strips; L, the size of the frame in the object space (ground); and l, the size of the frame in the image space\n\nUsually, the scale factor and the GSD depend on the precision and quality of the final products. In the nadir condition, the range of the frame overlapping could be 60–80% in the longitudinal direction and 50–80% in the transversal direction.\n\nThe minimum values of these ranges are used when a photogrammetric procedure is involved, where the collinearity equations are adopted for plotting the points (Kraus 2007). In opposite, it is better to improve the overlapping when a computer vision approach (e.g., structure from motion) is employed (Micheletti et al. 2015). In this case, the plotting is made with automatic feature extraction procedures, and the suggested value of the overlapping can achieve the 80% if the surface is characterized by a low contrast like snow or sand (Agisoft 2018).\n\nThe planning could be made or by the user, knowing precisely the relation of the photogrammetry or using some tool.\n\nUsually, the height of flight is fixed not considering a real elevation model. In some case, flight planners are able to consider some global digital elevation models and define a flight plan with a constant distance from the ground. This is important in particular in steep areas, where the value of GSD can be very different is the flight height is constant, and the surveyed area has a great difference in altitude.\n\nRecently, there is a new approach adopted for photogrammetry applications, which is based on the acquisition of oblique images (Fig. 7). In this case, the planning has to be completely different, and the traditional tools are not more available. The same problem arises when the image acquisition is made along a vertical façade (e.g., rock façade), where the flight is manually performed using the experience of the pilot. Moreover, the acquisition of vertical sectors often is affected by errors in the definition of the height, which is not perfectly guaranteed and stable due to the position quality estimated by the GNSS receiver. The oblique acquisition is typically based on the use of multirotor.\n\nAfter the data acquisition using the UAV, images, and GCPs are used for generating several products as digital surface models (DSM) and orthophoto. Typically, there are two possible approaches for data processing: photogrammetry based or computer vision based. Actually, the high diffusion of software based on Structure from Motion (SfM) algorithms has increased the computer vision approach that is presented in the “Data processing and 3D model generation” section.\n\nGround control points\n\nThe use of Ground Control Points is an essential element that could have a substantial impact on the accuracy of the SfM-based DSM (James and Robson 2012; Turner et al. 2015). GCPs are points of known coordinated that can be clearly recognized in the photo sequence acquired by UAV. These points can be elements present in the field and/or artificial targets placed in the surveyed area before the UAV flight. The position of GCPs is acquired using high accuracy topographic methods like GNSS or total stations and then identified in the photo sequence during the SfM procedure (Harwin and Lucieer 2012).\n\nThe use and the number of GCPs depend on the required final accuracy of the positioning of the DSM and the quality of the UAV positioning system. As said before, it is possible to have on the UAV a GPS only or a multi-constellation receiver, but it is important to evaluate the combination between receiver and antenna, in order to define the final performances. In some cases, an external GNSS receiver can be installed and used to collect the raw data of the UAV path. This solution is adopted for direct photogrammetry applications (Turner et al. 2014; Eling et al. 2015; Mian et al. 2015; Gabrlik et al. 2018), where is required a high-resolution GNNS on board that reduce the importance and the impact of GCPs on the final accuracy of the DSM. The number of GCPs and their position is hard to define a priori, but some simple operative suggestions can be useful for proper distribution of these points: (i) follow the limit of the area of interest, (ii) insert other GCPs inside the area of interest considering also the elevation differences of the area. Other critical considerations that have to be evaluated during the deployment of GCPs are, according to James et al. (2017): (i) the importance of datum alignment to gravity (the distribution of targets can be carefully considered in particular if the final model can be used for modeling gradient-sensitive processes like, for example, rainfall or runoff models), (ii) the presence of vegetation at the scale of the physical control targets (that could hamper the identification of targets on images), (iii) the absolute 3D positioning.\n\nAnother important element that should be carefully considered during the definition of number and position of GCPs is the real effort that the deployment and survey of these points required. Nex and Remondino (2014) proposed an evaluation of the time effort in a typical UAV-based photogrammetric workflow. The time effort evaluation proposed by Nex and Remondino (2014) is as follows: flight planning, 5%; image acquisition, 20%; GCPs field measurement, 15%; image triangulation, 15%; DSM generation, 25%; ortho mosaicking, 10%; feature extraction, 10%. Nowadays, working with the traditional photogrammetry the time usually required for the survey of GCPs is twice or more the time necessary for the UAV survey. This element should be carefully considered because the deployment of targets has to be done before the flight, and this activity can constrain the UAV flight activity that often should be done in the central part of the day to limit the influence of shadows.\n\nTypically, it is possible to have three kinds of GCPs: natural, artificial, and coded. First ones are “natural” points which are easily detectable in the images, and their coordinates can be measured by a topographic survey (e.g., total station or GNSS). Usually, these points are corners, artifacts, pedestrian crossing lines, some natural spot, and similar. As a best practice, each GCP needs to be well defined, and it means to select a point and not a blob or an ambiguous area.\n\nA weakness of this kind of GCPs is that not always it is possible to find some suitable points and the quality of the georeferencing could be low with respect to the use of artificial GCPs. Artificial marker (e.g., plastic or wooded panel) can be placed on the terrain and satisfy the required geometry of the distribution of GCPs. Using artificial marker, the geometry and the center is perfectly defined, and it can be correctly measured with high accuracy. In this case, it is very important to verify the color combination, because there is the risk to have a “pixel saturation” effect in the image, due to the white color.\n\nSince a few years, artificial GCPs have been replaced by “coded” panel, such as artificial support where the top is covered by a special design, where is possible to use the code with a purpose to include some properties (e.g., name, code). In Fig. 8, codified markers are shown.\n\nData processing and 3D model generation\n\nThe literature devoted to the use of UAV and the post-processing procedures of a “typical” dataset composed by a photo sequence is very vast and variegated. Just to cite some more representative papers, Westoby et al. (2012) published a relevant article for the use of structure from motion in geosciences; Nex and Remondino (2014) published a useful review of the use of UAV for 3D mapping, and James et al. (2017) described how it is possible to optimize the structure from motion process.\n\nThe field of computer vision has evolved, allowing the human-level capability in the extraction of information from image data. There are many and diverse applications of computer vision since much of human experience are associated with images and with visual information processing.\n\nNowadays, the most used solution for UAV image sequence process is based on the structure from motion (SfM) algorithms. A typical SfM process workflow can be found in many articles such as Turner et al. (2014) and Ajayi et al. (2017). A full description of how the structure from motion works is out from the scope of this manuscript, which is aimed to presents the principal elements of the procedure and some operative suggestions. The number of software that are able to acquire the photo sequence and process the available data are progressively increased in last years and now are available both freeware applications and commercial solutions. The most complete software have a detailed guide that describes the sequence of processes that starts from the camera calibration and the image orientation, and that continues with the image matching technique (Westoby et al. 2012).\n\nWith an iterative procedure, this software is able to reconstruct firstly a sparse point clouds and then a dense one that is generally preferred in case of terrain/surface reconstruction. After, the dense point cloud could be interpolated, simplified, classified, and finally textured for photo-realistic visualization (Nex and Remondino 2014). The photo-realistic representation is one of the most relevant results of SfM for engineering geology applications that, for example, can be used for a bedrock discontinuity analysis (Menegoni et al. 2019). Another significant result of the SfM procedure is the orthophoto generation of the surveyed area. A high-resolution image of the studied area is fundamental in many applications like, for example, the study of landslides (Peppa et al. 2017; Fiorucci et al. 2018a, b; Cignetti et al. 2019), rivers (Tamminga et al. 2015), or coastlines (Nikolakopoulos et al. 2019).\n\nData processing could be based on GCPs or, in the most recent cases, working with direct photogrammetry approach, where the position and orientation of the camera are known, and it is directly possible to create the block. Nowadays, there are already on the shelf some UAV that are able to realize the direct photogrammetry, because they are able to synchronize the shutter with the GPS time and to collect the raw GNSS data, with the purpose to realize the data processing or even to directly work in RTK.\n\nEven if direct photogrammetry approach is available, it is essential to know some milestones:\n\n1.\n\nGCPs are still fundamental because they allow having better control of the quality of the final model in terms of precision and accuracy; it is possible to reduce the numbers working with direct photogrammetry, but they are still essential to verify the quality and to correct some local deformation.\n\n2.\n\nRTK is available even for direct photogrammetry, but the basic of RTK positioning is still valid; therefore it is important to verify the datalink connection and the and the distance between master and rover;\n\n3.\n\nRTK navigation is not required; hence it could be sufficient to store the raw GNSS data for data processing and then use a post-processing approach for the acquisition of high-precision images acquisition points;\n\n4.\n\nOn the shelf, there are several commercial solutions, but the cost of these systems is not cheaper considering professional solution where the internal GNSS data could be analyzed and processed.\n\nAdditional remarks\n\nIn engineering geology, high-resolution topographic reconstructions of determined area are probably one of the most common uses of UAV. That is due to the limited cost of small commercial UAV equipped with a high-resolution photo camera. The section also proposed a selection of papers that can be used by readers to improve the knowledge of these aspects, which are fundamental for a correct reconstruction of a topographic model. Additional necessary steps (e.g., battery storage and charging, UAV maintenance) are not mentioned but they are vital aspects to be considered to work in a safe condition and to obtain the best result. The last comment is required considering other natural issues like birds attack. It seems funny, but in some wide-areas, it is possible to be affected by a predator attack as eagle, buzzard or similar birds. Usually, they want to protect their territory by the enemy and unfortunately, the UAVs (typically small fixed wings) are detected as “enemy” and then attacked.\n\nThe International Programme on Landslides (IPL) declared in Kobe, Japan, in 2006 that “strengthening research and learning on landslides and related earth system disasters for global risk preparedness” was a key objective and will be carried forward to form the “Kyoto 2020 Commitment” (Sassa 2017). The important study of landslides has fully embraced process understanding and new technologies, including LiDAR (light detection and ranging) and UAVs (unmanned aerial vehicles), in particular, small UAVs (< 20 kg), to good effect internationally, particularly in the last 30 years. These technologies have transformed the capabilities of engineering geologists, mapping geologists, engineers, and researchers.\n\nFor the last two decades terrestrial LiDAR scanning (TLS), or equivalent ground-based radar systems, have been available to survey landslides and other geohazards, remotely, allowing accurate Digital Elevation Models (DEM’s) of the ground surface to be produced from point clouds (Miller et al. 2007; Hobbs et al. 2010; Boon et al. 2015). Vegetation can be “stripped” from 3D datasets to reveal stunning high-resolution models of the landslide beneath; in many cases, this includes landslides previously undetected and subtle features within and beyond known landslides. From these data, displacements and volumes can be calculated (Quinn et al. 2010; Hobbs et al. 2013; Chesley et al. 2017). Further, more recently, it has been possible for surveys made by Unmanned Aerial Vehicles (UAVs) or Unmanned Aerial Systems (UAS’s) to replicate some of the capabilities of large and expensive aerial and satellite platforms. LiDAR scanners themselves, with the addition of hyperspectral sensors, can now be added to the UAV’s onboard facilities. This section takes an overview of developments and the consequent advantages for those studying, mapping, and surveying landslides. The development history of UAV, in general, is described in Colomina and Molina (2014) and its use in other spheres of geological study in Bemis et al. (2014), Tong et al. (2015), Wilkinson et al. (2016), Jordan et al. (2016), Chesley et al. (2017), Nieminski and Graham (2017), Nikolakopoulos et al. (2017a), Madjid et al. (2018), Nikolakopoulos et al. (2018), and Nikolakopoulos et al. (2019).\n\nIn many ways, it can be argued that the small instrumented UAV is the perfect tool for the assessment of landslides, where the terrain may be remote, hazardous, and inaccessible except on foot or entirely out of bounds. The UAV photogrammetry tool, where point clouds and 3D models can be produced from overlapping photography, meets this requirement head-on, but this has only been truly the case very recently. In its simplest form we now have a small, radio-controlled, electric rotary or fixed-wing aircraft fitted with a small, but high-resolution, camera easily capable of achieving a digital elevation model (DEM) resolution of between 5 and 25 cm (Madjid et al. 2018). This has developed from a simple “eye in the sky” to a sophisticated photogrammetric tool but, crucially, one available to professional and non-expert alike (Niethammer et al. 2012; Lucieer et al. 2014; Stumpf et al. 2014; Eltner et al. 2015; Peppa et al. 2016). Landslides come in a variety of forms and states. They can be large or small, inland or coastal, active or inactive (Hungr et al. 2014). There have been many instances, particularly on linear infrastructure such as rail, where an apparently small, active landslide has been investigated only for it to be later identified as part of a much larger, and possibly more hazardous, landslide. For this reason, ground investigations and remedial works applicable to the “small” landslide may turn out to be totally inadequate for the “large” landslide of which it is part. For this scenario, an early UAV survey could be vital in revealing the “big picture,” at least in the absence of any other “desk study” information.\n\nExamples of landslides studies in the UK using UAV\n\nLandslides in the UK tend to be driven by rainfall, both amount and intensity (Forster and Culshaw 2004; Pennington et al. 2015; Uhlemann et al. 2016). This can also apply to coastal cliffs, but with the additional factor of marine erosion (Poulton et al. 2006). The ability of geological formations to cope with water is a key factor. More permeable rocks/soils are able to accept more water than less permeable ones but they may also result in more rapid landslide triggering depending on the mechanisms involved. Slopes in low permeability rocks/soils, in particular clay-rich ones, may tend towards instability over many decades. This includes man-made slopes (e.g., cuttings and embankments) where the method of construction and the drainage regime are also important.\n\nThe distinction between “active” and “inactive” states can be difficult to determine during early investigations. In some cases, for example, where an active landslide poses a chronic threat, a monitoring regime may be needed to determine which parts are active, how the activity is progressing and what effect this is having on the overall hazard; and also to monitor the response to remedial measures. Such a regime can also aid the understanding of landslide mechanisms and their complexity. Again, a UAV survey may be the ideal solution here or, at least, an important part of the solution. Geo-registration of each survey in a landslide monitoring program is vital to compare individual surveys and calculate changes. Without good quality onboard GPS some form of ground control is required (Stumpf et al. 2014; Peppa et al. 2016). A landslide is traditionally mapped, characterized, and zoned using a small-scale, detailed “geomorphological” map; the starting point of which is some form of terrain model combined (in the last two decades) with digital input in the field via tablet PC. These can now be produced rapidly, automatically and remotely by uploading large numbers of UAV photos to proprietary software packages (Fig. 9).\n\nA large number of photographs taken from a wide variety of viewpoints is uploaded. Specialist “metric” cameras are no longer required, and everyday digital cameras are suitable. The result is a convincing rendition of the ground surface in the form of a colored “point cloud.” Point clouds are the “bread and butter” of terrestrial LiDAR surveys (TLS) and while the results of UAV photogrammetry are not equal, at least on paper (Wilkinson et al. 2016), to those of TLS (all other factors being equal) both outputs can be combined following processing, as indeed they can with full-scale (high-altitude) airborne LiDAR. It is reported that a combination of TLS and SfM (using both terrestrial and UAV platforms) provides the best result in rock slope stability surveys when linked to an independent survey control network (O’Banion et al. 2018). The coloration of the data (true RGB) itself adds hugely to the value of the survey for a geologist or geomorphologist, as this aids visualization and the identification of features. These factors amount to a powerful visualization and measurement combination when applied to landslide surveys.\n\nUAV-mounted LiDAR has also entered the public domain in the last 5 years. This is a desirable option mainly due to its 3D capability to “strip” foliage using the 3rd laser return to see the ground beneath and hence produce a DTM. However, it is very expensive; currently requiring a powerful (> 20 kg) UAV platform and subject to additional national restrictions or outright bans worldwide. In fact, the cost is currently higher than conventional TLS. Of course, technology is moving rapidly and these, and other, tools will become commonplace in the very near future; for example, multispectral and environmental sensors, some of which will be suitable for aspects of landslide surveying. Some multispectral sensors can be used for detecting minerals and water and for distinguishing rock types (Madjid et al. 2018); a potentially useful capability for landslide investigations and geological investigations more widely (Quinn et al. 2010). “Green” LiDAR has also been developed for its ability to “see-through” water for bathymetric surveying. In the UK, much of the land has been deforested for agriculture. The remaining areas of woodland are often found to contain previously undetected landslides, particularly on escarpment slopes (this, in turn, adding to the unsuitability for farming) such as shown at the British Geological Survey “landslide observatory” at Hollin Hill, North Yorkshire (Fig. 10).\n\nIn the UK many landslide boundaries match woodland boundaries. Currently, UAV photogrammetry is incapable of “stripping away” tree cover as each raw image is, by definition, 2D (Bemis et al. 2014). However, the level of detail already available to LiDAR is increasingly available to UAV photogrammetry and Structure from Motion techniques. Overall images of 3D models of the unwooded part of the landslide at Hollin Hill are shown in Fig. 11 and detail of the active backscarps in Fig. 12.\n\nThe use of UAV images for coastal landslide surveying and modeling at the British Geological Survey’s “coastal landslide observatory” on the Holderness coast of Yorkshire (Hobbs et al. 2020) is shown in Figs. 13 and 14. The results are fully compatible with, and complementary to, TLS survey results. One approach is to use TLS for the overall survey and UAV photogrammetry for infilling shadow (obscured) areas or for areas where greater detail is required. If a larger area is to be covered then the opposite approach may be more suitable.\n\nThe question of UAV photogrammetric accuracy has been examined, in the context of an active landslide by Peppa et al. (2016) and rock slopes (O’Banion et al. 2018), and for outcrop surveying by Wilkinson et al. (2016). The former was located at the BGS’s “landslide observatory” at Hollin Hill, North Yorkshire, UK, where the authors described the accuracy as “acceptable for landslide assessment.” Others have successfully used UAV for time series monitoring of similar landslides (Lucieer et al. 2014; Turner et al. 2015). This is an important consideration because landslides occur in a wide range of scales and behaviors (Hungr et al. 2014).\n\nLandslides which consist of unsaturated soil or weak rock (and often both) tend to feature large-scale movements (often on moderate slopes) which can be slow-moving and non-catastrophic, whereas landslides consisting of strong rock tend to undergo small deformations before catastrophic failure (often on steep slopes). However, it could be argued that where large deformations are involved high-accuracy (geodetic-quality) surveys are neither necessary nor cost-effective. The same argument could be applied to emergency situations where accuracy may be a secondary factor in either response or outcome. Nevertheless, using a network of ground control points (GCP’s), an accuracy was reported in terms of a “real terrain change equal to 9 cm” (Peppa et al. 2016).\n\nChallenges of using UAVs for landslide surveying\n\nRecurring problems encountered in landslide surveying with UAVs include the following:\n\nRegulation: national regulatory bodies have struggled to keep up with developments (Cracknell 2017) but are likely to restrict or even prevent UAV surveys in some countries. The international regulation situation is changing and there have been moves to clamp down on civilian use of drones. Usually, there is a requirement for commercial users to have completed a training program (Cracknell 2017; Cunliffe et al. 2017). The European Union (EU) has committed to introducing new regulations by 2019 (Dron 2017).\n\nSoftware licenses: these can be expensive and, at the higher end of geodetic-quality surveying, almost prohibitively so; particularly where complex processing and combinations of software packages are required, and also where multiple “seats” are involved. However, new generations of SfM software, in particular, are reducing the cost and complexity of image processing.\n\nWeather: small and micro-UAVs are usually incapable of operating in severe weather. However, many small UAVs can now deal with “TLS-tolerant” weather. The wind is the main problem for platform safety and camera stability; in particular, gusting wind. Precipitation, fog, and mist are also included, partly by virtue of damage to electronics and moving parts, but also obscuration of the landslide itself.\n\nComputing: UAV photogrammetry may occupy several hours of processing time, depending on survey size and laptop power. Nevertheless, the same can be said of TLS.\n\nAdvantages of using UAV for landslide surveying\n\nOf course, problems aside, there are many advantages to the use of UAV in landslide surveys. These include the following:\n\nPortability: many modern small and micro-UAVs can be back-packed to site and hand-launched and retrieved. This is an important consideration when trekking, for example through jungle, bog, or mountain, to reach a remote landslide (packing cases and launch ramps not needed).\n\nRapidity: the ability to move into a potentially hazardous area and out again quickly, having assessed the situation and completed the survey. This is particularly useful in the case of landslides involving infrastructures such as road, rail, pipelines, and transmission.\n\nOpportunism: this is really the combined effect of portability and rapidity. A cross-country expedition of several days or even hours is likely to benefit from the ability to deploy at any point and short notice. For example, colored point clouds of landslides often reveal subtle features more effectively when photographed in sunny conditions; particularly with a low sun angle. Also, there are distinct advantages to being able to repeat a survey the same day, for example, if there are problems with visibility. This may not be possible with full-scale aircraft in remote locations.\n\nProximity: a terrestrially deployed UAV survey can have an advantage over an equivalent full-scale (high altitude) airborne survey by virtue of its proximity. Rather than a blanket coverage with an average resolution, a targeted survey with a more detailed resolution can be achieved either by “loitering” over areas of interest (rotary) or by flying at lower altitude and speed (fixed wing). Satellite-borne remote sensing methods tend to have a oblique line of sight which may be unsuitable for cliffs and escarpments. Proximity also allows expert local observations to be made to aid interpretation of the survey results.\n\nDataset size: the size of the datasets (raw + processed) is typically modest compared with equivalent TLS surveys; for example: two hundred photos of 4 to 8 MB each, giving an overall LASer file format (.las) size of 200 MB for the small section of landslide shown in Fig. 12, compared with 1 GB for an equivalent TLS.\n\nCost: an off-the-shelf, ready-to-fly UAV with mounted camera is now less than $1000 (excluding training and processing software). This also typically amounts to less than 1 h’s flying time with a full-scale survey aircraft. Meanwhile, a TLS system can cost as much as $120,000.\n\nSafety: the safe deployment and operation of UAVs in the field should be a normal part of the overall risk assessment for the project. Fixed-wing and rotary types both have the capability to inflict personal injury and property damage; hence the importance of regulation and the effective assessment of weather and traffic (air and ground). The UAV system should also have its own Operations Manual and logbooks for pilot and batteries. Electric power is virtually ubiquitous for small UAV and utilizes lithium polymer (LiPo) batteries; the safety aspects of which (e.g., charging and transporting) should be carefully considered.\n\nAn improved understanding of landslides and other geohazards is necessary worldwide and will have an important impact on resilience, survivability, planning, and engineering. Recent developments lead to the conclusion that “UAV photogrammetry” and “structure from motion” methods are making a significant contribution to landslide surveying, mapping, monitoring, and research, in common with many other spheres of activity in the earth sciences. New and positive experiences with UAVs are being reported at an accelerating rate, for example in the fields of agriculture, archaeology, oceanography, glaciology and virtually every other branch of observational scientific research that has an “outdoor” component. Drone video footage is now used almost universally by the media in general, and the news media in particular, allowing landslide events to be understood more readily.\n\nDebris flows are “rapid, gravity-induced volume movements consisting of a mixture of water, sediment, wood and anthropogenic debris that propagate along channels incised on mountain slopes and onto debris fans” (Gregoretti et al. 2016). They occur in steep (mean channel gradient > 5%) and relatively small (area < 25 km2) torrent catchments (Rickenmann and Koschni 2010), transporting up to several hundred thousand cubic meters of debris (Hübl et al. 2009). The high solid-material concentration in the front of the debris flow, combined with high flow velocities, makes them very destructive (Rickenmann 2001). Numerous debris flow events occur every year, substantially affecting the quality of life in mountainous regions and causing extensive damage. Oberndorfer et al. (2007) examined over 5000 debris flow events that occurred in Austria between 1972 and 2004; according to the authors, these events caused total estimated damage of €965 million and 49 fatalities. In Switzerland, Alpine torrents and debris flows cause an estimated cost of around CHF 65 million every year (Rickenmann 2001).\n\nPromptly mapping the consequences of debris flow events by determining the spatial extent and volume of eroded and deposited material, is highly relevant to scientists and practitioners: Immediately after the event, this data can support search and rescue teams, or provide decision-support for structural and non-structural emergency measures. Subsequently, it may facilitate debris flow hazard management in many ways: foster process understanding (Theule et al. 2015; Pellegrino et al. 2015); benefit numerical simulation modeling (Rickenmann et al. 2006; Han et al. 2015); support planning and implementing mitigation measures, as well as hazard mapping (Rudolf-Miklau 2009) and integral risk management (Ballesteros Cánovas et al. 2016; Aronica et al. 2012).\n\nConventional techniques to map debris flow events mostly require the surveyor to access the affected area on foot. In the catchment, channel and deposition area, the surveyor measures or estimates sediment redistribution, relative to the pre-event terrain height. Erosion depth and deposition height are determined at discrete locations and interpolated for area-wide volume change approximations. This procedure is very time-consuming and hazardous and may provide only a rough estimation of terrain height changes. Furthermore, the quality of the results strongly depends on the surveyors’ experience, skills and knowledge of the pre-event terrain (Scheidl et al. 2008). Therefore, the use of various remote sensing techniques has been reported for debris flow mapping, including: High-resolution satellite imaging (Youssef et al. 2016; Elkadiri et al. 2014), manned-aircraft photography (Dietrich and Krautblatter 2016), airborne laser scanning (ALS) (Kim et al. 2014; Bull et al. 2010; Scheidl et al. 2008) or a combination of the above (Willi et al. 2015). However, compared with other natural hazard events (e.g., floods, earthquakes), debris flows affect relatively small areas (usually < 5 km2). Mapping a single debris flow event with one of the techniques mentioned above is hampered by low cost-efficiency; data acquisition is typically only commissioned in the case of large-scale events or a sequence of events (Lindner et al. 2016).\n\nIn recent years, the development of UAV has provided a wide range of new possibilities for high-resolution monitoring and mapping (Colomina and Molina 2014; Lucieer et al. 2014). In this contribution, the term UAV refers to aircraft with a typical weight of < 5 kg, flight times of 20–30 min, optimized for easy field deployment, recovery, and transport. In general, UAV can bridge the gap between full-scale, manned aerial, and terrestrial observations (Briese et al. 2013; Rosnell and Honkavaara 2012). They are credited as being able to allow flexible image acquisition at an unprecedented level of detail GSD of few centimeters or millimeters (Ryan et al. 2015). Additionally, the development of novel computer vision techniques and their implementation into a wide range of software packages have significantly reduced the requirements for the recorded data (Vander Jagt et al. 2015; Turner et al. 2012). Therefore, UAVs are very well suited for collecting aerial imagery of natural hazard events. This is reflected in a wide range of recent reports on UAV applications for mapping: landslides (Turner et al. 2015; Fernández et al. 2015; Stumpf et al. 2013; Niethammer et al. 2012), rockfall (Giordan et al. 2015; Danzi et al. 2013), glaciers (Boesch et al. 2015; Whitehead et al. 2013), and rock glaciers (Piermattei et al. 2016; Dall’Asta et al. 2015). However, to the knowledge of the authors, very few publications exist that deal with UAV-based debris flow mapping; some examples include Adams et al. (2016), Sotier et al. (2013), and Wen et al. (2011). This paper merges the authors’ experience from several UAV-based debris flow mapping missions, conducted in the European Alps between 2012 and 2016, into a practical guideline. In this contribution, the debris flow specific aspects are described for each stage of a typical UAV campaign: (i) mission planning and preparation; (ii) data collection and image acquisition; (iii) data processing and analysis. To conclude, a case study of a UAS debris flow mapping campaign is briefly presented.\n\nMission planning and preparation\n\nThe Area of Interest (AOI) is set by outlining the region to be mapped with the UAV. In this crucial first step of a UAV debris flow mapping campaign, it is essential to define (i) the location of key debris flow event areas (deposition and erosion hotspots); (ii) the scope of the campaign, i.e., size of the study area and thus time needed for data acquisition and processing; (iii) the mapping priority of all AOIs. If the AOI is too small or wrong areas are defined, essential parts of the debris flow event may be missed and will thus not be documented or considered in subsequent analyses (e.g., volume-balance calculation). AOI specification should, therefore, be performed in coordination with the civil protection and/or disaster control authorities in charge. Imagery or videos from human-crewed helicopter flights recorded by other agencies might provide essential indications for correctly setting the AOI.\n\nTwo distinctly different sub-areas of a debris flow event AOI can be identified using the type of process, which the sub-area is dominated by:\n\n1.\n\nErosion zone: torrent catchment, bordering the deposition zone at the fan apex; the entire catchment (in hydrological terms) contributes to the water volume of the event; material sourced from scouring in the torrent channel, lateral and bank erosion as well as slope failure (Fig. 15, left).\n\n2.\n\nDeposition zone: located in valley floor or on the alluvial cone; characterized by widespread deposition of sediment, wood or anthropogenic debris; the majority of direct and indirect damages occur here (Fig. 15, right).\n\nMapping the entire process area (i.e., erosion and deposition zone) allows reconstruction of the event’s volume-balance. This may provide important input for process understanding and for being able to analyze the event trigger and sequence.\n\nWhen settlements or infrastructure are affected by the debris flow event, communication with emergency services is very important. Be sure to make contact with the leading operational units of the civil protection and disaster relief and inform them about the planned data acquisition. The priority of UAV data acquisition may be ranked rather low if only documentation of the event is carried out, and no real-time data is delivered that would be necessary for search and rescue. Therefore, be prepared to have only a short timeframe for your UAV flight(s), which may be communicated at very short notice. Disastrous debris flow events, in particular, attract a large volume of air traffic (e.g., manned helicopters shuttling members of civil protection agencies, the press, and politicians). Keep the UAV as close as possible and always be prepared to abort data collection safely at short notice.\n\nThe choice of the most appropriate UAV platform for debris flow mapping depends on the size of the AOI. To cover small AOIs (< 1 km2), e.g., the deposition zone, it is expedient to use rotor UAV; to map larger areas (> 1 km2), e.g., the erosion zone, a fixed-wing UAV is better suited. The main priority of flight planning must be safe UAV operation under challenging frame conditions. These include, but are not limited to, (i) poor weather conditions directly following the event (high likelihood of precipitation, limited visibility, overcast sky); (ii) high frequency of air traffic; and (iii) limitations due to clearing up operations in the AOI. Minimum technical requirements for the UAV campaign (e.g., spatial resolution or image overlap), should be defined in the preparation phase but should be conservative and given lower priority. The flight areas (in particular in the deposition zone) should be limited in size while ensuring efficient data acquisition. This provides the pilot with more flexibility in detecting and dealing with potential flight interruptions.\n\nLegislation regarding UAV operation should be scrutinized. Depending on the national law, special rules may apply, and additional certification might be necessary to fly over groups of people or in densely settled areas. The responsible national authorities may be able to provide a certificate of exemption in case of emergencies.\n\nData collection and image acquisition\n\nData collection should take place as soon as possible after the event, to document as much unadulterated process area as possible. Generally, priority should be given to the deposition area, as clearing up operations will be carried out soon after the event, especially if the debris flow deposit affected settled areas or roads that need to be cleared. Promptly supplying the emergency services with UAV-based mapping result"
    }
}