{
    "id": "dbpedia_1572_3",
    "rank": 35,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7527789/",
        "read_more_link": "",
        "language": "en",
        "title": "Applications of unmanned aerial vehicle (UAV) in road safety, traffic and highway infrastructure management: Recent advances and challenges",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-pheelsevier.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Fatma Outay",
            "Hanan Abdullah Mengash",
            "Muhammad Adnan"
        ],
        "publish_date": "2020-11-11T00:00:00",
        "summary": "",
        "meta_description": "For next-generation smart cities, small UAVs (also known as drones) are vital to incorporate in airspace for advancing the transportation systems. This paper presents a review of recent developments in relation to the application of UAVs in three major ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7527789/",
        "text": "Transp Res Part A Policy Pract. 2020 Nov; 141: 116–129.\n\nPMCID: PMC7527789\n\nPMID: 33024357\n\nApplications of unmanned aerial vehicle (UAV) in road safety, traffic and highway infrastructure management: Recent advances and challenges\n\n,a ,b,⁎ and c\n\nFatma Outay\n\naCollege of Technological Innovation (CTI), Zayed University, Dubai, United Arab Emirates\n\nFind articles by Fatma Outay\n\nHanan Abdullah Mengash\n\nbDepartment of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Saudi Arabia\n\nFind articles by Hanan Abdullah Mengash\n\nMuhammad Adnan\n\ncTransportation Research Institute (IMOB)-Hasselt University, Belgium\n\nFind articles by Muhammad Adnan\n\naCollege of Technological Innovation (CTI), Zayed University, Dubai, United Arab Emirates\n\nbDepartment of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Saudi Arabia\n\ncTransportation Research Institute (IMOB)-Hasselt University, Belgium\n\n⁎Corresponding author.\n\nCopyright © 2020 Elsevier Ltd. All rights reserved.\n\nSince January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.\n\nAbstract\n\nFor next-generation smart cities, small UAVs (also known as drones) are vital to incorporate in airspace for advancing the transportation systems. This paper presents a review of recent developments in relation to the application of UAVs in three major domains of transportation, namely; road safety, traffic monitoring and highway infrastructure management. Advances in computer vision algorithms to extract key features from UAV acquired videos and images are discussed along with the discussion on improvements made in traffic flow analysis methods, risk assessment and assistance in accident investigation and damage assessments for bridges and pavements. Additionally, barriers associated with the wide-scale deployment of UAVs technology are identified and countermeasures to overcome these barriers are discussed, along with their implications.\n\nKeywords: Unmanned aerial vehicles (UAVs), Road safety, Traffic monitoring, Highway infrastructure management, Applications\n\n1. Introduction\n\nThe use of small Unmanned Aerial Vehicles (UAV), commonly known as ‘drones’, is increasing in all sectors. UAVs can perform air operations that manned aviation struggle with, and their use results in evident economic savings and environmental benefits whilst reducing the risk to human life. According to Business Inside Intelligence report (Joshi, 2019), commercial and civilian drones’ market is growing at a compound rate of 19%. Association for unmanned vehicle systems international (AUVSI) economic report forecasted that in the US alone by 2025 more than 100,000 jobs will be created with an economic impact of $82 billion in the commercial drone’s market (Jenkins and Vasigh, 2013). 7 million small UAVs are already deployed in air space for commercial use in various domains including real states, insurance and agricultural. Chamola et al. (2020) discussed the deployment of UAVs all over the world to manage the recent COVID-19 outbreak. This deployment was in relation to crowd surveillance, public announcements. screening masses, spraying disinfectants and delivery of medical supplies and other essentials. Over the years, the technology has been improved. However, there are still various challenges to overcome, such as safety of humans in cases of UAVs failure especially beyond visible line of sight, battery life, lack of clear government regulations and load carrying capacity (Barmpounakis et al., 2017, Mualla et al., 2019, Chamola et al., 2020).\n\nWithin, transportation field, there are a wide variety of ways this technology is being used and progress is being made to explore ways to benefit from the technology. Majority of the efforts are based on collecting traffic and driving behaviour data captured via cameras mounted on UAVs. This data is then used for a variety of purposes such as surveillance and monitoring, recognizing traffic violations, aid in managing traffic congestion, signal optimization and extracting vehicle trajectories to answer research questions in relation to accident risk assessment etc. (Barmpounakis et al., 2017, Gu et al., 2019, Menouar et al., 2017, Pham et al., 2020). Recently, the auto insurance industry and police departments have been exploring the potential of drones in traffic accident investigation (such as capturing traffic accident scene and using image mapping softwares to reconstruct imagery and markup maps). Drone-based solutions are being developed and tested to increase the efficiency of the claim process (Kure, 2020). Because of the many advantages of the technology, US Congress in the year 2012 passed a regulation that requires the Federal Aviation Authority (FAA) to integrate small drones into airspace by 2015. At around similar times, industry giants such as Amazon announced the use of drones for packages delivery in 2013 (Rakha and Gorodetsky, 2018). These events resulted in increased funding being made available for this technology and as a result, a significant increase in the UAV-based scientific literature is noted. This is also true in relation to the application of this technology in the transportation domain. This indicates the requirement of synthesizing the recent advancements and efforts that have been made within the transportation domain using UAV. We noticed a study from Barmpounakis et al. (2017) that summarized the literature on UAV applications in the transportation domain. However, since this study a significant advancement has been made as the number of research efforts increased many folds, therefore, it is important to perform a systematic review of literature, to understand 1) in what ways the UAV technology has been utilised to achieve specific objectives of a particular research/product in a transportation domain, 2) what advantages UAV technology has offered over the traditional method, 3) What barriers are associated with the wide-scale implementation of UAV technology for specific objectives and ways to overcome such barriers 4) Key areas to improve the current limitations of UAVs technology.\n\nThe focus of this paper is to review the research efforts that utilized UAVs in relation to three different domains of transportation such as road safety, traffic monitoring and management, highway infrastructure management. A systematic effort was made to gather and compile all the relevant materials available online. The reviewed documents include journal papers, conference papers, policy papers, technical reports, project deliverables, book chapters and webpages. presents used keywords in each domain, the number of screened articles and included articles within this review. The articles were searched for the publication year range from 2000 to 2020 in the SCOPUS and Google Scholar databases. The obtained studies/resources were screened based on their relevance to the specific transport domain. Patents are not explicitly considered in the review. We have summarised the research efforts for different domains in tables, especially in cases where the number of research efforts is higher. This is done to explicitly highlight the evolution of methods/methodologies and technology. However, if the number of research efforts is smaller, we described them in the text. In addition to that, this review focused on applications that have been made from small drones that are usually equipped with propellers which allows them to fly from any point rather than fixed wing type UAVs that require certain facility such as runways.\n\nTable 1\n\nDomainKeywordsScreenedIncludedRoad SafetyUAV/drones and accident OR accident management and drones/UAVs OR safety and UAVs/drones OR auto insurance and UAVs/dronesJournal: 25\n\nConferences: 19\n\nOthers: 15\n\nJournal: 13\n\nConferences: 07\n\nOthers:02Traffic Monitoring and ManagementCongestion and UAVs/drones OR Signals and UAVs/drones OR Vehicle trajectories and drones/UAVs OR traffic behaviour and drones/UAVs OR traffic monitoring and drones/UAVs OR Surveillance and drones/UAVs OR traffic rules violations and drones/UAVsJournal: 45 Conferences: 64\n\nOthers: 21Journal: 23\n\nConferences: 17\n\nOthers: 08\n\nHighway Infrastructure ManagementUAVs/drones and road design OR UAVs/drones and civil infrastructure OR UAVs/drones and bridge inspection OR UAVs/drones and the road surface OR UAVs/drone and highway infrastructure OR UAVs/drones and road mappingJournal: 24\n\nConferences: 21\n\nOthers: 09Journal:15\n\nConferences: 09\n\nOthers: 07\n\nThis paper is structured as follows: Section 2 describes the manner in which UAV technology has been employed in the road Safety domain. Section 3 presents a comprehensive review of the UAVs based application in relation to traffic monitoring and management. Section 4 discusses the research efforts in relation to the use of UAVs for the management of highway infrastructure management. Section 5 provides an account of barriers associated with the wide-scale use of UAVs technology and what efforts are being made to overcome them along with future scenarios of UAVs application and acceptability. Section 6 concludes the paper.\n\n2. Road safety\n\nRoad safety-based application of UAVs includes detailed accident investigation, risk assessment and overall surveillance of road network. In this section, we focused only on accident investigation and risk assessment. Details about road network surveillance are highlighted in 3, 5. Risk assessment efforts are characterised by the detailed analysis of vehicle trajectories extracted from UAV-based videos. It includes identification of potential conflicts and risky lane changes manoeuvres etc. Accident investigation studies are characterised based on methods, systems and application of vision algorithms to reconstruct accidents scenes using footages, photographs acquired from drones. The main challenges lie in the process of information extraction from the videos as well as deploying a system that is foolproof so that drones can carry out their function. Mehmood et al. (2018) compared the use of UAVs with three other alternatives in response to incident management by applying a multi-criteria decision analysis (MCDA) method. These four options are manned drone, UAV, helicopter and vehicle of the incident commander. UAV costs less than helicopters and manned drones and it is faster than the incident commander’s vehicle. The analysis based on three important parameters of response time, cost and availability of the option to reach the scene of a crash in most of the conditions, reveals that UAV is the best option.\n\n2.1. Accident investigation\n\nTraffic incident scene generation to help accident investigation from photogrammetry is being studied since the 1990s, however, there were several challenges, which has been overcome with the advancement of technologies especially with the advent of drones (UAV) (Cooner and Balke, 2000), that make them cost-efficient. Majority of the research efforts come under this theme of road safety are proposals, systems, software tools and image processing methodological advancements that help reconstruct the accurate accident scene and therefore assist in accident investigation. present a summary of the key research efforts. It is very clear from the progress of research that earlier efforts were focused more on the exploration of image processing results on the basis of external factors on controlling the drone to capture images such as shooting angle, altitude, glaring etc (Ardestani et al., 2016, Su et al., 2016). However, as the drone technology becomes improved and flights are more stable, now focus is more on advancing software capabilities to improve the methods used in image processing and scene reconstruction. Almost all of the studies/efforts are applied on a limited scale for testing and validation. Additionally, research efforts (Liu et al., 2019b, Ardestani et al., 2016, Raj et al., 2017; Pérez et al., 2019; Škorput et al., 2020) have proposed systems that are based on key modules such as:\n\n1)\n\nUAV flight planning and control\n\n2)\n\nCapturing video data from UAV on the accident site at various heights, angles\n\n3)\n\nVideo data transfer mechanism to the ground station\n\n4)\n\nImage processing (rectification, mosaicking, 3D model generation and its optimization)\n\n5)\n\nSystem application and validation, Accuracy measurement framework.\n\nTable 2\n\nReferenceResearch TypeHardwareSoftwareApplication ScaleFindingsArdestani et al. (2016)Prototype UAV system for 3D reconstruction of accident sceneUAV with GPS sensor, high resolution camera, HD transmitter, Ground station for communicationMission Control and planning tool, 3D photogrammetry software (No mention of specific package/algorithm)Experimental (testing of prototype)Shooting altitude, angle, Glares on smooth surface, Geo-tagging and GPS signals have impacts on quality of scanning resultsLiu et al. (2017)Method to improve UAV image processing (Image mosaic technology) for road traffic accident sceneNAAlgorithms used for image registration, image fusion, a method is proposed for image automatic rangingUsed already captured images to apply methodsProposed methods produced better results, however, efficiency is low.Su et al. (2016)UAV-based mapping system to acquire scene diagram (with a focus on camera calibration and image accuracy)Quadcopter, Gopro Hero 3 CameraAuthors own designed mapping softwareComparative analysis is performed with traditional and proposed method on one real traffic accident siteProposed method is 40% more efficient than traditional hand drawing method.Liu et al., 2019bProposed method to use UAV photogrammetry to reconstruct traffic accident sceneDJI Inspire 1 UAV, FC350 Camera with GPS functionality,Structure-from-Motion (SFM) algorithm is used for 3D reconstruction, Patch-based Multi-View Stereo algorithm is used for dense 3D point cloud model generation, Model optimisation (meshing and texturing) is done via Poisson surface reconstruction algorithmA simple accident scene for testing the methodReconstruction quality assessment is done via Peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). PSNR = 41.62. SSIM = 0.9475 (Indicate that quality is effective)Škorput et al. (2020)Proposed method to use UAV photogrammetry to reconstruct traffic accident sceneDJI Phantom 4 UAV,3D and orthophoto computer models (No mention of specific package/algorithm)A simple accident scene for testing the methodError reported under −5% to +2% in several 3D model measurements from with real dataPérez et al. (2019)Proposed method to use UAV photogrammetry to reconstruct traffic accident scene with a claim that it is low cost and simplifiedS500 Quadcopter, Gopro Hero 4 Black, Controller, GNSS Receiver, Ground control station, MonitorAgisoft Photoscan Pro along with manual tagging of 3 control pointsA simple accident scene for testing the method. Deployed at a height of 65 mPlanimetric accuracy of 7.5 cm is obtained by using the ASPRS standard.Raj et al. (2017)A protype system to recognise the vehicle involved in accident along with accident scene creation.Parrot AR Drone 2.0, Two cameras for front, downward facings, PC is used to control take-offs, landingsAR Drone LabVIEW Package for communication with UAV, background subtraction and Haar cascade classifier algorithms for vehicle detection, Image stitching techniqueA simple accident scene for testing the method95.81% accuracy is obtained for the proposed LabVIEW based vehicle detectionSerhani et al. (2019)Proposed a method to use drone captured images to estimate accident’s damage costImages dataset, accident images from drones, asset cost databaseClassification algorithm (Convolution neural network CNN), Cost estimation algorithmFew (two) accident images were analysed and cost estimated with the proposed method. Validation is also doneImage classification accuracy was around 0.79 to 0.94 and damage cost estimation accuracy was around 100% based on expert opinions.\n\nThe large-scale implementation of these proposed systems is still lacking. Furthermore, there are no studies available that compare different functionalities of modules discussed above to see which one is better off compared to another specifically for the reconstruction of the accident scene. In relation to accuracies of scene reconstruction, studies reported different indices to measure it. For example; Liu et al. (2019b) reported peak signal-to-noise ratio and structural similarity, Pérez et al. (2019) reported planimetric accuracy and Škorput et al. (2020) reported errors in percentage for various measurements. These studies claimed that their proposed methodologies are effective and have reasonable accuracies in reconstructing the scene.\n\n2.2. Risk assessment\n\nThere are a limited number of studies that can be grouped under this domain of road safety. Use of UAVs in these studies has facilitated the accurate extraction of vehicle trajectories so that analysis could be made at a microscopic level. Additionally, from traditional video data collection methods there were several limitations such as limited view because of the height of the physical structure where the camera is mounted, the tilt angle of the camera that results in inaccuracies in trajectories, lack of physical structures especially in interchange areas where safety problems are more severe. Zhang et al. (2013) proposed algorithms that detect collisions happened already or dangerous events that may result in collisions by analysing vehicle trajectories obtained from UAV based traffic video data. The most notable recent research effort is from Gu et al. (2019), where they developed an analysis framework. This was based on the extraction of vehicle trajectories using UAVs based video data to analyse mandatory-lane-change-related crash risk at freeway merging areas. A method was suggested that measure the crash risk between the merging vehicle and its surrounding vehicles by estimating a merging behaviour model that incorporates time-to-collision (safety measure).\n\nA few research efforts, however, advance the use of UAV technology in detecting the risk by incorporating on-board vision processing mechanisms. Kim and Chervonenkis (2015) studied on-board automatic detection of emergency and abnormal traffic situations with UAV artificial vision system. They proposed a system that detects stationary and moving vehicle based on UAV video data, and then at the same time, detect abnormal situations and classify them to aid the operator for making informed decisions. Algorithms developed in their study, however, are limited to recognised only a few abnormal situations. A study from Sharma et al. (2017) proposed a multi-UAV coordinated vehicular network to analyse driving behaviour for improvement of road safety. The motivation of their work was based on the notion that infrastructure-based vehicular ad hoc networks (VANETS) are constrained by traffic itself and therefore, limited in their scope. The formulation of VANETs using multiple UAVs make the system independent of roadside units and enhanced smooth communication and therefore vehicle tracking is more accurate. Their system used Decision Making Trial and Evaluation Laboratory (DEMATEL) approach (Wang et al., 2012) for computation driver behaviour ratings, vehicle ratings and overall reputation values to detect driving behaviour. These rating computations were carried over onboard devices installed on each UAV. Authors compared the proposed system with benchmark approaches in relation to communication efficiency of the collaborative network of UAVs and VANET and also for driving behaviour detection. On both accounts, they concluded that their proposed system outperformed the existing state of the art approaches. Iglesias et al. (2019) acquired a UAV based video data based on double grid UAV flights for appropriate assessment of sight distances. Structure from Motion Multi-view Stereo software was used to process a dense cloud point, which is further classified to produce a terrain model and a 3D- object model. Sight distances are calculated from the resulting environment model.\n\nIt is inevitable that with more use of the UAVs, the data would be available in abundance and risk assessment methods will be improved in future.\n\n3. Traffic monitoring and management\n\nThis section presents a review of research efforts that use UAVs technology in relation to online and offline extraction of traffic parameters from video data using vision processing methods so that traffic surveillance and monitoring mechanisms are improved. Furthermore, research efforts are also presented that improved the traffic flow analysis methods based on data collected from UAVs. These are in nature similar efforts as presented under offline risk assessment studies (i.e. collected data is used to improve analysis methods).\n\n3.1. Vehicle detection and extraction of traffic parameters\n\nMajority of the research efforts that utilise and promote the use of UAVs can be grouped within this section. These research efforts are mainly part of developing a set of algorithms, methods to extract meaningful information from video data. Accident scene reconstruction is also one such application (reviewed in Section 2.1) of these research efforts that have been originated lately. However, vehicle detection, their tracking and extraction of traffic flow parameters such as speed, density etc. is the prime focus since UAVs technology has started to use for civil applications. presents a synthesis of these research efforts.\n\nTable 3\n\nReferenceHardwareSoftwareFindingsKaaniche et al. (2005)UAV (Fixed wings), Autopilot and communication module, video cameraAlgorithm to detect vehicles based on Common fate law using a graph cut formulation with a verification stepAlgorithm is fast and can work in real time. Able to recognise vehicle.Lin et al. (2006)Aerial video footages from fixed wing UAVsImage processing tools to convert video footage into traffic informationA conceptual paperHeintz et al. (2007)UAV (Yamaha RMAX helicopter), Colour and thermal camera,DyKnow a stream-based knowledge processing middleware is used.Algorithm is fast and can work in real time. Able to recognise vehicle.Li (2008)UAV colour images from fixed wing UAVFuzzy segmentation algorithm that combines Fuzzy c-partition, genetic algorithm and colour histogramAlgorithm is able to recognize the vehicles and their position in the imagery.Cheng et al. (2009)UAV (Fixed wings), onboard camera, GPS/INS system GCP information for validationVideo frame matching algorithm (track the pixel from consecutive video frames)Algorithm is able to recognize the vehicles and their position in the imagery.Braut et al. (2012)UAV based imagesBackground model (track the pixel from consecutive frames)OD matrix at intersection was estimated with good accuracyGao et al. (2014)UAV (Radio controlled quadcopter model, HERO 3 camera, image transceiver systemCamshift algorithm to follow the tracks of target vehiclesTrajectories of vehicles are accurate enough to use for traffic performance analysis.Wang et al. (2014)Fixed wing UAV, Consumer grade camera,Software developed by the team can estimate dynamic position of vehicles from consecutive frames100 m long trajectory of around 8 vehicles, with general accuracy is of the order of 10 cmLee et al. (2015)Phantom 2, Gimbel base for camera stabilization, Ground station, FPV video transmitterGeneral quality of video data is discussed with no special vision processingRecommended and suggested to improve video quality and camera stabilizationKe et al. (2015)UAV video dataInterest point tracking based on optical flow method (KLT) and Velocity clustering approach is used for average velocity determinationYields good results with average error less than 12%.Barmpounakis et al. (2016)DJI 7 Spreading Wings S900 hexacopter, Onboard Camera offers 4 K 30 quality,Method used involves application of stabilization, Calibration and coordinates extractionVehicle and pedestrian trajectories are extracted. OD table data is also estimatedWang et al. (2016)Quadcopter (DJI Phantom 2), onboard camera (GoPro 3 Silver) and image transfer systemImage registration, image feature extraction (Edge (Prewitt edge detection), Optical flow (KLT) and Local feature point (SIFT) used for vehicle shape detection and vehicle tracking methods are employed for trajectory dataMore than 96% quality and completeness criteria are achieved with 100% correctness. Vehicle tracking error is 0% at 90 m altitude.Ke et al. (2017)UAV video dataInterest point tracking based on optical flow method (KLT) and Velocity clustering approach is used for average velocity determinationBi-directional traffic parameters are obtained. Error rates were around 17%Xu et al. (2017)UAV-based Video dataFaster R-CNN method was used and compared with other techniquesIn all criteria, method obtained higher accuracy compared to others.Khan et al. (2017)Argus-One UAV, onboard camera (4-K resolution at 25 fps)Method proposed Use of stabilization process, Geo registration, Optical flow tracking (KLT-based), Background subtraction and Blob analysis for vehicle detection and trackingA streamlined methodology for extracting trajectory from video dataBarmpounakis et al. (2019)DJI 7 Spreading Wings S900 hexacopter, Onboard Camera offers 4 K 30 qualitySimilar method as used in Barmpounakis et al., 2016Comparative study of microscopic traffic data obtained via UAV with OBD II data.\n\nErrors are in the range of −3 to 5% for average speed, increase in altitude did not cause the increase in error. Stabilization and georeferencing are key to obtain higher accuracy.Ke et al. (2018)UAV video data (20,000 video clips)Vehicle detection via Haar Cascade and CNN. Use of optical flow (KLT) for extracting vehicle parameters like volume, density and speedMethod is claimed to be used in congested conditions. Precision of the method is around 0.995 and recall is 0.957.Niu et al. (2018)3DR Solo Quadcopter, Onboard GoPro 4 Camera, transmitter device, Web Application interfaceTrained Haar Cascade Algorithm for vehicle detection and then frame-by-frame tracking algorithm for vehicle motion83–90% Accuracy in vehicle detection, tracking accuracy is 100%.Kyrkou et al. (2018)UAV video dataHaar Cascade and CNN for vehicle detection, Frame differencing for motion of vehicles, Background model for road mask detection in HSV colour. Heat map produce for more robust detectionVehicle count, speed could be determined.Zhu et al. (2018)Video data for calibration of model (manual annotated vehicles)Advanced deep Neural network model was trained for vehicle detection, localization, tracking and vehicle counting over time.Deep learning technologies are more effective than traditional vision-based algorithm. Ultra-high-resolution videos enables more accurate results compared to low resolution contents.Zhao et al. (2018)UAV, onboard camera, transmitting deviceExisting proposed algorithm are used for vehicle detectionBattery limitations, instability, data transmission and flight attitude are challenges to acquire accurate traffic dataZhang et al. (2019)UAV (Mavic Pro Platinum Model, Dji Company), onboard camera with 24 fps.Mask RCNN approach is used for vehicle detection and recognition.Complexity introduced due to presence of motorcycles and algorithm can recognize but errors are high in vehicle counts.Liu et al. (2019a)UAV video dataR-CNN model was used to vehicle detection, Kalman filtering as a tracking methodBetter results compared to YOLOv3.Ke et al. (2020)UAV video dataThree interconnected process streams that uses ensemble-based classification (Haar cascade + CNN) for vehicle detection, optical flow (KLT) for motion detection and modified Canny + Hough transformation for lane boundary detectionLane-level microscopic traffic parameters such as time/space headway and lane specific speed, density and volume along with individual speed and trajectory.\n\nAccuracy is also increased based on the metric defined as % of total frames with false positive and false negative.Ahmed et al. (2020)DJI Phantom 3, video camera 4 k resolution, flight time 15 minHeterogenous vehicle stream data is acquired (especially motorcycles). Data is extracted using a program that allows recording of manual key board strokes with a time stamp for certain events as the video progresses.Traffic flow dynamics within a green time was captured i.e. an outflow rate (veh/hr) during a green time for each type of vehicle. In weak lane-discipline environment traffic flow during green time contains significant variations compared to traffic stream that is characterised as strictly lane-discipline\n\nBefore 2014–15 most of the studies were conducted using fixed-wing type UAVs having lesser manoeuvrability compared to rotary-wing small drones. These drones were heavy, significantly larger in size and required professional skills for their operation and control. Additionally, they do not support vertical take-off and landing and also their application is costly. However, these drones have larger flight time and a more stable flight. With the advent of small drones and their availability on a cheaper price, efforts were focused more on utilising them to capture aerial videos. The studies used different vision process algorithms such as Image feature extraction, frame difference and Kanade-Lucas-Tomasi (KLT), background subtraction methods used in various key processes such as stabilization, vehicle detection, vehicle tracking etc. Khan et al. (2017) described that chain of processes through which raw UAV video is required to undergo so that appropriate trajectory of vehicles is obtained. Almost all studies presented their algorithm test in an offline mode (i.e. applied on collected video data) with a claim that it can also be used in a real-time setting to extract traffic parameters. These research efforts proposed algorithms/methods with a view-point that UAVs are installed with onboard video cameras that capture video and send it to ground station where these videos can be processed and extracted information on traffic parameters for further transfer of this information to a central control station. A series of work from Ke et al., 2015, Ke et al., 2017, Ke et al., 2018, Ke et al., 2020) presented a good example of how the vision processes have been evolved in extracting key traffic parameters. This has started with vehicle detection and average speed determination to lane level microscopic traffic parameters such as headway, lane-specific speed and individual vehicle speed and trajectory etc. In terms of algorithms, the focus has been shifted towards the application of machine learning and deep learning models (such as Haar cascade, R-CNN, Mask R-CNN, advanced DNN) for vehicle detection. However, for motion detection KLT approach is dominant apart from one effort (Liu et al., 2019a) that uses the Kalman filter approach. Barmpounakis et al. (2019) has evaluated the result from OBD-II (onboard diagnostic devices installed in vehicles) devices with processed data from vision algorithms (traditional) applied on UAVs-based video. They concluded that results from vision algorithms are having an error in the range of −3 to +5% with OBD-II data and a key to reducing these errors is the control over stabilization and geo-registration processes. Zhu et al. (2018) showed that deep learning models are more effective than traditional vision algorithms. However, these models require good and large quality of video/images data for their training but once the models are trained they can provide results more efficiently in the application environment. In comparison to the above, Ahmed et al. (2020) used a manual process to extract the required information (travel mode-specific outflow rate when the traffic signal indicates green) for the video data collected from UAV. They highlighted the fact that current vision algorithms are not suited for application in heterogeneous traffic environment which is characterised by the high presence of motorbikes and the traffic streams following a weak lane-discipline. Additionally, it is also mentioned that UAV video data is more appropriate for such analysis because of the bird eye-view, which is required to accurately capture the lateral movements of motorbikes that effect their travel time.\n\n3.2. Traffic flow analysis\n\nThis section discusses research efforts that advance the use of traffic parameters extraction processes from UAV-based data to further utilising it in various traffic flow analysis method. These analysis methods include the performance of different road geometries (such as a roundabout, signalized intersections, non-signalized intersection), different traffic flow behaviours (such as shock wave analysis, lane change behaviour, gap acceptance analysis), Car-following models with their calibration and validation for use in microscopic simulation packages.\n\nCoifman et al. (2004) based on some UAV field trials indicated the possibility of using UAV for tracking vehicle movement in an intersection, observe congestion on the network, monitoring parking lot utilization directly from the video. However, with the advent of vision processing algorithms, it is now a possibility that vehicle trajectories can be obtained and several in-depth analyses can be made. Salvo et al. (2014) used the vehicle trajectory data acquired from UAV video for analysing gap acceptance for an urban intersection that does not contain traffic signal and regulated using STOP sign. For vehicles that have accepted gap of less than 6 s in order to enter into the main road, three types of driving behaviours (i.e. aggressive, neutral and cautious) are identified based on a function of waiting time at the intersection entrance and number of gaps rejected. They have analysed this based on manually observing the UAVs videos. Khan et al. (2018a) extended their work presented in Khan et al. (2017) in relation to further processing of acquired vehicle trajectories from UAV data. Vehicle trajectories are processed in relation to obtaining critical points in the trajectory to classify them under various flow regimes i.e. uniform motion, accelerated/decelerated motion or stationary regime. The resulting trajectories are then analysed to identify shockwaves generated within the proximity of signalized intersection. For each flow regimes, different traffic flow parameters were also obtained (speed, density, flow) and resulting fundamental diagrams used to obtain other unknown traffic parameters. Using space–time diagrams and fundamental flow diagrams, traffic performance was also analysed at an intersection using indicators such as queue lengths and time required for dissipation of queue. Validation was also done using the ground truth data and it was mentioned that mean error was in the range of 7.5%. Khan et al. (2018b) further extended their traffic analysis work to study traffic behaviour for a roundabout. Their performance evaluation methodology includes the estimation of OD matrices for each leg of the roundabout and then using this as input to analyse gap acceptance behaviour of drivers. The critical gap was estimated as 3.83 s, which was found slightly less than the average specified value in Highway Capacity Manual (HCM, 2010) which is 4.1 s. This helps in estimating the level of service of roundabouts. Hao et al. (2019) develop a Deep Belief Networks (DBNs)- based machine learning model to analyse aggressive lane change of the drivers with dataset extracted from UAV-based videos. The aggressive lane change is modelled as a function of driving-related parameters (such as speed, distance to lead and rear vehicles, acceleration/deceleration), vehicle information (such as vehicle model), and driver information derived via registration number plate. The model provides an accuracy of around 80%. Ahmed et al. (2020) empirically explore the queue-jumping phenomenon of motorcycles by extracting information of outflow rate and travel times during the green time of traffic signals. This phenomenon is prevalent in heterogenous traffic stream that also has a property of weak lane discipline. Their exploration indicates that high variation of outflow rate exists during the green time and therefore, microscopic simulation models should incorporate this to better simulate traffic condition for signalized traffic intersection.\n\nBarmpounakis et al. (2020) presented the results from large-scale field experiments that use a swarm of drones (10 drones) for collecting such data that provide details of congestion propagation in urban networks. Their work was first of their kind to collect such data for congestion analysis that covers more than 100-km lanes of the road network, around 100 busy intersections, many bus stops and around 0.5 million trajectories. The paper discussed various possibilities to understand the mechanism of congestion formation and propagation in congested multimodal environments such as: 1) estimation of dynamic OD matrices at network level through a less costly and computationally efficient way, 2) estimation of joint distributions of travel times for successive links that provide an appropriate travel time reliability measure, 3) lane changing phenomenon usually modelled using gap analysis, however, the data will provide an opportunity to understand this in more detail as it is not understood well around the vicinity of traffic light especially in congested urban environments even simulation models are not calibrated and validated with this level of detail. 4) Revisiting fundamental flow diagram with this large scale of data even from small roads, 5) Impact of stop and go characteristics of service vehicles (such as Taxis, Bus and delivery vehicles in causing local disturbances in traffic flow and how this could further propagate congestion, delays etc. 6) study of network-level emission with the incorporation of effect of local disturbances due to lane change and stop and go behaviour of vehicles. Barmpounakis and Geroliminis (2020) further used this data and developed a methodological framework to identify lane-changing manoeuvre identification, they used Azimuth as the main concept for this. Based on the use of high-resolution data and time-series analysis tool, their algorithm predicted lane-changing manoeuvre with higher accuracy of 95%. It was also made clear that there with more exploration of this data, many new traffic flow phenomena can be discovered which cannot be studied previously due to limited data sets.\n\n4. Highway infrastructure management\n\nAnother very important area of application of UAVs technology within the transportation domain is to use them for monitoring and management of highway physical infrastructure. Two areas i.e. bridge inspection and monitoring and pavement distress recognition have been given a significant consideration and a variety of field experiments/trials are done to establish the protocol, methods and algorithms. In this section, such efforts are highlighted in detail in 4.1, 4.2. Apart from these efforts, there are a few noted that applied UAVs in relation to road design. A research effort from Zulkipli and Tahar (2018) is notable. They used small UAV (Quad-Rotors, Phantom 3 Pro) for engineering surveys to develop a small-scale map that can be used for road design. The UAVs images are processed using the UAV Agisoft PhotoScan, that finally generates the x, y, and z coordinates of the entire areas of interest. Their study used 4 K camera and its parameters are provided to image processing software. They also carried out a traditional mechanism in parallel to analyse the accuracy of the mapping and road design process (that involves elements like horizontal curves, superelevation etc.). Errors noted in the coordinates of important points are in the of +/−0.2 m in the horizontal plane. Authors recommended the use of GCP points used for image processing from the precise engineering surveys for better results.\n\n4.1. UAV as monitoring tool for bridge inspection\n\nResearch efforts and field trials-based studies are advocating the case of using UAVs for bridge inspection and monitoring. Otero et al. (2015) presented a proof of concept of utilising UAV for bridge and high mast luminaires. They performed several experiments in controlled conditions for testing UAV response in relation to wind conditions. Further, image quality in different flight scenarios, low light conditions, altitude and payload. In general, their results are in favour of using this technology, not just in terms of saving man-hours but also detecting the damages. Zink and Lovelace (2015) demonstrated the application of UAVs for four (04) bridge inspection throughout Minnesota, USA. They identified several advantages of using UAVs e.g. this technology can offer saving from reduced or eliminated traffic control and reduced use of under bridge inspection vehicle and lifts. In their investigation, they rely on infrared photos of various elements of the bridges for detecting any defects. Gillins et al. (2016) also reported the use of UAVs and their benefits to develop a cost-effective methodology for bridge inspection. Seo et al. (2018) reported use of a drone (DJI Phantom 4) to perform the bridge inspection. Resulting images were checked with those available in the past inspection report from the South Dakota Department of Transportation (DOT). Authors reported successful and efficient identification of different types of structural damages on the bridge.\n\nYin et al. (2015) proposed a prototype system for bridge inspection. For crack detection, they argued that traditional edge detection algorithms are limited in a sense that they require a threshold of the detector when the scale of the image is unknown, which is usually proportional to the distance between the structure surface and onboard camera. They proposed a Gaussian image pyramid algorithm that provides enhanced results for the crack area. Lei et al. (2018) also reported the similar shortcoming of traditional edge detection algorithms (Prewitt algorithm, Canny algorithm, Sobel algorithm) and proposed crack central point method to address the shortcomings. Their proposed algorithm is based on the characteristics of the fracture in the pre-processing images without the interference of noise. In the pre-processed image, the grey value at the centre of the crack is minimum and therefore, it is used to characterise the crack area in the enhancement process of the image. Their proposed algorithm outperformed traditional edge detection and also K-mean clustering even with lesser number of images. Wu et al. (2018) reported coupling of UAV images with deep learning models for bridge and pavement condition assessment. UAV that carrying a high-resolution camera and an infrared thermography camera was used to collect a large amount of data from the bridges and pavements. This data was used for training of deep neural network for damage classification and condition assessment. Only preliminary application was reported where model validation accuracy reached to around 79%. They mentioned that the use of UAV for a large-scale bridge can be tricky as special skills required, further, a powerful Raspberry Pi tiny processor is required to facilitate the development of autonomous and real-time infrastructure condition assessment.\n\n4.2. Pavement condition and road distresses monitoring\n\nPeriodic assessment pavement conditions and distress monitoring is usually a norm and therefore, transportation agencies and local governments have the mechanism and inventories in placed so that required repair works are carried out. Traditional mechanisms involve visual inspection and then in-situ tests to assess road distress, unevenness, rutting, cracks widths and their depth etc. Use of UAVs to help carried out part of this work is still in the development phase and not yet in practice. Highlights of some research efforts are and field trials are mentioned below.\n\nZhang (2008) developed the UAV based photogrammetry mapping system for assessing road condition, especially for unpaved roads. Their image processing system includes camera calibration, integrated sensor orientation, digital 3D road surface model and orthoimage generation, automated feature extraction and measurement for road condition assessment. However, the accuracy of their proposed method is not discussed in detail, as only photographic evidence was provided that shows the identification of washboarding ridges. However, later in another paper (Zhang and Elaksher, 2012) presented a similar system with some minor improvement in detail and provided a comparison of onsite measurements of distress with derived 3D information from processed UAV images. They found differences around 0.5 cm, which they mentioned that they are acceptable for unpaved road conditions. Dobson et al. (2013) proposed a similar system to generate a 3D road surface model using SFM vision processing algorithm for unpaved roads as a phase I of the project. In phase II, they reported improvement of their processing system which include a blurred image filter that removes blurred imagery before being processed for 3D reconstruction. This is to ensure high-quality outputs. Another important development was the independent distress detection component so that it provides flexibility in achieving commercialization goals (Brooks et al., 2016). To obtain more accuracy in damage assessment, Themistocleous et al. (2014) proposed the use of a range of tools and their integration. UAV images are proposed to be integrated with satellite imageries and the use of in-situ measurements from ground penetration radar (GPR) and field spectroscopy in an attempt to develop a sound methodology that is non-intrusive. However, the real demonstration of the integration of these technologies in assessing damages is not discussed. Knyaz and Chibunichev (2016) presented two photogrammetric techniques for road surface analysis (i.e. deformation/unevenness etc.) using images obtained from UAV (Geoscan 401) equipped with Sony- RX1 digital camera. They also used Agisoft PhotoScan image processing software along with various reference and control points. They concluded that measurement precision meets the requirements to extract road surface parameters extraction. Shaghlil and Khalafallah (2018) presented the requirement (obtained from Virginia and North Carolina Departments of Transportation) for UAV images and image processing tools to identify road cracks of as small as 0.00317 m (1/8 in.) in depth and 0.00635 m (1/4 in.) in width. They proposed an automated system based on the processing of drone images, however, they did not rigorously validate their proposed system accuracy in fulfilling the requirements. On a similar notion, Leonardi et al. (2018) proposed an automated method using UAV for road condition assessment. They reported sufficient accuracy of their 3D mapping data to identify pavement distress.\n\nLee (2019) reported use of DJI Mavic 2 Pro that carrying a 4 K high-resolution camera to obtained UAV videos and then further processing it for appropriate detection of potholes with all its features to develop a comprehensive GIS-based database. Pix4Dmapper was used for image processing and usual steps followed for the point cloud generation. For 3D reconstruction, point cloud data was used in CloudCompare, Autodesk Recap Pro and Civil 3D in a sequential way to obtain geometrical features of potholes. The accuracies of potholes measurement were in the range of +/−2.0 in.. Li et al., 2019a, Li et al., 2019b in their retracted article used low altitude UAV with light detection and ranging (UAV LiDAR) system to generate point cloud data and then random forest classification model for identifying different type of distresses (i.e. cracks, potholes, rutting and filler). They first reported the distress identification accuracy of 92.3%, however, later in the retraction, they have mentioned that it is around 89% owing to a reduction of 14 extracted features from the images. Tan and Li (2019) acquired road images from UAV and process those to reconstruct 3D models derived from Pix4Dmapper photogrammetry. Pavement surface was extracted by the application of region growing algorithm from the derived 3D model. They developed an algorithm to detect pavement distress and their corresponding dimensions. Their algorithm based on three steps, in the first step reference plane, was established using windows, which is required due to upslope and downslope of the road cross-section. The next step involves finding deviating points from the reference plane. In the third step, features are extracted based on road distress point clouds and the corresponding reference plane parameters. An error of around 1 cm was found when compared the results with in-situ measurements for road distress such as potholes, piling up and corrugation. Efficiency in relation to computing time is also determined based on the hardware used, which is around 3 to 6 min for distress detection.\n\n5. Wide-scale deployment of UAVs: Barriers, solutions and implications\n\n5.1. Airspace regulations/guidelines and their evolvement\n\nUse and control of drones in the urban environment have become a hot discussion topic and this issue is considered as a major barrier for their wide-scale deployment. Majority of research efforts discussed above did not specifically mention the regulations applicable to their data acquisition flights. Authorities are trying to develop regulations that ensure safety, privacy and noise concerns of the citizens and at the same time increase the efficiency of the services provided by UAV technology. It is possible that drones can be equipped with a system that can recognize any failure or unpredicted change in weather conditions and the system automatically abort the operation using some mechanisms such as the deployment of UAV parachutes, navigate back to the base (Barmpounakis et al., 2017). However, it means additional sensors and equipment that further increase the weight. UAVcoach.com (UAV Coach, 2020) has summarized the regulations in relation to various use type of UAV for many countries. At the moment most of the nation’s space monitoring agencies (such as Federal Aviation Authority (FAA from the US), European Aviation Safety Agency (EASA, EU) allow the use of drones with some restrictions, and the most critical restriction that is considered as a barrier of their wide-scale use is the operation of drones remain under the visual line of sight (VLOS) of the operator. Additional restrictions include weight, sensors and equipment (such as a camera), day-only operations, altitude, professional training and certification, registration of drones and prior permissions for using the air space especially in controlled flying space (FAA News, 2016).\n\nFAA has a special waiver application process to relax a few strict conditions and also making continuous amendments in their waiver program especially in relation with flying over people and moving vehicles, and night time operation etc. (FAA, 2019). Beyond visual line of sight (BVLOS) is something which poses a higher risk, however, there are strong indications that with onboard detect-and-avoid system FAA can generally include this in their waiver program (Choi, 2020). Some countries allow BVLOS flights, however, they do so after special consideration and exceptional approvals. Spain, France and Nigeria are in the list of those countries where regulations are less strict and express approvals are granted in relation to BVLOS flights (Stöcker et al., 2017). Civil Aviation Administration of China introduced a cloud-based system that is able to collect e-identification of UAVs in real-time for air traffic management. UAVs operating BVLOS and have weight more than 7 kg much be connected with this system (EASA, 2020). Recently, European Union Aviation Safety Agency (EASA) has published guidelines and regulations as Opinion 01/2020 (a proposal to the EU Commission for Adoption) on the use and control of UAVs in the urban environment which is a high-level regulatory framework for the U-space (EASA, 2020). This Opinion document will be subject to discussion and a first regulatory step to further evolve the UAV system and U-Space technologies in a harmonised manner across the EU.\n\n5.2. Technological constraints and solutions\n\nUAVs operations are limited by their battery life, which causes the shortening of the time UAV can fly and remain in the air. Flight time of the drones can vary based on the battery and type of drones, usual flight time is around 25–30 min provided that no other sensor mounted on UAV is taken power from its battery. Majority of the research efforts mentioned above in 2, 2.1, 3, 4 are based on the flight time of around 25–30 min. Researchers are trying to improve battery life of drones such as enhanced lithium-ion batteries and hydrogen fuel cells, more energy-efficient designs of UAVs, and the use of alternative energy sources such as solar energy to extend flight missions, UAVs may fly on the order of several hours in the future (Menouar et al., 2017). However, such drones tend to be costlier. The flight time (i.e., battery lifetime) of a UAV depends on several factors such as the energy source (e.g., battery, fuel, etc.,), type, weight, speed, and trajectory of the UAV (Mozaffari et al., 2019). When a single UAV is deployed, these factors can be optimized to increase the flight time. However, more research is now focused on using the UAV to enhance communication (i.e. transmitting signals to other devices such as ground stations, cloud platform etc,) and therefore, these communications also consume power along with the propulsion function of UAV. Researchers have done different experiments to enhance communication to the ground user by minimizing the flight time of multiple drones (Mozaffari et al., 2017). A range of routing protocols (Path Planning) and algorithms are also developed so as to minimize energy consumption and maximise the coverage/observability for traffic surveillance and monitoring.\n\nLiu et al. (2013) for traffic surveillance in the sparse road network, developed an algorithm for UAV deployment considering with/without UAV continuous flight distance. They used a K-means clustering algorithm to decompose the UAV cruising area into a number of sub-areas and further applied a simulated annealing-based solution algorithm. The multi-objective optimization model proposed by Liu et al. (2016) aims to minimize UAV cruise distance and minimize the number of UAVs being used. Mersheeva and Friedrich (2012) adopted a metaheuristic variable neighbourhood search algorithm, and Sundar and Rathinam (2012) presented a mixed-integer programming model for UAV route planning with refuelling depot constraints. A study by Ning et al. (2014) specifically considers the mobility constraints of traffic sensors, and a measure of traffic information acquisition benefits was used to evaluate the surveillance performance. Their proposed hybrid two-stage heuristic algorithms include both particle swarm optimization and ant colony optimization components. Zhang et al. (2015) using the time geography perspective, presented a linear integer programming model to maximise spatial and temporal coverage of traffic state detection under various UAV speed, admissible airspace, and operational budget constraints. Ghazzai et al. (2017) mentioned that due to their energy-limited capacity, UAVs are employed for temporary missions and, during idle periods, they are placed in stations where they can replenish their batteries. They proposed a method to determine the best locations for a given number of docking stations that the operator aims to install in a large geographical area. Based on average road network statistics, two essential conditions are imposed in making the placement decision: i) the UAV has to reach the incident location in a reasonable time, ii) there is no risk of UAV's battery failure during the mission. Two algorithms, namely a penalized weighted k-means algorithm and the particle swarm optimization algorithm, are proposed. Results show that both algorithms achieve close coverage efficiency in spite of their different conceptual constructions. Chow (2016) based on increasing need to monitor at a city level, proposed a method to systematically deploy drones over multiple periods using approximate dynamic programming algorithm. Liu et al. (2019c) based on the notion that previous studies are focus on static or deterministic UAV path planning, proposed a method that solves real-time UAV rerouting problem. In their algorithm, they identified existing visited targets and remaining unvisited targets, further, with the consideration of time window and developed a multi-objective optimization. Karaduman et al. (2019) proposed a routing algorithm of UAV using aerial road images captured in real-time. Their experimental work used already captured videos and simulation approach to validate their algorithm. Two methods are utilised for road detection. These are K-Nearest neighbour and Hough transformation. Their algorithm provided a heading direction for UAV so that UAV can follow a route. Elloumi et al. (2019) based on the opportunistic method with learning detected the highest number of events and at the same time minimizing the energy consumption of UAVs by limiting their travelled distance.\n\n5.3. UAVs future and emerging scenarios in transportation\n\nOne of the building blocks for any smart city is its reliance on Intelligent transport systems (ITSs). Emerging mobility paradigms that are based on connected and autonomous vehicles (CAV), UAV, Mobility as a service (Maas) can serve as enabling technologies that paved the way for enhanced transportation experiences (Nikitas et al., 2020). Autonomous and connected vehicles are one aspect; however, other facets of transportation also need to move towards automation such as highway maintenance, traffic police agents etc (Menouar et al., 2017). Wide-scale deployment of UAVs along with concepts/methods and algorithms discussed in 2, 3, 4, 5.2 can enable such automation. Roadside Units (RSUs) are envisaged to support communications (i.e. reliable internet access connectivity, emergency notification and other safety notifications) to achieve the goal of ITS. UAV based ITS, can be utilised for a dedicated short-range communication interface to better support vehicle-to-vehicle (V2V) and vehicle to infrastructure (V2X) communications. Use of UAVs in such a collaborative framework not only provides an opportunity of overcome technological constraints of RSUs (such as loss in line of sight communication, packet loss, latency, retransmission overhead and multiple target tracking of objects), but also support other adhoc communication networks by sharing some of their tasks.\n\nUse of UAVs as mobile aerial RSUs is now considering by many researchers as an advancement in adhoc vehicular networks (VANET). Oubbati et al. (2016) studied the cooperation of UAVs with VANET on the ground in assisting the routing process and improvement in the reliability of data delivery by enhancing the communication network. Their simulation shows encouraging results. Hadiwardoyo et al., 2018, Hadiwardoyo et al., 2019a, Hadiwardoyo et al., 2019b) presented a similar work, where UAVs are communicating with ground vehicles (UAV-to-Car communication). They mentioned that obstacles like hills, mountains are obstacles to such communication, therefore, their simulation model incorporates those features (i.e 3D space enabled communication) to test the performance of such communication. Their results show great degrees of similarities with those obtained in real conditions. However, it is required to be careful about security and privacy in the case of cyber-attacks. Furthermore, when UAVs are deployed at a larger scale swarm of UAVs may be simultaneously operating in different part of the cities. Human interference (operator) and UAVs automated management system should provide a balance for the seamless movement of UAV traffic in the sky. Raj and Palanichamy (2020) proposed an Air intelligent Relay-Road Side Unit (AIR-RSU) to determine the network connectivity and stability at every time instant. Lucic et al. (2020) extended the vision of RSU/UAV joint planning solution by adding a renewable energy component into the problem specification to offset the on-grid electricity cost. Their problem investigates the optimal placement of RSUs and UAV stations, RSU activation schedules if solar panels are attached and their coverage during each time period.\n\nFurther research in UAVs technology will open doors for their wide-scale applications in considered domains in this article. These are e.g. Introducing collision avoidance system in autonomous UAVs, avoidance of cyber-attacks, integration of more sensors to record other relevant data along with the integration of video data with other geospatial information such as Point of interest information etc. In addition to the above, acceptance of society is also a big challenge. Kellermann et al. (2020), reviewed the literature in relation to drones application in parcel delivery and passenger transportation. They concluded that literature often appeared oversimplified and lack scientific validation when it makes claims about traffic and travel time reduction and environmental benefits. Additionally, much of the debate about the technology ignore citizens as a stakeholder. They asserted that without public acceptance future developments and application of the technology will be slower. For example; in upscaling projects social equity needs to be considered which relate to concerns like availability of drones for a segment of the population, location of drone ports and increased noise/night time disturbances near areas who are not able to afford drone specific facility, visual integrity of skies and addressing public attitude like not-in my backyard (Schechtner et al., 2018). Efforts of the International Transport Forum (ITF) can be proved vital, where preparation of recommendations for transport ministries are ongoing for the integration of drones into the transport system (ITF, 2020). UAVs deployment, performance analysis, path planning, resource allocation, flight time optimization, energy efficiency are other key challenges that required more research efforts (Mozaffari et al., 2019). Conventional fields such as optimization theory, machine learning, game theory, stochastic geometry and transport theory can provide tools/method to overcome these challenges.\n\n6. Conclusion\n\nRecent applications of UAV in the transportation field especially in Road safety, traffic monitoring and highway infrastructure management have been critically reviewed and classified. Vision algorithms and image processing is found as a key element where progress is made that results in the advance application of UAVs in extracting key information that can be used in accident investigation and assessment, traffic flow analysis and damage assessment for bridges and roads. The bird eye-view angle of the camera provided by the UAVs is considered important as it allows extracting of vehicle trajectories with more accuracy in lateral distances, that significantly helps improvement in the traditional methodologies and models used in traffic analysis. The use of UAVs in communication networks alongside RSUs to support the goals of ITS has emerged as a profound solution, which is tested well and results are encouraging. Barriers for wide-scale deployments, such as airspace use regulations, technological constraints (battery life, flight range etc.) are discussed and how these issues are tackled so far and their implications are presented in detail. Future scenarios are also discussed along with the emphasis on public acceptance for more developments and application of UAVs.\n\nCRediT authorship contribution statement\n\nFatma Outay: Conceptualization, Methodology, Writing - original draft, Resources, Project administration. Hanan Abdullah Mengash: Investigation, Resources, Methodology, Supervision, Writing - original draft, Writing - review & editing. Muhammad Adnan: Investigation, Writing - original draft, Writing - review & editing.\n\nAcknowledgement\n\nThis research was supported by Zayed University Research Cluster grant #R17075. Additional resources to fund this research were obtained from the Deanship of Scientific Research at Princess Nourah bint Abdulrahman University through the Fast-track Research Funding Program. Authors also acknowledges the support provided by Mr. Tufail Ahmed, PhD student at Transportation Research Institute (IMOB), Hasselt University for compilation and initial screening of literature.\n\nReferences\n\nAhmed A., Outay F., Zaidi S.O.R., Adnan M., Ngoduy D. Examining queue-jumping phenomenon in heterogeneous traffic stream at signalized intersection using UAV-based data. Pers. Ubiquit. Comput. 2020 doi: 10.1007/s00779-020-01434-y. [CrossRef] [Google Scholar]\n\nArdestani, S.M., Jin, P.J., Volkmann, O., Gong, J., Zhou, Z., Feeley, C., 2016. 3D Accident Site Reconstruction Using Unmanned Aerial Vehicles (UAV). In: Presented in 95th Annual Meeting, Transportation Research Board, Washington DC, USA. Paper No. 16-5703.\n\nBarmpounakis E.N., Vlahogianni E.I., Golias J.C. Unmanned Aerial Aircraft Systems for transportation engineering: Current practice and future challenges. Int. J. Transp. Sci. Technol. 2017;5(3):111–122. [Google Scholar]\n\nBarmpounakis E.N., Vlahogianni E.I., Golias J.C., Babinec A. How accurate are small drones for measuring microscopic traffic parameters? Transport. Lett. 2019;11(6):332–340. [Google Scholar]\n\nBarmpounakis, E., Sauvin, G.M., Geroliminis, N., 2020. On the new era of urban traffic monitoring with massive drone data: The pNEUMA large-scale field experiment. Transport. Res. Part C: Emerg. Technol., 111, 50–71.\n\nBarmpounakis E., Geroliminis N. Lane Detection and lane-changing identification with high-resolution data from a swarm of drones. Transp. Res. Rec. 2020 0361198120920627. [Google Scholar]\n\nBrooks, C., Dobson, R.J., Banach, D.M., Roussi, C., Lefler, V., Hart, B. et al., 2016. Characterization of unpaved road condition through the use of remote sensing project-phase II, deliverable 8-D. Accessed on May 2020, https://rosap.ntl.bts.gov/view/dot/32118.\n\nCoifman, B., McCord, M., Mishalani, R.G., Redmill, K. 2004, January. Surface transportation surveillance from unmanned aerial vehicles. In: Proc. of the 83rd Annual Meeting of the Transportation Research Board, p. 28.\n\nChamola, V., Hassija V., Gupta V., Guizani M., 2020. A Comprehensive Review of the COVID-19 Pandemic and the Role of IoT, Drones, AI, Blockchain, and 5G in Managing its Impact, In: IEEE Access, vol. 8, pp. 90225–90265, doi: 10.1109/ACCESS.2020.2992341.\n\nCheng, P., Zhou, G., Zheng, Z., 2009, March. Detecting and counting vehicles from small low-cost UAV images. In: ASPRS 2009 Annual Conference, Baltimore, vol. 3, pp. 9–13.\n\nChoi, C., 2020. Farming With Drones Beyond Visual Line of Sight, Inside Unmanned Systems, Inside Engineering, Policy and Practice, Access on May 2020 https://insideunmannedsystems.com/farming-with-drones-beyond-visual-line-of-sight/.\n\nChow J.Y.J. Dynamic UAV-based traffic monitoring under uncertainty as a stochastic arc-inventory routing policy. Int. J. Transp. Sci. Technol. 2016;5(3):167–185. doi: 10.1016/j.ijtst.2016.11.002. [CrossRef] [Google Scholar]\n\nDobson, R.J., Brooks, C., Roussi, C., Colling, T., 2013, May. Developing an unpaved road assessment system for practical deployment with high-resolution optical data collection using a helicopter UAV. In: 2013 International Conference on Unmanned Aircraft Systems (ICUAS), IEEE, pp. 235–243.\n\nElloumi, M., Dhaou, R., Escrig, B., Idoudi, H., Saidane, L. A., Fer, A., 2019, October. Traffic monitoring on city roads using UAVs. In: International Conference on Ad-Hoc Networks and Wireless, Springer, Cham, pp. 588–600.\n\nEASA, 2020. High Level Regulatory Framework for the U-Space, European Union Aviation Safety Agency, Opinion No. 01/2020, Accessed on May 2020, https://www.easa.europa.eu/sites/default/files/dfu/Opinion%20No%2001-2020.pdf.\n\nFAA News, 2016, Summary of Small Unmanned Aircraft Rule (Part 107), Federal Aviation Authority, Washington DC, 20591, Accessed on May 2020, https://www.faa.gov/uas/media/Part_107_Summary.pdf.\n\nFAA, 2019. Operation of Small Unmanned Aircraft System Over People, Federal Register, Vol 84, No 30, Wednesday, February 13, 2019, Proposed Rule, Accessed on May 2020, https://www.govinfo.gov/content/pkg/FR-2019-02-13/pdf/2019-00732.pdf.\n\nGao, H., Kong, S.L., Zhou, S., Lv, F., Chen, Q., 2014. Automatic Extraction of multi-vehicle trajectory based on traffic videotaping from quadcopter model. In: Applied Mechanics and Materials, vol. 552, Trans Tech Publications Ltd, pp. 232–239.\n\nGhazzai, H., Menouar, H., Kadri, A., 2017, June. On the placement of UAV docking stations for future intelligent transportation systems. In: 2017 IEEE 85th Vehicular Technology Conference (VTC Spring), IEEE, pp. 1–6.\n\nGillins, M.N., Gillins, D.T., Parrish, C., 2016. Cost-effective bridge safety inspections using unmanned aircraft systems (UAS). In: Geotechnical and Structural Engineering Congress 2016, pp. 1931–1940.\n\nGu X., Abdel-Aty M., Xiang Q., Cai Q., Yuan J. Utilizing UAV video data for in-depth analysis of drivers’ crash risk at interchange merging areas. Accid. Anal. Prev. 2019;123:159–169. [PubMed] [Google Scholar]\n\nHadiwardoyo S.A., Hernández-Orallo E., Calafate C.T., Cano J.C., Manzoni P. Experimental characterization of UAV-to-car communications. Comput. Netw. 2018;136:105–118. [Google Scholar]\n\nHadiwardoyo, S.A., Calafate, C.T., Cano, J., Ji, Y., Hernández-Orallo, E., Manzoni, P., 2019a. 3D Simulation Modeling of UAV-to-Car Communications, IEEE Access, 7, 8808-8823, doi: 10.1109/ACCESS.2018.2889604.\n\nHadiwardoyo, S.A., Calafate, C.T., Cano, J., Ji, Y., Hernández-Orallo, E., Manzoni, P., 2019b. Evaluating UAV-to-Car Communications Performance: From Testbed to Simulation Experiments. In: 16th IEEE Annual Consumer Communications & Networking Conference (CCNC), Las Vegas, NV, USA, , pp. 1-6, doi: 10.1109/CCNC.2019.8651669.\n\nHao, Y., Xu, L., Wang, X., Li, Y., Chen, G., 2019, July. Aggressive Lane-change analysis closing to intersection based on UAV video and deep learning. In: 2019 5th International Conference on Transportation Information and Safety (ICTIS). IEEE, pp. 496–502.\n\nHeintz, F., Rudol, P., Doherty, P., 2007, July. From images to traffic behavior-a uav tracking and monitoring application. In: 2007 10th International Conference on Information Fusion. IEEE, pp. 1–8.\n\nHCM, 2010. Highway capacity Manual 2010. Transportation Research Board, National Research Council, Washington, DC, 1207.\n\nIglesias L., Santos-Berbel D., Pascual V., Castro M. Using small unmanned aerial vehicle in 3D modeling of highways with tree-covered roadsides to estimate sight distance. Remote Sensing. 2019;11(22):2625. [Google Scholar]\n\nInternational Transport Forum (ITF), 2020. Drones in the Transport System: Acceptability and Integration. Accessed online on 8 September 2020, https://www.itf-oecd.org/drones-transport-system-acceptability-integration.\n\nJenkins, D., Vasigh, B., 2013. The economic impact of unmanned aircraft systems integration in the United States, AUVSI Economic Report. Accessed on May 2020, https://higherlogicdownload.s3.amazonaws.com/AUVSI/958c920a-7f9b-4ad2-9807-f9a4e95d1ef1/UploadedImages/New_Economic%20Report%202013%20Full.pdf.\n\nJoshi, D., 2019. Drone technology uses and applications for commercial, industrial and military drones in 2020 and the future. Business Insider Intelligence research report preview of Drones for the Enterprise. Accessed on May 2020, https://www.businessinsider.com/drone-technology-uses-applications?r=US&IR=T.\n\nKaraduman M., Çınar A., Eren H. UAV traffic patrolling via road detection and tracking in anonymous aerial video frames. J. Intell. Rob. Syst. 2019;95(2):675–690. [Google Scholar]\n\nKe, R., Kim, S., Li, Z., Wang, Y., 2015, October. Motion-vector clustering for traffic speed detection from UAV video. In: 2015 IEEE First International Smart Cities Conference (ISC2). IEEE, pp. 1–5.\n\nKe R., Li Z., Kim S., Ash J., Cui Z., Wang Y. Real-time bidirectional traffic flow parameter estimation from aerial videos. IEEE Trans. Intell. Transp. Syst. 2017;18(4):890–901. [Google Scholar]\n\nKe R., Li Z., Tang J., Pan Z., Wang Y. Real-time traffic flow parameter estimation from UAV video based on ensemble classifier and optical flow. IEEE Trans. Intell. Transp. Syst. 2018;20(1):54–64. [Google Scholar]\n\nKe, R., Feng, S., Cui, Z., Wang, Y., 202.0 Advanced framework for microscopic and lane-level macroscopic traffic parameters estimation from UAV video, IET Intell. Transp. Syst., 14(7), 724–734.\n\nKellermann R., Biehle T., Fischer L. Drones for parcel and passenger transportation: A literature review. Transport. Res. Interdiscip. Perspect. 2020;4 doi: 10.1016/j.trip.2019.100088. [CrossRef] [Google Scholar]\n\nKhan M.A., Ectors W., Bellemans T., Janssens D., Wets G. Unmanned aerial vehicle–based traffic analysis: Methodological framework for automated multivehicle trajectory extraction. Transp. Res. Rec. 2017;2626(1):25–33. [Google Scholar]\n\nKhan M.A., Ectors W., Bellemans T., Janssens D., Wets G. Unmanned aerial vehicle-based traffic analysis: A case study for shockwave identification and flow parameters estimation at signalized intersections. Remote Sensing. 2018;10:458. doi: 10.3390/rs10030458. [CrossRef] [Google Scholar]\n\nKhan M.A., Ectors W., Bellemans T., Ruichek Y., Yasar A.H., Janssens D., Wets G. Unmanned aerial vehicle-based traffic analysis: A case study to analyze traffic streams at urban roundabouts. Procedia Comput. Sci. 2018;130:636–643. doi: 10.1016/j.procs.2018.04.114. [CrossRef] [Google Scholar]\n\nKim N.V., Chervonenkis M.A. Situation control of unmanned aerial vehicles for road traffic monitoring. Modern Appl. Sci. 2015;9(5):1. [Google Scholar]\n\nKure, M., 2020. How drones become a valuable tool for the auto insurance industry. Frobes article, Accessed on May 2020, https://www.forbes.com/sites/sap/2020/01/29/how-drones-become-a-valuable-tool-for-the-auto-insurance-industry/#56ff18a61ac9.\n\nKnyaz V.A., Chibunichev A.G. Photogrammetric techniques for road surface analysis. Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci. 2016;41(B5):515–520. [Google Scholar]\n\nKyrkou, C., Timotheou, S., Kolios, P., Theocharides, T., Panayiotou, C.G., 2018. Optimized vision-directed deployment of UAVs for rapid traffic monitoring. In: 2018 IEEE International Conference on Consumer Electronics, ICCE 2018, 2018-Janua, 1–6. https://doi.org/10.1109/ICCE.2018.8326145.\n\nKaaniche, K., Champion, B., Pégard, C., Vasseur, P., 2005. A vision algorithm for dynamic detection of moving vehicles with a UAV. In: proceedings of the 2005 IEEE International Conference on Robotics and Automation, pp. 1878-1883.\n\nBarmpounakis, E.N., Vlahogianni, E.I., Golias, J.C., 2016a. Extracting kinematic characteristics from unmanned aerial vehicles. In: Presented in 95th Annual Meeting, Transportation Research Board, Washington DC, USA. (No. 16-3429).\n\nBraut, V., Čuljak, M., Vukotić, V., Šegvić, S., Ševrović, M., Gold, H., 2012, May. Estimating OD matrices at intersections in airborne video-a pilot study. In: 2012 Proceedings of the 35th International Convention MIPRO, pp. 977-982.\n\nLee, J., Zhong, Z., Kim, K., Dimitrijevic, B., Du, B., Gutesa, S., 2015, January. Examining the applicability of small quadcopter drone for traffic surveillance and roadway incident monitoring. In: Transportation Research Board 94th Annual Meeting, No. 15-4184, pp. 15.\n\nLeonardi, G., Barrile, V., Palamara, R., Suraci, F., Candela, G., 2018, May. 3D Mapping of Pavement Distresses Using an Unmanned Aerial Vehicle (UAV) System. In: International Symposium on New Metropolitan Perspectives. Springer, Cham, pp. 164–171.\n\nLin, P.S., Puri, A., Hagen, L., 2006. Automatic transformation of video image data from UAVs into traffic information for simulation model calibration. In: Proceedings of The 13th ITS World Congress, London, 8-12 October 2006.\n\nLi, Y., 2008. Vehicle extraction using histogram and genetic algorithm based fuzzy image segmentation from high resolution UAV aerial imagery. ISPRS08, page B3b, 529.\n\nLi Z., Cheng C., Kwan M.P., Tong X., Tian S. Identifying asphalt pavement distress using UAV LiDAR point cloud data and random forest classification. ISPRS Int. J. Geo-Inf. 2019;8(1):39. [Google Scholar]\n\nLi, Z., Cheng, C., Kwan, M.-P., Tong, X., Tian, S., 2019b. Retraction: Li et al. Identifying Asphalt Pavement Distress Using UAV LiDAR Point Cloud Data and Random Forest Classification. ISPRS Int. J. Geo-Inf. 8, 39, doi.org/10.3390/ijgi8010039.ISPRS Int. J. Geo-Inf. 8, 402.\n\nLei B., Wang N., Xu P., Song G. New crack detection method for bridge inspection using UAV incorporating image processing. J. Aerosp. Eng. 2018;31(5):04018058. [Google Scholar]\n\nLee J.K. George Mason University; 2019. UAV-based Pothole Identification: A Photogrammetric Approach (Masters dissertation) [Google Scholar]\n\nLiu S., Wang S., Shi W., Liu H., Li Z., Mao T. Vehicle tracking by detection in UAV aerial video. Science China Informat. Sci. 2019;62(2):24101. [Google Scholar]\n\nLiu X., Zou H., Niu W., Song Y., He W. Proceedings of the 2019 2nd International Conference on Sensors, Signal and Image Processing. 2019. An approach of traffic accident scene reconstruction using unmanned aerial vehicle photogrammetry; pp. 31–34. [Google Scholar]\n\nLiu X., Gao L., Guang Z., Song Y. A UAV Allocation Method for Traffic Surveillance in Sparse Road Network. J. Highway Transport. Res. Develop. (English Edition) 2013;7(2):81–87. doi: 10.1061/jhtrcq.0000319. [CrossRef] [Google Scholar]\n\nLiu, X., Gao L., Guan Z., Song Y., Zhang R., 2016. A Multi-objective optimization model for Planning Unmanned Aerial Vehicle Cruise Route, Int. J. Adv. Robotic Syst. 13(3), doi: 10.5772/64165.\n\nLiu X., Peng Z.R., Zhang L.Y. Real-time uav rerouting for traffic monitoring with decomposition based multi-objective optimization. J. Intell. Rob. Syst. 2019;94(2):491–501. [Google Scholar]\n\nLiu, Y., Bai, B., Zhang, C., 2017. UAV image mosaic for road traffic accident scene. In: 32nd Youth Academic Annual Conference of Chinese Association of Automation (YAC), Hefei, pp. 1048–1052.\n\nLucic, M.C., Ghazzai, H., Massoud, Y., 2020. A Generalized dynamic planning framework for green UAV-assisted intelligent transportation system infrastructure. IEEE Syst. J. doi: 10.1109/JSYST.2020.2969372.\n\nOtero, L.D., Gagliardo, N., Dalli, D., Huang, W.-H., Cosentino, P., 2015. Proof of concept for using unmanned aerial vehicles for high mast pole and bridge inspections (No. BDV28-977-02). Florida. Dept. of Transportation. Research Center.\n\nMehmood, S., Ahmed, S., Kristensen, A. S., Ahsan, D., 2018, May. Multi Criteria Decision Analysis (MCDA) of Unmanned Aerial Vehicles (UAVs) as a Part of Standard Response to Emergencies. In: 4th International Conference on Green Computing and Engineering Technologies; Niels Bohrs Vej 8, Esbjerg, Denmark.\n\nMenouar H., Guvenc I., Akkaya K., Uluagac A.S., Kadri A., Tuncer A. UAV-enabled intelligent transportation systems for the smart city: Applications and challenges. IEEE Commun. Mag. 2017;55(3):22–28. [Google Scholar]\n\nMersheeva, V., Friedrich, G., 2012. Routing for continuous monitoring by multiple micro uavs in disaster scenarios. In: Proceedings of the 20th European Conference on Artificial Intelligence (ECAI 2012), Montpellier, France, 27–31 August 2012; pp. 588–593.\n\nMozaffari, M., Saad, W., Bennis, M., Debbah, M., 2017. Wireless communication using unmanned aerial vehicles (UAVs): Optimal transport theory for hover time optimization. IEEE Tran. Wireless Commun. 16(12) 8052–8066.\n\nMozaffari M., Saad W., Bennis M., Nam Y.H., Debbah M. A tutorial on UAVs for wireless networks: Applications, challenges, and open problems. IEEE Commun. Surv. Tutorials. 2019;21(3):2334–2360. [Google Scholar]\n\nMualla Y., Najjar A., Daoud A., Galland S., Nicolle C., Yasar A., Shakshuki E. Agent-based simulation of unmanned aerial vehicles in civilian applications: A systematic literature review and research directions. Future Generat. Comput. Syst. 2019;100:344–364. doi: 10.1016/j.future.2019.04.051. [CrossRef] [Google Scholar]\n\nNikitas A., Michalakopoulou K., Njoya E.T., Karampatzakis D. Artificial intelligence, transport and the smart city: Definitions and dimensions of a new mobility era. Sustainability. 2020;12(7):2789. [Google Scholar]\n\nNiu, H., Gonzalez-Prelcic, N., Heath, R.W., 2018. A UAV-based traffic monitoring system-invited paper. In: 2018 IEEE 87th Vehicular Technology Conference (VTC Spring), pp. 1-5.\n\nNing Z., Yang L., Shoufeng M., Zhengbing H. Mobile traffic sensor routing in dynamic transportation systems. IEEE Trans. Intell. Transp. Syst. 2014;15:2273–2285. [Google Scholar]\n\nPham, H.Q., Camey, M., Pham, K.D., Pham, K.V., Rilett, L.R., 2020. Review of Unmanned Aerial Vehicles (UAVs) Operation and Data Collection for Driving Behavior Analysis. In: CIGOS 2019, Innovation for Sustainable Infrastructure. Springer, Singapore, pp. 1111–1116.\n\nPérez J.A., Gonçalves G.R., Rangel J.M.G., Ortega P.F. Accuracy and effectiveness of orthophotos obtained from low cost UASs video imagery for traffic accident scenes documentation. Adv. Eng. Software. 2019;132:47–54. [Google Scholar]\n\nCooner, S.A., Balke, K.N., 2000. Use of photogrammetry for investigation of traffic incident scenes (No. TX-99/4907-2,). Accessed online on May 2020, https://static.tti.tamu.edu/tti.tamu.edu/documents/4907-2.pdf.\n\nRaj, C.V., Sree, B.N., Madhavan, R., 2017, July. Vision based accident vehicle identification and scene investigation. In: 2017 IEEE Region 10 Symposium (TENSYMP). IEEE, pp. 1–5.\n\nRaj A.S.A., Palanichamy Y. An aerial intelligent relay-road side unit (AIR-RSU) framework for modern intelligent transportation system. Peer-to-Peer Networking Appl. 2020:1–22. [Google Scholar]\n\nRakha T., Gorodetsky A. Review of Unmanned Aerial System (UAS) applications in the built environment: Towards automated building inspection procedures using drones. Autom. Constr. 2018;93:252–264. doi: 10.1016/j.autcon.2018.05.002. [CrossRef] [Google Scholar]\n\nSalvo, G., Caruso, L., Scordo, A., 2014. Gap acceptance analysis in an urban intersection through a video acquired by an UAV. Recent Advances in Civil Engineering and Mechanics, 199-205. Accessed online on May 2020, http://www.wseas.us/e-library/conferences/2014/Florence/SEMOTEC/SEMOTEC-26.pdf.\n\nSchechtner K., Casullo L., Garbarczyk A., Crist P., Egeland J., 2018. (Un)certain Skies? Drones in the world of tomorrow, Corporate Partnership Board Report, International Transport Forum, Organization for Economic Co-operation and Development, Accessed online on 8 September 2020, https://www.itf-oecd.org/uncertain-skies-drones.\n\nSeo J., Duque L., Wacker J.P. Field application of UAS-based bridge inspection. Transp. Res. Rec. 2018;2672(12):72–81. [Google Scholar]\n\nSerhani, M.A., Ng, T.T., Al Falasi, A., Al Saedi, M., Al Nuaimi, F., Al Shamsi, H., 2019, July. Drone-assisted inspection for automated accident damage estimation: A Deep Learning Approach. In: 2019 Eleventh International Conference on Ubiquitous and Future Networks (ICUFN). IEEE, pp. 682–687.\n\nShaghlil, N., Khalafallah, A., 2018, March. Automating highway infrastructure maintenance using unmanned aerial vehicles. In: Construction Research Congress, pp. 2-4.\n\nSharma, V., Chen, H-C., Kumar, R., 2017. Driver behaviour detection and vehicle rating using multi-UAV coordinated vehicular networks, J. Comput. Syst. Sci., 86, 3–32.\n\nŠkorput, P., Mandžuka, S., Gregurić, M., Vrančić, M.T., 2020. Applying Unmanned Aerial Vehicles (UAV) in traffic investigation process. In: Karabegović I. (Ed.), New Technologies, Development and Application II. NT 2019. Lecture Notes in Networks and Systems, vol. 76. Springer, Cham.\n\nStöcker C., Bennett R., Nex F., Gerke M., Zevenbergen J. Review of the Current State of UAV Regulations. Remote Sensing. 2017;9:459. [Google Scholar]\n\nSu S., Liu W., Li K., Yang G., Feng C., Ming J., Yin Z. Developing an unmanned aerial vehicle-based rapid mapping system for traffic accident investigation. Aust. J. Forensic Sci. 2016;48(4):454–468. [Google Scholar]\n\nSundar, K., Rathinam, S., 2012. Route planning algorithms for unmanned aerial vehicles with refueling constraints. In: Proceedings of the American Control Conference (ACC), Montréal, Canda, 27–29 June 2012; pp. 3266–3271.\n\nTan Y., Li Y. UAV Photogrammetry-based 3D road distress detection. ISPRS Int. J. Geo-Inf. 2019;8(9):409. [Google Scholar]\n\nThemistocleous, K., Neocleous, K., Pilakoutas, K., Hadjimitsis, D. G., 2014, August. Damage assessment using advanced non-intrusive inspection methods: integration of space, UAV, GPR, and field spectroscopy. In: Second International Conference on Remote Sensing and Geoinformation of the Environment (RSCy2014), vol. 9229, International Society for Optics and Photonics, pp. 92291O.\n\nUAV Coach, 2020. Your guide to all things drones. Accessed on May 2020, https://uavcoach.com.\n\nWang W.C., Lin Y.H., Lin C.L., Chung C.H., Lee M.T. DEMATEL-based model to improve the performance in a matrix organization. Expert Syst. Appl. 2012;39(5):4978–4986. [Google Scholar]\n\nWang, H., Duan, S., Zheng, Y., Liu, S., Dong, C., Li, Y., 2014. Using model aircraft to collect vehicle trajectory data (No. 14-2801).\n\nWang L., Chen F., Yin H. Detecting and tracking vehicles in traffic by unmanned aerial vehicles. Autom. Constr. 2016;72:294–308. doi: 10.1016/j.autcon.2016.05.008. [CrossRef] [Google Scholar]\n\nWu, W., Qurishee, M. A., Owino, J., Fomunung, I., Onyango, M., Atolagbe, B., 2018, September. Coupling deep learning and UAV for infrastructure condition assessment automation. In: 2018 IEEE International Smart Cities Conference (ISC2). IEEE, pp. 1–7.\n\nXu, Y., Yu, G., Wang, Y., Wu, X., Ma, Y., 2017. Car detection from low-altitude UAV imagery with the faster R-CNN. J. Adv. Transport.\n\nYin, Z., Mao, Y., Seto, C., 2015. Develop a UAV platform for automated bridge inspection (No. 25-1121-0003-295). Mid-America Transportation Center.\n\nZhao, S., Zhang, K., Brooks, C., Banach, D., Aden, S.T., 2018. A comprehensive overview of improving traffic flow observability using UAVs as mobile sensors. In: Presented in 97th Annual Meeting, Transportation Research Board, Washington DC, USA. Paper No. 18-04949.\n\nZhang C. An UAV-based photogrammetric mapping system for road condition assessment. Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci. 2008;37:627–632. [Google Scholar]\n\nZhang C., Elaksher A. An unmanned aerial vehicle-based imaging system for 3D measurement of unpaved road surface distresses. Comput.-Aided Civ. Infrastruct. Eng. 2012;27(2):118–129. [Google Scholar]\n\nZhang, H., Liptrott, M., Bessis, N., Cheng, J., 2019, September. Real-time traffic analysis using deep learning techniques and UAV based video. In: 2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, pp. 1–5.\n\nZhang, L., Peng, Z., Sun, D., Liu, X., 2013. A UAV-based automatic traffic incident detection system for low volume roads. In: Presented in 92nd Annual Meeting, Transportation Research Board, Washington DC, USA. Paper No. 13-4724.\n\nZhang J., Jia L., Niu S., Zhang F., Tong L., Zhou X. A space-time network-based modeling framework for dynamic unmanned aerial vehicle routing in traffic incident monitoring applications. Sensors. 2015;15(6):13874–13898. [PMC free article] [PubMed] [Google Scholar]\n\nZhu J., Sun K., Jia S., Li Q., Hou X., Lin W., Qiu G. Urban traffic density estimation based on ultrahigh-resolution uav video and deep neural network. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2018;11(12):4968–4981. [Google Scholar]\n\nZink, J., Lovelace, B., 2015. Unmanned aerial vehicle bridge inspection demonstration project. Research Project. Final Report, 40. Accessed on May 2020 http://www.dot.state.mn.us/research/TS/2015/201540.pdf.\n\nZulkipli M.A., Tahar K.N. Multirotor UAV-based photogrammetric mapping for road design. Int. J. Opt. 2018 doi: 10.1155/2018/1871058. [CrossRef] [Google Scholar]\n\nArticles from Transportation Research. Part A, Policy and Practice are provided here courtesy of Elsevier"
    }
}