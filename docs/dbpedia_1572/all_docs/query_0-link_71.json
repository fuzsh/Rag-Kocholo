{
    "id": "dbpedia_1572_0",
    "rank": 71,
    "data": {
        "url": "https://dl.acm.org/doi/abs/10.1145/3660043.3660158",
        "read_more_link": "",
        "language": "en",
        "title": "Deep Reinforcement Learning Unmanned Aerial Vehicle Autonomous Cruise System with Fusion of Visual Information",
        "top_image": "https://dl.acm.org/cms/asset/6a9156fc-37bb-4fd3-8239-341c35280844/3660043.cover.jpg",
        "meta_img": "https://dl.acm.org/cms/asset/6a9156fc-37bb-4fd3-8239-341c35280844/3660043.cover.jpg",
        "images": [
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-dl-logo-white-1ecfb82271e5612e8ca12aa1b1737479.png",
            "https://dl.acm.org/doi/abs/10.1145/specs/products/acm/releasedAssets/images/acm-logo-1-ad466e729c8e2a97780337b76715e5cf.png",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/footer-logo1-45ae33115db81394d8bd25be65853b77.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/Default_image_lazy-0687af31f0f1c8d4b7a22b686995ab9b.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-dl-8437178134fce530bc785276fc316cbf.png",
            "https://dl.acm.org/specs/products/acm/releasedAssets/images/acm-logo-3-10aed79f3a6c95ddb67053b599f029af.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Wuhan University of Technology",
            "China https:",
            "orcid.org",
            "Rui Liu",
            "Ying Shi",
            "Yufei Xie"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "/pb-assets/head-metadata/apple-touch-icon-1574252172393.png",
        "meta_site_name": "ACM Other conferences",
        "canonical_link": "https://dl.acm.org/doi/10.1145/3660043.3660158",
        "text": "Abstract\n\nUAV have a wide range of applications in military, aviation, agriculture, logistics, and other fields. However, when conducting real drone testing, there are high costs, safety risks, and environmental impacts.In this case, the virtual simulation scheme of UAV automatic cruise based on Airsim in Unreal urban environment proposed in this article can provide an economical and reliable solution, which has broad application prospects in the field of UAV research and development.This scheme utilizes the open-source cross platform simulator provided by Airsim to simulate real urban environmental scene information. By inputting UAV parameters and actual environmental data into the simulation system, it can simulate the real UAV flight and control process, effectively test and verify the performance and algorithm of the UAV.Meanwhile, virtual simulation can also easily replicate and adjust experimental results, improving testing efficiency and data reliability.The advantages of this paper are as follows: 1. Visual information coding strategy is integrated into deep reinforcement learning algorithm, which solves the defects of traditional algorithm in processing visual information to a certain extent. 2. A multi-information fusion Reward function based on distance reward, position-angle-deviation punishment and obstacle avoidance items is designed and introduced, which can make UAV adapt to more complex and changeable physical environment.\n\nReferences\n\n[1]\n\nWu Y, Wu S M, Zhang D J. 2013. Designing and Realizing of UAV Simulation System [J]. Applied Mechanics and Materials, 2240(284-287): 3401-3404. https://doi.org/10.4028/www.scientific.net/AMM.284-287.3401.\n\n[2]\n\nJonatan A, Assia B, Faiza B. 2023. Forest Fire Localization: From Reinforcement Learning Exploration to a Dynamic Drone Control [J]. Journal of Intelligent Robotic Systems, 109(4). https://doi.org/10.1007/s10846-023-02004-z.\n\n[3]\n\nYahao X, Yiran W, Keyang J. 2023. Multiple UAVs Path Planning Based on Deep Reinforcement Learning in Communication Denial Environment [J]. Mathematics, 11(2): 405-405. https://doi.org/10.3390/math11020405.\n\n[4]\n\nChen Y. 2023. Study on Flight Attitude Control of Four-rotor UAV [J]. Advances in Computer, Signals and Systems, 7(9). https://doi.org/ 10.23977/acss.2023.070904.\n\n[5]\n\nYuxiang Z, Jiansheng S, Hui H. UAV 3D online track planning based on improved SAC algorithm [J]. Journal of the Brazilian Society of Mechanical Sciences and Engineering, 2023, 46(1). https://doi.org/10.1007/s40430-023-04570-7.\n\n[6]\n\nYunyan Z, Yao W, Hao L. 2022. End-to-end UAV obstacle avoidance decision based on deep reinforcement learning [J]. Journal of Northwestern Polytechnical University, 40(5): 1055-1064. https://doi.org/10.1051/jnwpu/20224051055.\n\n[7]\n\nRăzvanIonuț B, Ciprian M B, Cătălin I. 2022. A Proximal Policy Optimization Reinforcement Learning Approachto Unmanned Aerial Vehicles Attitude Control [J]. Land Forces Academy Review, 27(4): 400-410. https://doi.org/10.2478/raft-2022-0049.\n\nIndex Terms\n\nDeep Reinforcement Learning Unmanned Aerial Vehicle Autonomous Cruise System with Fusion of Visual Information\n\nApplied computing\n\nElectronic commerce\n\nComputer systems organization\n\nDependable and fault-tolerant systems and networks\n\nFault-tolerant network topologies\n\nComputing methodologies\n\nArtificial intelligence\n\nControl methods\n\nRobotic planning\n\nRecommendations\n\nControl system of unmanned aerial vehicle used for endurance autonomous monitoring\n\nThe paper purpose is to present some aspects regarding the control system of unmanned aerial vehicle - UAV, used to local observations, surveillance and monitoring interest area. The calculus methodology allows a numerical simulation of UAV evolution in ...\n\nGuidance and nonlinear control system for autonomous flight of minirotorcraft unmanned aerial vehicles\n\nSmall unmanned aerial vehicles (UAVs) are becoming popular among researchers and vital platforms for several autonomous mission systems. In this paper, we present the design and development of a miniature autonomous rotorcraft weighing less than 700 g ...\n\nInformation-Measuring System for Unmanned Aerial Vehicle Payload Control\n\nAbstract\n\nThe features of payload control are indicated on the example of an unmanned aerial vehicle equipped with an onboard radar station, when it directly approaches a small, high-speed, and maneuvering air object. Algorithms are developed that are used ...\n\nInformation & Contributors\n\nInformation\n\nPublished In\n\n1132 pages\n\nISBN:9798400716157\n\nDOI:10.1145/3660043\n\nCopyright © 2023 ACM.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from [email protected].\n\nPublisher\n\nAssociation for Computing Machinery\n\nNew York, NY, United States\n\nPublication History\n\nPublished: 30 May 2024\n\nPermissions\n\nRequest permissions for this article.\n\nCheck for updates\n\nQualifiers\n\nResearch-article\n\nResearch\n\nRefereed limited\n\nConference\n\nICIEAI 2023\n\nContributors\n\nOther Metrics\n\nBibliometrics & Citations\n\nBibliometrics\n\nArticle Metrics\n\n0\n\nTotal Citations\n\n4\n\nTotal Downloads\n\nDownloads (Last 12 months)4\n\nDownloads (Last 6 weeks)0\n\nOther Metrics\n\nCitations\n\nView Options\n\nGet Access\n\nLogin options\n\nCheck if you have access through your login credentials or your institution to get full access on this article.\n\nSign in\n\nFull Access\n\nView options\n\nPDF\n\nView or Download as a PDF file.\n\nPDF\n\neReader\n\nView online with eReader.\n\neReader\n\nHTML Format\n\nView this article in HTML Format.\n\nHTML Format\n\nMedia\n\nFigures\n\nOther\n\nTables\n\nShare\n\nShare\n\nShare this Publication link\n\nCopied!\n\nCopying failed.\n\nShare on social media\n\nAffiliations\n\nRui Liu\n\nSchool of Automation, Wuhan University of Technology, China\n\nYing Shi\n\nSchool of Automation, Wuhan University of Technology, China\n\nYufei Xie\n\nSchool of Automation, Wuhan University of Technology, China\n\nRequest permissions Authors Info & Affiliations"
    }
}