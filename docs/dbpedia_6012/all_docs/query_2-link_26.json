{
    "id": "dbpedia_6012_2",
    "rank": 26,
    "data": {
        "url": "https://www.ojp.gov/ncjrs/virtual-library/abstracts/regularization-based-learning-choquet-integral",
        "read_more_link": "",
        "language": "en",
        "title": "Regularization-based learning of the Choquet integral",
        "top_image": "https://www.ojp.gov/sites/g/files/xyckuh241/files/images/2020-02/ojp_og.png",
        "meta_img": "https://www.ojp.gov/sites/g/files/xyckuh241/files/images/2020-02/ojp_og.png",
        "images": [
            "https://www.ojp.gov/themes/custom/ojp/assets/dist/img/us_flag_small.png",
            "https://www.ojp.gov/themes/custom/ojp/assets/dist/img/icon-dot-gov.svg",
            "https://www.ojp.gov/themes/custom/ojp/assets/dist/img/icon-https.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/OJP-seal.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/ojp-site-logo-no-seal_white.svg?v=1",
            "https://www.ojp.gov/themes/custom/ojp/assets/dist/img/close-white.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/ojp-full.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/bja.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/bjs.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/nij.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/ojjdp.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/ovc.svg",
            "https://www.ojp.gov/themes/custom/ojp/ojp_patternlab/source/images/ojp/smart.svg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "In this paper, the authors discuss a regularization approach to learning the fuzzy measure for the Choquet fuzzy integral; discuss the mathematical motivation for such an approach, as well as its applicability, impact, and desirable properties; and show that it is possible to reduce the effect of overfitting as well as to force the learning of fewer numbers of sources.",
        "meta_lang": "en",
        "meta_favicon": "/themes/custom/ojp/ojp_patternlab/source/images/ojp/favicon.png",
        "meta_site_name": "Office of Justice Programs",
        "canonical_link": "https://www.ojp.gov/ncjrs/virtual-library/abstracts/regularization-based-learning-choquet-integral",
        "text": "In this paper, the authors discuss a regularization approach to learning the fuzzy measure for the Choquet fuzzy integral; discuss the mathematical motivation for such an approach, as well as its applicability, impact, and desirable properties; and show that it is possible to reduce the effect of overfitting as well as to force the learning of fewer numbers of sources.\n\nA number of data-driven fuzzy measure (FM) learning techniques have been put forth for the fuzzy integral (FI). Examples include quadratic programming, Gibbs sampling, gradient descent, reward and punishment and evolutionary optimization. However, most approaches focus solely on the minimization of the sum of squared error (SSE). Limited attention has been placed on characterizing and subsequently minimizing model (i.e., FM) complexity. Furthermore, the vast majority of learning techniques are highly susceptible to over-fitting and noise. Herein, the authors explore a regularization approach to learning the FM for the Choquet FI. They investigate the mathematical motivation for such an approach, its applicability and impact on different types of FMs, and its desirable properties for quadratic programming (QP) based optimization. The authors show that L\\ regularization has a distinct meaning for measure learning and aggregation operators. Experiments are performed and validated with respect to the Shapley index. Specifically, they show that it is possible to reduce the effect of overfitting, and they can identify higher quality measures and, if desired, force the learning of fewer numbers of sources. (Published Abstracts Provided)"
    }
}