{
    "id": "dbpedia_3368_3",
    "rank": 43,
    "data": {
        "url": "https://www.science.gov/topicpages/s/scientific%2Bimpact%2Bmeasures",
        "read_more_link": "",
        "language": "en",
        "title": "scientific impact measures: Topics by Science.gov",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.science.gov/scigov/desktop/en/images/SciGov_logo.png"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "A Principal Component Analysis of 39 Scientific Impact Measures\n\nPubMed Central\n\nBollen, Johan; Van de Sompel, Herbert\n\n2009-01-01\n\nBackground The impact of scientific publications has traditionally been expressed in terms of citation counts. However, scientific activity has moved online over the past decade. To better capture scientific impact in the digital era, a variety of new impact measures has been proposed on the basis of social network analysis and usage log data. Here we investigate how these new measures relate to each other, and how accurately and completely they express scientific impact. Methodology We performed a principal component analysis of the rankings produced by 39 existing and proposed measures of scholarly impact that were calculated on the basis of both citation and usage log data. Conclusions Our results indicate that the notion of scientific impact is a multi-dimensional construct that can not be adequately measured by any single indicator, although some measures are more suitable than others. The commonly used citation Impact Factor is not positioned at the core of this construct, but at its periphery, and should thus be used with caution. PMID:19562078\n\nMeasuring scientific impact beyond academia: An assessment of existing impact metrics and proposed improvements.\n\nPubMed\n\nRavenscroft, James; Liakata, Maria; Clare, Amanda; Duma, Daniel\n\n2017-01-01\n\nHow does scientific research affect the world around us? Being able to answer this question is of great importance in order to appropriately channel efforts and resources in science. The impact by scientists in academia is currently measured by citation based metrics such as h-index, i-index and citation counts. These academic metrics aim to represent the dissemination of knowledge among scientists rather than the impact of the research on the wider world. In this work we are interested in measuring scientific impact beyond academia, on the economy, society, health and legislation (comprehensive impact). Indeed scientists are asked to demonstrate evidence of such comprehensive impact by authoring case studies in the context of the Research Excellence Framework (REF). We first investigate the extent to which existing citation based metrics can be indicative of comprehensive impact. We have collected all recent REF impact case studies from 2014 and we have linked these to papers in citation networks that we constructed and derived from CiteSeerX, arXiv and PubMed Central using a number of text processing and information retrieval techniques. We have demonstrated that existing citation-based metrics for impact measurement do not correlate well with REF impact results. We also consider metrics of online attention surrounding scientific works, such as those provided by the Altmetric API. We argue that in order to be able to evaluate wider non-academic impact we need to mine information from a much wider set of resources, including social media posts, press releases, news articles and political debates stemming from academic work. We also provide our data as a free and reusable collection for further analysis, including the PubMed citation network and the correspondence between REF case studies, grant applications and the academic literature.\n\nMeasuring scientific impact beyond academia: An assessment of existing impact metrics and proposed improvements\n\nPubMed Central\n\nLiakata, Maria; Clare, Amanda; Duma, Daniel\n\n2017-01-01\n\nHow does scientific research affect the world around us? Being able to answer this question is of great importance in order to appropriately channel efforts and resources in science. The impact by scientists in academia is currently measured by citation based metrics such as h-index, i-index and citation counts. These academic metrics aim to represent the dissemination of knowledge among scientists rather than the impact of the research on the wider world. In this work we are interested in measuring scientific impact beyond academia, on the economy, society, health and legislation (comprehensive impact). Indeed scientists are asked to demonstrate evidence of such comprehensive impact by authoring case studies in the context of the Research Excellence Framework (REF). We first investigate the extent to which existing citation based metrics can be indicative of comprehensive impact. We have collected all recent REF impact case studies from 2014 and we have linked these to papers in citation networks that we constructed and derived from CiteSeerX, arXiv and PubMed Central using a number of text processing and information retrieval techniques. We have demonstrated that existing citation-based metrics for impact measurement do not correlate well with REF impact results. We also consider metrics of online attention surrounding scientific works, such as those provided by the Altmetric API. We argue that in order to be able to evaluate wider non-academic impact we need to mine information from a much wider set of resources, including social media posts, press releases, news articles and political debates stemming from academic work. We also provide our data as a free and reusable collection for further analysis, including the PubMed citation network and the correspondence between REF case studies, grant applications and the academic literature. PMID:28278243\n\nMeasuring Academic Productivity and Changing Definitions of Scientific Impact\n\nPubMed Central\n\nSarli, Cathy C.; Carpenter, Christopher R.\n\n2016-01-01\n\nThis manuscript provides a brief overview of the history of communication of scientific research and reporting of scientific research impact outcomes. Current day practices are outlined along with examples of how organizations and libraries are providing tools to evaluate and document the impact of scientific research to provide a meaningful narrative suitable for a variety of purposes and audiences. PMID:25438359\n\nMeasuring co-authorship and networking-adjusted scientific impact.\n\nPubMed\n\nIoannidis, John P A\n\n2008-07-23\n\nAppraisal of the scientific impact of researchers, teams and institutions with productivity and citation metrics has major repercussions. Funding and promotion of individuals and survival of teams and institutions depend on publications and citations. In this competitive environment, the number of authors per paper is increasing and apparently some co-authors don't satisfy authorship criteria. Listing of individual contributions is still sporadic and also open to manipulation. Metrics are needed to measure the networking intensity for a single scientist or group of scientists accounting for patterns of co-authorship. Here, I define I(1) for a single scientist as the number of authors who appear in at least I(1) papers of the specific scientist. For a group of scientists or institution, I(n) is defined as the number of authors who appear in at least I(n) papers that bear the affiliation of the group or institution. I(1) depends on the number of papers authored N(p). The power exponent R of the relationship between I(1) and N(p) categorizes scientists as solitary (R>2.5), nuclear (R = 2.25-2.5), networked (R = 2-2.25), extensively networked (R = 1.75-2) or collaborators (R<1.75). R may be used to adjust for co-authorship networking the citation impact of a scientist. I(n) similarly provides a simple measure of the effective networking size to adjust the citation impact of groups or institutions. Empirical data are provided for single scientists and institutions for the proposed metrics. Cautious adoption of adjustments for co-authorship and networking in scientific appraisals may offer incentives for more accountable co-authorship behaviour in published articles.\n\nScientific impact: opportunity and necessity.\n\nPubMed\n\nCohen, Marlene Z; Alexander, Gregory L; Wyman, Jean F; Fahrenwald, Nancy L; Porock, Davina; Wurzbach, Mary E; Rawl, Susan M; Conn, Vicki S\n\n2010-08-01\n\nRecent National Institutes of Health changes have focused attention on the potential scientific impact of research projects. Research with the excellent potential to change subsequent science or health care practice may have high scientific impact. Only rigorous studies that address highly significant problems can generate change. Studies with high impact may stimulate new research approaches by changing understanding of a phenomenon, informing theory development, or creating new research methods that allow a field of science to move forward. Research with high impact can transition health care to more effective and efficient approaches. Studies with high impact may propel new policy developments. Research with high scientific impact typically has both immediate and sustained influence on the field of study. The article includes ideas to articulate potential scientific impact in grant applications as well as possible dissemination strategies to enlarge the impact of completed projects.\n\nQuantifying the evolution of individual scientific impact.\n\nPubMed\n\nSinatra, Roberta; Wang, Dashun; Deville, Pierre; Song, Chaoming; BarabÃ¡si, Albert-LÃ¡szlÃ³\n\n2016-11-04\n\nDespite the frequent use of numerous quantitative indicators to gauge the professional impact of a scientist, little is known about how scientific impact emerges and evolves in time. Here, we quantify the changes in impact and productivity throughout a career in science, finding that impact, as measured by influential publications, is distributed randomly within a scientist's sequence of publications. This random-impact rule allows us to formulate a stochastic model that uncouples the effects of productivity, individual ability, and luck and unveils the existence of universal patterns governing the emergence of scientific success. The model assigns a unique individual parameter Q to each scientist, which is stable during a career, and it accurately predicts the evolution of a scientist's impact, from the h-index to cumulative citations, and independent recognitions, such as prizes. Copyright Â© 2016, American Association for the Advancement of Science.\n\nScientific impact: the story of your big hit\n\nNASA Astrophysics Data System (ADS)\n\nSinatra, Roberta; Wang, Dashun; Deville, Pierre; Song, Chaoming; Barabasi, Albert-Laszlo\n\n2014-03-01\n\nA gradual increase in performance through learning and practice characterize most trades, from sport to music or engineering, and common sense suggests this to be true in science as well. This prompts us to ask: what are the precise patterns that lead to scientific excellence? Does performance indeed improve throughout a scientific career? Are there quantifiable signs of an impending scientific hit? Using citation-based measures as a proxy of impact, we show that (i) major discoveries are not preceded by works of increasing impact, nor are followed by work of higher impact, (ii) the precise time ranking of the highest impact work in a scientist's career is uniformly random, with the higher probability to have a major discovery in the middle of scientific careers being due only to changes in productivity, (iii) there is a strong correlation between the highest impact work and average impact of a scientist's work. These findings suggest that the impact of a paper is drawn randomly from an impact distribution that is unique for each scientist. We present a model which allows to reconstruct the individual impact distribution, making possible to create synthetic careers that exhibit the same properties of the real data and to define a ranking based on the overall impact of a scientist. RS acknowledges support from the James McDonnell Foundation.\n\nAuthor Impact Factor: tracking the dynamics of individual scientific impact\n\nNASA Astrophysics Data System (ADS)\n\nPan, Raj Kumar; Fortunato, Santo\n\n2014-05-01\n\nThe impact factor (IF) of scientific journals has acquired a major role in the evaluations of the output of scholars, departments and whole institutions. Typically papers appearing in journals with large values of the IF receive a high weight in such evaluations. However, at the end of the day one is interested in assessing the impact of individuals, rather than papers. Here we introduce Author Impact Factor (AIF), which is the extension of the IF to authors. The AIF of an author A in year t is the average number of citations given by papers published in year t to papers published by A in a period of Ît years before year t. Due to its intrinsic dynamic character, AIF is capable to capture trends and variations of the impact of the scientific output of scholars in time, unlike the h-index, which is a growing measure taking into account the whole career path.\n\nDeveloping a Test of Scientific Literacy Skills (TOSLS): measuring undergraduates' evaluation of scientific information and arguments.\n\nPubMed\n\nGormally, Cara; Brickman, Peggy; Lutz, Mary\n\n2012-01-01\n\nLife sciences faculty agree that developing scientific literacy is an integral part of undergraduate education and report that they teach these skills. However, few measures of scientific literacy are available to assess students' proficiency in using scientific literacy skills to solve scenarios in and beyond the undergraduate biology classroom. In this paper, we describe the development, validation, and testing of the Test of Scientific Literacy Skills (TOSLS) in five general education biology classes at three undergraduate institutions. The test measures skills related to major aspects of scientific literacy: recognizing and analyzing the use of methods of inquiry that lead to scientific knowledge and the ability to organize, analyze, and interpret quantitative data and scientific information. Measures of validity included correspondence between items and scientific literacy goals of the National Research Council and Project 2061, findings from a survey of biology faculty, expert biology educator reviews, student interviews, and statistical analyses. Classroom testing contexts varied both in terms of student demographics and pedagogical approaches. We propose that biology instructors can use the TOSLS to evaluate their students' proficiencies in using scientific literacy skills and to document the impacts of curricular reform on students' scientific literacy.\n\nDeveloping a Test of Scientific Literacy Skills (TOSLS): Measuring Undergraduatesâ Evaluation of Scientific Information and Arguments\n\nPubMed Central\n\nGormally, Cara; Brickman, Peggy; Lutz, Mary\n\n2012-01-01\n\nLife sciences faculty agree that developing scientific literacy is an integral part of undergraduate education and report that they teach these skills. However, few measures of scientific literacy are available to assess studentsâ proficiency in using scientific literacy skills to solve scenarios in and beyond the undergraduate biology classroom. In this paper, we describe the development, validation, and testing of the Test of Scientific Literacy Skills (TOSLS) in five general education biology classes at three undergraduate institutions. The test measures skills related to major aspects of scientific literacy: recognizing and analyzing the use of methods of inquiry that lead to scientific knowledge and the ability to organize, analyze, and interpret quantitative data and scientific information. Measures of validity included correspondence between items and scientific literacy goals of the National Research Council and Project 2061, findings from a survey of biology faculty, expert biology educator reviews, student interviews, and statistical analyses. Classroom testing contexts varied both in terms of student demographics and pedagogical approaches. We propose that biology instructors can use the TOSLS to evaluate their studentsâ proficiencies in using scientific literacy skills and to document the impacts of curricular reform on studentsâ scientific literacy. PMID:23222832\n\nCurrent Scientific Progress and Future Scientific Prospects Enabled by Spaceborne Precipitation Radar Measurements\n\nNASA Technical Reports Server (NTRS)\n\nSmith, Eric A.; Im, Eastwood; Tripoli, Gregory J.; Yang, Song\n\n2008-01-01\n\nFirst, we examine current scientific progress and understanding that have been possible through use of spaceborne precipitation radar measurements being provided by the TRMM and CloudSat satellites. Second, we look across a future 20-year time frame to assess how and why anticipated improvements in space radar systems will further advance scientific progress into topic areas once considered beyond the realm of space-based remote sensing. JAXA's 13.8 GHz Ku-band cross-track scanning Precipitation Radar (PR) developed for flight on NASA's non-sun-synchronous, diurnally-precessing TRMM satellite, was the first Earth radar flown in space that was designed specifically for precipitation measurement. Its proven accuracy in measuring global rainfall in the tropics and sub-tropics and its unanticipated longevity in continuing these measurements beyond a full decade have established the standards against which all follow-up and future space radars will be evaluated. In regards to the current PR measurement time series, we will discuss a selection of major scientific discoveries and impacts which have set the stage for future radar measuring systems. In fact, the 2nd contemporary space radar applicable for terrestrial precipitation measurement, i.e., JPL-CSA's 94 GHz nadir-staring Cloud Profiling Radar (CPR) flown on NASA's sun-synchronous CloudSat satellite, although designed primarily for measurement of non-precipitating cloud hydrometeors and aerosols, has also unquestionably advanced precipitation measurement because CPR's higher frequency and greatly increased sensitivity (approximately 30 dBZ) has enabled global observations of light rain rate spectrum processes (i.e., rain rates below 0.05 mm per hourand of precipitation processes in the high troposphere (particularly ice phase processes). These processes are beyond reach of the TRMM radar because the PR sensitivity limit is approximately 17 dBZ which means its lower rain rate cutoff is around 0.3 mm per hour and its\n\nFacilitymetrics for Big Ocean Science: Towards Improved Measurement of Scientific Impact\n\nNASA Astrophysics Data System (ADS)\n\nJuniper, K.; Owens, D.; Moran, K.; Pirenne, B.; Hallonsten, O.; Matthews, K.\n\n2016-12-01\n\nCabled ocean observatories are examples of \"Big Science\" facilities requiring significant public investments for installation and ongoing maintenance. Large observatory networks in Canada and the United States, for example, have been established after extensive up-front planning and hundreds of millions of dollars in start-up costs. As such, they are analogous to particle accelerators and astronomical observatories, which may often be required to compete for public funding in an environment of ever-tightening national science budget allocations. Additionally, the globalization of Big Science compels these facilities to respond to increasing demands for demonstrable productivity, excellence and competitiveness. How should public expenditures on \"Big Science\" facilities be evaluated and justified in terms of benefits to the countries that invest in them? Published literature counts are one quantitative measure often highlighted in the annual reports of large science facilities. But, as recent research has demonstrated, publication counts can lead to distorted characterizations of scientific impact, inviting evaluators to calculate scientific outputs in terms of costs per publicationâa ratio that can be simplistically misconstrued to conclude Big Science is wildly expensive. Other commonly promoted measurements of Big Science facilities include technical reliability (a.k.a. uptime), provision of training opportunities for Highly Qualified Personnel, generation of commercialization opportunities, and so forth. \"Facilitymetrics\" is a new empirical focus for scientometrical studies, which has been applied to the evaluation and comparison of synchrotron facilities. This paper extends that quantitative and qualitative examination to a broader inter-disciplinary comparison of Big Science facilities in the ocean science realm to established facilities in the fields of astronomy and particle physics.\n\nFacilitymetrics for Big Ocean Science: Towards Improved Measurement of Scientific Impact\n\nNASA Astrophysics Data System (ADS)\n\nJuniper, K.; Owens, D.; Moran, K.; Pirenne, B.; Hallonsten, O.; Matthews, K.\n\n2016-02-01\n\nCabled ocean observatories are examples of \"Big Science\" facilities requiring significant public investments for installation and ongoing maintenance. Large observatory networks in Canada and the United States, for example, have been established after extensive up-front planning and hundreds of millions of dollars in start-up costs. As such, they are analogous to particle accelerators and astronomical observatories, which may often be required to compete for public funding in an environment of ever-tightening national science budget allocations. Additionally, the globalization of Big Science compels these facilities to respond to increasing demands for demonstrable productivity, excellence and competitiveness. How should public expenditures on \"Big Science\" facilities be evaluated and justified in terms of benefits to the countries that invest in them? Published literature counts are one quantitative measure often highlighted in the annual reports of large science facilities. But, as recent research has demonstrated, publication counts can lead to distorted characterizations of scientific impact, inviting evaluators to calculate scientific outputs in terms of costs per publicationâa ratio that can be simplistically misconstrued to conclude Big Science is wildly expensive. Other commonly promoted measurements of Big Science facilities include technical reliability (a.k.a. uptime), provision of training opportunities for Highly Qualified Personnel, generation of commercialization opportunities, and so forth. \"Facilitymetrics\" is a new empirical focus for scientometrical studies, which has been applied to the evaluation and comparison of synchrotron facilities. This paper extends that quantitative and qualitative examination to a broader inter-disciplinary comparison of Big Science facilities in the ocean science realm to established facilities in the fields of astronomy and particle physics.\n\nNew Observational Technologies Scientific and Societal Impacts\n\nNASA Astrophysics Data System (ADS)\n\nFabry, F.; Zawadzki, I.\n\nINTRODUCTION REMOTE SENSING OF THE ATMOSPHERE REMOTE SENSORS AND THEIR SCIENTIFIC IMPACTS Air Temperature and Moisture Clouds and Precipitation Wind Others Related Scientific Considerations SOCIETAL IMPACTS CONCLUSIONS REFERENCES\n\nBig Science vs. Little Science: How Scientific Impact Scales with Funding.\n\nPubMed\n\nFortin, Jean-Michel; Currie, David J\n\n2013-01-01\n\nis it more effective to give large grants to a few elite researchers, or small grants to many researchers? Large grants would be more effective only if scientific impact increases as an accelerating function of grant size. Here, we examine the scientific impact of individual university-based researchers in three disciplines funded by the Natural Sciences and Engineering Research Council of Canada (NSERC). We considered four indices of scientific impact: numbers of articles published, numbers of citations to those articles, the most cited article, and the number of highly cited articles, each measured over a four-year period. We related these to the amount of NSERC funding received. Impact is positively, but only weakly, related to funding. Researchers who received additional funds from a second federal granting council, the Canadian Institutes for Health Research, were not more productive than those who received only NSERC funding. Impact was generally a decelerating function of funding. Impact per dollar was therefore lower for large grant-holders. This is inconsistent with the hypothesis that larger grants lead to larger discoveries. Further, the impact of researchers who received increases in funding did not predictably increase. We conclude that scientific impact (as reflected by publications) is only weakly limited by funding. We suggest that funding strategies that target diversity, rather than \"excellence\", are likely to prove to be more productive.\n\nResearchGate is no longer reliable: leniency towards ghost journals may decrease its impact on the scientific community.\n\nPubMed\n\nMemon, Aamir Raoof\n\n2016-12-01\n\nResearchGate has been regarded as one of the most attractive academic social networking site for scientific community. It has been trying to improve user-centered interfaces to gain more attractiveness to scientists around the world. Display of journal related scietometric measures (such as impact factor, 5-year impact, cited half-life, eigenfactor) is an important feature in ResearchGate. Open access publishing has added more to increased visibility of research work and easy access to information related to research. Moreover, scientific community has been much interested in promoting their work and exhibiting its impact to others through reliable scientometric measures. However, with the growing market of publications and improvements in the field of research, this community has been victimized by the cybercrime in the form of ghost journals, fake publishers and magical impact measures. Particularly, ResearchGate more recently, has been lenient in its policies against this dark side of academic writing. Therefore, this communication aims to discuss concerns associated with leniency in ResearchGate policies and its impact of scientific community.\n\nNREL Briefs Congressional Committee on Impact of Scientific Innovations on\n\nScience.gov Websites\n\nTransportation Future | News | NREL Briefs Congressional Committee on Impact of Scientific Innovations on Transportation Future NREL Briefs Congressional Committee on Impact of Scientific Innovations impact of new technologies will indeed be wide-ranging, it is also true that vehicles with conventional\n\nThe Non-Impact of Scientific Reviews of Oil Sands Environmental Impact Assessments\n\nNASA Astrophysics Data System (ADS)\n\nKienzle, S. W.; Byrne, J.\n\n2008-12-01\n\nSchindler (Science, Vol. 192: 509; 1976) stated that Environmental Impact Assessments authors \"conduct the studies regardless of how quickly results are demanded, write large, diffuse reports containing reams of uninterpreted and incomplete descriptive data, and in some cases, construct \"predictive\" models, irrespective of the quality of the data base.\" Schindler offered a solution: \"If we are to protect both our resources and scientific integrity, environmental scientists must seek to put their studies on a scientifically credible basis-to see that problems, terms of reference, funding, time constraints, reports, and conclusions are all within a bona fide scientific framework.\" When the first scientific panel was formed in 2003 by the Mikisew Cree First Nations (MCFN), Alberta, to objectively review EIAs of proposed oil sands mining projects, the scientific panel uncovered many severe omissions, errors, and a significant lack of substance that could not withstand scientific scrutiny. Neither the Terms of Reference for two major oilsands projects, estimated to be worth approximately CND 15 billion, nor the EIAs (one single EIA was over 11,000 pages long) contained the terms \"climate change\", \"trend analysis\", or \"risk analysis\", and nearly all environmental impacts were described by the proponents as \"negligible\". The Hydrology Section (over 950 pages in length) of one EIA did not contain a single peer-reviewed scientific publication. In summary, nothing had changed since Schindler's observations 27 years earlier. Since 2003, the authors have reviewed more than a dozen EIAs of proposed oilsands projects in northern Alberta. The \"non-impact\" of scientific reviews on the quality of EIAs and the insincerity of the stewards of the land are very sobering: apart from cosmetic improvements in the requirements of the Terms of Reference and the writing of the EIAs, no meaningful improvement of scientific content has been made. Key environmental concerns around water\n\nZebrafish in Brazilian Science: Scientific Production, Impact, and Collaboration.\n\nPubMed\n\nGheno, Ediane Maria; Rosemberg, Denis Broock; Souza, Diogo Onofre; CalabrÃ³, Luciana\n\n2016-06-01\n\nBy means of scientometric indicators, this study investigated the characteristics of scientific production and research collaboration involving zebrafish (Danio rerio) in Brazilian Science indexed by the Web of Science (WoS). Citation data were collected from the WoS and data regarding Impact Factor (IF) were gathered from journals in the Journal Citation Reports. Collaboration was evaluated according to coauthorship data, creating representative nets with VOSviewer. Zebrafish has attained remarkable importance as an experimental model organism in recent years and an increase in scientific production with zebrafish is observed in Brazil and around the world. The citation impact of the worldwide scientific production is superior when compared to the Brazilian scientific production. However, the citation impact of the Brazilian scientific production is consistently increasing. Brazil does not follow the international trends with regard to publication research fields. The state of Rio Grande do Sul has the greatest number of articles and the institution with the largest number of publications is PontifÃ­cia Universidade CatÃ³lica do Rio Grande do Sul. Journals' average IF is higher in Brazilian publications with international coauthorship, and around 90% of articles are collaborative. The Brazilian institutions presenting the greatest number of collaborations are PontifÃ­cia Universidade CatÃ³lica do Rio Grande do Sul, Universidade Federal do Rio Grande do Sul, FundaÃ§Ã£o Universidade Federal de Rio Grande, and Universidade de SÃ£o Paulo. These data indicate that Brazilian research using zebrafish presents a growth in terms of number of publications, citation impact, and collaborative work.\n\nZebrafish in Brazilian Science: Scientific Production, Impact, and Collaboration\n\nPubMed Central\n\nGheno, Ediane Maria; Rosemberg, Denis Broock; Souza, Diogo Onofre\n\n2016-01-01\n\nAbstract By means of scientometric indicators, this study investigated the characteristics of scientific production and research collaboration involving zebrafish (Danio rerio) in Brazilian Science indexed by the Web of Science (WoS). Citation data were collected from the WoS and data regarding Impact Factor (IF) were gathered from journals in the Journal Citation Reports. Collaboration was evaluated according to coauthorship data, creating representative nets with VOSviewer. Zebrafish has attained remarkable importance as an experimental model organism in recent years and an increase in scientific production with zebrafish is observed in Brazil and around the world. The citation impact of the worldwide scientific production is superior when compared to the Brazilian scientific production. However, the citation impact of the Brazilian scientific production is consistently increasing. Brazil does not follow the international trends with regard to publication research fields. The state of Rio Grande do Sul has the greatest number of articles and the institution with the largest number of publications is PontifÃ­cia Universidade CatÃ³lica do Rio Grande do Sul. Journals' average IF is higher in Brazilian publications with international coauthorship, and around 90% of articles are collaborative. The Brazilian institutions presenting the greatest number of collaborations are PontifÃ­cia Universidade CatÃ³lica do Rio Grande do Sul, Universidade Federal do Rio Grande do Sul, FundaÃ§Ã£o Universidade Federal de Rio Grande, and Universidade de SÃ£o Paulo. These data indicate that Brazilian research using zebrafish presents a growth in terms of number of publications, citation impact, and collaborative work. PMID:27045850\n\nA measure for the impact of research\n\nPubMed Central\n\nAragÃ³n, Alejandro M.\n\n2013-01-01\n\nThe last few years have seen the proliferation of measures that quantify the scientific output of researchers. Yet, most of these measures focus on productivity, thus fostering the âpublish or perishâ paradigm. This article proposes a measure that aims at quantifying the impact of research de-emphasizing productivity, thus providing scientists an alternative, conceivably fairer, evaluation of their work. The measure builds from a published manuscript, the literature's most basic building block. The impact of an article is defined as the number of lead authors that have been influenced by it. Thus, the measure aims at quantifying the manuscript's reach, putting emphasis on scientists rather than on raw citations. The measure is then extrapolated to researchers and institutions. PMID:23575957\n\nThinking Scientifically: Understanding Measurement and Errors\n\nERIC Educational Resources Information Center\n\nAlagumalai, Sivakumar\n\n2015-01-01\n\nThinking scientifically consists of systematic observation, experiment, measurement, and the testing and modification of research questions. In effect, science is about measurement and the understanding of causation. Measurement is an integral part of science and engineering, and has pertinent implications for the human sciences. No measurement isâ¦\n\nAtypical combinations and scientific impact.\n\nPubMed\n\nUzzi, Brian; Mukherjee, Satyam; Stringer, Michael; Jones, Ben\n\n2013-10-25\n\nNovelty is an essential feature of creative ideas, yet the building blocks of new ideas are often embodied in existing knowledge. From this perspective, balancing atypical knowledge with conventional knowledge may be critical to the link between innovativeness and impact. Our analysis of 17.9 million papers spanning all scientific fields suggests that science follows a nearly universal pattern: The highest-impact science is primarily grounded in exceptionally conventional combinations of prior work yet simultaneously features an intrusion of unusual combinations. Papers of this type were twice as likely to be highly cited works. Novel combinations of prior work are rare, yet teams are 37.7% more likely than solo authors to insert novel combinations into familiar knowledge domains.\n\nScholarly literature and the press: scientific impact and social perception of physics computing\n\nNASA Astrophysics Data System (ADS)\n\nPia, M. G.; Basaglia, T.; Bell, Z. W.; Dressendorfer, P. V.\n\n2014-06-01\n\nThe broad coverage of the search for the Higgs boson in the mainstream media is a relative novelty for high energy physics (HEP) research, whose achievements have traditionally been limited to scholarly literature. This paper illustrates the results of a scientometric analysis of HEP computing in scientific literature, institutional media and the press, and a comparative overview of similar metrics concerning representative particle physics measurements. The picture emerging from these scientometric data documents the relationship between the scientific impact and the social perception of HEP physics research versus that of HEP computing. The results of this analysis suggest that improved communication of the scientific and social role of HEP computing via press releases from the major HEP laboratories would be beneficial to the high energy physics community.\n\nDevelopment and Preliminary Validation of a New Measure of Values in Scientific Work.\n\nPubMed\n\nEnglish, Tammy; Antes, Alison L; Baldwin, Kari A; DuBois, James M\n\n2018-04-01\n\nIn this paper we describe the development and initial psychometric evaluation of a new measure, the values in scientific work (VSW). This scale assesses the level of importance that investigators attach to different VSW. It taps a broad range of intrinsic, extrinsic, and social values that motivate the work of scientists, including values specific to scientific work (e.g., truth and integrity) and more classic work values (e.g., security and prestige) in the context of science. Notably, the values represented in this scale are relevant to scientists regardless of their career stage and research focus. We administered the VSW and a measure of global values to 203 NIH-funded investigators. Exploratory factor analyses suggest the delineation of eight VSW, including autonomy, research ethics, social impact, income, collaboration, innovation and growth, conserving relationships, and job security. These VSW showed predictable and distinct associations with global values. Implications of these findings for work on research integrity and scientific misconduct are discussed.\n\nGrowing complex network of citations of scientific papers: Modeling and measurements\n\nNASA Astrophysics Data System (ADS)\n\nGolosovsky, Michael; Solomon, Sorin\n\n2017-01-01\n\nWe consider the network of citations of scientific papers and use a combination of the theoretical and experimental tools to uncover microscopic details of this network growth. Namely, we develop a stochastic model of citation dynamics based on the copying-redirection-triadic closure mechanism. In a complementary and coherent way, the model accounts both for statistics of references of scientific papers and for their citation dynamics. Originating in empirical measurements, the model is cast in such a way that it can be verified quantitatively in every aspect. Such validation is performed by measuring citation dynamics of physics papers. The measurements revealed nonlinear citation dynamics, the nonlinearity being intricately related to network topology. The nonlinearity has far-reaching consequences including nonstationary citation distributions, diverging citation trajectories of similar papers, runaways or \"immortal papers\" with infinite citation lifetime, etc. Thus nonlinearity in complex network growth is our most important finding. In a more specific context, our results can be a basis for quantitative probabilistic prediction of citation dynamics of individual papers and of the journal impact factor.\n\nThe Scientific Impact of Developing Nations.\n\nPubMed\n\nGonzalez-Brambila, Claudia N; Reyes-Gonzalez, Leonardo; Veloso, Francisco; Perez-AngÃ³n, Miguel Angel\n\n2016-01-01\n\nThis paper analyzes science productivity for nine developing countries. Results show that these nations are reducing their science gap, with R&D investments and scientific impact growing at more than double the rate of the developed world. But this \"catching up\" hides a very uneven picture among these nations, especially on what they are able to generate in terms of impact and output relative to their levels of investment and available resources. Moreover, unlike what one might expect, it is clear that the size of the nations and the relative scale of their R&D investments are not the key drivers of efficiency.\n\nBalance in scientific impact assessment: the EGU Awards Committe experience\n\nNASA Astrophysics Data System (ADS)\n\nMontanari, Alberto\n\n2016-04-01\n\nEvaluation of scientific impact is becoming an essential step all over the world for assigning academic positions, funding and recognition. Impact is generally assessed by means of objective bibliometric indicators which are frequently integrated with a subjective evaluation by one or more individuals. An essential requirement of impact assessment is to ensure balance across several potential discriminating factors, including gender, ethnics, culture, scientific field and many others. Scientific associations need to ensure balance in any step of their activity and in particular when electing their representatives, evaluating scientific contributions, reviewing papers and assigning awards. While ensuring balance is a strict necessity, how to get to target is still a matter of vivid debates. In fact, the context of science is very different with respect to the general context of society and the need for scientific associations to maintain confidentiality in their evaluation procedures makes the application of transparent procedures more complicated. This talk aims to present the experience and the efforts of the European Geosciences Union to ensure balance, with a particular focus on gender balance. Data and statistics will be presented in the attempt to provide constructive indications to get to the target of giving equal opportunities to researchers across gender, continents and ethnic groups. Science is a unifying discipline and balance will be vital to ensure that humans and our planet co-evolve sustainably.\n\nThe Scientific Impact of Developing Nations\n\nPubMed Central\n\nGonzalez-Brambila, Claudia N.; Reyes-Gonzalez, Leonardo; Veloso, Francisco; Perez-AngÃ³n, Miguel Angel\n\n2016-01-01\n\nThis paper analyzes science productivity for nine developing countries. Results show that these nations are reducing their science gap, with R&D investments and scientific impact growing at more than double the rate of the developed world. But this âcatching upâ hides a very uneven picture among these nations, especially on what they are able to generate in terms of impact and output relative to their levels of investment and available resources. Moreover, unlike what one might expect, it is clear that the size of the nations and the relative scale of their R&D investments are not the key drivers of efficiency. PMID:27023182\n\nNine Criteria for a Measure of Scientific Output\n\nPubMed Central\n\nKreiman, Gabriel; Maunsell, John H. R.\n\n2011-01-01\n\nScientific research produces new knowledge, technologies, and clinical treatments that can lead to enormous returns. Often, the path from basic research to new paradigms and direct impact on society takes time. Precise quantification of scientific output in the short-term is not an easy task but is critical for evaluating scientists, laboratories, departments, and institutions. While there have been attempts to quantifying scientific output, we argue that current methods are not ideal and suffer from solvable difficulties. Here we propose criteria that a metric should have to be considered a good index of scientific output. Specifically, we argue that such an index should be quantitative, based on robust data, rapidly updated and retrospective, presented with confidence intervals, normalized by number of contributors, career stage and discipline, impractical to manipulate, and focused on quality over quantity. Such an index should be validated through empirical testing. The purpose of quantitatively evaluating scientific output is not to replace careful, rigorous review by experts but rather to complement those efforts. Because it has the potential to greatly influence the efficiency of scientific research, we have a duty to reflect upon and implement novel and rigorous ways of evaluating scientific output. The criteria proposed here provide initial steps toward the systematic development and validation of a metric to evaluate scientific output. PMID:22102840\n\nUnderstanding the Impact of an Apprenticeship-Based Scientific Research Program on High School Students' Understanding of Scientific Inquiry\n\nERIC Educational Resources Information Center\n\nAydeniz, Mehmet; Baksa, Kristen; Skinner, Jane\n\n2011-01-01\n\nThe purpose of this study was to understand the impact of an apprenticeship program on high school students' understanding of the nature of scientific inquiry. Data related to seventeen students' understanding of science and scientific inquiry were collected through open-ended questionnaires. Findings suggest that although engagement in authenticâ¦\n\nDeveloping a Test of Scientific Literacy Skills (TOSLS): Measuring Undergraduates' Evaluation of Scientific Information and Arguments\n\nERIC Educational Resources Information Center\n\nGormally, Cara; Brickman, Peggy; Lutz, Mary\n\n2012-01-01\n\nLife sciences faculty agree that developing scientific literacy is an integral part of undergraduate education and report that they teach these skills. However, few measures of scientific literacy are available to assess students' proficiency in using scientific literacy skills to solve scenarios in and beyond the undergraduate biology classroom.â¦\n\nMeasuring the effectiveness of scientific gatekeeping.\n\nPubMed\n\nSiler, Kyle; Lee, Kirby; Bero, Lisa\n\n2015-01-13\n\nPeer review is the main institution responsible for the evaluation and gestation of scientific research. Although peer review is widely seen as vital to scientific evaluation, anecdotal evidence abounds of gatekeeping mistakes in leading journals, such as rejecting seminal contributions or accepting mediocre submissions. Systematic evidence regarding the effectiveness--or lack thereof--of scientific gatekeeping is scant, largely because access to rejected manuscripts from journals is rarely available. Using a dataset of 1,008 manuscripts submitted to three elite medical journals, we show differences in citation outcomes for articles that received different appraisals from editors and peer reviewers. Among rejected articles, desk-rejected manuscripts, deemed as unworthy of peer review by editors, received fewer citations than those sent for peer review. Among both rejected and accepted articles, manuscripts with lower scores from peer reviewers received relatively fewer citations when they were eventually published. However, hindsight reveals numerous questionable gatekeeping decisions. Of the 808 eventually published articles in our dataset, our three focal journals rejected many highly cited manuscripts, including the 14 most popular; roughly the top 2 percent. Of those 14 articles, 12 were desk-rejected. This finding raises concerns regarding whether peer review is ill--suited to recognize and gestate the most impactful ideas and research. Despite this finding, results show that in our case studies, on the whole, there was value added in peer review. Editors and peer reviewers generally--but not always-made good decisions regarding the identification and promotion of quality in scientific manuscripts.\n\nGlobalization: Its Impact on Scientific Research in Nigeria\n\nERIC Educational Resources Information Center\n\nAni, Okon E.; Biao, Esohe Patience\n\n2005-01-01\n\nThis article reports on a study which investigated the impact of globalization on scientific research in Nigeria. The research data were collected using a questionnaire survey which was administered to academics in science-based disciplines in four Nigerian universities: University of Calabar, University of Uyo, University of Lagos and Universityâ¦\n\nBringing ecology blogging into the scientific fold: measuring reach and impact of science community blogs.\n\nPubMed\n\nSaunders, Manu E; Duffy, Meghan A; Heard, Stephen B; Kosmala, Margaret; Leather, Simon R; McGlynn, Terrence P; Ollerton, Jeff; Parachnowitsch, Amy L\n\n2017-10-01\n\nThe popularity of science blogging has increased in recent years, but the number of academic scientists who maintain regular blogs is limited. The role and impact of science communication blogs aimed at general audiences is often discussed, but the value of science community blogs aimed at the academic community has largely been overlooked. Here, we focus on our own experiences as bloggers to argue that science community blogs are valuable to the academic community. We use data from our own blogs ( n â=â7) to illustrate some of the factors influencing reach and impact of science community blogs. We then discuss the value of blogs as a standalone medium, where rapid communication of scholarly ideas, opinions and short observational notes can enhance scientific discourse, and discussion of personal experiences can provide indirect mentorship for junior researchers and scientists from underrepresented groups. Finally, we argue that science community blogs can be treated as a primary source and provide some key points to consider when citing blogs in peer-reviewed literature.\n\nBringing ecology blogging into the scientific fold: measuring reach and impact of science community blogs\n\nPubMed Central\n\nDuffy, Meghan A.; Heard, Stephen B.; Kosmala, Margaret; Leather, Simon R.; McGlynn, Terrence P.; Ollerton, Jeff; Parachnowitsch, Amy L.\n\n2017-01-01\n\nThe popularity of science blogging has increased in recent years, but the number of academic scientists who maintain regular blogs is limited. The role and impact of science communication blogs aimed at general audiences is often discussed, but the value of science community blogs aimed at the academic community has largely been overlooked. Here, we focus on our own experiences as bloggers to argue that science community blogs are valuable to the academic community. We use data from our own blogs (nâ=â7) to illustrate some of the factors influencing reach and impact of science community blogs. We then discuss the value of blogs as a standalone medium, where rapid communication of scholarly ideas, opinions and short observational notes can enhance scientific discourse, and discussion of personal experiences can provide indirect mentorship for junior researchers and scientists from underrepresented groups. Finally, we argue that science community blogs can be treated as a primary source and provide some key points to consider when citing blogs in peer-reviewed literature. PMID:29134093\n\nInvestigating the Impact on Skill Development of an Undergraduate Scientific Research Skills Course\n\nERIC Educational Resources Information Center\n\nYeoman, Kay H.; Zamorski, Barbara\n\n2008-01-01\n\nThis paper describes the design and subsequent impact of a scientific research skills course. Student understanding of the university research environment, their confidence in finding and using scientific literature and in scientific writing and presentation pre- and post-course was investigated. The findings suggested that understanding of theâ¦\n\nAnalyzing Data Citations to Assess the Scientific and Societal Value of Scientific Data\n\nNASA Astrophysics Data System (ADS)\n\nChen, R. S.; Downs, R. R.\n\n2012-12-01\n\nStakeholders in the creation, distribution, support, funding, and use of scientific data can benefit by understanding the value that the data have for society and science. For decades, the scientific community has been using citations of articles in the published scientific literature as one of the primary measures used for evaluating the performance of scientists, departments, institutions, and scientific disciplines. Similarly, citations in the published literature of scientific data may be useful for measuring and assessing the value of the scientific data and the performance of the individuals, projects, programs, and organizations that have contributed to the data and their use. The results of citation analysis and other assessments of the value of data also can contribute to planning for future data collection, development, distribution, and preservation efforts. The planned release of new data citation indexes and the more widespread adoption of unique data identifiers and automated attribution mechanisms have the potential to improve significantly the capabilities for analyzing citations of scientific data. In addition, rapid developments in the systems and capabilities for disseminating data, along with education and workforce development on the importance of data attribution and on techniques for data citation, can improve practices for citing scientific data. Such practices need to lead not only to better aggregate statistics about data citation, but also to improved characterization and understanding of the impact of data use in terms of the benefits for science and society. Analyses of citations in the scientific literature were conducted for data that were distributed by an interdisciplinary scientific data center during a five-year period (1997 - 2011), to identify the scientific fields represented by the journals and books in which the data were cited. Secondary citation analysis also was conducted for a sample of scientific publications that used\n\nLong-Distance Interdisciplinarity Leads to Higher Scientific Impact\n\nPubMed Central\n\nLariviÃ¨re, Vincent; Haustein, Stefanie; BÃ¶rner, Katy\n\n2015-01-01\n\nScholarly collaborations across disparate scientific disciplines are challenging. Collaborators are likely to have their offices in another building, attend different conferences, and publish in other venues; they might speak a different scientific language and value an alien scientific culture. This paper presents a detailed analysis of success and failure of interdisciplinary papersâas manifested in the citations they receive. For 9.2 million interdisciplinary research papers published between 2000 and 2012 we show that the majority (69.9%) of co-cited interdisciplinary pairs are âwin-winâ relationships, i.e., papers that cite them have higher citation impact and there are as few as 3.3% âlose-loseâ relationships. Papers citing references from subdisciplines positioned far apart (in the conceptual space of the UCSD map of science) attract the highest relative citation counts. The findings support the assumption that interdisciplinary research is more successful and leads to results greater than the sum of its disciplinary parts. PMID:25822658\n\nLong-distance interdisciplinarity leads to higher scientific impact.\n\nPubMed\n\nLariviÃ¨re, Vincent; Haustein, Stefanie; BÃ¶rner, Katy\n\n2015-01-01\n\nScholarly collaborations across disparate scientific disciplines are challenging. Collaborators are likely to have their offices in another building, attend different conferences, and publish in other venues; they might speak a different scientific language and value an alien scientific culture. This paper presents a detailed analysis of success and failure of interdisciplinary papers--as manifested in the citations they receive. For 9.2 million interdisciplinary research papers published between 2000 and 2012 we show that the majority (69.9%) of co-cited interdisciplinary pairs are \"win-win\" relationships, i.e., papers that cite them have higher citation impact and there are as few as 3.3% \"lose-lose\" relationships. Papers citing references from subdisciplines positioned far apart (in the conceptual space of the UCSD map of science) attract the highest relative citation counts. The findings support the assumption that interdisciplinary research is more successful and leads to results greater than the sum of its disciplinary parts.\n\n[The impact of the annual scientific meetings of the Israel Society of Rheumatology as measured by publication rates of the abstracts in peer-reviewed journals].\n\nPubMed\n\nPerez, Shira; Hashkes, Philip J; Uziel, Yosef\n\n2004-04-01\n\nWe aimed to examine the impact and quality of the research presented in the Israel Society of Rheumatology (ISR) annual scientific meetings by measuring publication rates of the abstracts in peer-reviewed journals and investigating the factors that influenced publication. We examined the outcome of all 79 abstracts submitted to the ISR for the 1998-2000 annual meetings. A MEDLINE search of all abstracts, by authors, topics and keywords was performed. Senior authors of abstracts not found to be published in this search were interviewed regarding publication and factors influencing submission. We described the effect of variable factors on the rate of publication. As of September 2002, 63 (80%) abstracts were published in peer-reviewed journals or are currently in-press. Most abstracts were published in prominent journals (with a high impact factor). The majority of the abstracts (61%) were published in rheumatologic journals, 65% of the studies originated from tertiary centers and 19% of the studies were multicenter. The most common diseases studied were antiphospholipid syndrome (20%), systemic lupus erythematosus (19%) and inflammatory arthritis (18%). Most of the studies were of disease pathogenesis (35%) and clinical manifestations (33%). The most common study designs were basic science (34%). An overall 57% of the studies reported \"positive\" results and 9% reported \"negative\" results. None of the factors studied were associated with publication or non-publication. The main cause cited by authors for not publishing their abstract was lack of time to prepare a full paper or a desire to further expand the study. Within this group of 16 authors of abstracts, 11 authors still plan to submit a paper. The ISR annual meetings have an important clinical scientific impact as measured by the high rate of abstracts published as full length articles in leading peer-reviewed journals.\n\nMeasurement of Scientific Productivity in R&D Sector: Changing paradigm.\n\nPubMed\n\nKumar, Abhishek; Srivastava, Alpana; Kumar, R P Jeevan; Tiwari, Rajesh K\n\n2017-01-01\n\nScientific Productivity is a demand of policy makers for a judicious utilization of massive R&D budget allocated and utilized. A huge mass of intellectual assets is employed, which after investing manpower, infrastructure and lab consumables demand for a major outcome which contributes towards building nation's economy. Scientific productivity was only measured through publications or patents. Patents, earmarked as a strong parameter for innovation generation, where, Word Intellectual Property Organisation generated a data on applications for the top 20 offices for patents, where Australia, Brazil and Canada occupied top 3 positions. India ranked 9th with the total patent applications rising from 39762 (2010) to 42854 (2014) i.e. 15%, whereas, it contributes around 2% Patents (innovative productivity) on global scale. Many studies have come forward interestingly within scientific and academic domains in the form of measurement of scientific performance, however, development of productivity indicators and calculation of Scientific Productivity (SP) as a holistic evaluation system is a significant demand. SP, a herculean task is envisaged for productivity analysis and would submit significant factors towards fabricating an effective measurement engine in a holistic manner viable for an individual and organization, being supplementary to each other. This review projects the significance of performance measurement system in R&D through identification and standardization of key parameters. It also includes emphasis on inclusion of standardized parameters, effective for performance measurement which is applicable for scientists, technical staff as well as lab as a facility. This review aims at providing an insight to the evaluators, policy makers, and high level scientific panels to stimulate the scientific intellects on identified indicators so that their work proceeds to generate productive outcome contributing to the economic growth. CopyrightÂ© Bentham Science\n\nImpact of scientific and technological advances.\n\nPubMed\n\nDragan, I F; Dalessandri, D; Johnson, L A; Tucker, A; Walmsley, A D\n\n2018-03-01\n\nAdvancements in research and technology are transforming our world. The dental profession is changing too, in the light of scientific discoveries that are advancing biological technology-from new biomaterials to unravelling the genetic make-up of the human being. As health professionals, we embrace a model of continuous quality improvement and lifelong learning. Our pedagogical approach to incorporating the plethora of scientific-technological advancements calls for us to shift our paradigm from emphasis on skill acquisition to knowledge application. The 2017 ADEE/ADEA workshop provided a forum to explore and discuss strategies to ensure faculty, students and, ultimately, patients are best positioned to exploit the opportunities that arise from integrating new technological advances and research outcomes. Participants discussed methods of incorporating the impact of new technologies and research findings into the education of our dental students. This report serves as a signpost of the way forward and how to promote incorporation of research and technology advances and lifelong learning into the dental education curriculum. Â© 2018 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.\n\nEntitymetrics: Measuring the Impact of Entities\n\nPubMed Central\n\nDing, Ying; Song, Min; Han, Jia; Yu, Qi; Yan, Erjia; Lin, Lili; Chambers, Tamy\n\n2013-01-01\n\nThis paper proposes entitymetrics to measure the impact of knowledge units. Entitymetrics highlight the importance of entities embedded in scientific literature for further knowledge discovery. In this paper, we use Metformin, a drug for diabetes, as an example to form an entity-entity citation network based on literature related to Metformin. We then calculate the network features and compare the centrality ranks of biological entities with results from Comparative Toxicogenomics Database (CTD). The comparison demonstrates the usefulness of entitymetrics to detect most of the outstanding interactions manually curated in CTD. PMID:24009660\n\nOpen access versus subscription journals: a comparison of scientific impact.\n\nPubMed\n\nBjÃ¶rk, Bo-Christer; Solomon, David\n\n2012-07-17\n\nIn the past few years there has been an ongoing debate as to whether the proliferation of open access (OA) publishing would damage the peer review system and put the quality of scientific journal publishing at risk. Our aim was to inform this debate by comparing the scientific impact of OA journals with subscription journals, controlling for journal age, the country of the publisher, discipline and (for OA publishers) their business model. The 2-year impact factors (the average number of citations to the articles in a journal) were used as a proxy for scientific impact. The Directory of Open Access Journals (DOAJ) was used to identify OA journals as well as their business model. Journal age and discipline were obtained from the Ulrich's periodicals directory. Comparisons were performed on the journal level as well as on the article level where the results were weighted by the number of articles published in a journal. A total of 610 OA journals were compared with 7,609 subscription journals using Web of Science citation data while an overlapping set of 1,327 OA journals were compared with 11,124 subscription journals using Scopus data. Overall, average citation rates, both unweighted and weighted for the number of articles per journal, were about 30% higher for subscription journals. However, after controlling for discipline (medicine and health versus other), age of the journal (three time periods) and the location of the publisher (four largest publishing countries versus other countries) the differences largely disappeared in most subcategories except for journals that had been launched prior to 1996. OA journals that fund publishing with article processing charges (APCs) are on average cited more than other OA journals. In medicine and health, OA journals founded in the last 10 years are receiving about as many citations as subscription journals launched during the same period. Our results indicate that OA journals indexed in Web of Science and/or Scopus are\n\nDeveloping a Measure of Scientific Literacy for Middle School Students\n\nERIC Educational Resources Information Center\n\nFives, Helenrose; Huebner, Wendy; Birnbaum, Amanda S.; Nicolich, Mark\n\n2014-01-01\n\nScientific literacy reflects \"a broad and functional understanding of science for general education purposes\" (DeBoer, [DeBoer, G. E., 2000], p. 594). Herein, we present the ongoing development of the Scientific Literacy Assessment (SLA), a work-in-progress measure to assess middle school students' (ages 11-14) scientific literacy.â¦\n\nNetwork effects on scientific collaborations.\n\nPubMed\n\nUddin, Shahadat; Hossain, Liaquat; Rasmussen, Kim\n\n2013-01-01\n\nThe analysis of co-authorship network aims at exploring the impact of network structure on the outcome of scientific collaborations and research publications. However, little is known about what network properties are associated with authors who have increased number of joint publications and are being cited highly. Measures of social network analysis, for example network centrality and tie strength, have been utilized extensively in current co-authorship literature to explore different behavioural patterns of co-authorship networks. Using three SNA measures (i.e., degree centrality, closeness centrality and betweenness centrality), we explore scientific collaboration networks to understand factors influencing performance (i.e., citation count) and formation (tie strength between authors) of such networks. A citation count is the number of times an article is cited by other articles. We use co-authorship dataset of the research field of 'steel structure' for the year 2005 to 2009. To measure the strength of scientific collaboration between two authors, we consider the number of articles co-authored by them. In this study, we examine how citation count of a scientific publication is influenced by different centrality measures of its co-author(s) in a co-authorship network. We further analyze the impact of the network positions of authors on the strength of their scientific collaborations. We use both correlation and regression methods for data analysis leading to statistical validation. We identify that citation count of a research article is positively correlated with the degree centrality and betweenness centrality values of its co-author(s). Also, we reveal that degree centrality and betweenness centrality values of authors in a co-authorship network are positively correlated with the strength of their scientific collaborations. Authors' network positions in co-authorship networks influence the performance (i.e., citation count) and formation (i.e., tie strength\n\nNetwork Effects on Scientific Collaborations\n\nPubMed Central\n\nUddin, Shahadat; Hossain, Liaquat; Rasmussen, Kim\n\n2013-01-01\n\nBackground The analysis of co-authorship network aims at exploring the impact of network structure on the outcome of scientific collaborations and research publications. However, little is known about what network properties are associated with authors who have increased number of joint publications and are being cited highly. Methodology/Principal Findings Measures of social network analysis, for example network centrality and tie strength, have been utilized extensively in current co-authorship literature to explore different behavioural patterns of co-authorship networks. Using three SNA measures (i.e., degree centrality, closeness centrality and betweenness centrality), we explore scientific collaboration networks to understand factors influencing performance (i.e., citation count) and formation (tie strength between authors) of such networks. A citation count is the number of times an article is cited by other articles. We use co-authorship dataset of the research field of âsteel structureâ for the year 2005 to 2009. To measure the strength of scientific collaboration between two authors, we consider the number of articles co-authored by them. In this study, we examine how citation count of a scientific publication is influenced by different centrality measures of its co-author(s) in a co-authorship network. We further analyze the impact of the network positions of authors on the strength of their scientific collaborations. We use both correlation and regression methods for data analysis leading to statistical validation. We identify that citation count of a research article is positively correlated with the degree centrality and betweenness centrality values of its co-author(s). Also, we reveal that degree centrality and betweenness centrality values of authors in a co-authorship network are positively correlated with the strength of their scientific collaborations. Conclusions/Significance Authorsâ network positions in co-authorship networks influence\n\n[New bibliometric indicators for the scientific literature: an evolving panorama].\n\nPubMed\n\nLa Torre, G; Sciarra, I; Chiappetta, M; Monteduro, A\n\n2017-01-01\n\nBibliometrics is a science which evaluates the impact of the scientific work of a journal or of an author, using mathematical and statistical tools. Impact Factor (IF) is the first bibliometric parameter created, and after it many others have been progressively conceived in order to go beyond its limits. Currently bibliometric indexes are used for academic purposes, among them to evaluate the eligibility of a researcher to compete for the National Scientific Qualification, in order to access to competitive exams to become professor. Aim of this study is to identify the most relevant bibliometric indexes and to summarized their characteristics. A revision of bibliometric indexes as been conducted, starting from the classic ones and completing with the most recent ones. The two most used bibliometric indexes are the IF, which measures the scientific impact of a periodical and bases on Web of Science citation database, and the h-index, which measures the impact of the scientific work of a researcher, basing on Scopus database. Besides them other indexes have been created more recently, such as the SCImago Journal Rank Indicator (SJR), the Source Normalised Impact per Paper (SNIP) and the CiteScore index. They are all based on Scopus database and evaluate, in different ways, the citational impact of a periodic. The i10-index instead is provided from Google Scholar database and allows to evaluate the impact of the scientific production of a researcher. Recently two softwares have been introduced: the first one, Publish or Perish, allows to evaluate the scientific work of a researcher, through the assessment of many indexes; the second one, Altmetric, measure the use in the Web of the academic papers, instead of measuring citations, by means of alternative metrics respect to the traditional ones. Each analized index shows advantages but also criticalities. Therefore the combined use of more than one indexes, citational and not, should be preferred, in order to correctly\n\nOpen access versus subscription journals: a comparison of scientific impact\n\nPubMed Central\n\n2012-01-01\n\nBackground In the past few years there has been an ongoing debate as to whether the proliferation of open access (OA) publishing would damage the peer review system and put the quality of scientific journal publishing at risk. Our aim was to inform this debate by comparing the scientific impact of OA journals with subscription journals, controlling for journal age, the country of the publisher, discipline and (for OA publishers) their business model. Methods The 2-year impact factors (the average number of citations to the articles in a journal) were used as a proxy for scientific impact. The Directory of Open Access Journals (DOAJ) was used to identify OA journals as well as their business model. Journal age and discipline were obtained from the Ulrich's periodicals directory. Comparisons were performed on the journal level as well as on the article level where the results were weighted by the number of articles published in a journal. A total of 610 OA journals were compared with 7,609 subscription journals using Web of Science citation data while an overlapping set of 1,327 OA journals were compared with 11,124 subscription journals using Scopus data. Results Overall, average citation rates, both unweighted and weighted for the number of articles per journal, were about 30% higher for subscription journals. However, after controlling for discipline (medicine and health versus other), age of the journal (three time periods) and the location of the publisher (four largest publishing countries versus other countries) the differences largely disappeared in most subcategories except for journals that had been launched prior to 1996. OA journals that fund publishing with article processing charges (APCs) are on average cited more than other OA journals. In medicine and health, OA journals founded in the last 10 years are receiving about as many citations as subscription journals launched during the same period. Conclusions Our results indicate that OA journals indexed\n\n[SOME CONSIDERATIONS ABOUT THE INTRINSIC VALUE OF THE IMPACT FACTOR OF SCIENTIFIC JOURNALS].\n\nPubMed\n\nFranco-LÃ³pez, Ãngeles; GonzÃ¡lez-Gallego, Javier; Sanz-Valero, Javier; TuÃ±Ã³n, MarÃ­a JesÃºs; GarcÃ­a-De-Lorenzo, Abelardo; Culebras, JesÃºs M\n\n2015-12-01\n\nThe reason of higher number of citations of some articles is discussed. Some considerations about the journals' impact factor, its merits and its pitfalls are also made. Scientific journals' impact factor, popularized by the Institute for Scientific Information, has become an objective parameter for authors' evaluation and also for institutions and other related circumstances. There is no reason for the impact factor's gap between some English journals and those written in other languages. English journals probably benefit of the \"Mathew's effect\", according to which eminent scientists are more rewarded by similar contributions than others less known. It is paradoxical that most of the major achievements of our age do not appear among the 100 most cited articles. There is no homogeneity among all the articles appearing in each scientific journal: half of the articles are cited ten times more than the other half. However, those articles cited 0 times are credited like the better ones. Each article should be evaluated by its own citations, which would be its impact factor; the authors should be evaluated by their H index. Copyright AULA MEDICA EDICIONES 2014. Published by AULA MEDICA. All rights reserved.\n\nData Sharing and Scientific Impact in Eddy Covariance Research\n\nDOE Office of Scientific and Technical Information (OSTI.GOV)\n\nBond-Lamberty, B.\n\nDo the benefits of data sharing outweigh its perceived costs? This is a critical question, and one with the potential to change culture and behavior. Dai et al. (2018) examine how data sharing is related to scientific impact in the field of eddy covariance (EC), and find that data sharers are disproportionately high-impact researchers, and vice versa; they also note strong regional differences in EC data sharing norms. The current policies and restrictions of EC journals and repositories are highly uneven. Incentivizing data sharing and enhancing computational reproducibility are critical next steps for EC, ecology, and science more broadly.\n\nNot Normal: the uncertainties of scientific measurements\n\nPubMed Central\n\n2017-01-01\n\nJudging the significance and reproducibility of quantitative research requires a good understanding of relevant uncertainties, but it is often unclear how well these have been evaluated and what they imply. Reported scientific uncertainties were studied by analysing 41â000 measurements of 3200 quantities from medicine, nuclear and particle physics, and interlaboratory comparisons ranging from chemistry to toxicology. Outliers are common, with 5Ï disagreements up to five orders of magnitude more frequent than naively expected. Uncertainty-normalized differences between multiple measurements of the same quantity are consistent with heavy-tailed Studentâs t-distributions that are often almost Cauchy, far from a Gaussian Normal bell curve. Medical research uncertainties are generally as well evaluated as those in physics, but physics uncertainty improves more rapidly, making feasible simple significance criteria such as the 5Ï discovery convention in particle physics. Contributions to measurement uncertainty from mistakes and unknown problems are not completely unpredictable. Such errors appear to have power-law distributions consistent with how designed complex systems fail, and how unknown systematic errors are constrained by researchers. This better understanding may help improve analysis and meta-analysis of data, and help scientists and the public have more realistic expectations of what scientific results imply. PMID:28280557\n\nNot Normal: the uncertainties of scientific measurements\n\nNASA Astrophysics Data System (ADS)\n\nBailey, David C.\n\n2017-01-01\n\nJudging the significance and reproducibility of quantitative research requires a good understanding of relevant uncertainties, but it is often unclear how well these have been evaluated and what they imply. Reported scientific uncertainties were studied by analysing 41 000 measurements of 3200 quantities from medicine, nuclear and particle physics, and interlaboratory comparisons ranging from chemistry to toxicology. Outliers are common, with 5Ï disagreements up to five orders of magnitude more frequent than naively expected. Uncertainty-normalized differences between multiple measurements of the same quantity are consistent with heavy-tailed Student's t-distributions that are often almost Cauchy, far from a Gaussian Normal bell curve. Medical research uncertainties are generally as well evaluated as those in physics, but physics uncertainty improves more rapidly, making feasible simple significance criteria such as the 5Ï discovery convention in particle physics. Contributions to measurement uncertainty from mistakes and unknown problems are not completely unpredictable. Such errors appear to have power-law distributions consistent with how designed complex systems fail, and how unknown systematic errors are constrained by researchers. This better understanding may help improve analysis and meta-analysis of data, and help scientists and the public have more realistic expectations of what scientific results imply.\n\nWhat are Scientific Leaders? The Introduction of a Normalized Impact Factor\n\nNASA Astrophysics Data System (ADS)\n\nMatsas, George E. A.\n\n2012-12-01\n\nWe define a normalized impact factor (NIF) suitable for assessing in a simple way both the strength of scientific communities and the research influence of individuals. We define those with NIF â¥ 1 as scientific leaders because they influence their peers at least as much as they are influenced by them. The NIF has two outstanding characteristics: (a) it has a clear and universal meaning and (b) it is robust against self-citation misuse. We show how a single lognormal function obtained from a simplified version of the NIF leads to a clear \"radiography\" of the corresponding scientific community. An illustrative application analyzes a community derived from the list of outstanding referees recognized by the American Physical Society in 2008.\n\nExtensive review of shale gas environmental impacts from scientific literature (2010-2015).\n\nPubMed\n\nCosta, Daniele; Jesus, JoÃ£o; Branco, David; Danko, Anthony; FiÃºza, AntÃ³nio\n\n2017-06-01\n\nExtensive reviews and meta-analyses are essential to summarize emerging developments in a specific field and offering information on the current trends in the scientific literature. Shale gas exploration and exploitation has been extensively debated in literature, but a comprehensive review of recent studies on the environmental impacts has yet to be carried out. Therefore, the goal of this article is to systematically examine scientific articles published between 2010 and 2015 and identify recent advances and existing data gaps. The examined articles were classified into six main categories (water resources, atmospheric emissions, land use, induced seismicity, occupational and public health and safety, and other impacts). These categories are analyzed separately to identify specific challenges, possibly existing consensus and data gaps yet remained in the literature.\n\nTen-year growth in the scientific production of Brazilian Psychiatry: the impact of the new evaluation policies.\n\nPubMed\n\nGerolin, JerÃ´nimo; Bressan, Rodrigo A; Pietrobon, Ricardo; Mari, Jair de Jesus\n\n2010-03-01\n\nDeveloped by the Ministry of Education, the Qualis evaluation criteria have strongly impacted the scientific production of Post-Graduation Programs. A new set of more stringent criteria has been proposed for Qualis. Our aim was to evaluate the impact of the new Qualis criteria on the scientific production of Post-Graduation Programs in psychiatry over the last 10 years. We extracted data from annual reports published between 1998 and 2008, and compared performance measured in terms of the old Qualis rating criteria and the new set of criteria. There was a 25% increase in the number of Information Science Institute-indexed articles in the second five-year period, which rose from 1,213 to 1,518. While, according to the old Qualis criteria, 84% of the Information Science Institute production would have been classified as highly-rated (IF > 1), only 17% of the papers were classified as highly-rated (A1) according to the new Qualis rating criteria. Most papers (65%) were assigned to intermediate categories (B1 and B2) with an IF < 2.29. All psychiatric Post-Graduation Programs have increased their production, but by favoring quality over quantity, the new rules have proved to be more useful for discriminating among the scientific production.\n\nI Like, I Cite? Do Facebook Likes Predict the Impact of Scientific Work?\n\nPubMed\n\nRingelhan, Stefanie; Wollersheim, Jutta; Welpe, Isabell M\n\n2015-01-01\n\nDue to the increasing amount of scientific work and the typical delays in publication, promptly assessing the impact of scholarly work is a huge challenge. To meet this challenge, one solution may be to create and discover innovative indicators. The goal of this paper is to investigate whether Facebook likes for unpublished manuscripts that are uploaded to the Internet could be used as an early indicator of the future impact of the scientific work. To address our research question, we compared Facebook likes for manuscripts uploaded to the Harvard Business School website (Study 1) and the bioRxiv website (Study 2) with traditional impact indicators (journal article citations, Impact Factor, Immediacy Index) for those manuscripts that have been published as a journal article. Although based on our full sample of Study 1 (N = 170), Facebook likes do not predict traditional impact indicators, for manuscripts with one or more Facebook likes (n = 95), our results indicate that the more Facebook likes a manuscript receives, the more journal article citations the manuscript receives. In additional analyses (for which we categorized the manuscripts as psychological and non-psychological manuscripts), we found that the significant prediction of citations stems from the psychological and not the non-psychological manuscripts. In Study 2, we observed that Facebook likes (N = 270) and non-zero Facebook likes (n = 84) do not predict traditional impact indicators. Taken together, our findings indicate an interdisciplinary difference in the predictive value of Facebook likes, according to which Facebook likes only predict citations in the psychological area but not in the non-psychological area of business or in the field of life sciences. Our paper contributes to understanding the possibilities and limits of the use of social media indicators as potential early indicators of the impact of scientific work.\n\nI Like, I Cite? Do Facebook Likes Predict the Impact of Scientific Work?\n\nPubMed Central\n\nRingelhan, Stefanie; Wollersheim, Jutta; Welpe, Isabell M.\n\n2015-01-01\n\nDue to the increasing amount of scientific work and the typical delays in publication, promptly assessing the impact of scholarly work is a huge challenge. To meet this challenge, one solution may be to create and discover innovative indicators. The goal of this paper is to investigate whether Facebook likes for unpublished manuscripts that are uploaded to the Internet could be used as an early indicator of the future impact of the scientific work. To address our research question, we compared Facebook likes for manuscripts uploaded to the Harvard Business School website (Study 1) and the bioRxiv website (Study 2) with traditional impact indicators (journal article citations, Impact Factor, Immediacy Index) for those manuscripts that have been published as a journal article. Although based on our full sample of Study 1 (N = 170), Facebook likes do not predict traditional impact indicators, for manuscripts with one or more Facebook likes (n = 95), our results indicate that the more Facebook likes a manuscript receives, the more journal article citations the manuscript receives. In additional analyses (for which we categorized the manuscripts as psychological and non-psychological manuscripts), we found that the significant prediction of citations stems from the psychological and not the non-psychological manuscripts. In Study 2, we observed that Facebook likes (N = 270) and non-zero Facebook likes (n = 84) do not predict traditional impact indicators. Taken together, our findings indicate an interdisciplinary difference in the predictive value of Facebook likes, according to which Facebook likes only predict citations in the psychological area but not in the non-psychological area of business or in the field of life sciences. Our paper contributes to understanding the possibilities and limits of the use of social media indicators as potential early indicators of the impact of scientific work. PMID:26244779\n\nDoing peer review and receiving feedback: impact on scientific literacy and writing skills.\n\nPubMed\n\nGeithner, Christina A; Pollastro, Alexandria N\n\n2016-03-01\n\nDoing peer review has been effectively implemented to help students develop critical reading and writing skills; however, its application in Human Physiology programs is limited. The purpose of the present study was to determine the impact of peer review on Human Physiology majors' perceptions of their scientific literacy and writing skills. Students enrolled in the Scientific Writing course completed multiple writing assignments, including three revisions after receiving peer and instructor feedback. Students self-assessed their knowledge, skills, and attitudes related to science and writing in pre- and postcourse surveys (n = 26 with complete data). Seven survey items related to scientific literacy and writing skills impacted by peer review were selected for analysis. Scores on these survey items were summed to form a composite self-rating score. Responses to two questions regarding the most useful learning activities were submitted to frequency analysis. Mean postcourse scores for individual survey items and composite self-rating scores were significantly higher than precourse means (P < 0.05). Peer review was the most frequently noted among 21 learning activities for increasing scientific literacy and in the top 5 for improving writing skills. In conclusion, peer review is an effective teaching/learning approach for improving undergraduate Human Physiology majors' knowledge, skills, and attitudes regarding science and scientific writing. Copyright Â© 2016 The American Physiological Society.\n\nMethodological quality and scientific impact of quantitative nursing education research over 18 months.\n\nPubMed\n\nYucha, Carolyn B; Schneider, Barbara St Pierre; Smyer, Tish; Kowalski, Susan; Stowers, Eva\n\n2011-01-01\n\nThe methodological quality of nursing education research has not been rigorously studied. The purpose of this study was to evaluate the methodological quality and scientific impact of nursing education research reports. The methodological quality of 133 quantitative nursing education research articles published between July 2006 and December 2007 was evaluated using the Medical Education Research Study Quality Instrument (MERSQI).The mean (+/- SD) MERSQI score was 9.8 +/- 2.2. It correlated (p < .05) with several scientific impact indicators: citation counts from Scopus (r = .223), Google Scholar (r = .224), and journal impact factor (r = .216); it was not associated with Web of Science citation count, funding, or h Index. The similarities between this study's MERSQI ratings for nursing literature and those reported for the medical literature, coupled with the association with citation counts, suggest that the MERSQI is an appropriate instrument to evaluate the quality of nursing education research.\n\nMeasuring the Level of Complexity of Scientific Inquiries: The LCSI Index\n\nERIC Educational Resources Information Center\n\nEilam, Efrat\n\n2015-01-01\n\nThe study developed and applied an index for measuring the level of complexity of full authentic scientific inquiry. Complexity is a fundamental attribute of real life scientific research. The level of complexity is an overall reflection of complex cognitive and metacognitive processes which are required for navigating the authentic inquiryâ¦\n\nLeadership Strategies of Performance Measures Impacts in Public Sector Management: A National Content Analysis.\n\nERIC Educational Resources Information Center\n\nKubala, James Joseph\n\nA quantitative and qualitative study examined three leadership strategies found in performance-based management (human resource, scientific management and political strategies used in public sector management); a framework by which performance measurement (PM) supports leadership strategies; and how the strategies impact PM. It examined leadershipâ¦\n\nThe Impact of Recurrent On-Line Synchronous Scientific Argumentation on Students' Argumentation and Conceptual Change\n\nERIC Educational Resources Information Center\n\nChen, Chien-Hsien; She, Hsiao-Ching\n\n2012-01-01\n\nThis study reports the impact of Recurrent On-Line Synchronous Scientific Argumentation learning on 8th grade students' scientific argumentation ability and conceptual change involving physical science. The control group (N = 76) were recruited to receive conventional instruction whereas the experimental group (N = 74) received the Recurrentâ¦\n\nA shifting mosaic of scholarly publishing, scientific delivery, and future impact changing the face of learned societies\n\nUSGS Publications Warehouse\n\nLeslie, David M.\n\n2007-01-01\n\nNonprofit scientific societies hope that their activities advance their particular mission and impact their profession and, in the broadest sense, humanity in positive ways. The digital age has provided unprecedented mechanisms to enhance the delivery of science to the world. The marketplace of scientific publishing is a rapidly shifting mosaic of challenges and opportunities, and the responses of nonprofit and commercial publishers vary widely, but their outcomes are still uncertain. The response of the American Society of Mammalogists (ASM) provides an example of how a relatively small society has altered its scientific delivery to enhance member benefits while attempting to sustain its economic viability. Since 2000, ASM has moved from a self-publishing, break-even, print-only model to a copublishing agreement with a commercial publisher (Alliance Communications Group, a division of Allen Press, Inc., Lawrence, Kansas), which now offers members various print and electronic options and generates a shared royalty. Although it is too early to gauge the economic impact of these changes, the ASM leadership clearly attempted to signal its desire for members to view their society as a package of opportunities for edification and involvement rather than just a provider of serial subscriptions. Future challenges facing nonprofit scientific societies include open access, fiscal realities, archiving of publications, and scientific and societal impact; future opportunities include a strengthening of member responsibilities and professionalism, development of data registries to enhance scientific progress, and bundling of like societies. The manner in which nonprofit scientific societies respond to these challenges and opportunities will no doubt affect their sustainability and future impact. ?? 2007 American Society of Mammalogists.\n\nEvolution of scientific ballooning and its impact on astrophysics research\n\nNASA Astrophysics Data System (ADS)\n\nJones, William Vernon\n\n2014-05-01\n\nAs we celebrate the centennial year of the discovery of cosmic rays on a manned balloon, it seems appropriate to reflect on the evolution of ballooning and its scientific impact. Balloons have been used for scientific research since they were invented in France more than 200 years ago. Ballooning was revolutionized in 1950 with the introduction of the so-called natural shape balloon with integral load tapes. This basic design has been used with more or less continuously improved materials for scientific balloon flights for more than a half century, including long-duration balloon (LDB) flights around Antarctica for the past two decades. The U.S. National Aeronautics and Space Administration (NASA) is currently developing the next generation super-pressure balloon that would enable extended duration missions above 99.5% of the Earth's atmosphere at any latitude. The Astro2010 Decadal Survey report supports super-pressure balloon development and the giant step forward it offers with ultra-long-duration balloon (ULDB) flights at constant altitudes for about 100 days.\n\nOptimizing Resources for Trustworthiness and Scientific Impact of Domain Repositories\n\nNASA Astrophysics Data System (ADS)\n\nLehnert, K.\n\n2017-12-01\n\nDomain repositories, i.e. data archives tied to specific scientific communities, are widely recognized and trusted by their user communities for ensuring a high level of data quality, enhancing data value, access, and reuse through a unique combination of disciplinary and digital curation expertise. Their data services are guided by the practices and values of the specific community they serve and designed to support the advancement of their science. Domain repositories need to meet user expectations for scientific utility in order to be successful, but they also need to fulfill the requirements for trustworthy repository services to be acknowledged by scientists, funders, and publishers as a reliable facility that curates and preserves data following international standards. Domain repositories therefore need to carefully plan and balance investments to optimize the scientific impact of their data services and user satisfaction on the one hand, while maintaining a reliable and robust operation of the repository infrastructure on the other hand. Staying abreast of evolving repository standards to certify as a trustworthy repository and conducting a regular self-assessment and certification alone requires resources that compete with the demands for improving data holdings or usability of systems. The Interdisciplinary Earth Data Alliance (IEDA), a data facility funded by the US National Science Foundation, operates repositories for geochemical, marine Geoscience, and Antarctic research data, while also maintaining data products (global syntheses) and data visualization and analysis tools that are of high value for the science community and have demonstrated considerable scientific impact. Balancing the investments in the growth and utility of the syntheses with resources required for certifcation of IEDA's repository services has been challenging, and a major self-assessment effort has been difficult to accommodate. IEDA is exploring a partnership model to share\n\nTaking Advantage of Citation Measures of Scholarly Impact: Hip Hip h Index!\n\nPubMed\n\nRuscio, John\n\n2016-11-01\n\nProfessional decisions about hiring, tenure, promotion, funding, and honors are informed by assessments of scholarly impact. As a measure of influence, citations are produced by experts but accessible to nonexperts. The h index is the largest number h such that an individual has published at least h works cited at least h times apiece. This is easy to understand and calculate, as or more reliable and valid than alternative citation measures, and highly robust to missing or messy data. Striving for a large h index requires both productivity and influence, which provides healthy incentives for researchers striving for eminence through scientific impact. A number of factors that can influence h are discussed to promote the mindful use of what might otherwise be an ambiguous or misleading measure. The h index adds a transparent, objective component to assessments of scholarly impact, and even academic eminence, that merits at least two cheers. Â© The Author(s) 2016.\n\nScientific Discoveries: What Is Required for Lasting Impact.\n\nPubMed\n\nLÃ¸mo, Terje\n\n2016-01-01\n\nI have been involved in two scientific discoveries of some impact. One is the discovery of long-term potentiation (LTP), the phenomenon that brief, high-frequency impulse activity at synapses in the brain can lead to long-lasting increases in their efficiency of transmission. This finding demonstrated that synapses are plastic, a property thought to be necessary for learning and memory. The other discovery is that nerve-evoked muscle impulse activity, rather than putative trophic factors, controls the properties of muscle fibers. Here I describe how these two discoveries were made, the unexpected difficulties of reproducing the first discovery, and the controversies that followed the second discovery. I discuss why the first discovery took many years to become generally recognized, whereas the second caused an immediate sensation and entered textbooks and major reviews but is now largely forgotten. In the long run, discovering a new phenomenon has greater impact than falsifying a popular hypothesis.\n\nThe Potential for Altmetrics to Measure Other Types of Impact in Scientific Production: Academic and Social Impact Dynamics in Social Media and Networks\n\nERIC Educational Resources Information Center\n\nMaricato, JoÃ£o de Melo; Vilan Filho, Jayme Leiro\n\n2018-01-01\n\nIntroduction: Altmetrics is an area under construction, with a potential to study the impacts of academic products from social media data. It is believed that altmetrics can capture social and academic impacts, going beyond measures obtained using bibliometric and scientometric indicators. This research aimed to analyse aspects, characteristicsâ¦\n\nUse of Bibliometric Analysis to Assess the Scientific Productivity and Impact of the Global Emerging Infections Surveillance and Response System Program, 2006-2012.\n\nPubMed\n\nReaves, Erik J; Valle, Ruben; Chandrasekera, Ruvani M; Soto, Giselle; Burke, Ronald L; Cummings, James F; Bausch, Daniel G; Kasper, Matthew R\n\n2017-05-01\n\nScientific publication in academic literature is a key venue in which the U.S. Department of Defense's Global Emerging Infections Surveillance and Response System (GEIS) program disseminates infectious disease surveillance data. Bibliometric analyses are tools to evaluate scientific productivity and impact of published research, yet are not routinely used for disease surveillance. Our objective was to incorporate bibliometric indicators to measure scientific productivity and impact of GEIS-funded infectious disease surveillance, and assess their utility in the management of the GEIS surveillance program. Metrics on GEIS program scientific publications, project funding, and countries of collaborating institutions from project years 2006 to 2012 were abstracted from annual reports and program databases and organized by the six surveillance priority focus areas: respiratory infections, gastrointestinal infections, febrile and vector-borne infections, antimicrobial resistance, sexually transmitted infections, and capacity building and outbreak response. Scientific productivity was defined as the number of scientific publications in peer-reviewed literature derived from GEIS-funded projects. Impact was defined as the number of citations of a GEIS-funded publication by other peer-reviewed publications, and the Thomson Reuters 2-year journal impact factor. Indicators were retrieved from the Web of Science and Journal Citation Report. To determine the global network of international collaborations between GEIS partners, countries were organized by the locations of collaborating institutions. Between 2006 and 2012, GEIS distributed approximately US $330 million to support 921 total projects. On average, GEIS funded 132 projects (range 96-160) with $47 million (range $43 million-$53 million), annually. The predominant surveillance focu"
    }
}