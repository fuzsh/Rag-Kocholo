{
    "id": "dbpedia_2590_0",
    "rank": 86,
    "data": {
        "url": "https://www.encyclopedia.com/science-and-technology/mathematics/mathematics/mathematics",
        "read_more_link": "",
        "language": "en",
        "title": "Encyclopedia.com",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://www.encyclopedia.com/themes/custom/trustme/images/header-logo.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "Get information",
            "facts",
            "and pictures",
            "about Mathematics",
            "at Encyclopedia.com",
            "Make",
            "research",
            "projects",
            "and school reports",
            "about Mathematics",
            "easy",
            "with credible",
            "articles",
            "from our FREE",
            "online encyclopedia and dictionary"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "MathematicsAncient mathematics [1]Classical analysis [2]Theory of numbers [3]Algebra [4]Vector spaces and matrix algebra [5]Topology and abstract spaces [6]Foundations [7]BIBLIOGRAPHY [8]The history of mathematics, and to some extent its content, can be thought of as involving three major phases.",
        "meta_lang": "en",
        "meta_favicon": "/sites/default/files/favicon.ico",
        "meta_site_name": "",
        "canonical_link": "https://www.encyclopedia.com/science-and-technology/mathematics/mathematics/mathematics",
        "text": "MATHEMATICS.\n\nThis article comprises a compact survey of the development of mathematics from ancient times until the early twentieth century. The treatment is broadly chronological, and most of it is concerned with Europe.\n\nUnknown Origins\n\nIt seems unavoidable that mathematical thinking played a role in human theorizing from the start of the race, and in various ways. Arithmetic (as the later branch of mathematics became known) would have been one of them, motivated initially by forming integers in connection with counting. But other branches surely include geometry, linked to the appreciation of line, surface, and space; trigonometry, inspired by awareness of angles; mechanics, related to the motion of bodies large and small and the (in)stability of structures; part-whole theory, from consideration of collections of things; and probability, coming from judging and guessing about situations. In all cases the thinking would have started out as very intuitive, gradually becoming more explicit and less particular.\n\nSome of the associated contexts would have been provided by study of the environment (such as days) and the heavens (such as new and full moons), which was a major concern of ancient cultures in all parts of the world; in those times mathematics and astronomy were linked closely. For example, the oldest recognized artifact is a bone from Africa, thought to be about thirty-seven thousand years old, upon which phases of the moon seem to have been recorded.\n\nAmong the various ancient cultures, the Babylonians have left the earliest extant evidence of their mathematical practice. They counted with tokens from the eighth millennium; and from the late fourth millennium they expressed numbers and properties of arithmetic in a numeral system to base 10 and handled fractions in expansions of powers of 1/60. Many surviving artifacts seem to relate to education—for example, exercises requiring calculations of unknown quantities, which correspond to the solution of equations but are not to be so identified. They also developed geometry, largely for terrestrial purposes. The Egyptians pursued similar studies, even also finding a formula (not the same one) for the volume of the rectangular base of a pyramid of given sides. They also took up the interesting mathematical problem of representing a fraction as the sum of reciprocals.\n\nA major mathematical question for these cultures concerned the relationship between circles and spheres and rectilinear objects such as lines and cubes. They involve the quantity that we symbolize by, and ancient evidence survives of methods of approximating to its value. But it is not clear that these cultures knew that the same quantity occurs in all the relationships.\n\nOn Greek Mathematics\n\nThe refinement of mathematics was effected especially by the ancient Greeks, who flourished for about a millennium from the sixth century b.c.e. Pythagoras and his clan are credited with many things, starting with their later compatriots: the eternality of integers; the connection between ratios of integers and musical intervals; the theorem relating the sides of a right-angled triangle; and so on. Their contemporary Thales (c. 625–c. 547 b.c.e.) is said to have launched trigonometry with his appreciation of the angle. However, nothing survives directly from either man.\n\nA much luckier figure concerning survival is Euclid (fl. c. 300 b.c.e.), especially with his Elements. While no explanatory preface survives, it appears that most of the mathematics presented was his rendition of predecessors' work, but that (some of) the systematic organization that won him so many later admirers might be his. He stated explicitly the axioms and assumptions that he noticed; one of them, the parallel axiom, lacked the intuitive clarity of the others, and so was to receive much attention in later cultures.\n\nThe Elements comprised thirteen Books: Books 7–9 dealt with arithmetic, and the others presented basic plane (Books 1–6) and solid (Books 11–13) geometry of rectilinear and circular figures. The extraordinary Book 10 explored properties of ratios of smaller to longer lines, akin to a theory of irrational numbers but again not to be so identified. A notable feature is that Euclid confined the role of arithmetic within geometry to multiples of lines (say, \"twice this line is … \"), to a role in stating ratios, and to using reciprocals (such as 1/5); he was not concerned with lengths—that is, lines measured arithmetically. Thus, he said nothing about the value of, for it relates to measurement.\n\nThe Greeks were aware of the limitations of straight line and circle. In particular, they found many properties and applications of the \"conic sections\": parabola, hyperbola, and ellipse. Hippocrates of Chios (fl. c. 600 b.c.e.) is credited with three \"classical problems\" (a later name) that his compatriots (rightly) suspected could not be solved by ruler and compass alone: (1) construct a square equal in area to a given circle; (2) divide any angle into three equal parts; and (3) construct a cube twice the volume of a given one. The solutions that they did find enlarged their repertoire of curves.\n\nAmong later Greeks, Archimedes (c. 287–212 b.c.e.) stands out for the range and depth of his work. His work on circular and spherical geometry shows that he knew all four roles for; but he also wrote extensively on mechanics, including floating bodies (the \"eureka!\" tale) and balancing the lever, and focusing parabolic mirrors. Other figures developed astronomy, partly as applied trigonometry, both planar and spherical; in particular, Ptolemy (late second century) \"compiled\" much knowledge in his Almgest, dealing with both the orbits and the distances of the heavenly bodies from the central and stationary Earth.\n\nTraditions Elsewhere\n\nMathematics developed well from antiquity also in the Far East, with distinct traditions in India, China, Japan, Korea, and Vietnam. Arithmetic, geometry, and mechanics were again prominent; special features include a powerful Chinese method equivalent to solving a system of linear equations, a pretty theory of touching circles in Japanese \"temple geometry,\" and pioneering work on number theory by the Indians. They also introduced the place-value system of numerals to base 10, of which we use a descendant that developed after several changes in adopted symbols.\n\nThis system of numerals was mediated into Europe by mathematicians working in medieval Islamic civilization, often though not always writing in Arabic. They became the dominant culture in mathematics from the ninth century and continued strongly until the fourteenth. They assimilated much Greek mathematics; indeed, they are our only source for some of it.\n\nThe first major author was al-Khwarizmi (fl. c. 800–847), who laid the foundations of algebra, especially the solution of equations. He and his followers launched the theory using words rather than special symbols to mark unknowns and operations. Other interests in geometry included attempts to prove Euclid's parallel axiom and applications to optics and trigonometry; an important case of the latter was determining the qibla (that is, the direction of Mecca) for any time and place at times of Muslim prayer. Their massive contributions to astronomy included theory and manufacture of astrolabes.\n\nThe Wakening Europe from the Twelfth Century\n\nFrom the decline of the Roman Empire (including Greece) Euclid was quiescent mathematically, though the Carolingian kingdom inspired some work, at least in education. The revival dates from around the late twelfth century, when universities also began to be formed. The major source for mathematics was Latin translations of Greek and Arabic writings (and re-editions of Roman writers, especially Boethius). In addition, the Italian Leonardo Fibonacci (c. 1170–c. 1240) produced a lengthy Liber Abbaci in 1202 that reported in Latin many parts of Arabic arithmetic and algebra (including the Indian numerals); his book was influential, though perhaps less than is commonly thought. The Italian peninsula was then the most powerful region of Europe, and much commercial and \"research\" mathematics was produced there; the German states and the British Isles also came to boast some eminent figures. In addition, a somewhat distinct Hebrew tradition arose—for example, in probability theory.\n\nA competition developed between two different methods of reckoning. The tradition was to represent numbers by placing pebbles (in Latin, calculi ) in determined positions on a flat surface (in Latin, abacus, with one b ), and to add and subtract by moving the pebbles according to given rules. However, with the new numerals came a rival procedure of calculating on paper, which gradually supervened; for, as well as also allowing multiplication and division, the practitioner could show and check his working, an important facility unavailable to movers of pebbles.\n\nMathematics rapidly profited from the invention of printing in the late fifteenth century; not only were there printed Euclids, but also many reckoning books. Trigonometry became a major branch in the fifteenth and sixteenth centuries, not only for astronomy but also, as European imperialism developed, for cartography, and the needs of navigation and astronomy made the spherical branch more significant than the planar. Geometry was applied also to art, with careful studies of perspective; Piero della Francesca (c. 1420–1492) and Albrecht Dürer (1471–1528) were known not only as great artists but also as significant mathematicians.\n\nNumerical calculation benefited greatly from the development of logarithms in the early seventeenth century by John Napier (1550–1617) and others, for then multiplication and division could be reduced to addition and subtraction. Logarithms superseded a clumsier method called \"prosthaphairesis\" that used certain trigonometrical formulas.\n\nIn algebra the use of special symbols gradually increased, until in his Géométrie (1637), René Descartes (1596–1650) introduced (more or less) the notations that we still use, and also analytic geometry. His compatriot Pierre de Fermat (1601–1665) also worked in these areas and contributed some theorems and conjectures to number theory. In addition, he corresponded with Blaise Pascal (1623–1662) on games of chance, thereby promoting parts of probability theory.\n\nIn mechanics a notable school at Merton College, Oxford, had formed in the twelfth century to study various kinds of terrestrial and celestial motion. The main event in celestial mechanics was Nicolaus Copernicus's (1473–1543) De revolutionibus (1453; On the revolutions), where rest was transferred from the Earth to the sun (though otherwise the dynamics of circular and epicyclical motions was not greatly altered). In the early seventeenth century the next stages lay especially with Johannes Kepler's (1571–1630) abandonment of circular orbits for the planets and Galileo Galilei's (1564–1642) analysis of (locally) horizontal and vertical motions of bodies.\n\nThe Epoch of Newton and Leibniz\n\nBy the mid-seventeenth century, science had become professionalized enough for some national societies to be instituted, especially the Royal Society of London and the Paris Académie des Sciences. At that time two major mathematicians emerged: Isaac Newton (1642–1727) in Cambridge and Gottfried Wilhelm von Leibniz (1646–1716) in Hanover. Each man invented a version of the differential and integral calculus, Newton first in creation but Leibniz first in print. The use here of Leibniz's adjectives recognizes the superior development of his version. During the early 1700s Newton became so furious (or envious?) that he promoted a charge of plagiarism against Leibniz, complete with impartial committee at the Royal Society. It was a disaster for Britain: Newton's followers stuck with their master's theory of \"fluxions\" and \"fluents,\" while the Continentals developed \"differentials\" and \"integrals,\" with greater success. The accusation was also mathematically stupid, for conceptually the two calculi were quite different: Newton's was based upon (abstract) time and unclearly grounded upon the notion of limit, while Leibniz's used infinitesimal increments on variables, explicitly avoiding limits. So even if Leibniz had known of Newton's theory (of which the committee found no impartial evidence), he rethought it entirely.\n\nLeibniz's initial guard was largely Swiss: brothers Jakob (1654–1705) and Johann Bernoulli (1667–1748) from the 1680s, then from the 1720s Johann's son Daniel (1700–1782) and their compatriot Leonhard Euler (1707–1783), who was to be the greatest of the lot. During the eighteenth century they and other mathematicians (especially in Paris) expanded calculus into a vast territory of ordinary and then partial differential equations and studied many related series and functions. The Newtonians kept up quite well until Colin Maclaurin (1698–1746) in the 1740s, but then faded badly.\n\nThe main motivation for this vast development came from applications, especially to mechanics. Here Newton and Leibniz differed again. In his Principia mathematica (1687) Newton announced the laws that came to carry his name: (1) a body stays in equilibrium or in uniform motion unless disturbed by a force; (2) the ratio of the magnitude of the force and the mass of the body determines its acceleration; and (3) to any force of action there is one of reaction, equal in measure and opposite in sense. In addition, for both celestial and terrestrial mechanics, which he novelly united, the force between two objects lies along the straight line joining them, and varies as the inverse square of its length.\n\nWith these principles Newton could cover a good range of mechanical phenomena. His prediction that the Earth was flattened at the poles, corroborated by an expedition undertaken in the 1740s, was a notable success. He also had a splendid idea about why the planets did not exactly follow the elliptical orbits around the sun that the inverse square law suggested: they were \"perturbed\" from them by interacting with each other. The study of perturbations became a prime topic in the eighteenth century, with Euler's work being particularly significant. Euler also showed that law 2 could be applied to any direction in a mechanical situation, thus greatly increasing its utility. He and others made important contributions to the mechanics of continuous media, especially fluid mechanics and elasticity theory, where Newton had been somewhat sketchy.\n\nMathematics in the Eighteenth Century: The Place of Lagrange\n\nHowever, Newton's theory was not alone in mechanics. Leibniz and others developed an alternative approach, partly inspired by Descartes, in which the \"living forces\" (roughly, kinetic energy) of bodies were related to their positions. Gradually this became a theory of living forces converted into \"work\" (a later term), specified as (force x traversed distance). Engineers became keen on it for its utility in their concerns, especially when impact between bodies was involved; from the 1780s Lazare Carnot (1753–1823) urged it as a general approach for mechanics.\n\nCarnot thereby challenged Newton's theory, but his main target was a recent new tradition partly launched by Jean d'Alembert (1718–1783) in midcentury and developed further by Joseph-Louis Lagrange (1736–1813). Suspicious of the notion of force, d'Alembert had proposed that it be defined by Newton's law 2, which he replaced by one stating how systems of bodies moved when disturbed from equilibrium. At that time Euler and others proposed a \"principle of least action,\" which asserted that the action (a mechanical notion defined by an integral) of a mechanical system took its optimal value when equilibrium was achieved. Lagrange elaborated upon these principles to create Méchanique analitique (1788), in which he challenged the other two traditions; in particular, dynamics was reduced mathematically to statics. For him a large advantage of his principles was that they were formulated exclusively in algebraic terms; as he proclaimed in the preface of his book, there were no diagrams, and no need for them. A main achievement was a superb though inconclusive attempt to prove that the system of planets was stable; predecessors such as Newton and Euler had left that matter to God.\n\nLagrange formulated mechanics this way in order to make it (more) rigorous. Similarly, he algebraized the calculus by assuming that any mathematical function could be expressed in an infinite power series (the so-called Taylor series), and that the basic notions of derivative (his word) and integral could be determined solely by algebraic manipulations. He also greatly expanded the calculus of variations, a key notion in the principle of least action.\n\nAs in mechanics, Lagrange's calculus challenged the earlier ones, Newton's and Leibniz's, and as there, reaction was cautious. A good example for both contexts was Pierre-Simon Laplace (1749–1827), a major figure from 1770. While strongly influenced by Lagrange, he did not confine himself to the constraints of Lagrange's book when writing his own four-volume Traité de mécanique céleste (1799–1805; Treatise on celestial mechanics). His exposition of celestial and planetary mechanics used many differential equations, series, and functions.\n\nThe French Revolution and a New Professionalization\n\nLaplace published his large book in a new professional and economic situation for science. After the Revolution of 1789 in France, higher education and its institutions there were reformed, with a special emphasis upon engineering. In particular, a new school was created, the École Polytechnique (1794), with leading figures as professors (such as Lagrange) and as examiners (Laplace), and with enrollment of students determined by talent, not birth. A new class of scientists and engineers emerged, with mathematics taught, learned, researched, and published on a scale hitherto unknown.\n\nOf this mass of work only a few main cases can be summarized here. Joseph Fourier (1768–1830) is noteworthy for his mathematical analysis of heat diffusion, both the differential equation to represent it (the first important such equation found outside mechanics) and solutions by certain infinite series and by integrals that both now bear his name. From the 1820s they attracted much attention, not only for their use in heat theory but especially for the \"pure\" task of establishing conditions for their truth. New techniques for rigor had just become available, mainly from Augustin-Louis Cauchy (1789–1857), graduate of the École Polytechnique and now professor there. He taught a fourth approach to the calculus (and also function and series), based like Newton's upon limits but now fortified by a careful theory of them; although rather unintuitive, its mathematical merits gradually led worldwide to its preference over the other three approaches.\n\nIronically, Cauchy's own analysis of Fourier series failed, but a beautiful treatment following his approach came in 1829 from J. P. G. Dirichlet (1805–1859)—a French-sounding name of a young German who had studied with the masters in Paris. Dirichlet also exemplifies a novelty of that time: other countries producing major mathematicians. Another contemporary example lies in elliptic functions, which Carl Jacobi (1804–1851) and the young Norwegian Niels Henrik Abel (1802–1829) invented independently following much pioneering work on the inverse function by A. M. Legendre (1752–1833).\n\nJacobi and Abel drew upon a further major contribution to mathematics made by Cauchy when, by analogy with the calculus, he developed a theory of functions of the complex variable x + √ − 1y (x and y real), complete with an integral. His progress was fitful, from the 1810s to the 1840s; after that, however, his theory became recognized as a major branch of mathematics, with later steps taken especially by the Germans.\n\nBetween 1810 and 1830 the French initiated other parts of mathematical physics in addition to Fourier on heat: Siméon-Denis Poisson (1781–1840) on magnetism and electrostatics; André-Marie Ampère (1775–1836) on electrodynamics; and Augustin Jean Fresnel (1788–1827) on optics with his wave theory. Mathematics played major roles: many analogies were taken from mechanics, which itself developed massively, with Carnot's energy approach elaborated by engineers such as Gaspard-Gustave Coriolis (1792–1843), and continuum mechanics extended, especially by Cauchy.\n\nGeometry was also taught and studied widely. Gaspard Monge (1746–1818) sought to develop \"descriptive geometry\" into a geniune branch of mathematics and gave it prominence in the first curriculum of the École Polytechnique; however, this useful theory of engineering drawing could not carry such importance, and Laplace had its teaching reduced. But former student Jean Victor Poncelet (1788–1867) was partly inspired by it to develop \"the projective properties of figures\" (Traité des propries projectives de figures, 1822), where he studied characteristics independent of measure, such as the order of points on a line.\n\nThe main mathematician outside France at this time was C. F. Gauss (1777–1855), director of the Göttingen University Observatory. Arguably he was the greatest of all, with major work published in number theory, celestial mechanics, and aspects of analysis and probability theory. But he was not socially active, and he left many key insights in his manuscripts (for example, on elliptic functions).\n\nOther major contributors outside France include George Green (1793–1841), who, in An Essay on the Application of Mathematical Analysis to the Theories of Electricity and Magnetism (1828), produced a wonderful theorem in potential (his word) theory that related the state of affairs inside an extended body to that on its surface. But he published his book very obscurely, and it became well-known only on the reprint during the 1850s initiated by William Thomson (later Lord Kelvin), who was making notable contributions of his own to the theory.\n\nMidcentury Internationalism\n\nBy the 1840s Britain and the Italian and German states were producing quality mathematicians to complement and even rival the French, and new posts were available in universities and engineering colleges everywhere. Among the Germans, two figures stand out.\n\nFrom around 1860 Karl Weierstrass (1815–1897) gave lecture courses on many aspects of real-and complex-variable analysis and parts of mechanics at Berlin University, attended by students from many countries who then went home and taught likewise. Meanwhile at Göttingen, Bernhard Riemann (1826–1866) rethought complex-variable analysis and revolutionized the understanding of both Fourier series and the foundations of geometry. Much of this work was published only after his early death in 1866, but it soon made a great impact. The work on Fourier series led Georg Cantor (1845–1918) to develop set theory from the 1870s. On geometry Riemann showed that the Euclidean was only one of many possible geometries, and that each of them could be defined independently of any embedding space. The possibility of non-Euclidian geometries, using alternatives to the parallel axiom, had been exhibited around 1830 in little-recognized work by Janos Bolyai (1802–1860) and Nicolai Lobachevsky (1793–1856) (and, in manuscript, Gauss); Riemann, however, went much further and brought us proper understanding of the plurality of geometries.\n\nWeierstrass emulated and indeed enhanced Cauchy-style rigor, carefully formulating definitions and distinctions and presenting proofs in great detail. By contrast, Riemann worked intuitively, offering wonderful but often proof-free insights grounded upon some \"geometric fantasy,\" as Weierstrass described it. A good example is their revisions of Cauchy's complex-variable analysis: Weierstrass relied solely on power series expansions of the functions, whereas Riemann invented surfaces now named after him that were slit in many remarkable ways. Among many consequences of the latter, the German Felix Klein (1849–1925) and the Frenchman Henri Poincaré (1854–1912) in the early 1880s found beautiful properties of functions defined on these surfaces, which they related to group theory as part of the rise of abstract algebras.\n\nAnother example of the gap between Riemann and Weierstrass is provided by potential theory. Riemann used a principle employed by his mentor Dirichlet (and also envisaged by Green) to solve problems in potential theory, but in 1870 Weierstrass exposed its fallibility by a counterexample, and so methods became far more complicated.\n\nBetter news for potential theory had come at midcentury with the \"energetics\" physics of Thomson, Hermann von Helmholtz (1821–1894), and others. The work expression of engineering mechanics was extended into the admission of potentials, which now covered all physical factors (such as heat) and not just the mechanical ones that had split Carnot from Lagrange. The latter's algebraic tradition in mechanics had been elaborated by Jacobi and by the Irishman William Rowan Hamilton (1805–1865), who also introduced his algebra of quaternions.\n\nAmong further related developments, the Scot James Clerk Maxwell (1831–1879) set out theories of electricity and magnetism (including, for him, optics) in his Treatise on Electricityand Magnetism (1873). Starting out from the electric and magnetic potentials as disturbances of the ether rather than Newton-like forces acting at a distance through it, he presented relationships between his basic notions as differential equations (expressed in quaternion form). A critical follower was the Englishman Oliver Heaviside, who also analyzed electrical networks by means of a remarkable but mysterious operator algebra. Other \"Maxwellians\" preferred to replace dependence upon fields with talk about \"things,\" such as electrons and ions; the relationship between ether and matter (J. J. Larmor, Aether and Matter, 1900) was a major issue in mathematical physics at century's end.\n\nThe Early Twentieth Century\n\nA new leader emerged: the German David Hilbert (1862–1943). Work on abstract algebras and the foundations of geometry led him to emphasize the importance of axiomatizing mathematical theories (including the axioms of Euclidean geometry that Euclid had not noticed) and to study their foundations metamathematically. But his mathematical knowledge was vast enough for him to propose twenty-three problems for the new century; while a personal choice, it exercised considerable influence upon the community. He presented it at the International Congress of Mathematicians, held in Paris in 1900 as the second of a series that manifested the growing sense of international collaboration in mathematics that still continues.\n\nOne of Hilbert's problems concerned the foundations of physics, which he was to study intensively. In physics Albert Einstein (1879–1955) proposed his special theory of relativity in 1905 and a general theory ten years later; according to both, the ether was not needed. Mathematically, the general theory both deployed and advanced tensor calculus, which had developed partly out of Riemann's interpretation of geometry.\n\nAnother main topic in physics was quantum mechanics, which drew upon partial differential equations and vector and matrix theory. One of its controversies concerned Werner Heisenberg's principle of the uncertainty of observation: should it be interpreted statistically or not? The occurrence of this debate, which started in the mid-1920s, was helped by the increasing presence of mathematical statistics. Although probability must have had an early origin in mathematical thinking, both it and mathematical statistics had developed very slowly in the nineteenth century—in strange contrast to the mania for collecting data of all kinds. Laplace and Gauss had made important contributions in the 1810s, for example, over the method of least-squares regression, and Pafnuty Chebyshev (1821–1894) was significant from the 1860s in Saint Petersburg (thus raising the status of Russian mathematics). But only from around 1900 did theorizing in statistics develop strongly, and the main figure was Karl Pearson (1857–1936) at University College, London, and his students and followers. Largely to them we owe the definition and theory of basic notions such as standard deviation and correlation coefficient, basic theorems concerning sampling and ranking, and tests of significance.\n\nElsewhere, Cantor's set theory and abstract algebras were applied to many parts of mathematics and other sciences in the new century. A major beneficiary was topology, the mathematics of location and place. A few cases had emerged in the nineteenth century, such as the \"Möbius strip\" with only one side and one edge, Riemann's fantastical surfaces, and above all a remarkable classification of deformable manifolds by Poincaré; most of the main developments, however, date from the 1920s. General theories were developed of covering, connecting, orientating, and deforming manifolds and surfaces, along with many other topics. A new theory of dimensions was also proposed because Cantor had refuted the traditional understanding by mapping one-one all the points in a square onto all the points on any of its sides. German mathematicians were prominent; so were Americans in a country that had risen rapidly in mathematical importance from the 1890s.\n\nSome Reflections\n\nThe amount of mathematical activity has usually increased steadily or even exponentially, and the growth from the mid-twentieth century has been particularly great. For example, the German reviewing journal Zentralblatt Math published at the beginning of the twenty-first century a six-hundred-page quarto volume every two weeks, using a classification of mathematics into sixty-three numbered sections. To suggest the rate of increase, the other reviewing journal, the U.S. periodical Mathematical Reviews, published 3,800 octavo pages in 1980, 7,500 pages a decade later, and 9,800 pages in 2003. It would be impossible to summarize this mountain of work, even up to 1970; instead, some main points are noted relating to the previous sections and to the companion articles on algebras and on logic.\n\nNot only has the amount increased; the variety of theories has also greatly expanded. All the topics and branches mentioned above continue to develop (and also many more that were not noted), and new topics emerge and fresh applications are found. For example, beginning with the 1940s mathematics became widely utilized in the life sciences and medicine and has expanded greatly in economics and other social sciences relative to previous practice.\n\nMuch of that work lies in statistics, which after its very slow arrival has developed a huge community of practitioners in its own right. Often it functions rather separately from mathematics, with its own departments in universities.\n\nAnother enormous change has been the advent of computing, again particularly since World War II and indeed much stimulated by war work as on cryptography and the calculation of parameters in large technological artifacts. Mathematics plays a role both in the design, function, and programming of computers themselves and in the formulation of many mathematical theories. An important case is in numerical mathematics, where approximations are required and efficient algorithms sought to effect them. This kind of mathematics has been practiced continuously from ancient times, especially in connection with all sorts of applications. Quite often algorithms were found to be too slow or mathematically cumbersome to be practicable; but now computer power makes many of them feasible in \"number crunching\" (to quote a popular oversimplification of such techniques).\n\nA feature of many mathematical theories is linearity, in which equations or expressions of the form\n\n(A) ax by cz … and so on finitely or even infinitely\n\nmake sense, in a very wide range of interpretations of the letters, not necessarily within an algebra itself (for example, Fourier series shows it). But a dilemma arises for many applications, for the world is not a linear place, and in recent decades nonlinear theories have gained higher status, partly again helped by computing. The much-publicized theory of fractals falls into this category.\n\nFrom the Greeks onward, mathematicians have often been fascinated by major unsolved problems and by the means of solving them. In the late 1970s a proof was produced of the four-color theorem, stating that any map drawn upon a surface can be colored with four colors such that bounding regions do not share the same color. The proof was controversial, for a computer was used to check thousands of special cases, a task too large for people. Another example is \"Fermat's last theorem,\" that the sum of the nth powers of two positive integers is never equal to the nth power of another integer when n 2. The name is a misnomer, in that Fermat only claimed a proof but did not reveal it; the modern version (1994) uses modern techniques far beyond his ken.\n\nThis article has focused upon the main world cultures, but every society has produced mathematics. The \"fringe\" developments are studied using approaches collectively known as ethnomathematics. While the cultures involved developed versions of arithmetic and geometry and also some other branches, several of them also followed their own concerns; some examples, among many, are intricate African drawings made in one unbroken line, Celtic knitting patterns, and sophisticated rows of knotted strings called quipus used in Mexico to maintain accounts.\n\nA thread running from antiquity in all cultures, fringe or central, is recreational mathematics. Unfortunately, the variety is far too great even for summary here. Often it consists of exercises, perhaps posed for educational use, or perhaps just for fun; an early collection is attributed to Alcuin in the ninth century, for use in the Carolingian Empire. Solutions sometimes involve intuitive probability, or combinatorics to work out all options; with games such as chess and bridge, however, the analysis is much more sophisticated. Several puzzles appear in slightly variant forms in different cultures, suggesting transmission. Some are puzzles in logic or reasoning rather than mathematics as such, and it is striking that for some games the notion of decidability was recognized (that is, is there a strategy that guarantees victory?) long before it was studied metamathematically in the foundations of mainstream mathematics.\n\nLastly, since the early 1970s interest in the history of mathematics has increased considerably. There are now several journals in the field along with a variety of books and editions, collectively covering all main cultures and periods. One main motive for people to take up historical research was their dislike of the normal unmotivated way in which mathematics was (and is) taught and learned; thus, the links between history and mathematics education are strong. For, despite many appearances to the contrary, mathematics is a human activity.\n\nSee also Algebras ; Astronomy, Pre-Columbian and Latin American ; Calculation and Computation ; Geometry ; Logic ; Logic and Philosophy of Mathematics, Modern .\n\nbibliography\n\nBottazzini, Umberto. Il flauto di Hilbert. Turin: UTET, 1990.\n\nCajori, Florian. A History of Mathematical Notations. 2 vols. La Salle, Ill., and Chicago: Open Court, 1928–1929.\n\nCantor, Moritz. Vorlesungen über Geschichte der Mathematik. 4 vols. Leipzig, Germany: Teubner, 1899–1908. Classic source of the history of mathematics to 1799.\n\nChabert, Jean-Luc, et al., eds. A History of Algorithms: From the Pebble to the Microchip. Translated by Chris Weeks. Berlin and New York: Springer, 1999. French original, 1994.\n\nCooke, Roger. The History of Mathematics: A Brief Course. New York: Wiley, 1997.\n\nDauben, Joseph W., ed. The History of Mathematics from Antiquity to the Present: A Selective Bibliography. Rev. ed. New York: Garland, 1985. Lewis, Albert, ed. The History of Mathematics: A Selective Bibliography. Providence, R.I.: American Mathematical Society, 2000. In CD ROM format.\n\nDauben, Joseph W., and Scriba J. Christoph, eds. Writing the History of Mathematics: Its Historical Development. Basel, Switzerland, and Boston: Birkhaüser, 2002.\n\nDieudonné, Jean, ed. Abrégé d'histoire des mathématiques 1700–1900. 2 vols. Paris: Hermann, 1978. Includes a few parts on pure mathematics.\n\nDold, Yvonne, et al., eds. From China to Paris: 2000 Years Transmission of Mathematical Ideas. Stuttgart: Franz Steiner, 2002.\n\nFolkerts, Menso, Eberhard Knobloch, and Karin Reich. Mass, Zahl, und Gewicht. 2nd ed. Wiesbaden: Harrassowitz, 2001. Much elaborated exhibition catalog.\n\nGoldstein, Catherine, Jeremy Gray, and Jim Ritter, eds. L'Europe mathématique: histoires, mythes, identités. Paris: Editions de la Maison des Sciences de l'Homme, 1996.\n\nGottwald, Siegfried, Hans-Joachim Ilgands, and Karl-Heinz Schlote, eds. Lexikon bedeutender Mathematiker. Leipzig: Bibliographisches Institut, 1990. Many short biographies.\n\nGrattan-Guinness, I., ed. Companion Encyclopedia of the History and Philosophy of the Mathematical Sciences. 2 vols. London and New York: Routledge, 1994. Reprint, Baltimore: Johns Hopkins University Press, 2003. Material up to the 1930s.\n\n——. The Norton History of the Mathematical Sciences: The Rainbow of Mathematics. New York: Norton, 1998. Coverage until World War I.\n\nHistoria mathematica (1974–). The best single source for new historical writings.\n\nKlein, Felix, et al., eds. Encyklopädie der mathematischen Wissenschaften. 23 vols. Leipzig, Germany: Teubner, 1898–1935.\n\nKline, Morris. Mathematical Thought from Ancient to Modern Times. New York: Oxford University Press, 1972.\n\nKramer, Edna E. The Nature and Growth of Modern Mathematics. New York: Hawthorn, 1970.\n\nMay, Kenneth O. Bibliography and Research Manual of the History of Mathematics. Toronto: University of Toronto Press, 1973.\n\nMontucla, Jerome E. Histoire des mathématiques. 2nd ed. 4 vols. Vols. 3–4 edited by J. J. Lalande. Paris: Agasse, 1799–1802. Reprint, Paris: Blanchard, 1968.\n\nPier, Jean-Paul, ed. Development of Mathematics 1900–1950. Basel, Switzerland, and Boston: Birkhäuser, 1994. This and the follow-up volume focus mostly on pure mathematics.\n\n——. Development of Mathematics 1950–2000. Basel, Switzerland, and Boston: Birkhäuser, 2000.\n\nRoche, John J. The Mathematics of Measurement: A Critical History. London: Athlone Press, 1998.\n\nScriba, C. J., and P. Schreiber. 5000 Jahre Geometrie. Geschichte, Kulturen, Menschen. Berlin and New York: Springer, 2000.\n\nI. Grattan-Guinness\n\nMathematics\n\nAncient mathematics\n\nClassical analysis\n\nTheory of numbers\n\nAlgebra\n\nVector spaces and matrix algebra\n\nTopology and abstract spaces\n\nFoundations\n\nBIBLIOGRAPHY\n\nThe history of mathematics, and to some extent its content, can be thought of as involving three major phases. Ancient mathematics, covering the period from the earliest written records through the first few centuries A.D., culminated in Euclidean geometry, the elementary theory of numbers, and ordinary algebra. Equally important, this phase saw the evolution and partial clarification of axiomatic systems and deductive proofs. The next major phase, classical mathematics, began more than 1,000 years later, with the Cartesian fusion of geometry and algebra and the use of limiting processes in the calculus. From these evolved, during the eighteenth and nineteenth centuries, the several aspects of classical analysis. Other contributions of this phase include non-Euclidean geometries, the beginnings of probability theory, vector spaces and matrix theory, and a deeper development of the theory of numbers. About a hundred years ago the third and most abstract and demanding phase, known as modern mathematics, began to evolve and become separate from the classical period. This phase has been concerned with the isolation of several recurrent structures of analysis worthy of independent study—these include abstract algebraic systems (for example, groups, rings, and fields), topological spaces, symbolic logic, and functional analysis (Hilbert and Banach spaces, for example)—and various fusions of these systems (for example, algebraic geometry and topological groups). The rate of growth of mathematics has been so great that today most mathematicians are familiar in detail with the major developments of only a few branches of the subject.\n\nOur purpose is to give some hint of these topics. The reader interested in a somewhat more detailed treatment will find the best single source to be Mathematics: Its Content, Methods, and Meaning, the translation of a Russian work (Akademiia Nauk S.S.S.R. 1956). Other general works are Courant and Robbins (1941), Friedman (1966), and Newman (1956). More specific references are given where appropriate. We do not here discuss probability, mathematical statistics, or computation, even though they are especially important mathematical disciplines for the social sciences, because they are covered in separate articles in the encyclopedia.\n\nAncient mathematics\n\nThe history of ancient mathematics divides naturally into three periods. In the first period, the pre-Hellenic age, the beginnings of systematic mathematics took place in ancient Egypt and in Mesopotamia. Contrary to much popular opinion, the mathematical developments in Mesopotamia were deeper and more substantial than those in Egypt. The Babylonians developed elementary arithmetic and algebra, particularly the computational aspects of algebra, to a surprising degree. For example, they were able to solve the general quadratic equation, ax2 + bx + c = 0. An authoritative and readable account of Babylonian mathematics as well as of Greek mathematics is presented by Neugebauer (1951).\n\nThe second period of ancient mathematics was the early Greek, or Hellenic, age. The fundamentally new step taken by the Greeks was to introduce the concept of a mathematical proof. These developments began around 600 b.c. with Thales, Pythagoras, and others, and reached their high points a little more than a century later in the work of Eudoxus, who is responsible for the theory of proportions, which in antiquity held the place now held by the modern theory of real numbers.\n\nThe third period is the Hellenistic age, which extended from the third century b.c. to the sixth century a.d. The early part of this period, sometimes called the golden age of ancient mathematics, encompassed Euclid’s Elements (about 300 b.c.), which is the most important textbook ever written in mathematics, the work on conics by Apollonius (about 250 b.c.), and above all the extensive and profound work of Archimedes on metric geometry and mathematical physics (Archimedes died in 212 b.c.). The second most important systematic treatise of ancient mathematics, after Euclid’s Elements, is Ptolemy’s Almagest (about a.d. 150). Ptolemy systematized and extended Greek mathematical astronomy and its mathematical methods. The mathematical sophistication of Archimedes and the richness of applied mathematics evidenced by the Almagest were not equaled until the latter part of the seventeenth century.\n\nClassical analysis\n\nThe intertwined and rapid growth of mathematics and physics during the seventeenth, eighteenth, and nineteenth centuries centered in a major way on what is now called classical analysis : the calculus of Newton and Leibniz, differential and integral equations and the special functions that are their solutions, infinite series and products, functions of a complex variable, extremum problems, and the theory of transforms. At the basis of all this are two major ideas, function and limit. The first evolved slowly, beginning with the correspondence, established in the Cartesian fusion of the two best-developed areas of ancient mathematics, between algebraic expressions and simple geometric curves and surfaces, until we now have the present, very simple definition of the term “function” A set ｆ of points in the plane (ordered pairs of numbers) of the form (x,y) is called a function if at most one y is associated with each x. If (x, y) is a member of ｆ, it is customary to write y = f(x); x is sometimes called the independent variable and y the dependent variable, but no causal meaning should be read into this terminology.\n\nThe notion and notation may be generalized to more than one independent variable; if g is a set of ordered triples (x, y, z) with at most one z associated with each pair (x,y), then z =g(x, y) is called a function of two arguments. Since the most general notion of function can relate any two sets of objects, not just sets of numbers, it is sometimes desirable to emphasize the numerical character of the function. Then ｆ is said to be a real-valued function of a real variable; here the term “real” refers to real numbers (in contrast to complex numbers, which will be discussed later).\n\nAlthough a real-valued function has been defined as a set of ordered pairs of numbers, (x,y), where the domain of x is is an unspecified set of numbers, the subsequent discussion of functions is mostly confined to the familiar case in which the domain of x is an interval of numbers. Even when the discussion applies more generally, it is helpful to keep the interval case in mind.\n\nA desire to understand limits was apparent in Greek mathematics, but a correct definition of the concept eluded the Greeks. A fully satisfactory definition, which was not evolved until the nineteenth century (by Augustin Louis Cauchy), is the following: b is the limit of ｆ at a if and only if for every positive number є there is a positive number δ such that, when the absolute value of x—a is less than є and greater than 0 (that is, 0 <│x - a│ < δ), the absolute value of f(x) – b is less than є (that is, │f(x) – b│ < є). In other words, b is the limit of ｆ at a if x can be chosen sufficiently close to a (but not equal to a) to force f(x) to be as close to b as de-sired. Symbolically, this is written limx→af(x) = b. The limit of ｆ at a may exist even though f(a) is not defined; moreover, when f(a) is defined, b may or may not equal f(a). If it does—that is, if f(x) is “near” f(a) whenever x is “near” a—then f is\n\nsaid to be continuous at a. If ｆ is continuous at each a in an interval, ｆ is said to be continuous over that interval.\n\nThe calculus\n\nThe calculus defines two new concepts, the derivative and the integral, in terms of function and limit. They and their surprising relationship serve as the basis of the rest of mathematical analysis.\n\nThe derivative. The first definition arises as the answer to the question “Given a function ｆ, what is its slope (or, equivalently, its direction or rate of change) at any point x?” For example, suppose that y = ｆ(x) represents the distance, y, that a particle has moved in x units of time; then what is the rate of change of distance—the instantaneous velocity—at time x? If h is a short period of time, then an approximate answer is the distance traversed between x and x + h, that is, ｆ(x + h)— ｆ(x), divided by the time, h, taken to travel that distance (see Figure 1). The approximation is better the smaller the value of h, which suggests the definition of the rate of change of ｆ at x as the limit of this ratio as h approaches 0, that is,\n\nThis limit, if it exists, is denoted by ｆ(x) (or by dｆ(x)/dx or by dy/dx) and is called the derivative of ｆ at x. If f(x) exists, then ｆ can be shown to be continuous at x, but the converse is not true in general.\n\nOne of the earliest and most important applications in the social sciences of the concept of a derivative has been to the mathematics of marginal concepts in economics. For example, let x represent output, C(x) the cost of output x, and R(x) the revenue derived from output x; then C’(x) and R’(x) (or dC(x)/dx and dR(x)/dx) are the marginal cost and marginal revenue, respectively. Marginal utility, marginal rate of substitution, and other marginal concepts are defined in a similar fashion. Many of the fundamental assumptions of economic theory receive precise formulation in terms of these marginal concepts.\n\nThe integral. The second concept in the calculus arises as the answer to the question “What is the area between the graph of a function ｆ and the line y = 0 (the horizontal axis, or abscissa, of the coordinate system) over the interval from a to b?” (Regions below the abscissa are treated as negative areas to be subtracted from the positive ones above the abscissa; see Figure 2.) The solution, which will not be stated precisely, involves the following steps: the abscissa is partitioned into a finite number of intervals; using the height of the function at some value within each interval, the function is approximated by the resulting step function; the area under the step function is calculated as the sum of the areas of the rectangles of which it is composed; and, finally, the limit of this sum is calculated as the widths of the intervals approach zero (and, therefore, as their number approaches infinity). When this limit exists, it is called the Riemann integral of f from a to b and is symbolized as ∫baｆ(x) dx. It can be shown that the Riemann integral exists if ｆ is continuous over the interval; it also exists for some discontinuous functions. For more advanced work, the concept of the length of an interval is generalized to the concept of the Lebesgue measure of a set, and the Riemann integral is generalized to the Lebesgue integral Roughly, the vertical columns used to approximate the area in the Riemann integral are replaced in the Lebesgue integral by horizontal slabs.\n\nAlthough the interpretation of the integral as an extension of the elementary concept of area is\n\nimportant, even more important is its relation (called the fundamental theorem of the calculus) to the derivative: Consider as a function of the upper limit, x, of the interval over which the integral is computed; it can then be proved that the derivative of this function, F’(x) exists and is equal to f(x). Put another way, the rate of change at x of the area generated by ｆ is equal to the value of ｆ at x; or put still another way, the operation of taking the derivative undoes the operation of integration. This fact plays a crucial role in the solution of many problems of classical applied mathematics that are formulated in terms of derivatives of functions.\n\nIntroductions to the calculus and elementary parts of analysis are Apostol (1961–1962) and Bartle (1964).\n\nImplicit definitions of functions\n\nAn algebraic equation such as x2 – 5 x – 3 = 0 implicitly defines two numbers (namely, the two values of x, 3 and –½) for which the equality holds. Other algebraic equations implicitly define sets of numbers for which they hold.\n\nA functional equation is an equality stated in terms of an unknown function; it implicitly defines those functions (as in the algebraic case, there may be more than one) that render the equality true.\n\nOrdinary differential equations. Suppose it is postulated that the amount of interest (that is, the rate of change of money at time t) is proportional to (that is, is a constant fraction, k of) the amount, ｆ(t), of money that has been saved. (This is the case of continuous compound interest.) Then ｆ satisfies the equation ｆ'( t ) = kｆ(t). This is a simple example of an ordinary differential equation, the solution of which is any function having the property that its derivative is k times the function. The solutions are f(t) = f(0) exp(kt), where f(0) denotes the initial amount of money at time t = Q. Another simple economic example is the differential equation that arises from the assumption that marginal cost always equals average cost (that is, dC (x)/dx = C(x)/x) which has the solution that average cost is constant, that is, that C(x) = kx for some constant, k.\n\nSome laws of classical physics are formulated as second-order, linear, ordinary differential equations of the form\n\nｆ” (t) + P(t)ｆ’(t) + Q(t)ｆ(t) = R(t),\n\nwhere ｆ” is the derivative of ｆ(ｆ” is called the second derivative of ｆ ) and P, Q, and R are given functions. If, for example, ｆ denotes distance, then this differential equation asserts that at each time t, a linear relation holds among distance, velocity, and acceleration.A vast literature is concerned with the solutions to this class of equations for different restrictions on P, Q, and R; most of the famous special functions used in physics—Bessel, hypergeometric, Hankel, gamma, and so on—are solutions to such differential equations (see Coddington 1961).\n\nPartial differential equations Many physical problems require differential equations a good deal more complicated than those just mentioned. For example, suppose that there is a flow of heat along one dimension, x. Let ｆ(x,t ) denote the temperature at position x at time t. With t fixed, one can find the rate of change (the derivative) of temperature with changes in x; denote this by ∂ｆ(x,t)/∂x and its second derivative with respect to x by ∂2 ｆ(x,t)/∂x2. These are called partial derivatives. Similarly, holding x fixed, the derivative with respect to t is denoted by ∂ｆ(x,t)/∂t. According to classical physics, temperature changes due to conduction in a homogeneous one-dimensional medium satisfy the following partial differential equation:\n\nwhere ｆ is the thermal conductivity, p the density, and σ thespecific heat of the medium. Problems involving two or more independent variables (usually, time and some or all of the three space coordinates)—fluid flow, heat dissipation, elasticity, electromagnetism, and so on—lead to partial differential equations. Their solution is often very complex and requires the specification of the unknown function along a boundary of the space. This requirement is called a boundary condition. (See Akademiia Nauk S.S.S.R. [1956] 1964, chapter 6.)\n\nIntegral equations. Some physical problems lead to integral equations. In one type, functions g and K of one and two variables, respectively, and a constant, λ are given, and the problem is to find those functions, f, for which\n\nThis equation is called Fredholm’s linear integral equation or the inhomogeneous linear integral equation. Basically, it asserts that the value of some quantity ｆ at a point x is equal to an impressed value, g(x), plus a weighted average of its value at all other points. Integral equations arise in empirical contexts for which it is postulated that the value of a function at a point depends on the behavior of the function over a large region of its domain. Thus, in the example just considered the value of ｆ at x depends on the integrand K(x,y)ｆ(y) integrated over the interval (a,b). There is a large body of literature dealing with the solution of various types of integral equations, especially those of interest in physics and probability theory.\n\nFunctional equations. Although both differential and integral equations (and mixtures of the two, called integrodifferential equations) are examples of functional equations, that term is often restricted to equations that involve only the unknown function, not its derivatives or integrals. A simple, well-known example is ｆ(xy) =ｆ(x) + ｆ(y), which implicitly defines those functions that trans-form multiplication into addition. If ｆ is required to be continuous, then the solutions are where K is a positive constant; this integral is called the natural logarithm. The choice of K is usually referred to as the selection of the base of the logarithm.\n\nDifference equations are functional equations of special importance in the social sciences. They arise both in the study of discrete stochastic processes (in learning theory, for example) and as discrete analogues of differential equations. Here the unknown function is defined only on the integers (or, equivalently, on any equidistant set of points), not on all of the real numbers, and so the function is written ｆn = ｆ ( n ), where n is an integer. The equation states a relation among values of the unknown function for several successive integers. For example, the second-order, linear difference equation—the analogue of the second-order, linear, ordinary differential equation, described above—is of the form.\n\nｆn+2 + Pnｆn+1 + Qnｆn = Rn.\n\nIn some probabilistic models of the learning process it is postulated (or derived from more primitive assumptions) that the probability of a particular response on trial n+ 1, denoted by pn+1, is some function of pn and of the actual events that occurred on trial n. The simplest such assumption is the linear one, that is, pn+1 = αpn + β where α and β are parameters that depend upon the events that actually occur. If there is a run of trials during which the same events occur, so that α and β are constant, then the solution to the above first-order, linear difference equation is\n\nWhen different events occur on different trials, the equation to be solved becomes considerably more complex. An introduction to difference equations is Goldberg (1958).\n\nGiven a functional equation—in the most general sense—the answer to the question of whether a solution exists is not usually obvious. Exhibiting a solution, of course, answers the question affirmatively, but often the existence of a solution can be proved before one is found. Such a result is known as an existence theorem. If a solution exists, it is also not usually obvious whether it is unique and, if it is not unique, how two different solutions relate to one another. A statement of the nature of the nonuniqueness of the solutions is known, somewhat inappropriately, as a uniqueness theorem. Some rather general existence and uniqueness theorems are available for differential and integral equations, but in less well understood cases considerable care is needed to discover just how restrictive the equation is.\n\nA general work on functional equations is Aczel (1966).\n\nThree other areas of classical analysis\n\nThree other branches of classical analysis will be briefly discussed.\n\nExtremum problems For what values of its argument does a function assume its maximum or its minimum value? This type of problem arises in theoretical and applied physics and in the social sciences. In its simplest form, a real-valued function ｆ is defined over some interval of the real numbers, and the problem is to find those x° for which ｆ(x°) is a maximum or a minimum. If ｆ is differentiable and if x° is not one of the end points of the interval, a necessary condition is that f'(x°) = 0; moreover, x ° is a local maximum if ｆ(x°) <0 and a local minimum ifｆ (x°) >0. (These statements should be intuitively clear for graphs of simple functions.) From these results it is easy to find, for example, which rectangle has the maximum area when the perimeter is held constant: it is the square whose sides are each equal to a quarter of the perimeter.\n\nA much more difficult and interesting problem—the subject of the calculus of variations—is to find which function (or functions) ｆ of a given family of functions causes a given function ｆ of ｆ (known as a functional) to assume its maximum or minimum value. For example, let ｆ be a continuous function that passes through two fixed points in the plane, and let F(ｆ) be the surface area of the body that is generated by rotating ｆ about the abscissa. A question that may be asked is “For which ｆ (or ｆ’s) is F(f) a minimum?” A major tool in the solution of this problem is a second-order, ordinary differential equation, known as Euler ’s equation, that ｆ must necessarily satisfy (just as the solution x0 to the simpler problem necessarily satisfies ｆ '(xO) = 0). (See Akademiia Nauk S.S.S.R. [1956] 1964, chapter 8.)\n\nWithin the past twenty years new classes of extremum problems have been posed and partially solved; they are mainly of concern in the social sciences, and they go under the names of linear, non-linear, and dynamic programming. An example of a linear programming problem is the following diet problem. Each of several foodstuffs, ｆ1,ｆ2,..., ｆk, contains known amounts of various nutritional components, such as vitamins and proteins. Let fij be the amount of component j in food fi, j = 1, 2,..., n, and let a, be the minimum amount of component j acceptable in the diet. If Xi is the amount of food fi in the diet, the diet will be acceptable only if the following n inequalities are fulfilled:\n\nx1 ｆ1 + x2ｆ2j +...+ xk ｆkj ≥ ai, j = 1,2,...,n.\n\nIf Pi denotes the price of food ｆi, the problem is to choose the xi so as to minimize the cost,\n\nx1p1+ x2p2+...+ xkpk,\n\nwhile fulfilling the above linear inequalities. [SeeProgramming.]\n\nFunctions of a complex variable One of the most beautiful subfields of analysis is the theory of functions of a complex variable, which was developed in the nineteenth century, starting with the work of Cauchy. It has been significant in the growth of several two-dimensional, continuous physical theories, including parts of electromagnetism, hydrodynamics, and acoustics, but so far its applications in the social sciences have been mainly restricted to mathematical statistics, as in the concept of the characteristic function of a probability distribution. A complex number, z, is of the form z = x+iy, where x and y are real numbers and i = Sums and products are defined in such a way that the resulting arithmetic reduces to that of the ordinary numbers when y = 0. Because a point (x,y) in the plane can be (usefully) identified with the complex number x + iy, functions from the plane into the plane can be interpreted as complex-valued functions of a complex variable. If the derivative of such a function exists at all points of a region, derivatives of all orders exist and the function can be expressed as a convergent power series of the form α0 + α1,z + α2,z2+...+ for some circle of z’s within that region. It is clear from this result that the mere supposition that the derivative exists is a much stronger condition for complex-valued functions than for ordinary numerical functions. Such functions, which are called analytic, are very strongly constrained—among other things, specifying an analytic function over a small region determines it completely—and this fact has been effectively exploited to solve many two-dimensional problems of theoretical and practical interest. Interestingly, the theory cannot be neatly generalized beyond two dimensions. An introductory work on functions of a complex variable is Cartan (1961).\n\nIntegral transforms. Suppose that ｆ is any continuous, real-valued function defined over an interval from α to b and that K is a fixed, continuous, real-valued function of two variables, the first of which is also on the interval from α to b; then is called an integral transform of ｆ. If K satisfies certain restrictions, knowing I is equivalent to knowing ｆ. Nevertheless, if K is carefully chosen, I may have convenient properties not possessed by ｆ. For example, if α = 0, b=∞, and K(x,y) = e-xy, then I, which is then known as the Laplace transform and which is closely related to the moment-generating function of statistics, has the property that it converts certain integrals (convolutions) of two functions into multiplications of their transforms. In statistics such a convolution represents the distribution of the sum of two independent random variables. Another well-known and important example is the Fourier transform, which is used widely in statistics, and to a lesser extent in probabilistic models of behavior, to obtain a probability distribution from its characteristic function.\n\nTheory of numbers\n\nDespite several intellectual crises that led mathematicians to introduce new types of numbers into mathematics, it was not until about a hundred years ago that numbers were treated as being something other than intuitively understood. The natural numbers, 1,2,3,..., and their ratios, the positive rationals, are ancient concepts. The Greeks first noted their incompleteness when they showed that they are inadequate to represent the length of the diagonal of a square whose side is of length 1. Certain irrational numbers had to be added, and later 0, negative numbers, and complex numbers were added so that certain classes of equations would all have solutions. To clarify this patchwork and to understand the uniqueness of the additions, nineteenth-century mathematicians undertook the axiomatization of various aspects of the number system. Perhaps the most subtle step was the definition of irrational numbers in terms of sets of rational numbers (roughly, the set of all rationals less than the irrational to be defined).\n\nThe axiomatization of numbers is not really the mainstream of the “theory of numbers.” When one sees a book or course with that title, it usually refers to the study of properties of the natural numbers, mainly the prime numbers. Recall that an integer is prime if it is divisible only by 1 and itself; the first few primes are 3, 5, 7, 11, and 13. In addition to the many results that can be proved directly (some of which were known to the ancients), such as that every integer can be represented uniquely as the product of powers of primes and that there are infinitely many primes, other results have depended upon the application of deep results from analysis. For example, parts of the theory of functions of a complex variable were used to show that the number of primes not larger than n divided by the number n/lnn, where Inn is the natural logarithm of n, that is, is a ratio that approaches 1 as n becomes large. Not only has this work greatly increased the depth of understanding of integers, but it has fed back into analysis and was one of the factors leading to the development of parts of contemporary abstract algebra.\n\nMany applications of mathematics (for example, in statistics) involve counting the number of distinct events or objects that satisfy certain conditions; often these counting problems are quite difficult. Theorems providing explicit formulas or recursion schemes are called combinatorial theorems. One of the earliest important examples was the binomial theorem for the expansion of (a + b)n, which is now part of every elementary algebra course. [SeeProbability, article on Formal Probability.]\n\nA general introduction to the theory of numbers is Ore (1948).\n\nAlgebra\n\nClassically, algebra was the theory of solving equations expressed in terms of the four arithmetical operations—addition, subtraction, multiplication, and division. The linear and quadratic equations of elementary algebra are familiar examples. Historically, the expression of mathematical problems in the form of equations, using letters to stand for the unknown numbers, was a major step in clarifying and simplifying the mathematical nature of many kinds of problems. Perhaps the most important consequence of the introduction of letters and the use of equations was the extension of routine methods of calculation to quite complicated settings. The introduction of algebraic equations probably ranks in importance in the history of ideas with the earlier invention, probably first by the Babylonians, of the place-value system of notation for numbers; such a system was needed to develop simple algorithms for performing arithmetical computations.\n\nThe general theory of algebraic equations, the elementary parts of which are studied in high school, has a long and distinguished history in mathematics. The proof by Niels Henrik Abel in 1824 that solutions of an algebraic equation of degree five or greater, where the degree is the highest exponent of any term in the equation, cannot be expressed in terms of radicals (that is, expressions definable in terms of square roots) was one of the most important mathematical results of the first half of the nineteenth century. Another result of basic importance is the fundamental theorem of algebra, which was first proved in the eighteenth century but which was proved rigorously only in the last half of the nineteenth century. This theorem asserts that every algebraic equation always has at least one root that is a real or a complex number. Also of great significance were the proofs that not all numbers are roots of algebraic equations; numbers that are not such roots are called transcendental numbers. The most famous proofs of this sort are Charles Hermite’s (in 1873) that e is transcendental and F. Lindemann’s (in 1882) that π is transcendental.\n\nOrderings\n\nMuch of the work in algebra during the present century has been devoted to generalized mathematical systems that are characterized not in terms of the four fundamental arithmetical operations but in terms of generalizations of these operations and of the familiar ordering relations of “less than” and “greater than.”\n\nIn a number of the social sciences the theory of binary relations has received extensive application. From an algebraic standpoint a binary relation structure may be characterized as consisting of a set A and a set R of ordered pairs (x,y), where x and y are both elements of A. Such an R is called a binary relation on A. A relation R is said to be a partial ordering of A when it is reflexive, antisymmetric, and transitive—that is, when it satisfies the following three properties: reflexive; for every x in A, xRx; antisymmetric: for every x and y in A, if xRy and yRx, then x – y; transitive: for every x, y, and z in A, if xRy and yRz, then xRz. If R is also connected in A (that is, if for any two elements x and y in A with x ≠ y, either xRy or yRx) then R is said to be a complete or simple ordering or, sometimes, a linear ordering of A. The concept of a complete ordering is a direct abstraction of the order properties of “≤” with respect to the real numbers. A familiar use of the concept of an ordering relation is in utility theory, particularly in the classical theory of demand in economics, in which it is assumed that each individual has an ordering relation over the set of commodity bundles or, more generally, over the set of alternatives with which he is presented. The general concept of ordering relations also has far-ranging applications in the theory of measurement within psychology and sociology, and more general binary relations have been extensively applied in anthropology in the study of kinship systems.\n\nPartial orderings can be extended in another direction by imposing additional conditions to obtain lattices, which have also been used in the social sciences. In a different direction, but still within the framework of binary relations, is the theory of graphs, in which no restrictions are placed on the binary relation, R. Applications of graph theory have been made to social-psychological and sociological problems, especially to provide a mathematical method for representing various kinds of relationships between persons.\n\nGroups, rings, and fields\n\nAnother direction of generalization of classical algebra has been to what are called groups, rings, and fields. A group is a set A together with a binary operation, o, satisfying the following axioms. First, the operation o is associative, that is, for x, y, and z in A, x o (y o z) =(x o y) o z. Second, there is an element e, called the identity, of the set A such that for every x in A, xoe = eo x = x. And, finally, for each element x of A there is an inverse element x-1 such that x o x-1 = e. It is obvious that if A is taken as the set of integers, o as the operation of addition, e as the number 0, and the inverse of x as the negative of x, then the set of integers is a group under the binary operation of addition. The theory of groups has had profound ramifications in other parts of mathematics and in the sciences, ranging from the theory of algebraic equations to geometry and physics. The reason for the fundamental importance of group theory is perhaps best summarized by stating that a group is the appropriate way to formulate the very important concept of symmetry. In the range of applications of group theory just mentioned, the underlying thread is the concept of symmetry, whether it is in the symmetry of the roots of an equation or the symmetry properties of the fundamental particles of physics. As a simple example, consider the finite group of rotations 90°, 180°, 270°, and 360°. A square does not change its apparent orientation under such a rotation about its center, but an equilateral triangle does. This group of rotations is the symmetry group of rotations for a square but not, of course, for an equi-lateral triangle. Although the methods and results of group theory have not yet had special applications of depth in the social sciences, they are important to many of the general mathematical results that have been applied.\n\nThe theories of rings and fields represent rather direct generalization of arithmetical properties of the number system. The theory of groups is fun damentally a generalization of the concept of a single binary operation, such as addition or multiplication, whereas rings and fields are algebraic systems that have two fundamental operations. The most familiar example of a field or of a ring is the set of rational numbers or of real numbers with respect to the operations of addition and multiplication.\n\nBoolean algebras\n\nAlgebraic aspects of the theory of sets have been studied under the heading of Boolean algebras. The concept of an algebra of sets, that is, a collection of sets closed under union and complementation, is fundamental in the modern theory of probability, where events are interpreted as sets of possible outcomes and numerical probabilities are assigned to events. [SeeProbability, article on Formal Probability.]\n\nIsomorphism and homomorphism\n\nIt should be mentioned that certain very general mathematical concepts find their most natural definition and application in modern algebra. One of the most important concepts is that of the isomorphism of two mathematical systems. An isomorphism is a oneto-one mapping of a system A onto a system B in which the operations and relations of A are preserved under the mapping and have the same structure as the operations and relations of system B. If the mapping is not one-to-one but the operations and relations are preserved, then it is called a homomorphism. A well-known application of the concept of isomorphism in the social sciences is in theories of fundamental measurement in which one shows that an appropriate algebra of empirical operations is isomorphic to some numerical algebra. It is this isomorphism that permits the direct application of computational methods to the results of measurement.\n\nIntroductory works on algebra, both for this and for the next section, are Birkhoff and MacLane (1941) and Mostow, Sampson, and Meyer (1963).\n\nVector spaces and matrix algebra\n\nLinear algebra is one of the most important generalizations of classical elementary algebra. The objects to which the operations of addition and multiplication are applied are now matrices, vectors of an n-dimensional space, and linear transformations (an n × n matrix is a particular representation of a linear transformation in n-dimensional space). More particularly, linear algebra arises as a generalization of the linear equations so familiar in elementary algebra, and historically one of the most important tasks of linear algebra has been to find solutions of systems of linear equations. As many research workers in the social sciences know, the numerical solution of linear equations can be an extremely laborious and difficult affair when the number of equations is large. The set of coefficients of a system of linear equations gives rise to the concept of a rectangular array of numbers, which is precisely what a matrix is. An algebra of matrices in terms of addition and multiplication may be constructed; the distinguishing feature of this algebra, as compared with the algebra of the real numbers, is that multiplication is not commutative—that is, AB is not usually equal to BA, and the product of two nonzero matrices can be zero.\n\nThe intuitive geometric concept of a vector may be represented by a column or row of n numbers, and an algebra of vectors, which bears a close resemblance to the algebra of numbers, may be constructed. Simple (linear) transformations of vectors, such as rotations and stretches of the co-ordinate system in space, can be interpreted as multiplication by matrices. The interaction between the geometrical intuitions about n-dimensional space and the algebraic techniques of calculation provided by linear algebra and the theory of matrices have made them powerful tools in the application of mathematics to many parts of science. These applications have been particularly prominent in statistics (for example, in factor analysis), as well as in economics, where it is often useful to treat n-dimensional bundles of commodities as vectors.\n\nTopology and abstract spaces\n\nIntuitively, a topological transformation of a geometrical figure or object is a deformation that introduces neither breaks nor fusions in the object. Put more exactly, a topological transformation is one that is one-to-one, is continuous, and has a continuous inverse. If one starts with a circle—perhaps the best example of a simple closed curve—one can deform it topologically into an ellipse or into the shape of a crescent, but one cannot deform it topologically into a figure eight, for example, because then two distinct points of the circle are fused as the intersection point of the eight. Also, one cannot deform it into a straight line segment, because to do so would introduce a break in the circle. Many familiar qualitative geo-metrical properties are topological invariants in the sense that they are not altered (are invariant) under topological transformations. Examples are the property of being inside or outside a closed figure in the plane; the property of a surface being closed, such as the surface of a sphere or an ellipsoid; or the property of the dimension of an object. For example, the surface of a sphere cannot be topologically transformed into a one-dimensional curve or a three-dimensional sphere. We shall not attempt here to give an exact definition of continuity as it is used in topology; we simply remark that it is a reasonable generalization of the concept of continuity used in analysis.\n\nTopological methods and results have far-reaching applications in many branches of mathematics, but as yet the methods themselves have not been directly applied in those parts of the social sciences concerned extensively with empirical data. The most direct applications have been in economics, where topological fixed-point theorems have been of great importance in investigating the conditions guaranteeing the existence of a stable equilibrium in a competitive economy. The classical example of a fixed-point theorem—first proved by L. E. J. Brouwer, at the beginning of this century—states that for every topological mapping of an n-dimensional sphere into itself there is always at least one point that maps into itself, that is, remains fixed. Familiar examples of such mappings are rotations in two or three dimensions for which the center of the rotation is the fixed point of the transformation.\n\nTopological space\n\nAs a typical example of abstraction in modern mathematics, the intial concept of a topological transformation of familiar geometrical figures has led to the general abstract notion of a topological space. Roughly speaking, a topological space consists of a set, X , and a family, ℱ of subsets of X , called open sets, for which the following four conditions are satisfied: the empty set is inℱ X is in ℱ the union of arbitrarily many sets each of which is in ℱ is also in ℱ and the intersection of any finite number of sets from ℱ is also in ℱ. The concept of an open set is a generalization of the notion of an open interval of real numbers (an interval that does not include its end points). For example, the natural topology of the real line is the family of open intervals together with the sets that are formed from arbitrary unions and finite intersections of open intervals. Generally speaking, the notion of open set is used to express the idea of continuity. The important thing about a continuous function is that it does not jumble neighboring points too much, and this requirement may be expressed by requiring of a topological transformation that open sets be mapped into open sets and that the inverse of an open set be an open set.\n\nMetric space Other kinds of abstract spaces have come into prominence in the development of topology. Perhaps the most important is the concept of a metric space. A set, X , together with a distance function, d, that maps pairs of points into real numbers is called a metric space if d satisfies the following conditions: d(x,y) = 0 if and only if x = y, that is, the distance between x and y is 0 if and only if x and y are the same point; d(x,y) ≥ 0, which asserts that distance is a non-negative real number; d(x,y) = d(y , x), that is, distance is symmetric; and, finally, d(x, y) + d(y, z) ≥ d(x, z), which is known as the triangle inequality. The concept of a metric space has had important applications in many parts of mathematics and is a fundamental concept in modern mathematics. It has been applied in recent work in scaling theory in psychology and sociology, particularly to the problems of multidimensional scaling, and also in certain areas of mathematical economics [see Scaling]. It is clear that the notion of a metric space generalizes, in a very natural way, the concept of distance in Euclidean space.\n\nA typical metric problem raised in the social sciences is this: Given data in the form of “distances” among a finite set of points, what is the smallest dimensional Euclidean space within which the points can be embedded so that these distances equal the Euclidean or some other preassigned metric of that space? Recently this problem has been effectively generalized by permitting certain transformations of the “distances” that preserve their metric property. Little has yet been done about embeddings in non-Euclidean spaces.\n\nAn introductory work on topology is Hocking and Young (1961).\n\nFoundations\n\nAs was remarked above, the concept of a rigorous mathematical proof originated in ancient Greek mathematics. The modern formal axiomatic method, characteristic of twentieth-century mathematical research and one of the most important topics to be clarified in modern research on foundations of mathematics, is conceptually very close to the approach followed in Euclid ’s Elements. The main difference is that the primitive concepts of the theory are now treated as undefined or meaningless. All that is assumed about them must be formally expressed in the axioms. In contrast, in the Elements primitive concepts such as those of point and line are given an interpretation or meaning from the very beginning. This modern conception originated with David Hilbert, who provided the first complete, modern axiomatization of geometry in 1889. It is customary to say that the concepts of the theory are implicitly defined by the axioms. What is not recognized often enough is that the collection of axioms together explicitly de fines the theory embodied in the concepts. Thus, in slightly more exact phrasing, the axioms of Euclidean geometry define the theory of Euclidean geometry by defining the phrase “is a model of Euclidean geometry.” In the same fashion, the axioms of group theory define the theory of groups by specifying what kinds of objects are called groups or, in other words, what kinds of objects are models of the theory of groups (here we are using the term “model” in the logical or mathematical sense).\n\nA more particular aim of foundational research has been to provide a set of axioms that would serve as a basis for the main body of mathematics. At least three major positions on the foundations of mathematics have been enunciated in the twentieth century; they differ in their conception of the nature of mathematical objects.\n\nIntuitionism\n\nIntuitionism holds that in the most fundamental sense mathematical objects are themselves thoughts or ideas. The intuitionist holds that one can never be certain that he has correctly expressed the mathematics when it is formalized as a mathematical theory. As part of this thesis, the classical logic of Aristotle, in particular the law of excluded middle, has been challenged by Brouwer and other intuitionists because it permits the derivation of purely existential, nonconstructive statements about mathematical objects. In particular the validity of classical reductio ad absurdum proofs depends upon this logical law. Although intuitionists express themselves in a way which suggests a psychological analysis of mathematics, it should be emphasized that their conception of mathematical objects as thoughts has not been seriously explored by any intuitionists from the standpoint of scientific psychology.\n\nPlatonism\n\nA second view of mathematics, the Platonistic one, is that mathematical objects are abstract objects that exist independently of human thought or activity. Those who hold that set theory or logic itself provides an appropriate foundation for mathematics (adherents of logicism) usually adopt some form of Platonism in their basic attitude. From the standpoint of working mathematics, set theory—and thus Platonism—has been the most influential conception of mathematics in this century. Set theory itself originated in the late nineteenth century with the revolutionary work of Georg Cantor. Its foundations were called into question by Bertrand Russell’s discovery of a simple paradox which arises in considering the set of all objects that are not members of themselves. If it is supposed that to every property there corresponds the set of objects having this property, then a contradiction within classical logic may easily be derived by considering the set whose members are those and only those sets that are not members of themselves. An apparently satisfactory foundation for set theory, which avoids this and related paradoxes, was formulated in 1908 by Ernst Zermelo, and with suitable technical extensions it provides a satisfactory basis for most of the mathematics published in this century.\n\nFormalism\n\nThe third influential position on the foundation of mathematics, called formalism, was developed by Hilbert and others. This view is that the primary mathematical objects are the symbols in which mathematics is written. This carries to the extreme the development of the axiomatic method begun by the Greeks. Under the formalist account the interpretation and use of mathematics must then be given from outside pure mathematics. From a psychological or behavioral standpoint, there is much that is appealing about formalism, but again little effort has yet been made to relate the detailed results and methods of formalism to theoretical or experimental work in scientific psychology.\n\nRelevance of research on foundations\n\nIn view of the high degree of agreement about the validity of most published pieces of mathematics, the skeptical social scientist may question the real relevance of these varying views about the foundations of mathematics to working mathematics itself. There is a highly invariant content of mathematics recognized by almost all mathematicians, including those concerned with the foundations of mathematics, and this invariant content is essentially untouched by radically different philosophical views about the nature of mathematical objects. A reasonable conjecture is that future research in the foundations of mathematics will attempt to capture this invariant content by concentrating on the character of mathematical thinking rather than on the nature of mathematical objects.\n\nOne other important aspect of foundational research in the twentieth century is the fundamental work on mathematical logic, in particular the attempt by Gottlob Frege, A. N. Whitehead, Bertrand Russell, and others to reduce all of mathematics to purely logical assumptions. These efforts have led to great clarification of the nature of mathematics itself and to vastly increased standards of precision in talking about mathematical proofs and the structure of mathematical systems. Of major importance were the deep results of Kurt Godel (1931) on the logical limitations of any formal system rich enough to express elementary number theory. His results show that any such formal system must be essentially incomplete in the sense that not all true sentences of the theory can be proved as theorems.\n\nAn introductory work on foundations is Knee-bone (1963).\n\nMathematics applied to social sciences\n\nApplications of mathematics to specific social science problems are described, and detailed references are given, elsewhere in this encyclopedia. That material is not repeated here; several reason-ably general references are Allen (1938), Coleman (1964), Kemeny and Snell (1962), Luce (1964), Luce, Bush, and Galanter (1963-1965), Samuelson (1947). Suffice it to say that these applications involve only fragments of the whole of mathematics, and they have not been as successful as those in the physical sciences. The reasons are many, among them these: the effort so far expended is much less; the basic empirical concepts and variables have not been isolated and purified to the same degree; mathematics grew up with and was to some extent molded by the needs of physics, and so it may very well be less suited to social science problems if these problems are of a basically different character from those of physics; a typical social science problem appears to involve more variables than one is accustomed to handling in physics; and, finally, social scientists are generally not extensively trained in mathematics.\n\nA social scientist who attempts to formulate and solve a scientific problem in mathematical terms is often disappointed with the mathematics he can find. This may happen simply because a mathematical system appropriate to his problem does not seem to have been invented, or, as is more common, the definite and often quite complex mathematical system that he happens to want to under-stand in depth has not been investigated in any detail. In this century especially, mathematicians have tended to focus on very general classes of systems, and the theorems concern properties that are true of all or of large subclasses of them; however, these results do not usually provide much detailed information about any particular member of the class.\n\nAs an example, the axioms of group theory are not categorical—that is, two groups need not be isomorphic. Therefore, theorems about groups in general tell one little about the specific properties of a particular group. But this is what is of interest when a particular group is used to represent an empirical structure, as in modern particle physics.\n\nWhen this happens, it is necessary for the applied mathematician to carry out considerable mathematical analysis to achieve the understanding he needs to answer scientifically interesting questions.\n\nWe have already discussed two parts of mathematics in which highly specific systems have been explored in depth: classical analysis and matrix algebra. A primary motivation for this detailed work was the needs of physical science. In fortunate instances, a problem may be formulated in terms of one of these systems, in which case specific results can sometimes be extracted from the existing literature. Examples where this has been done are in the application of matrix algebra to factor analysis and of Markov chains (a part of probability theory) to several areas, including learning, social interaction, and social structure [see Factor Analysis; Markov Chains].\n\nTheory as detailed as this, however, is not typical of contemporary mathematics. We have in mind such active areas as associative and non-associative algebras, homological algebra, group theory, topological groups, algebraic topology, rings, manifolds, and functional analysis.\n\nThe generality of contemporary mathematics can be seductive in that it invites sophistic treatments of scientific problems. It is often not difficult to find some general branch of mathematics within which to cast a specific social or behavioral problem without, however, actually capturing in detail the various constraints of the problem. Without these constraints few explicit results and predictions can be proved. Nevertheless, the real emptiness of such endeavors can be shrouded for the unwary in the impressive symbolism and ringing terms of whatever mathematics it is that is not being seriously used.\n\nIf the growth of the social sciences parallels at all that of the physical sciences, they will study in detail various systems, which, although of peripheral mathematical interest, are of substantive interest. Indeed, some examples already exist, including these: (1) Just as classes of maximum and minimum problems have been formulated and solved in the physical sciences, other classes have arisen in the social sciences, such as linear, nonlinear, and dynamic programming, game theory, and statistical decision theory. (2) Various mathematical structures that may correspond to (parts of) empirical structures have been investigated, for example, aspects of the theory of relations and the closely related theory of graphs, matrix algebra, and concatenation algebras, which arose in the study of grammar and syntax. (3) Underlying the success of much physical theory is the fact that many variables can be represented numerically. The theories that account for this in physics are not suitable for the social sciences, but alternative possibilities are under active development, particularly in terms of theories of fundamental and derived measurement. The mathematics is reasonably involved, although for the most part the proofs are self-contained. (4) Although the theory of stochastic processes is a well-developed part of probability theory, a number of the processes that have found applications in the social sciences had not previously been studied by probabilists; their properties have been partially worked out in the social science literature. Among the most prominent examples are the nonstationary processes that have arisen in learning theory. Some of these postulate that on each trial one of several operators Qi transforms a response probability into the corresponding probability on the next trial. Two special cases have been most adequately studied. One assumes that the Qi are linear operators and the other assumes that the operators commute with one another—that is, Qi,Qj; = Qj,Qi,.[See Learning.]\n\nAs increasing use is made of mathematics in the social sciences, one may anticipate the investigation of very specific mathematical systems and, ultimately, the isolation of interesting abstract properties from these systems for further study and generalization as pure mathematics.\n\nR. Duncan Luce and Patrick Suppes\n\nBIBLIOGRAPHY\n\nAczÉl, J. 1966 Lectures on Functional Equations and Their Applications. New York: Academic Press.\n\nAkademiia Nauk S.S.S.R., Matematicheskii Institut (1956) 1964 Mathematics: Its Content, Methods, and Meaning. Edited by A. D. Aleksandrov, A. N. Kolmogorov, and M. A. Laurent’ev. 3 vols. Cambridge, Mass.: M.I.T. Press. → First published in Russian.\n\nAllen, R. G. D. (1938) 1962 Mathematical Analysis for Economists. London: Macmillan.\n\nApostol, Tom M. 1961-1962 Calculus. 2 vols. New York: Blaisdell.\n\nBartle, Robert G. 1964 The Elements of Real Analysis. New York: Wiley.\n\nBirkhoff, Garrett; and Maclane, Saunders (1941) 1965 A Survey of Modern Algebra. 3d ed. New York: Macmillan.\n\nCartan, Henri (1961) 1963 Elementary Theory of Analytic Functions of One or Several Complex Variables. Reading, Mass.: Addison-Wesley. → First published in French.\n\nCoddington, Earl A. (1961) 1964 An Introduction to Ordinary Differential Equations. Englewood Cliffs,N.J.: Prentice-Hall.\n\nColeman, James S. 1964 Introduction to Mathematical Sociology. New York: Free Press.\n\nCourant, Richard; and Robbins, Herbert (1941) 1961 What Is Mathematics? An Elementary Approach to Ideas and Methods. Oxford Univ. Press.\n\nFriedman, Bernard 1966 What Are Mathematicians Doing? Science 154:357–362.\n\nGÖdel, Kurt (1931) 1965 On Formally Undecidable Propositions of the Principia mathematica and Related Systems. I. Pages 4-38 in Martin Davis (editor), The Undecidable: Basic Papers on Undecidable Propositions, Unsolvable Problems and Computable Functions. Hewlett, N.Y.: Raven. → First published in German in Volume 38 of the Monatshefte fur Mathematik und Physik.\n\nGoldberg, Samuel 1958 Introduction to Difference Equations: With Illustrative Examples From Economics, Psychology, and Sociology. New York: Wiley. → A paperback edition was published in 1961.\n\nHocking, John G.; and YOUNG, GAIL S. 1961 Topology. Reading, Mass.: Addison-Wesley.\n\nKemeny, John G.; and Snell, J. Laurie 1962 Mathematical Models in the Social Sciences. Boston: Ginn.\n\nKneebone, G. T. 1963 Mathematical Logic and the Foundations of Mathematics: An Introductory Survey. New York: Van Nostrand.\n\nLuce, R. Duncan 1964 The Mathematics Used in Mathematical Psychology. American Mathematical Monthly 71:364–378.\n\nLuce, R. Duncan; Bush, Robert R.; and Galanter Eugene (editors) 1963–1965 Handbook of Mathematical Psychology. 3 vols. New York: Wiley.\n\nMostow, George; Sampson, Joseph H.; and Meyer, Jean-pierre 1963 Fundamental Structures of Algebra. New York: McGraw-Hill.\n\nNeugebauer, Otto (1951) 1957 The Exact Sciences in Antiquity. 2d ed. Providence, R.I.: Brown Univ. Press.\n\nNewman, James R. (editor) 1956 The World of Mathematics. 4 vols. New York: Simon & Schuster.\n\nOre, Øystein 1948 Number Theory and Its History. New York: McGraw-Hill.\n\nSamuelson, Paul A. (1947) 1958 Foundations of Economic Analysis. Harvard Economic Studies, Vol. 80. Cambridge, Mass.: Harvard Univ. Press.\n\nMATHEMATICS\n\nBible\n\nThe Bible does not deal directly with proper mathematical subjects; however there are some parts that do relate indirectly to different mathematical topics. These are widely discussed by the various commentators on the Bible and Talmud: the ratio of 300:50:30 between the three dimensions of Noah's ark (in the past, a basic ratio in shipbuilding), the mathematical model of a rainbow, the number of 220 sheep and goats sent by Jacob to Esau (220 as the first number of the smallest pair of amicable numbers), the calculations of the visibility of the crescent of the new moon, the total amount and volume of the daily *manna, Moses' financial report on the donations for the building of the Tabernacle (mishkan), the commandment of keeping exact measures and balances, chance and probability in relation to the fair division of the land of Israel, lot-drawing to insure the fair division of holy duties and privileges, the curve of \"projectile motion\" in relation to the unintentional killing of a man by throwing a stone, the surprising distribution of the 12 tribes into two equal groups of six on Mt. Gerizim and Mt. Ebal, and more.\n\nThe members of the tribe of Issachar were known as \"Marei de-Ḥushbena\" – the masters of calculations – as their elders specialized in astronomical and calendar calculations. Christian scholars have dealt extensively with Bible mathematics. Among others, an early 18th-century scholar, J.J. Schmidt published an interesting tractate called Biblicus Mathematicus (Zuellichau, 1732) in which many biblical-mathematical subjects are discussed, often based on Jewish sources. In another tractate there is a report on a request to the rabbinical court of Frankfurt to elaborate upon the "
    }
}