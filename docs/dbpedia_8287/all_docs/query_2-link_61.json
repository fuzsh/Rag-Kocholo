{
    "id": "dbpedia_8287_2",
    "rank": 61,
    "data": {
        "url": "https://cstheory.stackexchange.com/questions/52859/where-is-the-model-theory-in-programming-language-theory",
        "read_more_link": "",
        "language": "en",
        "title": "Where is the model theory in programming language theory?",
        "top_image": "https://cdn.sstatic.net/Sites/cstheory/Img/apple-touch-icon@2.png?v=da033b2b5220",
        "meta_img": "https://cdn.sstatic.net/Sites/cstheory/Img/apple-touch-icon@2.png?v=da033b2b5220",
        "images": [
            "https://cdn.sstatic.net/Sites/cstheory/Img/logo.svg?v=10b092e532a3",
            "https://www.gravatar.com/avatar/0161b7ba0a4de1bece2aa08a8fe282bb?s=64&d=identicon&r=PG",
            "https://www.gravatar.com/avatar/fd24d0ef4a02a6df6e5d88f803a11c27?s=64&d=identicon&r=PG&f=y&so-version=2",
            "https://www.gravatar.com/avatar/59d57d95bc7c45ced5f1969279cec06b?s=64&d=identicon&r=PG",
            "https://www.gravatar.com/avatar/eef361d616082b83f1f1a1e74dc572d8?s=64&d=identicon&r=PG",
            "https://www.gravatar.com/avatar/0161b7ba0a4de1bece2aa08a8fe282bb?s=64&d=identicon&r=PG",
            "https://cstheory.stackexchange.com/posts/52859/ivc/0c39?prg=37f8174e-7668-48d3-8b1c-0bcf0228302f"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": "2023-05-20T21:55:40",
        "summary": "",
        "meta_description": "I have a background in mathematical logic and am trying to learn some programming language theory. In the syntax of, say, first-order logic, one of the first distinctions you learn about is between",
        "meta_lang": "en",
        "meta_favicon": "https://cdn.sstatic.net/Sites/cstheory/Img/favicon.ico?v=b72736ad174d",
        "meta_site_name": "Theoretical Computer Science Stack Exchange",
        "canonical_link": "https://cstheory.stackexchange.com/questions/52859/where-is-the-model-theory-in-programming-language-theory",
        "text": "The model theory of programming languages is called denotational semantics. You can google the term to find out more about it, I'll give an extreme synthesis of it.\n\nDenotational semantics is a special case of \"categorical logic\", which is itself a generalization (introduced in the 1960s by Bill Lawvere) of the usual model theory of first-order logic. The idea is that a programming language may be seen as a (syntactic) category whose objects are combinations of basic types (Booleans, natural numbers, etc.) and whose arrows are equivalence classes of programs depending on a finite number of arguments. When I say \"combinations of basic types\" I mean that usually the syntactic category has at least products and a terminal object, the rest depends on the language. I am not going to explain what it means for two programs to be \"equivalent\" (and therefore to represent the same arrow in the syntactic category), but intuitively it means that they \"evaluate to the same thing\".\n\nFor example, for your program $f$, if the multiplication you use in its definition has type $A\\times A\\to A$, then $f$ would be an arrow of the syntactic category of type $A\\times A\\times\\mathsf{nat}\\to A$. (Programs that do not return anything are typed with the terminal object).\n\nNow, depending on your programming language, its syntactic category $\\mathcal C$ will have a certain structure and properties (like I said, it will have at least finite products). Then, your language will have (denotational) models in any category with that structure and properties. Given such a category $\\mathbf D$, a model is just a structure-and-property-preserving functor $F:\\mathcal C\\to\\mathbf D$. For example, $\\mathbf D$ could be $\\mathbf{Set}$, so your types will be interpreted by sets and your programs by functions. More often, $\\mathbf D$ will be a category with the property that every arrow has a (least) fixpoint, because fixpoints are needed to interpret recursion. A famous example is $\\mathbf{Cpo}$, the category of complete partial orders and Scott-continuous maps.\n\nThe fact that the category $\\mathcal C$ is \"syntactic\" means, a bit more technically, that it is sort of the \"free category\" with such and such structure/properties built from the syntax of the programming language. Therefore, the functor $F$ corresponding to the denotational model will be defined as soon as you define it on the basic types and on the basic pieces of the syntax of your programming language. This is precisely what happens in the usual model theory for first-order logic, where a model is defined as soon as you fix a set (more generally, an object of a category) interpreting the universe where your individuals live, and a function/relation (more generally, a morphism/subobject) for every function/relation symbol of your logical language. The fact that the model must verify the axioms of the theory correponds, in denotational semantics, to the fact that the arrows of the syntactic category are equivalence classes of programs, so your denotational model must equate equivalent programs.\n\nA final word of warning: in many expository texts on programming languages, denotational semantics is presented directly as an interpretation of the basic pieces of syntax into a certain category, without any reference to the functorial perspective or the construction of the syntactic category, so don't be surprised if you do not see that appearing explicitly.\n\nAddendum: let me clarify how categorical logic is able unify traditional model theory (of first-order logic) and denotational semantics.\n\nThe categorical viewpoint on traditional model theory is that every first-order theory $\\mathbb T$ induces a Boolean pretopos $\\mathrm{Syn}(\\mathbb T)$, the syntactic category of $\\mathbb T$. It doesn't matter what a Boolean pretopos is exactly, all it matters for the sake of this answer is that the category $\\mathbf{Set}$ of sets and functions is a Boolean pretopos, and that we may define a (very large) category of Boolean pretoposes and morphisms between them, which are functors preserving all the properties that make a category into a pretopos.\n\nOne of the pillars of categorical logic (the observation originally due to Lawvere) is that a model of $\\mathbb T$ in the traditional sense is exactly the same thing as a morphism of Boolean pretoposes\n\n$$\\mathrm{Syn}(\\mathbb T)\\to\\mathbf{Set}.$$\n\nAs I said in the comments, one may take another Boolean pretopos as $\\mathbf{Set}$, and get models in that pretopos. For example, if $\\mathbf{FinSet}$ is the category of finite sets, then a morphism $\\mathrm{Syn}(\\mathbb T)\\to\\mathbf{FinSet}$ is a finite model of $\\mathbb T$.\n\nAs Andrej pointed out, the theory of programming languages is more similar to universal algebra at this level, in the sense that a programming language may be seen as an equational theory: there are no logical operators, quantifiers, or anything like that, only terms (representing programs), built out of function symbols (or \"term-formers\"), and equalities between them (representing the so-called \"operational semantics\" of the programming language). Also, with respect to first-order logic, there are types, that is, the equational theory is multisorted (in traditional model theory, every first-order theory implicitly has only one sort).\n\nHowever, the idea of (denotational) model is exactly the same as that of first-order model. For example, the theory $\\mathbb G$ of groups is a (single-sorted) equational theory, and a group in the traditional sense is just a product-preserving functor\n\n$$\\mathrm{Syn}(\\mathbb G)\\to\\mathbf{Set}.$$\n\nHere, changing the target category is very useful, and you have even more freedom than in (classical) first-order logic because you have less properties to preserve (equational logic is much simpler than first-order logic--in fact, in this case all you need is a category with finite products, which is way less than a (Boolean) pretopos). For example, product-preserving functors $\\mathrm{Syn}(\\mathbb G)\\to\\mathbf{Top}$ are topological groups, product-preserving functors $\\mathrm{Syn}(\\mathbb G)\\to\\mathbf{Sch}$ are algebraic groups, etc., all objects which naturally come up in mathematics. Categorical logic gives a uniform account of all this variety of structures.\n\nSimilarly, when one defines a denotational model of a programming language $\\mathbb P$ in which types and programs are interpreted as objects and arrows of some category $\\mathbf D$, one is implicitly defining the syntactic category $\\mathrm{Syn}(\\mathbb P)$ and a structure/property-preserving functor\n\n$$\\mathrm{Syn}(\\mathbb P)\\to\\mathbf{D}.$$\n\nThe big difference with model theory, pointed out by Martin Berger in his comment, is that, in the theory of programming languages, there is no canonical class of categories, fixed once and for all, such that $\\mathbf{D}$ and $\\mathrm{Syn}(\\mathbb P)$ belong to that class. This is in sharp contrast with first-order logic (where we have (Boolean) pretoposes) or algebraic theories like $\\mathbb G$ (where we have finite-product categories). In other words, there is no canonical \"logical structure\" that we know $\\mathbb P$ must have (unlike first-order theories or algebraic theories): it all depends very much on the kind of programming language that $\\mathbb P$ is. This is ultimately due to the lack of a formal definition of \"programming language\".\n\nThat being said, there are some important cases, encompassing many useful situations. For example, a typical categorical structure for programming languages is that of a Cartesian closed category with a natural number object and a fixpoint operator, which is enough to define a Turing-complete programming language. (This shows, in particular, that you cannot take $\\mathbf D=\\mathbf{Set}$, because $\\mathbf{Set}$ does not have a fixpoint operator. So being able to vary the target of the intepretation functor is a generalization which is absolutely fundamental to programming languages!).\n\nAnother big difference with traditional model theory is that, usually, people do not study the relationship between various models $F:\\mathrm{Syn}(\\mathbb P)\\to\\mathbf D$ for a fixed $\\mathbf D$, because they differ in uninteresting ways. For example, when $\\mathbb P$ is the simply-typed $\\lambda$-calculus, the only choice you have in defining $F$ is to pick an object of $\\mathbf D$ for each atomic type, and the specific choice is often irrelevant. So, contrarily to first-order logic, it is interesting to change $\\mathbf D$ rather than pick a $\\mathbf D$ and then let $F$ vary. In fact, when people say that they have a \"model\" of a programming language, usually they mean that they have a $\\mathbf D$ with the desired structure/properties, not that they have fixed one specific $F$. This is another reason why denotational semantics has a different flavor than usual model theory, even though technically they are related via categorical logic.\n\nBy the way, all this (long!) digression was only to drive my point home: denotational semantics is to programming languages what model theory is to first-order theories (with all the necessary caveats). You do not need to know categorical logic in order to understand or study denotational semantics!\n\nModels in some semantic framework are essentially a mapping from synthetic objects to some other domain of object. In the sematic domain we typically identify or take as equivalent a bunch of synthetic objects. We do this because we know things about the sematic domain that we can use to learn things about the synthetic objects.\n\nAt the one extreme, one can map a program to the function that it computes over the standard model. Two programs are the same if they compute the same function. That is not a very useful semantics, we are often interested in also how they compute it. (I assume we at least care about what function the program is computing.)\n\nAt the other extreme, we can take the synthetic objects themselves as the semantic domain. That is not a very useful semantics.\n\nBetween these two there are many possibly semantic domains that one can use. Denotational semantics (with emphasize on s) are some very useful semantic domains. Note that we don't just care about the objects themselves but the relationships between them.\n\nHowever, keep in mind that things are not as clean as they may look at first. Denotational semantics works great for languages that are nice (functional programming), but you will see someone taking about the denotational semantics of a common programming language like Go or C or Java or JavaScript or Python. Similarly for languages like Prolog.\n\nHaving a semantic domain also is not sufficient for model theory in the sense of logic. We can construct models but model theory cares more about nonstandard models typically than standard model, because that is what is related to provablity in theories. We don't need just a syntax with construction rules, we need axioms about what can be said about those objects that are inherently incomplete. I want to go to the nonstandard model of reals with infinitesimals and show something holds there and then transfer that back to standard reals using the fact that the language and the theory cannot distinguish between these two. In programming the languages are typically too powerful. The typical model theory deals with relatively simple cases that are not strong enough to express computation. Almost all interesting programming language are expressive enough to write a Turing machine simulator. The model theory of arithmetic theories like PA might be more inline from the perspective of complexity they have. Even there, one needs to not use the True Arithmetic theory but some limited set of axioms. When taking about programming language, the theory people typically use is all of mathematics. These are I think partly responsible for why we don't have a model theory of programming languages in the sense of logic."
    }
}