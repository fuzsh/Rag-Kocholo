{
    "id": "dbpedia_6170_3",
    "rank": 61,
    "data": {
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9053426/",
        "read_more_link": "",
        "language": "en",
        "title": "Class Size and Student Performance in a Team-Based Learning Course",
        "top_image": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "meta_img": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0",
        "images": [
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/favicons/favicon-57.png",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg",
            "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/logos/AgencyLogo.svg",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/logo-june.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif",
            "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/corrauth.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Minna Ng",
            "Thomas M. Newpher"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "High-enrollment university courses can be associated with decreased student learning and course satisfaction. In these large classes, students report feelings of isolation, reduced faculty interaction, and less motivation. Here we address whether team-based ...",
        "meta_lang": "en",
        "meta_favicon": "https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico",
        "meta_site_name": "PubMed Central (PMC)",
        "canonical_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9053426/",
        "text": "Class size is one major factor thought to impact student learning, achievement, and classroom dynamics, as well as course and instructor ratings (Cash et al., 2017; Wright et al., 2019). In higher education, large class sizes are associated with student feelings of isolation and anonymity, both of which can lead to decreased student motivation and retention (Carbone and Greenberg, 1998; Mulryan-Kyne, 2010; Wulff et al., 1987). In addition, instructors report difficulty engaging with students and reduced faculty-student interactions in large classes (Carbone and Greenberg, 1998; Gibbs et al., 1996; Mulryan-Kyne, 2010; Wulff et al., 1987). Furthermore, small class sizes are associated with increased student engagement (Gleason, 2012), as well as higher student ratings of the course and instructor quality (Bedard and Kuhn, 2008; Benton and Cashin, 2012; Kwan, 1999; Mandel and Sussmuth, 2011; Monks and Schmidt, 2011; Sapelli and Illanes, 2016; Westerlund, 2008). There are a number of possible explanations for the positive classroom dynamics observed with smaller classes. These could include stronger student-faculty relations, greater personal attention, and more frequent use of active learning and interactive pedagogies (Cash et al., 2017; Wright et al., 2019).\n\nNot surprisingly, students in smaller classes typically self-report greater learning (Benton and Pallett, 2013; Monks and Schmidt, 2011). However, direct measures of student learning related to class size are quite variable. For example, some studies report mixed results or no effect related to class size (Bellante, 1972; De Paola et al., 2013; Edgell, 1981; Gleason, 2012; Hancock, 1996; Hill, 1998; Jarivs, 2007; Kennedy and Siegfried, 1997; Matta et al., 2015; Olson et al., 2011; Raimondo et al., 1990), while others report increased student learning and performance with small class sizes (Arias and Walker, 2004; Baeten et al., 2010; Bandiera et al., 2010; Becker and Powers, 2001; Freeman et al., 2014; Gibbs et al., 1996; Kogl Camfield et al., 2016; Kokkelenberg et al., 2006; Westerlund, 2008). To date, the relationship between class size and student learning remains a highly debated topic in higher education (Ake-Little et al., 2020).\n\nThere are several possible explanations for the variable findings between studies on class size and learning. These could include the demographics of the student populations, the types of schools, and the teaching methods employed (Ballen et al., 2018). Indeed, it remains unknown which types of teaching approaches are best suited for student learning in large university classrooms. One might predict that more engaging and structured teaching methods that motivate students, encourage them to attend, and provide opportunities to practice would help improve student learning in larger university courses (Eddy and Hogan, 2014). Consistent with this idea, a meta-analysis comparing the effectiveness of active learning pedagogies to lecture-based courses found that active learning significantly increases student achievement in all class sizes (0–50, 51–110, and >110) (Freeman et al., 2014). However, the study also found that courses with fewer than 50 students showed greater learning gains than groups of 51 or more students (Freeman et al., 2014), suggesting that even mixed active learning approaches work better in lower enrollment courses. These findings highlight the need to better understand the exact types of active learning methods and course structures that improve student learning in high enrollment courses.\n\nOne active learning method that has the potential to work well for large university courses is team-based learning (TBL). In TBL, students work together in permanent teams throughout the semester. Not only do students complete individual readiness assurance tests (iRATs) during each learning module, but they also collaborate with peers on team readiness assurance tests (tRATs) and application activities, designed to promote learning on Bloom’s lower-order (recall, understand) and higher-order (apply, analyze, evaluate, synthesize) cognitive outcomes (Bloom, 1956; Michaelsen et al., 2004; Michaelsen and Sweet, 2008). Of note, TBL was created over 40 years ago for the purpose of transforming large lecture halls into inclusive, interactive spaces that provide strong motivation to attend, participate, and learn (Michaelsen et al., 1982). Importantly, many of the design elements thought to promote learning in TBL (immediate feedback, retrieval practice, and distributed practice) would be present to the same extent in both small and large TBL courses (Butler et al., 2014; Dunlosky et al., 2013; Schmidt et al., 2019). While some evidence indicates that larger TBL courses are harder for instructors to manage (Allen et al., 2013; Thompson et al., 2007a; Thompson et al., 2007b), to date, the relationship between class size and student performance in TBL has not been formally addressed.\n\nGiven the highly structured and interactive design of TBL courses, we predicted that student performance on exam questions that tested lower- and higher-order learning outcomes would be similar across a range of TBL course term sizes. Furthermore, we expected that measures addressing the classroom environment would not decline as enrollment size increased. To this end, we analyzed student exam performance and end-of-semester course evaluations from a single undergraduate neuroscience course. This single TBL course was taught across a range of enrollment sizes (19–103) over four course terms. We found that the lower enrollment versions of the course had higher student ratings of course quality than the higher enrollment versions, even though all course terms were taught by the same instructor. However, exam performance and several measures of the classroom environment did not differ across a range of course term sizes, suggesting that for this TBL course, many aspects of the learning experience were not negatively impacted in higher enrollment course terms.\n\nMATERIALS AND METHODS\n\nThis study was approved by the Duke University Institutional Review Board. The course was taught at a private university in the southeastern United States. For ratings of the classroom environment, we used data from end-of-semester course evaluation surveys from four different terms of the same undergraduate neuroscience course. All four course terms were taught by the same instructor. Course evaluations were collected and provided by the Office of Assessment and made available to the instructors and researchers after grades were posted by the Registrar’s Office. Students enrolled in this in-person undergraduate neuroscience course submitted anonymous campus-wide course evaluations on their perceptions of a range of questions addressing classroom dynamics and course characteristics. Twenty minutes of in-class time were reserved to complete the voluntary course evaluations, although students also had the option to take evaluations outside of class time. Seven different measures of the classroom environment were analyzed, except for Term 1 and Term 2 where “course difficulty” data were not collected. The students were asked to provide responses to the following questions on their end of semester course evaluations:\n\nThe course had clearly defined student learning objectives.\n\nThe course had clear expectations for assignments and other work.\n\nThe course had a welcoming and inclusive classroom environment.\n\nThe course helped me to effectively communicate ideas orally.\n\n(For questions 1–4, response options were on a Likert rating scale: 5 = strongly agree, 4 = agree, 3 = neutral, 2 = disagree, and 1 = strongly disagree; or NA = not applicable. )\n\nPlease characterize the difficulty of the subject matter.\n\n(Response options were on a Likert rating scale: 5 = very high, 4 = high, 3 = moderate, 2 = low, and 1 = very low; or NA = not applicable.)\n\nGive an overall rating for the quality of this course.\n\nGive an overall rating for the quality of instruction.\n\nFor questions 6–7, response options were on a Likert rating scale: 5 = excellent, 4 = very good, 3 = average, 2 = marginal, and 1 = poor; or NA = not applicable.\n\nTo measure Bloom’s cognitive outcomes, we analyzed average student performance on summative exam questions taken during each of the four course terms. The summative exam questions tested students on all content learned during the semester, including Bloom’s lower-order and higher-order cognitive outcomes. As summative exam questions were slightly different between course terms, we restricted our analysis to questions that were identical and reused between the corresponding semesters, Term 1-Term 2 and Term 3-Term 4. The summative exam questions came from two different midterm exams. One midterm was offered at the halfway point of the course term and the second at the end of the course term. Exam questions were multiple choice and covered the range of Bloom’s taxonomic levels (Bloom, 1956). Student performance was tracked across all identical test questions between terms, referred to as “All Questions” ( , , and ). The exam questions were then divided into two categories based on Bloom’s taxonomy: lower-order cognitive outcomes for recall and understanding level questions (Lower Bloom’s), and higher-order cognitive outcomes for application, analysis, and evaluation (Higher Bloom’s). See Appendix 1 for examples of lower- and higher-order questions. The number of student exams used to measure exam performance was not identical to the starting enrollment for each course term. In some cases, students withdrew from the course and did not complete one or both of the midterms. While the large majority of students completed their midterms online using the course management software (Sakai ©), several students completed midterms on paper and their records were not stored. Performance on assessments and responses on end-of-semester course evaluations were analyzed using non-parametric Mann Whitney U tests, performed in IBM SPSS®.\n\nTable 3\n\n64 Students (Term 4)101 Students (Term 3)nmeanSDnmeanSD(U)p value Classroom Environment: Learning Objectives374.810.74694.670.87(1129.00)0.125Clear Expectations374.760.76694.610.81(1106.50)0.122Course Difficulty373.760.64693.700.73(1220.00)0.681Oral Communication373.830.95693.801.02(1046.00)0.974Welcoming/Inclusive374.680.78694.620.89(1255.50)0.849 Course Quality 37 4.62 0.55 68 4.35 0.66 (983.00) 0.037 * Instructor Quality374.920.28684.810.43(1136.50)0.179 Summative Exam Performance: All Questions (59 questions)6382.8014.579782.6313.47(1668.50)0.698 Lower Bloom's (50 questions)6385.0612.619784.7211.50(1181.00)0.634 Higher Bloom's (9 questions)6370.2218.859771.0018.08(39.00)0.894\n\nTable 4\n\n19 Students (Term 1)103 Students (Term 2)nmeanSDnmeanSD(U)p value Classroom Environment: Learning Objectives134.311.49594.750.28(347.50)0.416Clear Expectations134.311.49594.580.95(467.50)0.890 Oral Communication 12 4.25 1.14 50 3.58 1.01 (174.50) 0.019 * Welcoming/Inclusive134.311.49594.440.91(341.00)0.056 Course Quality 12 5.00 0.00 58 4.14 0.74 (120.00) 0.000 *** Instructor Quality 12 5.00 0.00 58 4.62 0.57 (228.00) 0.017 * Summative Exam Performance: All Questions (44 questions)1677.8012.6010180.0912.72(813.00)0.195 Lower Bloom's (37 questions)1677.5912.8210181.0012.13(538.00)0.113 Higher Bloom's (7 questions)1678.8612.1910175.2915.65(21.50)0.701\n\nTable 5\n\n19 Students (Term 1)103 Students (Term 2)nmeanSDnmeanSD(U)p value Summative Exam Performance: All Questions (44 questions)884.1613.7210080.2312.72(807.50)0.179 Lower Bloom’s (37 questions)882.8912.9010081.1612.04(578.50)0.250 Higher Bloom’s (7 questions)880.8615.4010075.2915.98(18.00)0.404\n\nPrecise definitions and ranges for small, medium, and large university classes vary between studies (Cash et al., 2017; Freeman et al., 2014; Wright et al., 2019). As such, we did not label these classes as small, medium, or large. Rather, we refer to them by their enrollment size. In all classes, tables shared among teammates were the same size and style and were spaced apart similarly. The courses in these analyses used the same classroom space, except Term 1, which was held in a smaller classroom with seating for 20 students. Classrooms for all terms and sizes were single-level, as opposed to stadium seating.\n\nThe same male instructor (T.M.N.) taught this course and had six years of teaching experience (one year with TBL) prior to the start of Term 1. The TBL course analyzed in this study was a 200-level intermediate undergraduate neuroscience course and, at the time, was a graduation requirement for the Neuroscience major. The following is the course description that appeared on the syllabus, and below are the six learning objectives for the course.\n\nCourse Description:\n\n“In this course, learners explore the organization of neural systems that allow us to sense our environment, plan and execute complex movements, encode and retrieve memories, and experience a wide range of emotions. We also examine the development of the brain and spinal cord and how changes in the structure and function of these neural systems underlie the devastating effects of neurological and psychiatric disorders.”\n\nCourse Learning Objectives:\n\n-Describe how neurons generate, propagate, and communicate electrical signals.\n\n-Recall the major steps of synaptic transmission and the signaling pathways that drive synaptic plasticity.\n\n-Compare and contrast sensory pathways and describe how stimuli generate electrical signals in sensory neurons to produce different sensations.\n\n-Characterize the pathways and brain regions that control movement.\n\n-Explain how cortical and subcortical brain structures develop and control cognitive processes, including memory, emotion, attention, and planning.\n\n-Predict how lesions in neural systems could lead to the development of neurological and psychiatric disorders.\n\nThe characteristics for all four course terms are shown in . While all four terms covered similar neuroscience content, there were some notable differences between course terms. First, Term 1 was a summer session course, while Terms 2, 3, and 4 where all taught during the fall semester. In addition, Terms 3 and 4 included discussion section meetings and allowed for more TBL modules compared to Terms 1 and 2, which did not have discussion section meetings. This meant that Terms 3 and 4 had more class meetings and TBL modules, allowing for more material to be covered in a term. To account for this, pairwise comparisons were made only between corresponding terms: Term 1 with Term 2, and Term 3 with Term 4.\n\nTable 1\n\nTerm Enrollment TBL Modules Meetings Discussion Term Length Exams Team Size Term 119827No6 (summer)26Term 2103828No14 (fall)26Term 31011242Yes14 (fall)26Term 4641040Yes14 (fall)26\n\nThe standard TBL unit or module consists of two major phases: the readiness assurance process (RA) and the application activity (Michaelsen et al., 2004). The RA process starts with students reading basic background material or watching videos outside of class, followed by individual and team readiness assurance tests (iRATs and tRATs) at the start of the next class period. The iRATs and tRATs serve as formative assessments and are designed to promote student preparedness for the in-class team activities that occur throughout the module. Next, in the application phase of the module, students deepen their learning by collaborating with teammates on complex problems which help them achieve the higher-order cognitive outcomes (Michaelsen et al., 2004). For all four terms, the course was taught using a standard TBL format (Haidet et al., 2014), except that a pre-lecture was included in the class period prior to the readiness assurance process-described in (Ng and Newpher, 2020). The readiness assurance process (iRAT, tRAT, feedback and mini-lecture) was completed during the second class-period of each TBL module. The application activities were completed on the third day of each module.\n\nTeams were formed based on the amount of experience students had in the field of neuroscience. Specifically, each team had a mix of students with none, some, or a great deal of neuroscience coursework and research experience. Teams were permanent and worked together for the entire semester. On average, the TBL learning teams each had six members. Although, in a few cases, teams had five or seven members if there were uneven numbers of students in the class. Evaluations of teammates were submitted halfway through the term and again at the end of the term.\n\nStudents enrolled in this course typically include third and fourth-year students majoring in neuroscience. Other typical students include those who are majoring in related disciplines such as biology and psychology, second-year students who have yet to declare a major, as well as visiting students and graduate/post-baccalaureate students ( ). The summer term course in this study (Term 1) met five days per week for 75-minute class sessions over six weeks. The fall term courses met two times per week for Term 2 (75-minute class sessions) and three times per week for Terms 3 and 4 (two 75-minute sessions and one 50-minute session) over 14 weeks. All fall term classes were taught in the early afternoon (1:25pm start) and the summer term course was taught late morning (11:00am start).\n\nTable 2\n\nTerm W Major Nonmajor Undeclared 4 th 3 rd 2 nd 1 st Grad Visiting Term 115.815.815.826.310.521.126.30.010.531.6Term 22.065.214.518.428.247.622.30.01.90.0Term 33.965.313.920.819.851.428.90.00.00.0Term 41.564.125.09.425.060.910.91.60.01.6\n\nDISCUSSION\n\nSummary\n\nHere we have measured exam performance and student self-report of several measures of the classroom environment in a single TBL-taught course. Our findings demonstrate that, for this particular course, student performance on exam questions across Bloom’s taxonomy and student self-report of a welcoming and inclusive classroom environment were not negatively impacted in higher enrollment course terms. Importantly, these findings suggest that, for this single course analyzed, the TBL approach was able to scale to the larger classroom setting. Below we discuss the significance of these findings and propose strategies to improve the experience for students in high enrollment university courses.\n\nClass Size and the Classroom Environment in TBL\n\nRegardless of class size, students in a TBL class have a small-group learning experience for the entire duration of the semester. Discussions with teammates and frequent interactions with members of other groups, would be predicted to help maintain a social, engaging, and positive classroom environment in large TBL courses. Consistently, we saw no differences across class size comparisons for ratings of “a welcoming and inclusive classroom environment” ( and ). Furthermore, in our comparison between Term 4 (64 students) and Term 3 (101 students), only one of the classroom environment measures was rated significantly greater by students in Term 4: course quality ( ). No significant differences were found in the other measures: “clearly defined student learning objectives,” “clear expectations for assignments and other work,” or “perceptions of difficulty.” In our second comparison between Terms 1 and 2 (19 and 103 students, respectively), the class size difference was even greater (5.4-fold increase) compared to Terms 3 and 4 (1.58-fold increase). Consistent with the greater size difference, three of the classroom environment measures were rated significantly higher by students in the lower enrollment term: course quality, instructor quality, and oral communication ( ).\n\nIn both of these comparisons, the higher enrollment terms had significantly lower course quality ratings. Interestingly, this was despite having the same course structure and content, as well as a similar proportion of class time devoted to interacting with peers and engaging in collaborative learning. The instructor was also the same, yet, in the Term 1 versus Term 2 comparison, the higher enrollment group had a significantly lower rating for instructor quality. These findings are in agreement with past studies describing a negative relationship between class size and course evaluation scores (Bedard and Kuhn, 2008; Benton and Cashin, 2012; Kwan, 1999; Mandel and Sussmuth, 2011; Monks and Schmidt, 2011; Sapelli and Illanes, 2016; Westerlund, 2008).\n\nOne possible explanation for the decreased student ratings of course and instructor quality with the higher enrollment TBL classes may be decreased student-faculty interaction and one-on-one attention. While we have not directly measured the amount of student-faculty interaction in our course terms, past studies have documented fewer interactions and difficulty engaging with students in larger classes (Carbone and Greenberg, 1998; Mulryan-Kyne, 2010; Wulff et al., 1987). However, despite the additional challenges faced with high enrollment TBL classes, several measures of classroom environment did not change across different class sizes in our study. We propose that the frequent interactions with team members throughout the semester may have helped maintain the ratings for a ‘welcoming and inclusive classroom environment.’ However, given that our study did not include a non-TBL control group with the same instructor, we cannot be sure whether this rating of the classroom environment is a direct result of the TBL approach or perhaps, instructor personality and rapport with students.\n\nClass Size and Exam Performance in TBL\n\nOur finding that exam scores were similar across a range of enrollment sizes ( , , and ) suggests that, for these TBL course terms, student exam performance (and presumably content knowledge outcomes) was not negatively impacted in a larger classroom environment. Furthermore, students’ accuracy on questions that tested lower-order and higher-order cognitive outcomes did not significantly change with the size of the class ( , , and ). The design elements of TBL that promote motivation and learning-retrieval practice, spaced practice, and feedback (Butler et al., 2014; Dunlosky et al., 2013; Schmidt et al., 2019)-would be present to the same extent in any-sized TBL class, thus providing a possible explanation for why exam performance did not vary across our different-sized TBL course terms.\n\nLimitations and Future Directions\n\nOne limitation of this study was the need to include a summer session course in the analysis between Terms 1 and 2. Fall terms for this course typically enroll 60 or more students. As such, the summer session term provided the only opportunity to examine student performance and the classroom environment in a low enrollment version of this course. Additionally, the summer session version of this course was only offered one year, so additional replicates were not possible. As a result, we cannot rule out the possibility that the duration of the course terms-6 weeks for summer session versus 14 weeks for fall/spring term courses-had an effect on the content knowledge outcomes. Indeed, while some studies show no effect, others have reported that shorter course terms are associated with improved performance on exams (Austin and Gustafson, 2006; Scott and Conrad, 1992). How this may manifest in TBL classes should be further explored.\n\nThe summer session TBL term enrolled a number of visiting and graduate/post-baccalaureate students. By comparison, the high enrollment version of the class offered during the fall term enrolled a low percentage of these non-degree seeking students ( ). To account for the possibility that these differences in student demographics influenced our outcomes, we re-ran the analysis excluding the data from non-degree students ( ). Our findings were the same: there was no significant difference in exam performance between low and high enrollment TBL groups.\n\nIn order to generalize our findings, future studies should explore the relationship between TBL course size and student performance with a larger number of classes and broader range of courses at different institutions, as well as with different student populations. For example, it would be particularly valuable to know the content knowledge outcomes and students’ perceptions of quality of the course and their instructor in introductory STEM classes which are frequently large and can have enrollments of 300 to 400. Monitoring classroom behaviors and faculty interactions to confirm that they are indeed reduced in larger TBL courses should also be further explored.\n\nProposed Strategies for Larger TBL Classes\n\nDespite any drop in student exam performance, our higher enrollment course terms did suffer from lower evaluations of course quality. While this may be an unavoidable consequence of higher enrollment classes, there may be strategies that TBL facilitators can implement in large classes to improve student perception of the course and instructor. As is always the case with TBL, facilitators should work hard to achieve student buy-in with the TBL approach and should ensure that students learn how to work and communicate in teams effectively (Thompson et al., 2007a; Thompson et al., 2007b). In fact, an entire TBL module could be dedicated to helping students learn more about TBL and why it is being used. It is also possible that team teaching or utilizing teaching assistants as additional facilitators could help increase student engagement and one-on-one attention. Lastly, as has been shown for large non-TBL courses, the instructor can help make classes feel smaller by learning names (Holstead, 2019), walking through aisles, using humor, and having a more engaging classroom presence (Cash et al., 2017). Future studies should investigate the impact of these instructor behaviors on student perception and enjoyment of TBL in a large classroom setting."
    }
}