{
    "id": "dbpedia_3412_0",
    "rank": 57,
    "data": {
        "url": "http://lambda-the-ultimate.org/node/3127%25E7%259B%25B8%25E5%25AF%25B9%3Dnofollow%3Ffrom%3D680",
        "read_more_link": "",
        "language": "en",
        "title": "Lambda the Ultimate",
        "top_image": "",
        "meta_img": "",
        "images": [
            "http://lambda-the-ultimate.org/node/themes/chameleon/ltu/tagline.png",
            "http://lambda-the-ultimate.org/misc/xml.gif"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "favicon.ico",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Home\n\nFeedback\n\nFAQ\n\nGetting Started\n\nDiscussions\n\nSite operation discussions\n\nRecent Posts\n\n(new topic)\n\nDepartments\n\nCourses\n\nResearch Papers\n\nDesign Docs\n\nQuotations\n\nGenealogical Diagrams\n\nArchives\n\nUser login\n\nNavigation\n\nPlatonic C# - Managing Referential Transparency through Unique Types\n\nThe idea of Platonic C# is to enforce referential transparency within the context of C#, by enforcing a set of rules around defaulting to immutability of data structures and requiring uniqueness of instances of mutable types.\n\nComputer History Museum releases PostScript source\n\nThe Computer History Museum, in conjunction with Adobe, has released the PostScript source code. Here is the release, with some helpful historical context and several photos:\n\nThe story of PostScript has many different facets. It is a story about profound changes in human literacy as well as a story of trade secrets within source code. It is a story about the importance of teams, and of geometry. And it is a story of the motivations and educations of engineer-entrepreneurs.\n\nThe Computer History Museum is excited to publicly release, for the first time, the source code for the breakthrough printing technology, PostScript. We thank Adobe, Inc. for their permission and support, and John Warnock for championing this release.\n\nThe Verse Calculus: a Core Calculus for Functional Logic Programming\n\nThe Verse Calculus: a Core Calculus for Functional Logic Programming\n\nhttps://simon.peytonjones.org/assets/pdfs/verse-conf.pdf\n\nLENNART AUGUSTSSON, Epic Games, Sweden\n\nJOACHIM BREITNER\n\nKOEN CLAESSEN, Epic Games, Sweden\n\nRANJIT JHALA, Epic Games, USA\n\nSIMON PEYTON JONES, Epic Games, United Kingdom\n\nOLIN SHIVERS, Epic Games, USA/li>\n\nTIM SWEENEY, Epic Games, USA\n\nFunctional logic languages have a rich literature, but it is tricky to give them a satisfying semantics. In this\n\npaper we describe the Verse calculus, VC, a new core calculus for functional logical programming. Our main\n\ncontribution is to equip VC with a small-step rewrite semantics, so that we can reason about a VC program\n\nin the same way as one does with lambda calculus; that is, by applying successive rewrites to it.\n\nThis draft paper describes our current thinking about Verse. It is very much a work in progress, not a finished\n\nproduct. The broad outlines of the design are stable. However, the details of the rewrite rules may well change; we\n\nthink that the current rules are not confluent, in tiresome ways. (If you are knowledgeable about confluence proofs,\n\nplease talk to us!)We are eager to enagage in a dialogue with the community. Please do write to us.\n\nLtU is now running in a new, more stable environment\n\nLtU has experienced a long period of downtime recently. Its software infrastructure was outdated enough that it became difficult to maintain when problems arose. It has now been migrated to a brand new environment. It should be much more stable from now on.\n\nGraydon Hoare: 21 compilers and 3 orders of magnitude in 60 minutes\n\nIn 2019, Graydon Hoare gave a talk to undergraduates (PDF of slides) trying to communicate a sense of what compilers looked like from the perspective of people who did it for a living.\n\nI've been aware of this talk for over a year and meant to submit a story here, but was overcome by the sheer number of excellent observations. I'll just summarise the groups he uses:\n\nThe giants: by which he means the big compilers that are built the old-fashioned way that throw massive resources at attaining efficiency\n\nThe variants, which use tricks to avoid being so massive:\n\nFewer optimisations: be traditional, but be selective and only the optimisations that really pay off\n\nUse compiler-friendly languages, by which he is really taking about languages that are good for implementing compilers, like Lisp and ML\n\nTheory-driven meta-languages, esp. how something like yacc allows a traditional Dragon-book style compiler to be written more easily\n\nBase compiler on a carefully designed IR that is either easy to compile or reasonable to bytecode-interpret\n\nExercise discretion to have the object code be a mix of compiled and interpreted\n\nUse sophisticated partial evaluation\n\nForget tradition and implement everything directly by hand\n\nI really recommend spending time working through these slides. While much of the material I was familiar with, enough was new, and I really appreciated the well-made points, shout-outs to projects that deserve more visibility, such as Nanopass compilers and CakeML, and the presentation of the Futamura projections, a famously tricky concept, at the undergraduate level.\n\nLatent Effects for Reusable Language Components\n\nLatent Effects for Reusable Language Components, by Birthe van den Berg, Tom Schrijvers, Casper Bach Poulsen, Nicolas Wu:\n\nThe development of programming languages can be quite complicated and costly. Hence, much effort has been devoted to the modular definition of language features that can be reused in various combinations to define new languages and experiment with their semantics. A notable outcome of these efforts is the algebra-based “datatypes \"a la carte\" (DTC) approach. When combined with algebraic effects, DTC can model a wide range of common language features. Unfortunately, the\n\ncurrent state of the art does not cover modular definitions of advanced control-flow mechanisms that defer execution to an appropriate point, such as call-by-name and call-by-need evaluation, as well as (multi-)staging. This paper defines latent effects, a generic class of such control-flow mechanisms. We demonstrate how function abstractions, lazy computations and a MetaML-like staging can all be expressed in a modular fashion using latent effects, and how they can be combined in various ways to obtain complex semantics. We provide a full Haskell implementation of our effects and handlers with a range of examples.\n\nLooks like a nice generalization of the basic approach taken by algebraic effects to more subtle contexts. Algebraic effects have been discussed here on LtU many times. I think this description from section 2.3 is a pretty good overview of their approach:\n\nLE&H is based on a different, more sophisticated structure than AE&H’s free monad. This structure supports non-atomic operations (e.g., function abstraction, thunking, quoting) that contain or delimit computations whose execution may be deferred. Also, the layered handling is different. The idea is still the same, to replace bit by bit the structure of the tree by its meaning. Yet, while AE&H grows the meaning around the shrinking tree, LE&H grows little “pockets of meaning” around the individual nodes remaining in the tree, and not just around the root. The latter supports deferred effects because later handlers can still re-arrange the semantic pockets created by earlier handlers.\n\nIntroducing PathQuery, Google's Graph Query Language\n\nIntroducing PathQuery, Google's Graph Query Language\n\nWe introduce PathQuery, a graph query language developed to scale with Google's query and data volumes as well as its internal developer community. PathQuery supports flexible and declarative semantics. We have found that this enables query developers to think in a naturally \"graphy\" design space and to avoid the additional cognitive effort of coordinating numerous joins and subqueries often required to express an equivalent query in a relational space. Despite its traversal-oriented syntactic style, PathQuery has a foundation on a custom variant of relational algebra -- the exposition of which we presently defer -- allowing for the application of both common and novel optimizations. We believe that PathQuery has withstood a \"test of time\" at Google, under both large scale and low latency requirements. We thus share herein a language design that admits a rigorous declarative semantics, has scaled well in practice, and provides a natural syntax for graph traversals while also admitting complex graph patterns.\n\nThings that are somewhat interesting to me, from an engineering standpoint:\n\n1. PathQuery has a module/compilation system, enabling re-use of PathQuery modules across projects. (Someone had mentioned that Google has around 40,000 PathQuery modules already, internally...)\n\n2. PathQuery supports native functions so that some query pieces can be evaluated procedurally (peephole optimization)\n\n3. Use of relational algebra to enable a lot of known optimizations, plus future optimizations\n\nAlso, from a socio-linguistic perspective, Graph Languages are effectively the new Object-Relational Mapping layer, but they solve an interesting organizational problem of allowing multiple teams to code in different languages, without needing to re-write / re-implement entities and mapping configurations in each language. It's the Old New Thing again...\n\nGoogle announces Logica: organizing your data queries, making them universally reusable and fun\n\nYou can read more about it at the Google Open Source blog post, Logica: organizing your data queries, making them universally reusable and fun.\n\nThey advocate for datalog-like language they developed internally at Google.\n\nThe reason?\n\nGood programming is about creating small, understandable, reusable pieces of logic that can be tested, given names, and organized into packages which can later be used to construct more useful pieces of logic. SQL resists this workflow. Although you can encapsulate certain repeated computations into views and functions, the syntax and support for these can vary among implementations, the notions of packages and imports are generally nonexistent, and higher-level constructions (e.g. passing a function to a function) are impossible."
    }
}