{
    "id": "dbpedia_6524_3",
    "rank": 78,
    "data": {
        "url": "https://www.linkedin.com/pulse/from-frontlines-leipzig-llms-knowledge-graphs-jan-voskuil",
        "read_more_link": "",
        "language": "en",
        "title": "From the frontlines in Leipzig: LLMs and Knowledge Graphs",
        "top_image": "https://media.licdn.com/dms/image/v2/D4E12AQH93nhIEzfeKQ/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1696407670506?e=2147483647&v=beta&t=CLol1wUfn6bPzX7aOQ2sOqbCRvIpP4odCyof_6gLJ3I",
        "meta_img": "https://media.licdn.com/dms/image/v2/D4E12AQH93nhIEzfeKQ/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1696407670506?e=2147483647&v=beta&t=CLol1wUfn6bPzX7aOQ2sOqbCRvIpP4odCyof_6gLJ3I",
        "images": [
            "https://media.licdn.com/dms/image/v2/D4E12AQH93nhIEzfeKQ/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1696407670506?e=2147483647&v=beta&t=CLol1wUfn6bPzX7aOQ2sOqbCRvIpP4odCyof_6gLJ3I"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "Jan Voskuil"
        ],
        "publish_date": "2023-10-04T08:36:04+00:00",
        "summary": "",
        "meta_description": "This year’s edition of SEMANTiCS, in Leipzig, was wonderful: great venue, a big turn-out and a tsunami of bright ideas and real-world use cases. It was good to be in Leipzig again, the city that is the home of DBPedia, and that played such a big part in the early days of SEMANTiCS.",
        "meta_lang": "en",
        "meta_favicon": "https://static.licdn.com/aero-v1/sc/h/al2o9zrvru7aqj8e1x2rzsrca",
        "meta_site_name": "",
        "canonical_link": "https://www.linkedin.com/pulse/from-frontlines-leipzig-llms-knowledge-graphs-jan-voskuil",
        "text": "This year’s edition of SEMANTiCS, in Leipzig, was wonderful: great venue, a big turn-out and a tsunami of bright ideas and real-world use cases. It was good to be in Leipzig again, the city that is the home of DBPedia, and that played such a big part in the early days of SEMANTiCS.\n\nMost keynotes, and some conference presentations, were about what the rise of LLMs (large language models) such as ChatGPT means for knowledge graph technology. That is the topic of this post. I will summarize the main points that were made, and offer some thoughts of my own.\n\nThe long tail conundrum\n\nThe relevant keynotes were those presented by Edward Curry (University of Galway), Xin Luna Dong (Meta), and Aidan Hogan (University of Chile). The gist: LLMs perform poorly on the long tail and cannot, therefore, be used in certain tasks, such as product recommendations, as Xin Luna Dong forcefully demonstrated.\n\nThis notion of long tail goes back to the American linguist George Zipf. Studying word frequencies in the 1940’s, he found that a small number of words (the head) is very frequent, and a very large number of words (the tail) is extremely infrequent. Later, it appeared that such Zipf distributions are found everywhere in nature and culture as well. You can substitute star types, commercial products, insect species, pop songs, minerals, molecules and many more things for “words” and the result is the same. The generalized version of Zipf’s finding is often called the power law.\n\nThus, that LLMs perform poorly on the long tail means that they give excellent results on common things, but bad results on things that are uncommon. ChatGPT can give accurate information about pop culture, but not about, say, obscure patents on dog food production — or, as Aidan Hogan showed, about the Turing Award winner who was born in South America. We could create an LLM as big as ChatGPT and train it exclusively on patents, but still, it will show great results on types of patents that occur frequently, but not on those occurring infrequently. You cannot escape the power law by simply adding more things — it is like chasing your own tail.\n\nWell-curated knowledge graphs are symbolic representations of precise knowledge. They perform at a constant quality level for the things they cover, frequent things or infrequent things alike. That is why, in practice, knowledge graphs are used for product recommendations and not LLMs, as Xin Luna Dong showed. Curation, though, is expensive. So, can we somehow combine LLMs and knowledge graph technology? A torrent of wild ideas was generated down there in Leipzig. Before we turn to these, first a bit more on LLMs and AI.\n\nLLMs are not about statistics\n\nSome people dismiss LLMs as “just” stochastic parrots. There are two interesting answers to this summary dismissal. First, all the evidence we have tells us that we, humans, are also stochastic parrots. Philosopher Daniel Dennet notoriously argues that there exists no “miracle stuff”. Human personality, consciousness, and cognition arise from ordinary matter. There seems to be nothing beyond the neural networks in our brain to explain these phenomena. Our neural networks are trained during our lifetimes as well as across innumerable generations through evolution, which leads to hard-wired networks primed for certain tasks — as neurobiologist Dale Purves has argued convincingly with respect to the neural basis of our vision [1].\n\nThe other, perhaps more interesting way to counter the dismissal of LLMs as “just” statistics is that the word ‘statistics’ invites one to entertain a great and unwarranted simplification of what is really going on. Yes, LLMs predict the next word based on the previous ones relative to a corpus. But it is nothing like the classical way of computing probabilities. LLMs, like (other types of) neural networks, are models: big balls of numbers generated through simple operations based on reams of input examples. These models form a highly compressed representation of all the examples they have seen. They are far too complex for us to truly understand, at least using the analytical tools we have available just now. As a result, AI-research proceeds mostly as if it is an empirical science that moves forward by trail-and-error. We discover the math as we go along. It feels as exciting as particle physics in the early 20th century.\n\nWe do not understand LLMs yet!\n\nThat process leads to a constant stream of surprises. Here is one: if you train a neural network with three hidden layers to recognize pictures of cars, people and animals, then, in the resulting model, the first layer recognizes edges, the second recognizes corners and contours, and the third recognizes object parts. Nobody predicted this. It was discovered after the fact by analyzing the model, as described by Goodfellow, Bengio and Courville in their deep learning bible [2].\n\nA whole different level of jaw-dropping amazement has recently been reported in an article in Scientific American [3]. When asked for the 83d Fibonacci number, ChatGPT could not give a useful answer. However, after an elaborate prompt explaining how to compute these numbers (1, 2, 3, 5, 8, …), ChatGPT nailed it. It executed a computation, but how? It has no access to the operating system and cannot allocate working memory. It can’t run a program. The jury is still out on what happened there. The article presents more of such completely unexpected results, and argues that LLMs may have other latent abilities that no one has discovered yet.\n\nSo, the right question to ask is: what is an LLM exactly a model of? Maybe, just maybe, it is a model of a generally intelligent agent. Or perhaps of some part of it, incomplete and quite imperfect — but still. We simply do not know. We are at the very beginning of the journey.\n\nLLMs and the modularity of cognition\n\nThe question of how to combine LLMs, knowledge graphs and the like should be put in a broader perspective. Spatial reasoning, numerical computation, and other more specific problems are best solved outside of the LLM, it seems. This tallies with current ideas in cognitive science. Many brain scientists believe that human cognition can be thought of as consisting of functional modules specialized in certain tasks. This is obvious for vision and language processing, and may also be the case for other specialized tasks.\n\nOf course, it is unsurprising that in Leipzig, most attention went to curated knowledge graphs. A few years ago, Frank van Harmelen and Annette ten Teije published an overview of architectural patterns in which AIs and knowledge graphs are combined in existing research projects [4]. There is a limited number of basic patterns out there, and these can be fused into more complex designs. It would be interesting to see some systematic research in how the options perform.\n\nLLMs and knowledge graphs: the current state of the art\n\nSo, let’s turn to the ideas that turned up, focusing on a few highlights. Edward Curry talked about Foundation Models, like ChatGPT. There are methods to “customize” them for specific tasks using curation processes. This leads, in one example, to auto-generation of knowledge graph structures describing the scene in a picture. Xin Luna Dong showed how very large knowledge graphs can be populated by LLMs, while keeping control over quality. Aidan Hogan asked ChatGPT to produce a SPARQL query for finding said Turing Award winner in Wikidata, with uncannily accurate results.\n\nThe vendors present in Leipzig accepted the challenge and presented some ideas of their own. TopQuadrant has equipped its product TopBraid EDG with AI-based capabilities to turn text into ontologies, taxonomies or data graphs. You can read more about this in a recent blog post by Irene Polikoff .\n\nAndreas Blumauer of Semantic Web Company demonstrated how their product, PoolParty, leverages knowledge graphs to automatically enrich output from ChatGPT with hyperlinks to authoritative source materials and additional information. This strategy turns ChatGPT into explainable AI. A recent blog post by Andreas discusses this further.\n\nIt is impossible to do justice to all vendors and presenters — there was way too much to summarize in a short blog post. You may want to check out RDFox, Metaphacts, Ontotext, TriplyDB and the other vendors listed on the conference website. And have a look at the proceedings and recordings.\n\nKnowledge Graph technology has become a lot more interesting\n\nWhat is the essential point about well-curated knowledge graphs? Right: that they are well-curated. This starts with using solid ontologies as the foundation. The relevance of the workshop entitled “3rd Workshop on Ontologies for FAIR and FAIR Ontologies (Onto4FAIR)” cannot, therefore, be underestimated. Organized by Luiz Olavo Bonino da Silva Santos , Giancarlo Guizzardi and others, it brought together an interesting mix of theory and practice. In an ever more data-hungry world where the models want to learn, effective methodologies for ontology design play a crucial role. The discipline of ontology-driven conceptual modeling provides these. The most important one is, no doubt, Unified Foundational Ontology (UFO) and its application through OntoUML.\n\nIncidentally, application of UFO in the construction of federated knowledge graphs was the topic of my own presentation at this edition of SEMANTiCS. You can find a recording here: https://lnkd.in/epQHRrAJ. In brief, I show how UFO brings to light small and large mistakes in ontologies that underpin such knowledge graphs, and how it helps to fix them — or, at least, work around them safely.\n\nIn the early years of SEMANTiCS, many thought of knowledge graphs as an academic solution looking for real-world problems. Today, their position in the data economy is well-established. I am looking forward already to the 20th anniversary edition of SEMANTiCS in Amsterdam!\n\nPost Scriptum\n\nSome of the background materials mentioned in this post are treated in more detail in lesson 5.2 “Knowledge graphs and AI” in Taxonic’s e-learning course Linked Data Essentials, the general go-to course for anyone from any background with an interest in Linked Data.\n\nFootnotes\n\n[1] Dale Purves and R. Beau Lotto (2003). Why We See What We Do: An Empirical Theory of Vision. Sinauer Associates.\n\n[2] Ian Goodfellow, Yoshua Bengio and Aaron Courville (2016). Deep Learning. MIT Press, Cambridge, Mass.\n\n[3] George Musser (2023). “How AI Knows Things No One Told It.” June issue of Scientific American 2023. (Link)"
    }
}