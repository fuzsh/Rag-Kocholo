{
    "id": "correct_subsidiary_00019_2",
    "rank": 36,
    "data": {
        "url": "http://mpsoc-forum.org/archive/2010/agenda.html",
        "read_more_link": "",
        "language": "en",
        "title": "MPSoC 2010",
        "top_image": "",
        "meta_img": "",
        "images": [
            "http://mpsoc-forum.org/archive/2010/photos/mpsoc10a.png",
            "http://mpsoc-forum.org/archive/2010/photos/line.png",
            "http://mpsoc-forum.org/archive/2010/photos/line.png",
            "http://www.w3.org/Icons/valid-xhtml10-blue"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            "mpsoc",
            "fundamental and strategic issues to master multi-processor SoC design",
            "2010",
            "mpsoc'10"
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "International Forum onEmbedded MPSoC and Multicore",
        "meta_lang": "",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Monday June 28\n\nSESSION 1: Keynote\n\nNaoki Nishi, NEC Corp., Japan\n\nMPSoc Technology Direction in Real World Computing\n\nWidespread of broad band network enabled us to be familiar with âConnected World,âand present system trend is \"Cloud Computing.\" With emerging ubiquitous computing devices, ICT systems provide new values in our daily life as well as social activities, which will lead to real world computing era. The author will present an address of system direction, and opportunities for embedded system equipments utilizing Multi-/Many-core HW and SW technologies required for both ubiquitous devices and underlying network and IT (ex. datacenter) system resources for real world computing era.\n\nSESSION 2: Design Methodology\n\n(Mini-Keynote)\n\nGuy Bois, Ecole Polytechnique MontrÃ©al, Canada\n\nFast and accurate estimation for automatic design space exploration of MPSoC systems\n\nMPSoC design involves several decisions such as hardware/software partitioning, task assignment to processors and communication architecture exploration. Algorithms based on meta-heuristics such as simulated annealing and tabu search need to estimate quickly and accurately metrics like area and latency to explore this large design space in a reasonable amount of time. We propose a fast and accurate method for evaluating the performance and hardware cost of candidate MPSoC architectures based on the characterization of a target platform and the application. The trace-based performance characterization and estimation detects violations of timing constraints and takes into account schedule-dependent interactions like bus contention, context switches, task blocking and task preemption. Experimental results applying this estimation to an automatic design space exploration with the Space Codesignâ¢ platform will also be presented.\n\nFrÃ©dÃ©ric PÃ©trot, TIMA Laboratory, INP-Grenoble, France\n\nAnnotation within dynamic binary translation for fast and accurate system simulation\n\nThis talk covers the basis of dynamic binary translation, a technique widely used in virtualization to perform high performance uniprocessor code interpretation. We present how to enhance this technique so that it can be used for accurate Multiprocessor SoC simulation, by introducing timing and/or power annotations at translation time. The focus here does not concern the value of the annotations, but how and when should these annotations be added. We show, by using abstract cache models, that the accuracy for simple risc processors is acceptable, and that the speed of simulation is still very good.\n\nNorbert Wehn, University of Kaiserslautern, Germany\n\nEfficiency Metrics for Design Space Exploration of Wireless Baseband Processing\n\nWireless communications systems require efficient digital baseband receivers. Appropriate metrics are key for efficient design space exploration to quantify the algorithmic and the implementation complexity respectively of a receiver. However conventional metrics are computation centric, i.e., they only focus on operations. In this talk we will show that such metrics can result in wrong conclusions and present suited metrics for area and energy efficiency using the example of various channel decoding architectures.\n\nAhmed Jerraya, CEA-LETI, France\n\nHow can MPSoC take benefit from emerging 3D-IC technology\n\nThe market of SoC/ASSP (System on Chip/Application Specific Single Product chip) devices for mobile and consumer applications amounts to 50B$ in 2009 and is driven by the demand for an evermore processing power to satisfy the user demand for increased functionality to support multimedia applications and ever-higher communication bandwidths. This increased demand is not a business as usual and cannot be satisfied by simple scaling, since different parts of these chips (memory, logic, I/O) do not scale at the same rate, this in addition to even more stringent constraints on power and an increased focus on reliability. For cost and performance reasons future SoC will be made by stacking dies from different technologies. 3-D ICs integration enable dramatically improved performances at a much lower cost than new leading-edge CMOS technology below 32 nm transistor fabrication. 3D integration is also expected to be a serious alternative to below 45 nm technology to continue the race toward integration at lower cost. Improvements of density of integration and performances will continue thanks to 3D-IC technologies. Additionally, 3D enables an easier mix of technology in the same IC. This talk addresses market opportunities, technology trends and design challenges for 3D integration.\n\nVijaykrishnan Narayanan, Pennsylvania State University, USA\n\nInfluence of emerging device technologies on system design\n\nThis talk will present our recent explorations with system design using emerging devices such as interband tunnel transistors. We show how these devices can be used to dramatically decrease the Vcc max to result in significant power reductions. We will show new challenges and opportunities that arise in the use of the devices at the circuit and systme level.\n\nEl Mostapha Aboulhamid, Universite de montreal, Canada\n\nTiming verification of subsystems integration\n\nMPSOCs may be composed of many subsystems that interact globally in an asynchronous manner. The system may also be subject to some cyclic timing constraints during this interaction. Therefore Timing verification is important for the design of such systems. We can formulate the problem as follow: Given a digital system composed of several interconnected components. Due to manufacturing or environmental variation, the delay between two events of a component may not be a precise number, and is usually specified with a lower bound and upper bound by the manufacturers. We look to verify timing constraint requirement for the overall system and check consistency and feasibility of the system given the different delays on components. A way to check system consistency and time verification consists of using exhaustive simulation but it is impractical for large systems. Therefore, analytical algorithms are necessary to ensure that all timing requirements will be satisfied. In the current work, we try to find an algorithm that calculates the bounds on time separation between different events. We work on the problem of cyclic systems with min-max-linear constraints which is known to be NP-complete even in the acyclic case. Very little work has been done in the area of cyclic constraints. First we try to find the frequency of the cyclic graph from which we extract an acyclic graph that is repeated each constant period of time, we use the approach used for finding the k-periodic scheduling. Then we represent the acyclic graph obtained before, under a mixed linear integer problem, in order to apply a branch and cut algorithm that is a hybrid of branch and bound and cutting plane methods, implemented in the solver Cplex to calculate the maximum separation time between each event in the acyclic graph. We present some comparisons with previous heuristics and algorithms for acyclic graphs and we show the superiority of the proposed approach.\n\nSuzanne Lesecq, CEA LETI MINATEC, France\n\nRobust control of a FLL\n\nThe generation of a local frequency can be achieved thanks to a Frequency Locked Loop (FLL). This FLL is made of a Digital Controlled Oscillator (DCO), a \"sensor\" and a controller. The DCO is sensitive to temperature and variability. The control must ensure that the output frequency is equal to the reference one after a transient period, without any overshoot, and in a \"reasonable\" settling time, whatever the DCO characteristics. During this talk, we provide a fully digital model of the FLL. Then we develop the robust (against variations) control of the DCO. The controlled designed will be implemented in the LoCoMoTiV CEA circuit that is developed in order to test \"Local Compensation of Modern Technology Induced Variability\".\n\nSESSION 3: Domain Specific Processing\n\n(In-Depth Technical Presentation)\n\nPing Chao and Youn-Long Lin, National Tsing Hua University, Taiwan\n\nMemory Access Optimization for Ultra High Resolution Video Decoding\n\nUltrahigh resolution H.264/AVC decoding requires huge bandwidth for accessing reference frame data stored in DRAM. Irregular access from such units as motion compensation makes memory system design difficult. Conventional cache-based approach cannot deliver satisfactory performance. We describe a Scratch Pad Memory (SPM)-based reference frame access optimization scheme that rearranges access patterns to reduce burst access latency. Furthermore, we propose an on-line data layout generator that helps minimizing the SPM size requirement. A small hardware overhead running at 200MHz can support QFHD (3840x2160) at 30 frames per second (fps) using a 128-bit DRAM memory system.\n\nEmil Matus, Technical University Dresden, Germany\n\nMPSoC architectures for baseband signal processing of future mobile terminals\n\nFuture (4G) wireless networks are intended to provide technologies enabling broadband, low-latency and guaranteed QoS communication. These technologies introduce significant increase in air-interface complexity which in conjunction with stringent power constraints and multi-mode operation poses new challenges to modem design. This talk presents the concept and design issues of MPSoC architecture for base-band signal processing and application mapping strategies.\n\nZhiyi Yu, Fudan University, China\n\nPushing many-core processors as powerful and energy-efficient as ASIC for domain-specific applications\n\nTraditional uni-core processors are facing serious challenges in performance and energy-efficiency, and many-core processors are widely considered as the most promising candidates for the future computational platforms. By presenting a couple of many-core processors, we believe that it is possible to push many-core processors as powerful and energy-efficient as ASIC for some specific application domains such as communication and multi-media. The three many-core processors we will present include: 1) the 36-core asynchronous array of simple processors which uses GALS clocking style and simple cores to achieve high energy efficiency; 2) the 167-core 65nm computation platform which has dual voltage supply and powerful on-chip communication capability, and 3) the 40-core SeaForth chip which utilizes stack-based cores to achieve extremely small area and low power-consumption.\n\nSESSION 4: HW/SW Interaction\n\n(In-Depth Technical Presentation)\n\nTakahisa Suzuki, Fujitsu Laboratories LTD. , Japan\n\nSystem impact caused by software-hardware harmonized implementation\n\nThere is an unbridgeable gulf between an academic improvement technique and the improvement technique of products with restriction. The environment of benchmark in the laboratories and the condition of the product are different from each other. In the actual embedded products, OS is implemented basically. The influence that the difference of the algorithm of memory management, the process management ... of OSes exerts on the performance is large. The performance difference by the combination of the algorithm and the hardware architecture is also great. Moreover, the influence of the characteristic of the applications is also large. Therefore, it is insufficient only to consider the typical HW/SW co-designed the specified conditions in the laboratories. In actual products, it is important that software, hardware, application program execution environment and OS are harmonized. This talk will introduce the several case via actual development.\n\nDavid Kleidermacher, Green Hills Software, USA\n\nMulticore Virtualization for ARM Processors\n\nFostered by the latest embedded multicore processors, a new generation of hypervisor technology is rapidly making its way into a wide range of electronic products. Embedded virtualization has specialized requirements, involving footprint constraints, power efficiency, and reliability. This session will introduce and compare hypervisor implementations across different ARM core variants, with an emphasis on multicore platforms, and explain how this exciting technology can be practically applied to enable compelling new capabilities across a wide range of embedded and mobile applications.\n\nChong-Min Kyung, KAIST, Korea\n\nPower and Temperature-Aware Clock Frequency and Thread Assignment in Multi-layer MPSoC\n\nThis paper proposes a power management method through Vdd/clock frequency adjustment and thread assignment for each processor core to maximize the total instruction throughput performance in multi-layer MPSoC's having constraints on the peak power and temperature.\n\nTuesday June 29\n\nSESSION 5: Keynote\n\nKazuo Kajimoto, Panasonic Corporation, Japan\n\nState Transition of Software Innovation in relation to Hardware Innovation- Once was âFollowerâ, through âLeaderâ, it would be âConstraintâ -\n\nLSIâs innovation continues tremendously rapidly according to Mooreâs law Along with design rule innovation and hardware architecture innovation such as multiple core, the latest LSI becomes functionally huge, but spatially small, low power consumption. This ideal LSI derived from not only seeds driven approach within hardware innovation but needs driven approach, that is, software led innovation. At the beginning era of Personal Computer, CPU speed innovation was technology leader. At that time, the goal of software technology is how to utilize the latest hardware speed. Then the innovation of software created many applications such as âWord Processingâ, âSpread Sheetâ, âPersonal Databaseâ and so on. When digital AV based consumer electronics was planned, phase change of innovation scenario was occurred in some technical fields which have real time processing requirement such as CODEC technology. In this field, software algorithm established first and refined within software innovation by using simulation. And software created the requirements for hardware, after that, hardware responded the requirements and created balanced combination of CPU and DSP architecture. In Panasonic, this architecture was named âUniPhierâ which represents unified integrated platform for wide variety of consumer electronics products such as DTV, DVD, Blu-ray, cellar phone and so on. In the âUniphierâ, hardware balancing point between CPU and DSP is changed according to softwareâs requirement. Currently, CPU sometimes includes some real time processing process which was originally done by DSP because software requires complex but rapid conditional process of DRM. In other words, UniPhierâs hardware architecture is designed by UniPhierâs software based on the consumer electronics marketâs requirements. Then, what is next phase of mutual interaction between innovation of software and that of hardware? Nowadays, open source software has the power from both technical and business point of view. The development style of open source software assumes define de facto hardware architecture such as PC architecture. But currently open source software also assumes some non PC architecture. It means that the movement of open source software might sometimes never allow various hardware designs. Innovation style in open source software world will continue to generate more and more software assets, more rapidly than expected. After we have big amount of software asset, the software itself might be constraint of hardware innovation because it is much more cost to convert all of software asset to new hardware architecture. In order to keep innovation of hardware, software virtualization technology will be important and the virtualization technology should be assisted by hardware architecture. Giving consumer innovated products continuously in the future, Iâd like to design new consumer electronics software architecture based on open source software and virtual machine.\n\nSESSION 6: MPSoC Platform\n\n(Mini-Keynote)\n\nDavid Atienza, EPFL, Swizerland\n\nActive Cooling Control for Thermal Management of 3D MPSoCs\n\nContinuous technical advances in manufacturing technologies are fueling the trend towards more powerful 3D Multi-Processor System-on-Chip (MPSoC) designs. However, 3D stacking creates additional manufacturing steps beyond the standard technology ones due to the high power density resulting from the placement of computational units on top of each other. Therefore, the power densities in 3D stacks will increase heat density, leading to degraded performance if thermal-aware design and thermal management are not handled properly. For instance, one of the novel cooling proposals is to use water flowing through liquid microchannels in addition to traditional heat sinks. During this mini-keynote, I will present a novel controller for energy-efficient cooling that is able to adjust the liquid flow rate to meet the desired temperature and to minimize pump energy consumption. Since in multicore systems workload varies at runtime, and the system is generally not fully utilized, it is not energy-efficient to adjust the coolant flow rate based on the worst-case conditions, as this would cause an excess in pump power. Hence, the proposed controller is the first generation of a new set of active cooling controllers to be developed in the coming years for forthcoming 3D MPSoCs, which is able to adjust the liquid flow rate to meet the desired temperature and to minimize pump energy consumption. This technique also includes a job scheduler, which balances the temperature across the system to maximize cooling efficiency and to improve reliability. In addition, the proposed controller forecasts maximum system temperature, and uses this forecast to proactively set the flow rate. This way, we can avoid over- or under-cooling due to delays in reacting to temperature changes.\n\nSoo-lk Chae, Seoul National University, Korea\n\nA multi-core platform with three video-specific processsors for HDvideo codec applications\n\nWe developed a progrqammable video platform for HD video codec applications. FIrst, I will briefly describe the architecture of the platform. Then I will explain three video-specific processors employed in the platform: one for parsing, one for motion compensation, and one for intra prediction, transformation, quantization, and deblocking filtering.\n\nJenq-Kuen Lee, National Tsing-Hua University, Taiwan\n\nParallelization of Stereo Vision Applications on Embedded Multi-Core Platforms\n\nMarkov random field models provide a robust formulation of low-level vision problems. Among the problems, stereo vision remains the most investigated field. The belief propagation provides accurate result in stereo vision problems, however, the algorithm remains slow for practical use. In this talk we examine and extract the parallelisms in the belief propagation method for stereo vision on multi-core processors. The stereo vision application is also used to evaluate an embedded multi-core platform developed by ITRI and our site. Our embedded multi-core platform is equipped with MPU and multi-core computational engines. A streaming remoting programming model for embedded multi-core systems is further supported to assist programmers to develop multi-core application. I will present preliminary experimental results both on ESL platforms and physical platforms.\n\nJohn Goodacre, ARM, UK\n\nExtending the ARM Architecture\n\nThis talk will introduce a set of new ARM Cortex architecture extensions being introduced into future ARM application processors. The talk will discuss their structure, implication and the requirements which drove their creation.\n\nChris Rowen, Tensilica, USA\n\nSilicon-Efficient DSPs and Digital Architecture for LTE Baseband\n\nMobile baseband SOCs face an essential paradox - on one hand, increased mobility dictates smaller batteries, longer battery life and improved energy efficiency. On the other hand, the complexity of new baseband standards like LTE - plus the multimedia, network protocols and application services enabled by fast baseband - dictate increased programmability, ubiquitous multi-core and more software layers. How could this possibly work? This talk describes practical successes for ultra-low energy processors used for LTE PHY subsystem designs achieving 150Mbps data rates in 200-300mW.\n\nYuan Xie, Pennsylvania State University, USA\n\nModeling, Architecture, and Applications of Emerging Memorytechnologies for MPSOC\n\nBy combing the speed of SRAM, the density of DRAM, and the non-volatility of Flash memory, emerging memory technologies (Phase-Change RAM (PCRAM) and Magnetic RAM (MRAM)) demonstrated a great potential to be the candidates for future memory hierarchy design. As such emerging memory technologies are getting mature, this talk will try to address some key questions for better utilizing such memories to improve the performance/power/reliability of future MPSOC systems. For example, how to model such emerging memory technologies? What will be the impacts on the future memory hierarchy? What are the research challenges to overcome for such a new memory hierarchy? What will be the novel applications/architectures with emerging memory technologies?\n\nRolf Ernst, Technical University of Braunschweig, Germany\n\nCertification of Trusted MpSoC Platforms\n\nMpSoCs are efficient platform for systems integration. However, due to physical resource sharing, safety critical systems integration becomes more challenging compared to distributed systems potentially leading to increasing certification cost. RECOMP (Reduced Certification Costs for Trusted Multi-core Platforms) is a European project with a 25 Mio â¬ budget intending to develop HW and SW architectures, design methods, and tools to efficiently design and (re-)certify MpSoCs for mixed critical systems. It looks at the whole supply chain, from the semiconductor vendors through OS, software and control unit suppliers, to systems integrators (OEMs) including key certification agencies. Players from different industries are involved, from automotive, aerospace, and industrial systems. The talk will present some of the main challenges and suggest solutions from an academic point of view. One of the main requirements is a flexible trade-off between development, certification, and production cost that is highly influenced by production volume, product lifetime, and system criticality.\n\nSESSION 7: Programming and Scheduling\n\n(In-Depth Technical Presentation)\n\nMartti Forsell, VTT, Finland\n\nStrong programming models for MP-SOCs\n\nDue to poor performance scalability potential of single processor SOCs, MP-SOCs employing multiple well-integrated processor cores are increasingly being used to cover computing needs of embedded and now also low-end general purpose systems. This shift from single core to multicore systems, however, has raised an old but very challenging problem to the limelights of embedded and general purpose system design flow to program MP-SOCs so that application development is not more difficult than for single core SOCs and still get high performance and utilization out of them for a very wide range of application-specific and general purpose algorithms? Apparently the current models making use of asynchronous shared memory and message passing do not fulfill neither programmability nor performance requirements. In this presentation we propose using strong programming models to solve the programmability problems of MP-SOCs and discuss about required architectural changes to underlying MP-SOC architectures. The models are based on synchronous shared memory concept that is supported by the only well-developed and widely usable theory of parallel algorithms.\n\nKees Vissers, Xilinx, USA\n\nProgramming and Performance of FPGAs all in C and C++\n\nIn recent years there have emerged new High Level Synthesis tools for Asics and FPGAs. These tools combined with modern FPGAs have a stunning performance, and an ease of programming similar to DSPs. The latest certified results from BDTI show that programming Xilinx FPGAs with these tools provided a 30x performance/$ benefit over a modern VLIW DSP processor. Even more surprising is that the programming effort was less then programming the DSP for the video application. The presentation will show in detail the certified results and will discuss the impact of this for the next generation video applications and wireless applications. The results will be shown in context of processors, multi-processors and processor-FPGA combinations.\n\nMartin Schoeberl, Technical University of Denmark, Denmark\n\nSchedule Memory Access, not Threads\n\nChip-multiprocessing is considered the future path for performance enhancements in computer architecture. Eight processor cores on a single chip are state-of-the art and several hundreds of cores on a single die are expected in the near future. General purpose computing is facing the challenge how to use the many cores. However, in embedded real-time systems thread-level parallelism is naturally used. We assume a system where we can dedicate a single core for each thread. In that case classic real-time scheduling disappears. However, the threads, running on their dedicated core, still compete for a shared resource, the main memory. A time-sliced memory arbiter is used to avoid timing influences between threads. The schedule of the arbiter is integrated into the worst-case execution time (WCET) analysis. The WCET results are used as a feedback to regenerate the arbiter schedule. Therefore, we schedule memory access instead of CPU time.\n\nSESSION 8: Low Power\n\n(In-Depth Technical Presentation)\n\nKunio Uchiyama, Hitachi, Ltd., Japan\n\nPower-efficient Heterogeneous Multicore for Digital Convergence\n\nFor digital systems in the digital-convergence era, various functions such as communication, security, audio, video, and recognition are required in a single device. However, improving the operating frequency of an embedded LSI in the system is saturated due to the significantly increasing power consumption problem. To solve this difficulty, heterogeneous parallelism on an SoC has been studied. A power-thrifty architecture, which combines embedded CPUs and special processing cores such as dynamic reconfigurable processors, has been proposed targeting a superior performance per power ratio and functional flexibility. From the viewpoint of programming, a parallelizing compiler and an Application Program Interface (API) have been developed that are suitable for heterogeneous parallelism. The evaluation results of various applications tested using prototype chips and programs will also be discussed.\n\nYasuhiro Tawara, Renesas Technology Corp., Japan\n\nDVFS and power-off controls on a multicore operating system\n\nLow power design techniques are current highlights not only in SoC's for mobile appliances requiring long battery run time but also in high-performance multiprocessors designed taking care of environmental sustainability. Different low-power techniques such as the dynamic voltage and frequency scaling (DVFS) and the power-off of a power domain might have ever been implemented on some multicore hardware. But there can be various ways in the phase of organizing such different hardware techniques into integrated software on the Linux operating system. This talk will introduce a part of our technique to integrate the Linux frameworks such as CPUFreq and CPU HotPlug into an efficient low-power multicore system.\n\nTuomas Jarvinen, ST-Ericsson, Finland\n\nDesigning for low power in SoC projectss\n\nLow power consumption is an increasingly important design challenge in current mobile products. Even today the power starts to limit the computational performace of the system. Therefore, power is one of main design parameters among the area and performance when defining the new product. Architectural work includes definition of power domains and operating points early in the design flow, which play a critical role in the power efficiency. After architectural specifications are ready the implementation begins. Feedback is provided already from early stages on power consumption and modifications are done to the design. This work continues until the targets are met and design is ready for production. Management of the power optimization requires systematic approach and accurate models.\n\nWednesday June 30\n\nSESSION 9: Keynote\n\nMarco Cornero, ST-Ericsson, Italy\n\nMPSoc's in Mobile phones: parallel computing for the masses\n\nWith the quick adoption of ARM multi-core solutions, the Mobile industry has suddenly accelerated the shift towards multi-processing that is happening right now. This is in addition to the GPGPU trend that has renewed the interest in parallel processing in the PC and supercomputing worlds, which it is quickly reaching the mobile space as well, and the move towards many-cores architectures for multimedia acceleration. In other words, multi-processing everywhere, soon in the hands of the masses, enabling really exciting and compelling applications, such as augmented reality, in battery-powered devices. In my talk I will share our experience of driving such as fundamental shift from the perspective of an early industrial adopter, including motivations, vision, results and the day-to-day mix of practical issues and theoretical challenges that we are facing in these exciting times.\n\nSESSION 10: NOC & Many-Core\n\n(Mini-Keynote)\n\nMarcello Coppola, STMicroelectronics, France\n\nNoC: Myth or Reality?\n\nDesign complex SoC is getting more and more timing consuming and error-prone. NoC is a promising technology for SoC integration and on-chip interconnection, offering faster and low power communication network and potentially smaller time-to-market. This presentation will start with a brief summary of MPSoCs in ST and how NoCs are reducing the gap between growing system complexity and designer productivity.\n\nK. Charles Janac, Arteris Inc., USA\n\nNetwork on Chip - Not just for Complex SoCs Anymore\n\nNetwork on Chip IPs have seen adoption at the high-end of the SoC market for designs such as Application Processors, Complex Baseband Modems and Digital TV SoCs. Recent developments in zero latency NoC connections, reductions in gate/wire utilization and sharing of Network Interface Units have made NoC IPs competitive for even the smallest SoC designs. This presentation covers conceptual and data comparisons for network on chip IPs utilized at low SoC complexities to show that there are in fact benefits in utilizing Network on Chip IP technology at any SoC complexity level.\n\nGabriela Nicolescu, Ecole Polytechnique de MontrÃ©al, Canada\n\nMulti-Objective Design Space Exploration for MPSoC\n\nMany-core platforms, providing large numbers of parallel execution resources, emerge as a response to the increasing computation needs of embedded applications. A major challenge raised by this trend is the efficient design space exploration. This is a non- trivial problem because of the number of parameters to be considered for characterizing both the applications and the underlying platform architectures. This talk discusses the main techniques for the design space exploration in MPSoC design and propose a new technique that minimizes the number of simulations needed to identify a Pareto curve.\n\nOmar Hammami, ENSTA PARISTECH, France\n\nDesign and Implementation of a NOC Based 2048 PE on Large Scale Emulator\n\nLarge scale MPSOC stresses all aspects of MPSOC: design automation, parallel architecture, performance evaluation and benchmarks. We will describe in this talk ongoing effort for the design and implementation of a NOC based 2048 PE on large scale emulator.\n\nSungjoo Yoo, POSTECH, Korea\n\nNetwork awareness in memory controllers for many-core\n\nNetwork-on-chip and memory controller can become correlated with each other in case of high network congestion since the network port of memory controller can be blocked due to the (back-propagated) network congestion. We call such a problem network congestion-induced memory blocking. In order to resolve the problem, we present a novel idea of network congestion-aware memory controller where the memory controller performs (1) congestion-aware memory access scheduling and (2) congestion-aware network entry control, based on the global information of network congestion.\n\nSESSION 11: Keynote\n\nSebastian Steibl, Intel, Germany\n\nSingle-chip Cloud Computer: Architecture, Design and Application of a 48 Core Research Microprocessor\n\nWe will present the design of the experimental Single-chip Cloud Computer (SCC) by Intel Labs. The SCC is a research microprocessor containing the most Intel Architecture cores ever integrated on a single silicon chip - 48 cores. We envision the SCC as a concept vehicle for research in the areas of parallel computing including system software, compilers and applications. It incorporates technologies intended to scale multi-core processors to one hundred cores and beyond including an on-chip network, advanced power management technologies, new data-sharing options using software managed memory coherency or hardware accelerated message passing, and intelligent resource management. The SCC contains eight voltage domains: two for on and off chip I/O and six for the cores. It has a NUMA architecture including local caches and on-die distributed memory for low latency, hardware-assisted message passing or scratchpad use as well as an abundant external DRAM bandwidth and capacity. Thus, the processor can be used as a proxy for future MP-SoC platforms by running several independent applications and operating systems concurrently on dedicated resources while applying fine-grain voltage and frequency scaling for best energy efficiency. In this talk we will review the chip's architecture and show the emulation-based design flow that enabled us to build the SCC with a relatively small design team while keeping high confidence in the quality of the design. This approach allowed us to boot an OS in order to begin system software design before production. Finally, we will describe an SCC co-traveler research program where Intel will collaborate with dozens of industry and academic research partners. We expect that this program will significantly accelerate the evolution and adoption of many-core hardware and software technologies. To highlight the potential of this program, we will share some initial experiences and results from our first partners in this research community.\n\nSESSION 12: Heterogeneous MPSoCs\n\n(In-Depth Technical Presentation)\n\nYankin Tanurhan, Virage Logic, USA\n\nSeamless Integration of Heterogeneous Co-Processors in Today's SoCs\n\nSri Parameswaran, University of New South Wales, Australia\n\nHeterogeneous Multi-Processor Pipelines: an MPSoC Story\n\nSeveral modern systems, from ubiquitous mobile phones to powerful gaming machines, contain multiple heterogeneous processing cores. In a modern phone, for example, a general purpose processor manages the human machine interface, while a DSP manages the baseband signal processing. Usually, these heterogeneous multi-processor systems isolate tasks, and execute the isolated tasks in separate processors. In this talk a novel heterogeneous multiprocessor pipeline system is described, where a single streaming application is executed by multiple processors. The processors in the system are connected in a pipeline via queues (FIFOs) which allow communication at a higher bandwidth, devoid of the contention exhibited by typical shared bus architecture. Recent developments in Application Specific Instruction Set Processors (particularly from Tensilica Inc), have driven the creation of these multi processor pipelines with ASIPs as the building blocks. Each ASIP in the pipeline is customized with differing additional instructions, and instruction and data cache sizes to improve performance of the task mapped on that particular ASIP. As a result, the performance of the whole system is improved, while minimizing the increase in area. The permutation of configurations for each ASIP make up the design space of the pipelined multiprocessor system, and is rapidly explored. An automated design methodology to choose the best ASIP configurations as the final design in a reasonable amount of time is shown. The rapid exploration methodology used is able to explore design spaces up to 10^16 design points, which is almost impossible to explore otherwise. Finally, the possibilities of merging pipeline systems are discussed as the future work.\n\nSESSION 13: Applications\n\n(In-Depth Technical Presentation)\n\nRudy Lauwereins, IMEC, Belgium\n\nProcessors for wireless sensor nodes: can you do something useful in just a few microwatts\n\nAutonomous wireless sensor nodes find a growing number of applications in wellness, health care, building automation, industrial maintenance and so forth. Typically, they consist of a sensing device, analog conditioning circuit, digital signal processing, wireless transmission and power management. Due to their abundant nature and often also due to the difficulty in reaching them after they have been deployed in the field, battery operation is cumbersome. Energy harvesting from the ambient environment with some form of local storage to cope with fluctuations in energy production is often the only viable alternative. This limits the available power to the order of 100 microwatts. Performing sensing, processing and transmission in 100 microwatts is a real challenge. In this presentation, I will use an ambulatory ECG system as a design example. It contains multiple digital signal processors, not in the classical multi-core way to obtain extremely high performancce, but rather consisting of tiny, highly specialized cores, to obtain reasonable compute performance at extremely low power consumption. I will also describe the careful trade-off between analog and digital as well as between compute and communicate that is due to fit the low power budget.\n\nKees van Berkel, STEricsson, Eindhoven University of Technology, France\n\nMulti-Core for Mobile Phones\n\nHigh-end mobile phones support multiple radio standards and a rich suite of applications, which involves advanced radio, audio, video, and graphics processing. The overall digital workload amounts to nearly 100GOPS, from 4b integer to 24b floating-point operations. With a power budget of only 1W this inevitably leads to heterogeneous multi-core architectures with aggressive power management. We review the state-of-the-art as well as trends towards Software Defined Radio and LTE-Advanced, from a multi-core perspective.\n\nYukoh Matsumoto, TOPS Systems Corporation, Japan\n\nCG Application Domain Specific Heterogeneous Multi-Core Processor\n\nWe have co-designed CG Application-Domain Specific Heterogeneous Multi-Core architecture and its algorithm for a Desk-Top Real-Time Ray Tracing system with HD (1920 x 1080 pixels) resolution based on Free form Curved Surface expression and 35 bands reflective spectrum color model. The required computing performance corresponds to 800 TFLOPS, and the power consumption constraints to 1kW. We can have a hierarchical heterogeneous Multi-Core architecture based on TOPSTREAM platform architecture with 73 processors, three-levels of on-chip memory hierarchy, and inter-processor communication via shared register banks. The software programming model following Kahn Process Network (KPN) enables easy migration from a legacy sequential processing to a distributed parallel processing.\n\nSESSION 14: Keynote\n\nPieter J. Mosterman, MathWorks, USA\n\nA computational semantics of time-based models and its role in Model-Based Design\n\nThe successful design of modern systems requires us to use computational methods in order deal with their terrific complexity. Well-documented issues such as those found in the design of the F-22 and the Ariane-V are painful indicators that we have not yet mastered a systematic design methodology. The three basic drivers that complicate matters are: (i) we do not understand computation well, (ii) the system complexity has outgrown the power of traditional design methods, and (iii) hardware is increasingly designed as a (reconfigurable) platform of a heterogeneous nature. In an attempt to address these complications, this presentation discusses Model-Based Design and develops a declarative semantics of time-based models which allows: (i) reasoning about the formalism and models, (ii) raising the level of abstraction, and (iii) decoupling from implementation so as to facilitate the exploitation of varying distributed architectures.\n\nSESSION 15: HW & SW Techniques\n\n(Mini-Keynote)\n\nUlrich Ramacher, Infineon, Germany\n\nOn the Challenges of Programming XGOLD SDR 20\n\n23 RISC, 36 controllers, 12 vector engines, 1 GPU and 1 GP_DSP have to cooperate when running LTE with a power budget of less than 500mW. The steps of power-minimal parallel programming are presented and respective requirements for tools discussed.\n\nRaphaÃ«l David, CEA LIST, France\n\nLow Power management in embedded multi-core architectures\n\nDue to the complexity increase of embedded applications, multi-core systems on chip (MPSOC) are becoming the mainstream for architecture design. Indeed, according to ITRS, the number of cores in high-end systems will exceed 100 cores in 2012. With an expected 32% a year increase in the number of cores per die, the concept of multi-cores will even evolve to many-cores in the coming years. Managing complexity in such system is a challenge that cannot be talked only by off-line application analysis and compilation techniques. In fact to deal with variability coming from technology as well as advance embedded application that are highly data-dependant, runtime resources management strategies have to be put in place. This talk deals with this new challenge of dynamically managing tens to hundreds of core. In particular this talk will focus on the power management of such devices.\n\nKees Goossens, Eindhoven University of Technology, Netherlands\n\nVirtualized Processor Power Management\n\nVirtualisation has traditionally been seen as either time-sharing a compute resource or as instruction-set virtualisation. More recently, the idea of performance virtualisation\n\n(or composability), whereby different applications are guaranteed to not interfere with each other has been proposed. In this presentation we show how performance virtualisation on a processor can be extended to include power management. Each (real-time) application has its own independent power management, such that there is no interference between applications.\n\nJoachim Kunkel, Synopsys, USA\n\nVirtual Prototyping - Ready For Prime Time?\n\nVirtual Prototyping has been used by advanced users to accelerate the development of software for software intensive SoC-based products. This talk will describe the current status of virtual prototyping technology and explore what it will take achieve broader adoption in the software development community.\n\nKiyoung Choi, Seoul National University, Korea\n\nSome Applications of Coarse-Grained Reconfigurable Array\n\nWith the ever increasing requirements for more flexibility and higher performance in embedded systems design, coarse-grained reconfigurable array has drawn much attraction. Its performance and reconfigurability render new areas of application. This talk presents several new applications of coarse-grained reconfigurable array including acceleration of\n\napplications running on a general purpose processor and fault tolerant computing. Preliminary results are also presented.\n\nLars Bauer, Karlsruhe Institute of Technology, Germany\n\nKAHRISMA: A Multi-grained Reconfigurable Multicore Architecture\n\nFine-grained and coarse-grained reconfigurable processors use different types of reconfigurable hardware to accelerate applications, increase the system efficiency, and provide significantly extended flexibility. They have demonstrated their advantages in comparison to GPPs, ASIPs, and ASICs particularly in scenarios where a high adaptivity is demanded, i.e. where at-design-time optimizations are inefficient. Existing reconfigurable architectures either concentrate on fine- or on coarse-grained reconfigurability and target single-core processors. Certainly, for bit/byte-level processing, irregular data structures etc. fine-grained approaches are superior, whereas for regular word-level processing coarse-grained approaches are more efficient. This talk will present a new paradigm that combines both approaches seamlessly such that the overall performance, efficiency, and flexibility is increased to a greater extend. Additionally, the reconfigurable hardware is used to implement further processing cores on demand. This hypermorphism allows exploiting task- and thread-level parallelism complementary to data- and instruction-level parallelism that is addressed by multi-grained reconfigurable accelerators.\n\nPieter Van der Wolf, Virage Logic, Netherlands\n\nEfficient and predictable integration of MPSoCs\n\nHeterogeneous MPSoCs typically integrate a diverse set of system functions, which have different requirements on the SoC infrastructure that binds them together. A Host subsystem, for example, typically has no hard real-time requirements, but demands lowest latency to unlock CPU performance. Examples of real-time functions are Video Processing on a function-specific engine with input/output buffers that are not allowed to run empty/full, or Audio Processing on a CPU that can sustain only so much latency for its memory accesses in order to meet its deadlines. We illustrate how SoC infrastructure technology can support the efficient integration of system functions with such diverse requirements, with specific attention to guaranteed Quality-of-Service (QoS) for the real-time system functions. Key benefits of such SoC infrastructure technology are predictable MPSoC performance, improved time-to-market, and low latency for demanding CPUs, while avoiding costly over-dimensioning to guarantee real-time behavior.\n\nSESSION 16: NOC\n\n(In-Depth Technical Presentation)\n\nYuichi Nakamura, NEC Corp., Japan\n\nThe layout evaluation and hierarchical layout method of NoCs\n\nThis presentation is about the layout evaluation of a NoC architecture and also proposes a hierarchical NoC layout method. It is said that wire count and wire length reduction are among the benefits of NoC, enabling the design of many-core LSIs. To confirm the benefits, we first present the results of a layout comparison between AXI and NoC with a 16-core design in DSM. The results of this evaluation indicate that the maximum delay in the NoC is 2.3 times smaller than in AXI. The NoC has a significantly shorter TAT time of the layout tool. In addition, to achieve the ease of design for many cores NoC, an ad-hoc hierarchical layout method is proposed, since we experienced that a global layout approach cannot be effectively applied to many-core NoCs. With a 16-core design, the global and hierarchical layouts give very similar results, but the proposed hierarchical layout method becomes more effective when the number of cores is increased. In addition, hierarchical layout enables core swapping, since the method allows to modify the layout only for the specified area.\n\nTakashi Miyamori, Toshiba Corporation, Japan\n\nEvaluation of Network-on-Chip for Large Scale Many-Core Systems\n\nIn this presentation, we evaluate architectures and performance of Network-on-Chip for large scale many-core, up to 1024 cores. The multi-core architecture of Toshiba's Venezia, that consists of low power and small media extended embedded processors, is extended to many-core architecture. Realistic media processing programs were simulated on the cycle-based SystemC many-core simulator.\n\nIan O'connor, Lyon Institute of Nanotechnology, France\n\nOptical networks on chip for MPSoC data communication\n\nThe shift to distributed multi-processor architectures is the recognized route to high performance and computing capacity, and requires organized high-speed communication between processors. Metallic interconnect will be highly inefficient in this role due to unachievable tradeoffs between design parameters such as inter-line crosstalk, latency, global throughput, connectivity and power consumption. The concept of integrated optical interconnect is a potential technological solution to alleviate some of these issues involved in exchanging data between cores in MPSoC architectures. In this work, we present two types of approach for the use and ongoing assessment of optical interconnect instead of electrical interconnect in on-chip data communication structures. We firstly detail simulation-based quantitative comparisons for direct point-to-point links at the physical link level, using single-wavelength links. The data was obtained using optical link synthesis and technology performance characterization and analyzes optical link performance for several sets of photonic component parameters and CMOS technology generations. Importantly for technological development, the results of such analyses can generate useful feedback from system designers to component designers. This work contributed to the development of the world's first demonstration of a working optical link on a CMOS wafer. We then describe concurrent physical and system-level evaluations for optical networks on chip integrated in an industrial MPSoC characterization environment and using real traffic characteristics. Such architectures are shown to enable high bandwidth and low contention routing of data using wavelength multiplexing.\n\nSESSION 17: Keynote\n\nJae Cheol Son, Samsung Electronics, Korea\n\nMPSoC Technology for New Wave of User Experiences\n\nRapid advances in technologies such as communication, internet, computing, and semiconductor will keep driving new wave of user experiences. The new user experiences will enrich all our lives, but will demand ever increasing computing power. To meet the computing demand and power reduction need simultaneously, high-performance and low-power MPSoC solution is inevitable. To achieve more efficient MPSoC design, the solution cannot be a simple integration of multiple computing cores, but must have highly optimized cores with necessary hardware IP blocks. Moreover, understanding of user experiences and application software-hardware interfaces is another essential factor for successful design. This presentation will discuss key technologies and upcoming challenges to maneuver competitive MPSoC design.\n\nSESSION 18: Emerging Device and Design Technologies\n\n(Mini-Keynote)\n\nKoichiro Yamashita, Fujitsu Laboratories LTD., Japan\n\nEvaluation and development methodology for progressing of MPSoC technology to industrial field of mobile platform\n\nProgressing the MPSoC technology to the consumer product is an important event. Especially, it is indispensable to achieve the demand of performance progress and long battery life of the portable terminal. However, it is difficult to unite the results of study and the succession of industrial software asset. It is a problem to migrate several hundred million steps of the terminal software in the seamless. (several ten million steps are implemented only even as for OS platform) Therefore, it is not realistic rewriting all of system resources to achieve the best performance on the MPSoC platform. This talk will introduce the activity of SMP-WG of the Symbian Foundation based on the former subjects.\n\nTsuyoshi Isshiki, Tokyo Institute of Technology, Japan\n\nMPSoC Platform for Super Hi-vision Video Processing System\n\nAs High Definition Television (HDTV) has become a commodity, next-generation panel displays and projectors are moving towards higher resolutions such as 4K2K (digital cinema) and 8K4K (Super Hi-vision). Image processing engine for these high resolution systems must cope with extremely high data rate of up to 30Gbps and provide a wide variety of image processing functions (enhancement, noise reduction, resizing, frame conversion, color adjustment). This talk will address the design issues of such mage processing systems on the perspective of algorithm development and MPSoC architecture exploration.\n\nBenjamin Carrion Schafer, NECCorp., Japan\n\nComplete C-Based SoC Design: Is it possible?\n\nESL is becoming mainstream when modeling complete SoCs in order to evaluate different architectural trade-offs and get some early performance estimates. ESL models are mainly described in SystemC. The central question is if these models can ultimately be synthesized in order to reduce further the development cycle or if these models need to be manually described and integrated at the RT-level. We strongly believe that complete SoCs can be fully designed in C and show with the help of 2 examples how this is possible.\n\nJan Madsen, Technical University of Denmark, Denmark\n\nA Bio-Inspired Reconfigurable Hardware Architecture Supporting Self-organisation and Self-healing\n\nElectronic devices based on modern chip technology are susceptible to both transient and permanent failures due to increased integration and to process variability of the chip technology. In this talk, we will present a reconfigurable hardware platform, which is capable of Self-organisation and Self-healing based on biological principles. The platform is a multicore chip, where each core acts as a cell. An application is compiled into a compact representation resembling the biological DNA. Self-organisation allows the cells of the platform to autonomously determine their functionality from the DNA based on their position. In case of a cell failure, other cells are able of detect this and re-establish the lost functionality at a nearby idle-cell through the sharing of DNA, effectively obtaining Self-healing of the platform.\n\nSESSION 19: 3D-IC Technologies\n\n(In-Depth Technical Presentation)\n\nTadahiro Kuroda, Keio University, Japan\n\nThruChip Interface (TCI) for 3D System Integration\n\nA ThruChip Interface (TCI) employs near field inductive coupling that is suitable for a high-density parallel channel arrangement with small cross talk, and hence, area interface for 3D CMOS integration. It is less expensive than TSV by 20Â¢/chip, since it is implemented by digital circuits in a standard CMOS. It bears comparison with TSV in terms of data rate (11Gb/s/ch), reliability (BER<10-14), and energy dissipation (0.14pJ/b). ESD protection devices can be eliminated to lower delay, power, and area. It provides with an AC coupling link to make interface design easy under multiple/variable VDDâs. The cost/performance will further be improved exponentially by thinning chip thickness. The TCI has been employed to commercial applications. It enables staking of 64 NAND flash memory chips in a package to realize a package-size SSD (Solid-State Drive). Microprocessor and memory chips are linked by the TCI to lower power dissipation by two orders of magnitude compared with a DDR interface. This talk will cover basics, applications, and future perspectives of the TCI.\n\nHsien-Hsin Sean Lee, Georgia Institute of Technology, USA\n\nDesign, implementation, and test for a 3D-IC many-core processor\n\n3D integration is a promising technology to continue CMOS scaling, also known as Mooreâs Law, in the vertical dimension. It enables a true System-on-Chip design by stacking multiple die, fabricated with either homogeneous or heterogeneous processes, onto the same package using inter-die vias or through-silicon vias (TSV). By stacking memory directly atop of a processor, a 3D-IC system also provides new exciting opportunities to address the immense bandwidth and high energy-efficiency required by a future many-core system. However, 3D technology adoption is being hampered by an insufficient understanding of 3D testing issues and by the lack of design-for-testability techniques. Without appropriate test strategies, 3D-IC will never become economically viable for volume production. In this talk, I will discuss the design and implementation of a 3D-IC many-core processor we recently designed and taped out using 130nm process provided by Chartered Semiconductor (GLOBALFOUNDARIES). The design was aimed at demonstrating the memory bandwidth attainable between the core and memory layers using face-to-face inter-die vias for streaming applications. Optionally, additional bandwidth can be made available and delivered from the stacked DRAM layers using TSV. In addition, I will also describe our physical design methodology as well as the design-for-test strategy we used in this 3D chip. Finally, I will discuss the learning, challenges, and prospects of 3D-IC processor system we obtained from this exercise.\n\nNaoki Nishi\n\nNaoki Nishi is a general manager at central research labs., NEC Corporation. He received the B.E. and M.E. degrees in system engineering from Hiroshima University in 1982 and 1984, respectively. He joined NEC Corporation, Kawasaki, Japan, in 1984, where he was engaged in the architectural research and development on supercomputer, especially multiple and OoO instruction issue logic, parallel memory system, and highly parallel supercomputer with CMOS VLSI technology. Since 1996, he has been engaged in the research and development on low power multi-/Many-core architecture. Now, He is managing System IP-core Research Lab., NEC.\n\nKazuo Kajimoto\n\nMr. Kajimoto was received the B.E. and M.E. degrees in information science from Kyoto University in 1984 and 1986, respectively. He joined Matsushita Electric Industrial Co., Ltd. ,that is, current Panasonic Corporation in 1986. Mr. Kajimoto is currently the director of System Engineering Center, Corporate R&D Domain, Panasonic Corporation and he is in charge of corporate level software strategy in various business fields such as device business and set business. Previously, he was one of chief software architect of âUniPhierâ which is the system platform of consumer electronics hardware and software designed by Panasonic and which is applied a variety of consumer electronics such as DTV, DVD, Blu-ray, Cellular Phone, Security System and so on. And nowadays âUniPhierâ is adopted by not only Panasonicâs products but by other companyâs ones Mr. Kajimoto is representative of Panasonic Corporation in wide range of software technology field like Open Source Software, Process Improvement Technology and so on and he sits on board member of CE Linux Forum, Software Industry Committee of Japan Electronics and Information Technology Industries Association (JEITA) etc.\n\nMarco Cornero\n\nMarco Cornero is in charge of Advanced Computing in ST-Ericsson CTO Office and 3G Multimedia Business Unit. He is coordinating the introduction of Symmetric Multi Processing in ST-Ericsson chipsets, and he is following the evaluations and evolution of other strategic software technologies, such as OpenCL and platform virtualization.\n\nBefore joining ST-Ericsson Marco was director of advanced software development tools in STMicroelectronics, working on several aspects of SoC programming, including static and just-in-time compilers, heterogeneous multi-processing programming models and tools, run-times and operating systems. Marco holds a Ph.D. and a Master degree in Computer Science, both from the University of Genova, Italy.\n\nJae Cheol Son\n\nDr. Jae Cheol Son is a Vice President at SoC Platform Development Team of Samsung Electronics, where he leads the high-performance low-power processor development. Prior to joining Samsung Electronics, he held various management and engineering positions at Sun Microsystems and Luminous Networks, where he focused on development of high-performance microprocessors and advanced ASIC products. He received B.S. degree from Yonsei University, Seoul, Korea, and M.E. and Ph.D. degrees from KAIST, Daejeon, Korea, all in Electrical Engineering. His research interests include high-performance microprocessor and VLSI design, multimedia processing, and statistical signal processing. He is a Senior Member of IEEE.\n\nPieter J. Mosterman\n\nPieter J. Mosterman is a Senior Research Scientist at The MathWorks in Natick, MA where he works on core SimulinkÂ® simulation and code generation technologies and an Adjunct Professor at the School of Computer Science of McGill University. Before, he was a Research Associate at the German Aerospace Center (DLR) in Oberpfaffenhofen. He has a Ph.D. degree in Electrical and Computer Engineering from Vanderbilt University in Nashville, TN, and a M.Sc. degree in Electrical Engineering from the University of Twente, Netherlands. His primary research interests are in Computer Automated Multiparadigm Modeling (CAMPAM) with principal applications in design automation, training systems, and fault detection, isolation, and reconfiguration. He designed the Electronics Laboratory Simulator, nominated for The Computerworld Smithsonian Award by Microsoft Corporation in 1994. In 2003, he was awarded the IMechE Donald Julius Groen Prize for a paper on HYBRSIM, a hybrid bond graph modeling and simulation environment.\n\nSebastian Steibl\n\nSebastian Steibl is the Director of Intel Labs Braunschweig in Germany. Sebastian leads a team of researchers and engineers in developing technologies ranging from the next generation Intel CPU architectures, high bandwidth memory and memory architectures to emulation and FPGA many-core prototyping methodology. He co-led the design of Intel's Single Chip Cloud Computer, a concept microprocessor aimed at enabling research in the area of parallel programming and tera-scale computing. Sebastian joined Intel in 2000 through an acquisition and has more than 20 years of experience in computer architecture and silicon design. Prior to becoming the Director of Intel Labs Braunschweig, he worked in various engineering management positions inside and outside of Intel, owning multiple successful product designs in Optical Networking space. Sebastian has a Dipl.-Ing. degree from Technical University of Braunschweig.\n\nYuichi Nakamura\n\nYuichi Nakamura received his B.E. degree in information engineering and M.E. degree in electrical engineering from the Tokyo Institute of Technology in 1986 and 1988, respectively. He received his D.E. from the Graduate School of Information, Production and Systems, Waseda University, in 2007. He is currently a senior principal researcher at System IP Core Research Labs., NEC Corp. He is also a guest professor of National Institute of Informatics.\n\nTakashi Miyamori\n\nTakashi Miyamori received the B.S. and M.S. degrees in electrical engineering from Keio University, Japan, in 1985 and 1987, respectively. In 1987, he joined Toshiba Corporation, where he was engaged in the research and development of microprocessors. He is currently a Chief Specialist and working on the development of configurable processor cores, media processors, image singal processing processors, and multi-core processors.\n\nTadahiro Kuroda\n\nHe received the Ph.D. degree in EE from the University of Tokyo. From 1982 to 2000 he was with Toshiba Corporation, where he designed CMOS/BiCMOS/ECL SRAMs, ASICs, ASSPs. From 1988 to 1990, he was a Visiting Scholar with the University of California, Berkeley, where he conducted research in the field of VLSI CAD. He invented a Variable Threshold-voltage CMOS technology and a Variable Supply-voltage scheme in 1996. In 2000, he moved to the Keio University, and he has been a professor since 2002. He is a Visiting MacKay Professor at the University of California, Berkeley. His research interests include low-power, high-speed CMOS design for wireless and wireline communications, human computer interactions, and ubiquitous electronics. He has published more than 200 technical publications including 60 invited papers and 21 books/chapters, and filed more than 100 patents. He served as a conference chair and a TPC member of IEEE conferences such as Symp. on VLSI Circuits, CICC, A-SSCC, DAC, ASP-DAC, ICCAD, ISLPED. He is an IEEE Fellow, an IEEE SSCS Distinguished Lecturer, and an elected AdCom member.\n\nKunio Uchiyama\n\nKunio Uchiyama, Chief Scientist & Corporate Officer of Hitachi, Ltd., received the B.S., M.S., and Ph.D degrees from Tokyo Institute of Technology. Since 1978 he has been working for the Central Research Laboratory, Hitachi, Ltd., Tokyo, Japan, on design automations, mainframse, cache memories, and microprocessors. From 1985 to 1986 he was a visiting researcher at the Department of Computer Science, Carnegie-Mellon University. He also serves as a visiting professor of Waseda University. He got the Ichimura-award, R&D100, the chief officer's award of Japanese Science and Technology agency, and the national Medal of Honor with Purple Ribbon in 1998, 1999, 2000, and 2004 respectively.\n\nSuzuki Takahisa\n\nTakahisa SUZUKI has received the M.E. degrees in computer science from Waseda University, and joined Fujitsu Laboratories LTD in 2004. Currently he is working for a SMP operating system on mobile phone system and attending SMP Working Group of Symbian Foundation as a R&D leader of Fujitsu.\n\nYasuhiro Tawara\n\nYasuhiro Tawara is a senior engineer at Renesas Technology Corp. and currently leading development of multicore operating systems. He received BS degree in Mathematics from Waseda University and joined Hitachi, Ltd. in 1989. He designed an optimizing compiler and a part of the SuperH RISC engine in Hitachi, Ltd.. He received MS degree in Computer Science from Stanford University in 1996. After that, he engaged in development of integrated design environments and compilers in Hitachi, Ltd.. He joined Renesas Technology Corp. in 2003 when it was spun out of both Mitsubishi Electric Corp. and Hitachi, Ltd.. He has been engaged in performance evaluation of processors, system level verification and multicore operating system development. His current interests are multicore operating systems, load balancing algorithm, low-power system design, and many-core architecture.\n\nYukoh Matsumoto\n\nDr. Yukoh Matsumoto is the chief architect, and president and CEO of TOPS Systems Corp. Currently, he leads â3D stacked heterogeneous Multi-Processor chip projectâ funded by NEDO, as well as âUltra-Android projectâ, embedded software platform to utilize heterogeneous Multi-Core processors, sponsored by METI. In his 24 years of carrier, he has architected and designed over 10 advanced Multi-Core processors, x86 microprocessors, and DSPs. He received the Takeda Techno-Entrepreneurship Award in 2001. Prior to TOPS Systems, he co-founded TOPS Corp. in 1997 and has held several positions within Texas Instruments Research and Development organization. He received the Dr. of Information Sciences (the Ph.D.) degree from the Graduate School of Tohoku University, Sendai, Japan, in 2007 and participated in the MOT (Management of Technology) program at the Graduate School of Engineering in Tokyo University from 2004 through 2005.\n\nZhiyi Yu\n\nZhiyi Yu received the Ph.D. degree in electrical and computer engineering from the University of California, Davis in 2007. Dr. Yu is currently an Associate Professor with the State Key Laboratory of ASIC & System, Microelectronics Department, Fudan University, China. His research interests include digital VLSI design and computer architecture, with an emphasis on multi-core and many-core processors. From 2007 to 2008, he was with IntellaSys Corporation, CA, USA, where he participated in the design of the many-core SEAForth chips which utilize stack-based processors with extremely small area and low power consumption. When in UC Davis, he was a key designer of the 36-core Asynchronous Array of simple Processors (AsAP) chip, and one of the designers of the 167-core second generation computational array chip. He serves as a member of the Technical Program sub-Committee of the IEEE Asian Solid-State Circuits Conference (ASSCC) in 2009, and a member of the TPC of the IEEE I\n\nnternational Conference on ASIC in 2009.\n\nYoun-Long Lin\n\nYoun-Long Lin is a Tsing Hua chair professor of computer science of National Tsing Hua University. He received his Ph.D. in computer science from the University of Illinois, Urbana-Champaign, IL, U.S.A. in 1987. He co-found Global UniChip Corp. His research interest includes physical design and high level synthesis of VLSI and VLSI design of video codec.\n\nHsien-Hsin Sean Lee\n\nDr. Hsien-Hsin S. Lee is an Associate Professor in the School of Electrical and Computer Engineering at Georgia Institute of Technology. He received his Ph.D. degree in Computer Science and Engineering from the University of Michigan, Ann Arbor. His main research interests include computer architecture, low-power VLSI, cyber security, and the emerging 3D integration technology. Prior to joining Georgia Tech in 2002, he spent 6 years as a senior processor architect and a researcher at Intel Corporation designing Pentium III processor and performed research for Itanium architecture and one year at Agere Systems as an architecture manager for their StarCore DSP. Dr. Leeâs received the Horace H. Rackham Distinguished Dissertation Award from the University of Michigan, an NSF CAREER Award, a Department of Energy Early CAREER Award, and the Georgia Tech ECE Outstanding Jr. Faculty Award. He had co-authored 3 papers that won Best Paper Awards and holds 4 U.S. patents. He is a senior member of both the ACM and the IEEE.\n\nKees Vissers\n\nKees Vissers graduated from Delft University in the Netherlands. He worked at Philips Research in the Netherlands and the USA. His research included VLIW processors, reconfigurable architectures, HDTV signal processing, and Hardware Software Co-design. He worked as a visiting industrial Fellow at CMU and UC Berkeley. He worked at two startups, consulted for Nvidia and Xilinx, and has worked at Xilinx Labs for 5 years. He heads the team on advanced architectures and programming models for FPGAs and processors.\n\nYankin Tanurhan\n\nDavid Kleidermacher\n\nDavid Kleidermacher is Chief Technology Officer at Green Hills Software where is responsible for technology strategy, platform planning, and solutions design. Kleidermacher is a leading authority in systems software and security, including secure operating systems and virtualization technology. Kleidermacher earned his bachelor of science in computer science from Cornell University and is an active writer and speaker on technology subjects. He has been with Green Hills Software since 1991.\n\nMartin Schoeberl\n\nMartin Schoeberl is associate professor at the Technical University of Denmark, at the Department of Informatics and Mathematical Modelling. His research focus is on time-predictable computer architectures and on Java for hard real-time systems. He developed the time-predictable Java processor JOP and led the research on a time-predictable chip-multiprocessor version of JOP. This platform was developed within the EU project JEOPARD (Java Environment for Parallel Realtime Development). His current research focus is on time-predictable computer architectures for hard real-time systems.\n\nIan O'connor\n\nIan O'Connor (IEEE S'95-M'98-SM'07, IEE S'87-M'98) is Professor for Heterogeneous and Nanoelectronics Systems Design in the Department of Electronic, Electrical and Control Engineering at Ecole Centrale de Lyon, France. He is currently head of the Heterogeneous Systems Design group at the Lyon Institute of Nanotechnology, of which he is also one of the vice-directors. Since 2008, he also holds a position of Adjunct Professor at Ecole Polytechnique de MontrÃ©al, Canada. His research interests include design methods and tools for physically heterogeneous systems on chip, and their application to novel system architectures based on non-conventional devices. He has authored or co-authored around 100 book chapters, journal publications and conference papers and has been workpackage leader or scientific coordinator for several national and european projects. He also serves as an expert with the french Observatory for Micro and Nano Technologies (OMNT).\n\nEmil Matus\n\nDr. Emil Matus is senior scientist at Vodafone Chair Mobile Communication Systems where he is leading modem design group. He received his MS and PhD degrees in Electrical Engineering from University of Technology in Kosice (Slovakia). Prior to joining Vodafone chair in 2003 he was research associate at University of Technology in Kosice, visiting scientist at Friedrich-Alexander UniversitÃ¤t Erlangen-NÃ¼rnberg and visiting scientist at UPC Barcelona focused on wavelet transform and image compression research. His current research interests include algorithms and programmable architectures for baseband signal processing.\n\nMartti Forsell\n\nMartti Forsell received M.Sc., Ph.Lic., and Ph.D. degrees in computer science from University of Joensuu, Finland in 1991, 1994, and 1997, respectively. He has acted as a lecturer, researcher, and acting professor in the Department of Computer Science, University of Joensuu. Currently he is a Chief Research Scientist at VTT, Oulu, Finland, as well as an Adjunct Professor in the Department of Electrical and Information Engineering at the University of Oulu. Dr. Forsell has a long background in parallel and sequential computer architecture and parallel computing research. He is the inventor of the first scalable high-performance CMP architecture armed with an easy-to-use general-purpose parallel application development scheme (consisting of a computational model, programming language, experimental optimizing compiler, and simulation tools) exploiting the PRAM-model, as well as a number of other TLP and ILP architectures for general purpose computing and digital signal processing, architectural techniques and development methodologies and tools. He is a co-organizer of the Highly Parallel Processing on a Chip (HPPC) workshop series. His current research interests are processor and computer architectures, chip multiprocessors, multiprocessor systems-on-chip, networks on chip, models of parallel computing, functionality mapping techniques, parallel languages, compilers, simulators, and performance, silicon area and power consumption modeling. He has published 75 scientific publications and participated to various research and development projects in cooperation with academia and industry.\n\nRudy Lauwereins\n\nRudy Lauwereins is vice president of imec, which performs world-leading research and delivers industry-relevant technology solutions through global partnerships in nano-electronics, ICT, healthcare and energy. He is responsible for imec's Smart Systems Technology Office, covering energy efficient green radios, vision systems, (bio)medical and lifestyle electronics as well as wireless autonomous transducer systems and large area organic electronics. He is also a part-time Full Professor at the Katholieke Universiteit Leuven, Belgium, where he teaches Computer Architectures in the Master of Science in Electrotechnical Engineering program, and a director of the Institute\n\nfor BroadBand Technologies (IBBT). Before joining imec in 2001, he held a tenure Professorship in the Faculty of Engineering at the Katholieke Universiteit Leuven since 1993. He had obtained a Ph.D. in Electrical Engineering in 1989. Rudy Lauwereins served in numerous international program committees and organizational committees, and gave many invited and keynote speeches. He was the general chair of the DATE conference (Design, design Automation and Test in Europe) in 2007. He is a senior member of the IEEE. Professor Lauwereins has authored and co-authored more than 350 publications in international journals, books and conference proceedings.\n\nKees van Berkel\n\nKees van Berkel:\n\nâ¢ received an M.Sc. degree (cum laude) in EE from the Delft University of Technology in 1980 and a PhD degree in CS from the Eindhoven University of Technology (TU/e, 1992);\n\nâ¢ is fellow at ST-Ericsson; previously fellow at Philips Research, NXP Research, and ST-NXP Wireless;\n\nâ¢ is a part-time professor in Computing Science at the TU/e since 1996;\n\nâ¢ published about 50 papers, about 25 patent (applications);\n\nâ¢ pioneered asynchronous VLSI during the 90âs, published a book on Handshake Circuits, and contributed to their industrial application;\n\nâ¢ co-architected the EVP, a vector DSP for modem and SDR applications, currently in production\n\nâ¢ currently researches software defined radio, digital wireless communication, multi-core architectures, vector processors, and low power.\n\nTuomas Jarvinen\n\nTuomas Jarvinen completed his M.Sc. and Dr. Tech. degrees year 2000 and 2004 from Tampere University of Technology, Finland. His research involved digital signal processing algoritms and their systematic computation structures. The results have been publiced in several international conference and journal articles. At the beginning of year 2006 he joined Nokia Technology Platforms where he worked in various roles in digital SoC design projects. Since 2008 he has been working in ST Microelectronics and ST-Ericsson designing e.g. U8500 platform. Currently he work as a SoC architect concentrating on power analysis and optimization.\n\nSri Parameswaran\n\nSri Parameswaran is a Professor in the School of Computer Science and Engineering at the University of New South Wales. He also serves as the Program Director for Computer Engineering. His research interests are in System Level Synthesis, Low power systems, High Level Systems and Network on Chips. He serves on the editorial boards of ACM Transactions on Embedded Computing Systems, the Eurasip Journal on Embedded Systems and the Design Automation of Embedded Systems. He has served on the Program Committees of Design Automation Conference (DAC), Design and Test in Europe (DATE), the International Conference on Computer Aided Design (ICCAD), the International Conference on Hardware/Software Codesign and System Synthesis (CODES-ISSS), and the International Conference on Compilers, Architectures and Synthesis for Embedded Systems (CASES).\n\nChong-Min Kyung\n\nChong-Min Kyung received B.S. in EE from Seoul National University in 1975, M.S. and Ph.D. in EE from KAIST in 1977 and 1981, respectively. From 1981 to 1982, he worked at Bell Telephone Laboratories, Murray Hill. Since he joined KAIST in 1983, he has been working on CAD algorithms, 3-D graphics, and System-on-a-Chip design and verification methodology, development of various RISC/CISC microprocessors, VLIW and reconfigurable DSP cores. His current research includes system-level low-power design, electrical/thermal co-design in 3D IC, architectures of H.264 video CODEC and rate-distortion-power optimization. He is founding Director of the IDEC(Integrated Circuit Design Education Center) since 1995, Director of SoCium, and President of Sharing and Technologies, Inc. He served as General Chair in the Korean Semiconductor Conference 2002, ISOCC 2004, A-SSCC 2007, and ASP_DAC 2008. He received the Most Excellent Design Award, and Special Feature Award in the University Design Contest in the ASP-DAC 1997 and 1998, respectively. He received the Best Paper Awards in the 36th DAC held in New Orleans, LA, the 10th ICSPAT, Orlando, FL, in September 1999, and the 1999 ICCD Austin, TX. In 2000, he received National Medal from Korean government for his contribution to research and education in IC design. He is a member of National Academy of Engineering Korea, and Korean Academy of Science and Technology. He is IEEE fellow and Hynix Chair Professor at KAIST.\n\nGuy Bois\n\nGuy Bois is professor at the Department of Computer and Software Engineering of Ãcole Polytechnique de MontrÃ©al. His research interests include Electronic System Level (ESL), more precisely virtual platforms, architectural exploration, cosynthesis and functional verification. He is also cofounder of Space Codesign Systems Inc. Dr. Bois received his bachelor and PhD degrees in computer science from the University of Montreal. He is also engineer.\n\nEl Mostapha Aboulhamid\n\nEl Mostapha Aboulhamid is active in modeling, synthesis and verification in hardware systems. He obtained an Engineering degree from ENSIMAG, France in 1974 and a Ph.D. from Montreal University in 1984. He is currently professor at Universite de Montreal. His current interests are in system level modeling, formal verification techniques at higher level and formal refinement of hardware/software systems.\n\nGabriela Nicolescu\n\nJan Madsen\n\nJan Madsen is Professor in computer-based systems at DTU Informatics at the Technical University of Denmark (2002- ), where he is currently heading the section on Embedded Systems Engineering. He is the leader of the Hardware Platforms and Multiprocessor System-on-Chip Cluster within the EU/IST Network of Excellence ArtistDesign and member of the Strategic Management Board of ArtistDesign. He is senior member of IEEE and is currently serving as Vice Chair of IEEE Denmark Section.\n\nHis research interests are related to design of embedded computer systems. In particular system-level modeling and analysis of multiprocessor systems, including RTOS modeling and hardware/software codesign. He is generally interested in design methodologies (including CAD tools) and implementations of embedded systems, covering areas of wireless sensor networks and biochips. He has published more than 100 publications in international journals and conferences as well as co-authored 9 book chapters and 4 edited books. Jan Madsen is the lead delegate for Denmark in the Governing Board of the ARTEMIS Joint Undertaking, a new pan-European research initiative for\n\npublic-private partnership in Embedded Systems. He is on the steering committee of InfinIT, a national innovation network on ICT, where he is coordinating the strategic focus area on Embedded Systems. He is site leader in SYSMODEL (funded by ARTEMIS JU) and activity leader of Execution Platforms and Chairman of the Steering Board of DaNES (funded by the Danish Advanced Technology Foundation). He is serving on the panel of Computer Science in the Swedish National Research Council in 2007 and 2009. He is Program Chair of CODES+ISSSÂ¹11 and has been Program Chair of DATEÂ¹07 and CODESÂ¹00, and General Chair of CODESÂ¹01. He is member of the steering committee of the CODES+ISSS (ESWEEK). He is or has served on many program committees, including SIES, ARC, NOCS, LCTES, DAC, CODES+ISSS, ISSS, CODES, RTSS, DATE, and PARC.\n\nRaphaÃ«l David\n\nRaphaÃ«l David is in charge of the Multi-core architectures design team at the CEA LIST. He received his Ph.D. degree in computer engineering for having designed the DART reconfigurable processor, from the University of Rennes I, France, in 2003. He has joined the CEA LIST in a post-doctoral position to study reconfigurable architectures benefits to reduce power consumption of embedded systems. Since 2004 he has proposed dynamic execution models for programmable and reconfigurable multi- and many-cores systems to support variable execution conditions, either coming from technology or data-dependant applications. He is now in charge of the MPSOC design team in the Embedded Computing Lab of the CEA LIST and explores the architectures design space to support such advanced execution models. He is also involved in the implementation of dynamically reconfigurable processors for image processing and low power design.\n\nAhmed Jerraya\n\nDr. Ahmed Jerraya is Director of Strategic Design Programs at CEA/LETI France. He served as General Chair for the Conference DATE in 2001, Co-founded MPSoC Forum (Multiprocessor system on chip) and served as the organization chair of ESWEEK2009. He supervised 51 PhD, co-authored 8 Books and published more than 250 papers in International Conferences and Journals.\n\nFrÃ©dÃ©ric PÃ©trot\n\nFrÃ©dÃ©ric PÃ©trot received the PhD degree in Computer Science from UniversitÃ© Pierre et Marie Curie (Paris VI), Paris, France, in 1994, where has been Assistant Professor in Computer Science until September 2004. From 1989 to 1996, F. PÃ©trot was one of the main contributors of the open source Alliance VLSI CAD system whose working team received the French Seymour Cray award in 1994. Since 1996, he headed the work on the definition and implementation of the Disydent environment, oriented toward the\n\nspecification and implementation of multiprocessor SoCs. He joined TIMA in September 2004, and holds a professer position at the Ensimag, Institut Polytechique de Grenoble, France. Since 2007, he heads the System Level Synthesis group of TIMA, where his main focus is the architectural enhancement of MPSoCs and their programming.\n\nMarcello Coppola\n\nMarcello Coppola received the Master degree in Computer Science from Pisa University, in 1992. Previously, he was with the Transputer architecture group at INMOS (UK) working on the architecture of the C104 router. He is now an R&D Director of STMicroelectronics. He introduced the NoC at ST and ST Ericsson and he is responsible of Spidergon STNoC program; managing architecture, design, prototyping and modeling teams. Moreover, he is coordinating several world-wide university and European research programs. His research interests include design methodologies for system-on-chip, with particular emphasis to network-on-chip, multicore and many-core architectures, parallel programming and system level design. He has published several research articles in various books and journals. He was a member of the OSCI language working group contributing towards SystemC2.0 definition and OSCI standardization. He was an early introduced of SystemC in ST.\n\nOmar Hammami\n\nOmar Hammami is a Professor at ENSTA/DGA since 2000. Prior to that he was Assistant Professor from 1991 to 1993 with ENSEEIH, Toulouse, and Associate Professor with the University of Aizu, Japan, from 1993 to 2000. He received his Ph.D. degree in computer science and electrical engineering from Paul Sabatier University, Toulouse and has since worked in the field of circuits, system level design methodologies, embedded parallel architectures, and system on chip (SOC) for multimedia and wireless communications. His current interest is in complex systems design and systems engineering. He has been involved in numerous international and national research and industrial projects in those areas, and has been funded by various government and funding agencies. He is a regular reviewer for various journals (IEEE, EURASIP, etc.) and conferences as Program Committee Member.\n\nNorbert Wehn\n\nNorbert holds the chair for Microlectronic System Design in the department of Electrical Engineering and Information Technology at the University of Kaiserslautern. He has more than 200 publications in various fields of microelectronic system design and holds several patents. He is chairman of the European Design Automation Association, Chairman of the Research Center âAmbient Systemsâ at TU Kaiserslautern, associate editor of various journals and member of several scientific advisory boards. In 2003 he served as program chair for DATE 2003 and as general chair for DATE 2005 respectively. His special research interests are VLSI-architectures for mobile communication, forward error correction techniques, low-power, advanced SoC architectures and reliability issues in SoC.\n\nRolf Ernst\n\nRolf Ernst received a diploma in CS and a Dr.-Ing. in EE from the University of Erlangen-Nuremberg, Germany, in 81 and 87. From 88 to 89, he was with Bell Laboratories, Allentown, PA. Since 90, he has been a professor of electrical engineering at the Technische UniversitÃ¤t Braunschweig, Germany, where he chairs a university institute of 65 researchers and staff. He was Head of the Department of Electrical Engineering from 1999 to 2001. His research activities include embedded system design and design automation. The activities are currently supported by the German \"Deutsche Forschungsgemeinschaft\" (corresponds to the NSF), by the German BMBF, by the European Union, and by industrial contracts, such as from Intel, Thomson, EADS, Ford, Bosch, and Volkswagen. He gave numerous invited presentations and tutorials at major international events and contributed to seminars and summer schools in the areas of hardware/software co-design, embedded system architectures, system modeling and verification. He is an IEEE Fellow and served as an ACM-SIGDA Distinguished Lecturer. He is a member of the German Academy of Science and Engineering, acatech.\n\nUlrich Ramacher\n\nLars Bauer\n\nLars Bauer received his MSc (Dipl.-Inform.) and PhD (Dr.-Ing.) in Computer Sciences from the University of Karlsruhe, Germany in 2004 and 2009 respectively. His main research interests are extensible processors and reconfigurable computing systems with a focus on dynamically varying run-time situations and concepts that allow systems to adapt to changing requirements. He received the DATE'08 best paper award and a HiPEAC paper award (for DAC'08 paper) for his work on adaptive reconfigurable\n\nprocessors. He is currently working as a PostDoc at the Chair for Embedded Systems (CES) at the Karlsruhe Institute of Technology (KIT).\n\nBenjamin Carrion Schafer\n\nBenjamin Carrion Schafer received the B.Eng. degree in electrical engineering from the Polytechnic University of Madrid, Madrid, Spain, the M.Sc. degree in microelectronics from Birmingham City University, Birmingham, U.K., and FH-Darmstadt, Darmstadt, Germany. After completing his Ph.D. at the University of Birmingham, he was a Postdoctoral Researcher with the Computer Science Department, University of California Los Angeles (UCLA), from 2003 to 2004.He was a Visiting Researcher at Seoul National University, Seoul, Korea, from 2005 to 2007 at the School of Electrical Engineering and Computer Science. Currently, he works as an Assistant Manager at NEC Corporation's R&D Central Laboratories, EDA Center, Kawasaki, Japan. He served on the TPC of CASES 2006, as a committee member at the RECONFIG conference and currently seves as TPC at DAC's user track.\n\nTsuyoshi Isshiki\n\nTsuyoshi Isshiki has received B.E. and M.E. degrees from Tokyo Institute of Technology in 1990 and 1992, respectively, and received PhD in Computer Engineering from University of California at Santa Cruz in 1996. He is currently an Associate Professor at Tokyo Institute of Technology, Dept. of Communications and Integrated Systems. His research interests include multimedia SoC designs, Multiprocessor SoC design methodology and its design tools.\n\nKoichiro Yamashita\n\nKoichiro YAMASHITA has received the M.E. degrees in computer science from Waseda University, and joined Fujitsu LTD in 1995. He had worked for parallel operating system on the vector-parallel super computing system (VPP series) for 5 years, and moved to electric device group (EDG) of Fujitsu LTD in 2001. In 2006, he moved to Fujitsu Laboratories. In 2009, he works as manager of mobile phone BU of Fujitsu LTD and senior researcher of platform technology labs of Fujitsu Laboratories concurrently. In 2009, he assumed the position of the chairman of SMP Working Group of Symbian Foundation.\n\nSungjoo Yoo\n\nDr. Sungjoo Yoo received B.S., M.S., and Ph.D. at Seoul National University, Korea, in 1992, 1995, and 2000, respectively. He worked at TIMA laboratory, Grenoble, France from 2000 to 2004 and worked as principal engineer at System LSI Division, Samsung Electronics from 2004 to 2008. He joined POSTECH (Pohang university of science and technology) in August 2008. His current research interests include memory hierarchy and network-on-chip for many-core SoC, low power design based on runtime-distribution and temperature-aware DVFS, and power efficiency/performance/reliability improvement of solid state disk.\n\nKiyoung Choi\n\nKiyoung Choi is a professor of the Department of Electrical Engineering and Computer Science, Seoul National University. He received B.S. degree in electronics engineering from Seoul National University in 1978 and M.S. degree in electrical and electronics engineering from KAIST in 1980. He received Ph.D. degree in electrical engineering from Stanford University in 1989. He worked for Cadence Design Systems from 1989 to 1991. His research interests are in computer architecture, embedded systems design, low power design, and design automation.\n\nSoo-lk Chae\n\nPh. D. Electrical Engineering from Stanford University, Stanford, California, in 1987 âDefect Detection and Classification for VLSI Pattern Inspectionâ, M. S. Electrical engineering from Seoul National University, Seoul, Korea, in 1978, B. S. Electrical engineering from Seoul National University, Seoul, Korea, in 1976.\n\nKees Goossens\n\nKees Goossens received his PhD from the University of Edinburgh in 1993 on hardware verification using embeddings of formal semantics of hardware description languages in proof systems. He worked for Philips/NXP Research from 1995 to 2010 on networks on chip for consumer electronics, where real-time performance and low cost are major constraints. He was part-time full professor at the Delft university of technology from 2007 to 2010, and is currently full professor at the Eindhoven university of technology, where his research focusses on composable (virtualised), predictable (real-time), low-power embedded systems.\n\nPieter van der Wolf\n\nPieter van der Wolf is a Senior Principal Scientist at Virage Logic since November 2009. Previously he was a Senior Principal Scientist and Technology Competence Manager at NXP Semiconductors, which was spun out of Philips Electronics in 2006. Before that Pieter worked for 10 years at Philips Research. He received his MSc and PhD degrees in Electrical Engineering from Delft University of Technology. His main interests are SoC architectures and SoC design methodologies.\n\nDavid Atienza\n\nDavid Atienza received his MSc and PhD degrees in Computer Science from Complutense University of Madrid (UCM), Spain, and Inter-University Micro-Electronics Center (IMEC), Belgium, in 2001 and 2005, respectively. Currently, he is Professor and Director of the Embedded Systems Laboratory (ESL) at EPFL, Switzerland, and Adjunct Professor at the Computer Architecture and Automation Department of UCM. Additionally, he is Scientific Counselor of long-time research of IMEC Nederland (IMEC-NL), Holst Centre, Eindhoven, The Netherlands. His research interests focus on design methodologies for high-performance embedded systems and Systems-on-Chip (SoC), including new thermal management techniques for 2D/3D Multi-Processor SoCs, dynamic memory management and memory hierarchy optimizations for embedded systems, novel architectures for logic and memories in forthcoming nano-scale electronics and 3D integrated circuits, as well as Networks-on-Chip design. In these fields, he is co-author of more than 100 publications in prestigious journals and international conferences. He has received a Best Paper Award at the IEEE/IFIP VLSI-SoC 2009 Conference and two Best Paper Award Nominations at the ICCAD 2006 and DAC 2005 conferences. He is an Associate Editor of IEEE Transactions on CAD (in the area of System-Level Design), IEEE Letters on Embedded Systems and Elsevier Integration: The VLSI Journal. He is also an elected member of the Executive Committee of the IEEE Council of Electronic Design Automation (CEDA) since 2008 and an elected member of the Board of Governors of the IEEE Circuits and Systems Society (CASS) since 2010.\n\nJenq-Kuen Lee\n\nJenq Kuen Lee received the B.S. degree in computer science from National Taiwan University in 1984. He received a Ph.D. in computer science from Indiana University in 1992, where he also received a M.S. (1991) in computer science. He is now a professor in the Department of Computer Science at National Tsing-Hua University, Taiwan, where he joined the department in 1992. He has also been a director for MOE ESW (embedded system software) consortium, Taiwan since 2008. He was a key member of the team who developed the first version of the pC++ language and SIGMA system while at Indiana University. He was also a recipient of the most original paper award in ICPP '97 with the paper entitled \"Data Distribution Analysis and Optimization for Pointer-Based Distributed Programs\". In 2005, he led a MOEA research team to develop compilers for PAC VLIW DSP processors with distributed register files. In addition, his research team won the design contest awards (golden award) in the embedded system software track of Taiwan MOE ESW design contest both in 2007 and 2008. He is also a recipient of Google Research Award 2009. His research interests are in optimizing compilers, compilers for low-power, embedded compilers, and middleware designs for embedded multi-core systems.\n\nJohn Goodacre\n\nJohn joined ARM in February 2002 and took responsibility for their platform architecture. Today he has responsibility for the application processorâs technology roadmap including the definition and market development of the ARM MPCore multicore processor technology now realized in both the ARM11 MPCore and the Cortex-A9 MPCore. Prior to working at ARM, he specialized in enterprise software having worked for Microsoft for 5 years, firstly as Group Program Manager in the Exchange Server group and latterly as the manager of a team developing mobile phones software. Graduating from the University of York with a BSc in Computer Science, John has over 20 years experience of realizing new technologies in the engineering industry.\n\nChris Rowen\n\nDr. Chris Rowen is the founder, chief technical officer, and a member of the board of directors of Tensilica, Inc. He founded Tensilica in July 1997 to develop automatic generation of application-specific microprocessors for high-volume communication and consumer systems. He was a pioneer in the development of RISC architecture at Stanford in the early 1980s and helped start MIPS Computer Systems Inc. in 1984, where he serves in a variety of functions including as vice president for microprocessor development and as the manager for MIPS' European operations. When Silicon Graphics purchased MIPS, he became the technology and market development leader for Silicon Graphics Europe. In 1996, he was hired by Synopsys to be vice president and general manager of the Design Reuse Group. This experience helped him realize the limitations of current microprocessors for embedded design, which led him to the founding of Tensilica. He received a B.A. in physics from Harvard University and M.S. and Ph.D. in electrical engineering from Stanford University. He is well known as a speaker on complex technology and business issues, has authored the book, \"Engineering the Complex SOC\" (published by Prentice Hall in 2004) and numerous technical articles and conference papers, and he holds over two dozen US and international patents.\n\nYuan Xie\n\nYuan Xie is Associate Professor in Computer Science and Engineering department at the Pennsylvania State University. He received Ph.D. degrees from Princeton University. Before joining Penn State, he was with IBM Microelectronic Division. he has published 120+ journal papers and conference papers in the area of EDA, Architecture and VLSI circuit designs. He was a recipient of the SRC Inventor Recognition Award in 2002, He was a recipient of NSF CAREER award in 2006, IBM Faculty Award in 2008. He also received a few Best Paper Award and Best Paper Award Nominations in a few prestigious conferences. He is currently Associate Editor of IEEE TVLSI, IEEE TCAD, IEEE Design & Test of Computers, ACM Journal of Emerging Technologies, and IET Computers and Digital Techniques. He is also ACM Distinguished Speaker.\n\nK. Charles Janac\n\nK. Charles Janac is the Chairman, President and Chief Executive Officer of Arteris Holdings. Arteris has pioneered the market for Network on Chip (NoC) interconnect IP and Tools for on-chip communications in complex semiconductor chips. The Company has facilities in San Jose, California and Paris, France. Charlie has over 20 years experience building technology companies. He started hi"
    }
}