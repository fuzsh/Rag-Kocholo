{
    "id": "dbpedia_6397_3",
    "rank": 49,
    "data": {
        "url": "https://github.com/uzh-rpg/event-based_vision_resources",
        "read_more_link": "",
        "language": "en",
        "title": "based_vision_resources",
        "top_image": "https://opengraph.githubassets.com/0ca7cdbffa0de2dc09c8c1eed7375db350dbfa8ecd5da42401730cad3658379d/uzh-rpg/event-based_vision_resources",
        "meta_img": "https://opengraph.githubassets.com/0ca7cdbffa0de2dc09c8c1eed7375db350dbfa8ecd5da42401730cad3658379d/uzh-rpg/event-based_vision_resources",
        "images": [
            "https://avatars.githubusercontent.com/u/8024432?s=64&v=4",
            "https://avatars.githubusercontent.com/u/34153640?s=64&v=4",
            "https://avatars.githubusercontent.com/u/10061874?s=64&v=4",
            "https://avatars.githubusercontent.com/u/56065023?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5257730?s=64&v=4",
            "https://avatars.githubusercontent.com/u/5856176?s=64&v=4",
            "https://avatars.githubusercontent.com/u/19912588?s=64&v=4",
            "https://avatars.githubusercontent.com/u/26314241?s=64&v=4",
            "https://avatars.githubusercontent.com/u/8776810?s=64&v=4",
            "https://avatars.githubusercontent.com/u/583229?s=64&v=4",
            "https://avatars.githubusercontent.com/u/6841681?s=64&v=4",
            "https://avatars.githubusercontent.com/u/11943350?s=64&v=4",
            "https://avatars.githubusercontent.com/u/45338857?s=64&v=4",
            "https://avatars.githubusercontent.com/u/31000629?s=64&v=4"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [
            "uzh-rpg"
        ],
        "publish_date": null,
        "summary": "",
        "meta_description": "Contribute to uzh-rpg/event-based_vision_resources development by creating an account on GitHub.",
        "meta_lang": "en",
        "meta_favicon": "https://github.com/fluidicon.png",
        "meta_site_name": "GitHub",
        "canonical_link": "https://github.com/uzh-rpg/event-based_vision_resources",
        "text": "Survey paper\n\nWorkshops\n\nDevices and Manufacturers\n\nCompanies working on Event-based Vision\n\nNeuromorphic Systems\n\nReview papers\n\nBio-inspiration\n\nAlgorithms, Applications\n\nApplications / Algorithms\n\nFeature Detection and Tracking\n\nCorners\n\nParticles in fluids\n\nEye Tracking\n\nOptical Flow Estimation\n\nScene Flow Estimation\n\nReconstruction of Visual Information\n\nIntensity-Image Reconstruction\n\nVideo Synthesis\n\nImage super-resolution\n\nJoint/guided filtering\n\nTone mapping\n\nVisual Stabilization\n\nPolarization Reconstruction\n\nDepth Estimation (3D Reconstruction)\n\nMonocular\n\nStereo\n\nStereoscopic panoramic imaging\n\nSLAM (Simultaneous Localization And Mapping)\n\nLocalization, Ego-motion estimation\n\nVisual Odometry\n\nVisual-Inertial Odometry\n\nSegmentation\n\nObject Segmentation\n\nMotion Segmentation\n\nPattern recognition\n\nObject Recognition\n\nGesture Recognition\n\nRepresentation / Feature Extraction\n\nRegression Tasks\n\nLearning Methods / Frameworks\n\nSignal Processing\n\nEvent Denoising\n\nCompression\n\nControl\n\nObstacle Avoidance\n\nSpace Applications\n\nTactile Sensing Applications\n\nObject Pose Estimation\n\nHuman Pose Estimation\n\nHand Pose Estimation\n\nIndoor Lighting Estimation\n\nData Encryption\n\nNuclear Verification\n\nOptical Communication\n\nAnimal Behavior Monitoring\n\nOptical Applications\n\nAuto-focus\n\nSpeckle Analysis\n\nInterferometry or Holography\n\nWavefront sensing\n\nOptical super-resolution\n\nSchlieren imaging\n\nDriver Monitoring System\n\nMulti-tasking networks: Face, Head Pose & Eye Gaze estimation\n\nDrowsiness or Yawn\n\nDistraction\n\nFace Alignment and Landmark Detection\n\nVisual Voice Activity Detection\n\nSimulators and Emulators\n\nDatasets\n\nSoftware\n\nDrivers\n\nSynchronization\n\nLens Calibration\n\nAlgorithms\n\nUtilities\n\nNeuromorphic Processors and Platforms\n\nCourses\n\nTheses and Dissertations\n\nDissertations\n\nMaster's Theses\n\nPeople / Organizations\n\nEETimes articles\n\nContributing\n\nGallego, G., Delbruck, T., Orchard, G., Bartolozzi, C., Taba, B., Censi, A., Leutenegger, S., Davison, A., Conradt, J., Daniilidis, K., Scaramuzza, D.,\n\nEvent-based Vision: A Survey,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 44(1):154-180, Jan. 2022.\n\nCVPR 2023 Fourth International Workshop on Event-based Vision, Videos\n\nIEEE Embedded Vision Workshop Series, with focus on Biologically-inspired vision and embedded systems.\n\nIISW 2023 Int. Image Sensor Workshop\n\nMFI 2022 First Neuromorphic Event Sensor Fusion Workshop with videos incl. Event Sensor Fusion Jeopardy game - Virtual. Videos\n\ntinyML Neuromorphic Engineering Forum - Virtual, 2022. Videos\n\nCVPR 2021 Third International Workshop on Event-based Vision - Virtual. Videos\n\nICRA 2020 Workshop on Unconventional Sensors in Robotics - Virtual. Videos\n\nNeuro-Inspired Computational Elements (NICE) Workshop Series. Videos\n\nCapo Caccia Workshops toward Cognitive Neuromorphic Engineering.\n\nThe Telluride Neuromorphic Cognition Engineering Workshops. Videos, Telluride 2020 (Online): Videos, Slides\n\nCVPR 2019 Second International Workshop on Event-based Vision and Smart Cameras. Videos\n\nIROS 2018 Unconventional Sensing and Processing for Robotic Visual Perception.\n\nICRA 2017 First International Workshop on Event-based Vision. Videos\n\nIROS 2015 Event-Based Vision for High-Speed Robotics (slides), Workshop on Alternative Sensing for Robot Perception.\n\nICRA 2015 Workshop on Innovative Sensing for Robotics, with a focus on Neuromorphic Sensors.\n\nDVS (Dynamic Vision Sensor): Lichtsteiner, P., Posch, C., and Delbruck, T., A 128x128 120dB 15μs latency asynchronous temporal contrast vision sensor, IEEE J. Solid-State Circuits, 43(2):566-576, 2008. PDF\n\nProduct page at iniVation. Buy a DVS\n\nProduct specifications\n\nUser guide\n\nIntroductory videos about the DVS technology\n\niniVation AG invents, produces and sells neuromorphic technologies with a special focus on event-based vision into business. Slides by S. E. Jakobsen, board member of iniVation.\n\nEvent Cameras - Tutorial - Tobi Delbruck, version 4\n\nSamsung's DVS\n\nSlides and Video by Hyunsurk Eric Ryu, Samsung Electronics (2019).\n\nSuh et al., A 1280×960 Dynamic Vision Sensor with a 4.95-μm Pixel Pitch and Motion Artifact Minimization, IEEE Int. Symp. Circuits and Systems (ISCAS), 2020.\n\nSon, B., et al., A 640×480 dynamic vision sensor with a 9µm pixel and 300Meps address-event representation, IEEE Int. Solid-State Circuits Conf. (ISSCC), 2017, pp. 66-67.\n\nSmartThings Vision commercial product for home monitoring. in Australia\n\nPaper at IEDM 2019, about low-latency applications using Samsung's VGA DVS.\n\nHVS (Hybrid Vision Sensors) like ATIS, DAVIS, CDAVIS, and other HVS that output brightness change events and intensity frames, either mono or color\n\nATIS (Asynchronous Time-based Image Sensor), Posch et al. JSSC 2011, A QVGA 143 dB Dynamic Range Frame-Free PWM Image Sensor With Lossless Pixel-Level Video Compression and Time-Domain CDS.\n\nDAVIS (Dynamic and Active Pixel Vision Sensor): Brandli, C., Berner, R., Yang, M., Liu, S.-C., Delbruck, T., A 240x180 130 dB 3 µs Latency Global Shutter Spatiotemporal Vision Sensor, IEEE J. Solid-State Circuits, 49(10):2333-2341, 2014. PDF\n\nProduct page at iniVation. Buy a DAVIS\n\nProduct specifications\n\nUser guide\n\nDAVIS346: Taverni, G; Paul Moeys, D; Li, C; Cavaco, C; Motsnyi, V; San Segundo Bello, D; Delbruck, T., Front and Back Illuminated Dynamic and Active Pixel Vision Sensors Comparison, IEEE Trans. Circuits Syst. Express Briefs, 2018\n\nCDAVIS HVS: Li, C., Brandli, C., Berner, R., Liu, H., Yang, M., Liu, S.-C., Delbruck, T., An RGBW color VGA rolling and global shutter dynamic and active-pixel vision sensor, Int. Image Sensors Worskhop, 2015.\n\nPrototype only\n\nSDAVIS192: Moeys, D. P., Corradi, F., Li, C., Bamford, S. A., Longinotti, L., Voigt, F. F., Berry, S., Taverni, G., Helmchen, F., Delbruck, T., A Sensitive Dynamic and Active Pixel Vision Sensor for Color or Neural Imaging Applications, IEEE Trans. Biomed. Circuits Syst. 12(1):123-136 2018.\n\nPrototype only\n\nOmnivision HVS: Guo et al, A 3-Wafer-Stacked Hybrid 15MPixel CIS + 1 MPixel EVS with 4.6GEvent/s Readout, In-Pixel TDC and On-Chip ISP and ESP Function, ISSCC, (2023).\n\nPrototype, commercially n.a.\n\nSony HVS: Kodama et al., 1.22μm 35.6Mpixel RGB Hybrid Event-Based Vision Sensor with 4.88μm-Pitch Event Pixels and up to 10K Event Frame Rate by Adaptive Control on Event Sparsity, ISSCC (2023)\n\nPrototype only, commercially n.a.\n\nInsightness's Silicon Eye QVGA event sensor.\n\nThe Silicon Eye Technology\n\nSlides and Video by Stefan Isler (2019).\n\nSlides and Video by Christian Brandli, CEO and co-founder of Insightness (2017).\n\nPROPHESEE’s Metavision Sensor and Software\n\nATIS (Asynchronous Time-based Image Sensor): Posch, C., Matolin, D., Wohlgenannt, R. (2011). A QVGA 143 dB Dynamic Range Frame-Free PWM Image Sensor With Lossless Pixel-Level Video Compression and Time-Domain CDS, IEEE J. Solid-State Circuits, 46(1):259-275, 2011. PDF, YouTube, YouTube\n\nProphesee Gen4 is described in: Finateu et al., A 1280×720 Back-Illuminated Stacked Temporal Contrast Event-Based Vision Sensor with 4.86μm Pixels, 1.066GEPS Readout, Programmable Event-Rate Controller and Compressive Data-Formatting Pipeline, IEEE Int. Solid-State Circuits Conf. (ISSCC), 2020, pp. 112-114.\n\nBuy a Prophesee packaged sensor VGA\n\nProphesee Cameras Specifications\n\nWhat is event-based vision and sample applications, YouTube\n\nDownload free or buy Metavision software\n\nDocumentation and tutorials\n\nKnowledge Base and Community Forum\n\nSONY's explanation of Event-based Vision Sensor (EVS) Technolgy\n\nCelePixel, Shanghai. CeleX-V: the first 1 Mega-pixel event-camera sensor.\n\nSensitive DVS (sDVS)\n\nAll are prototypes, commerically n.a.\n\nLeñero-Bardallo, J. A., Serrano-Gotarredona, T., Linares-Barranco, B., A 3.6us Asynchronous Frame-Free Event-Driven Dynamic-Vision-Sensor, IEEE J. of Solid-State Circuits, 46(6):1443-1455, 2011.\n\nSerrano-Gotarredona, T. and Linares-Barranco, B., A 128x128 1.5% Contrast Sensitivity 0.9% FPN 3us Latency 4mW Asynchronous Frame-Free Dynamic Vision Sensor Using Transimpedance Amplifiers, IEEE J. Solid-State Circuits, 48(3):827-838, 2013.\n\nSDAVIS192: Moeys, D. P., Corradi, F., Li, C., Bamford, S. A., Longinotti, L., Voigt, F. F., Berry, S., Taverni, G., Helmchen, F., Delbruck, T., A Sensitive Dynamic and Active Pixel Vision Sensor for Color or Neural Imaging Applications, IEEE Trans. Biomed. Circuits Syst. 12(1):123-136 2018.\n\nDLS (Dynamic Line Sensor): Posch, C., Hofstaetter, M., Matolin, D., Vanstraelen, G., Schoen, P., Donath, N., and Litzenberger, M., A dual-line optical transient sensor with on-chip precision time-stamp generation, IEEE Int. Solid-State Circuits Conf. - Digest of Technical Papers, Lisbon Falls, MN, US, 2007.\n\nFact sheet at AIT.\n\nLWIR DVS: Posch, C., Matolin, D., Wohlgenannt, R., Maier, T., Litzenberger, M., A Microbolometer Asynchronous Dynamic Vision Sensor for LWIR, IEEE Sensors Journal, 9(6):654-664, 2009.\n\nPrototype, commercially n.a.\n\nSmart DVS (GAEP): Posch, C., Hoffstaetter, M., Schoen, P., A SPARC-compatible general purpose Address-Event processor with 20-bit 10ns-resolution asynchronous sensor data interface in 0.18um CMOS, IEEE Int. Symp. Circuits and Systems (ISCAS), 2010.\n\nPrototype, commercially n.a.\n\nPDAVIS (Polarization Event Camera):\n\nPrototype, commercially n.a.\n\nBio-inspired Polarization Event Camera, arXiv [cs.CV] (2021) PDAVIS video.\n\nPDAVIS: Bio-inspired Polarization Event Camera. CVPR-W Proceedings (2023)\n\nCenter Surround Event Camera (CSDVS): Delbruck, T., Li, C., Graca, R. & Mcreynolds, B.,\n\nUtility and Feasibility of a Center Surround Event Camera\n\narXiv [cs.CV] (2022) CSDVS videos\n\nProposed architecture.\n\niniVation AG invents, produces and sells neuromorphic vision sensors (DAVIS, DVExplorer, and others), with a focus on event-based vision for business; supplies the advanced DV event camera software.\n\niniLabs AG invents neuromorphic technologies for research.\n\nSamsung develops Gen2 and Gen3 dynamic vision sensors and event-based vision solutions.\n\nIBM Research (Synapse project) and Samsung partenered to combine the TrueNorth chip (brain) with a DVS (eye).\n\nProphesee (Formerly Chronocam) is the inventor and supplier of 4 Event-Based sensors generations, including commercial-grade versions as well as industry’s largest software suite. The company focuses on Industrial, Mobile-IoT and Automotive applications.\n\nInsightness AG built visual systems to give mobile devices spatial awareness. The Silicon Eye Technology. Aquired by Sony in 2019 and part of Sony Advanced Imager Sensors division.\n\nSLAMcore develops Localisation and mapping solutions for AR/VR, robotics & autonomous vehicles.\n\nCelePixel (formerly Hillhouse Technology) offer integrated sensory platforms that incorporate various components and technologies, including a processing chipset and an image sensor (a dynamic vision sensor called CeleX).\n\nAIT Austrian Institute of Technology sells neuromorphic sensor products.\n\nInspection during production of carton packs\n\nUCOS Universal Counting Sensor\n\nIVS Industrial Vision Sensor\n\nSerrano-Gotarredona, T. , Andreou, A.G. , Linares-Barranco, B.,\n\nAER Image Filtering Architecture for Vision Processing Systems,\n\nIEEE Trans. Circuits Syst. I, Fundam. Theory Appl., 46(9):1064-1071, 1999.\n\nSerrano-Gotarredona, R., Oster, M., Lichtsteiner, P., Linares-Barranco, A., Paz-Vicente, R., Gomez-Rodriguez, F., Riis, H.K., Delbruck, T., Liu, S.-H., Zahnd, S., Whatley, A.M., Douglas, R., Hafliger, P., Jimenez-Moreno, G., Civit, A., Serrano-Gotarredona, T., Acosta-Jimenez, A., Linares-Barranco, B.,\n\nAER building blocks for multi-layer multi-chip neuromorphic vision systems,\n\nAdvances in neural information processing systems, 1217-1224, 2006.\n\nLiu, S.-C. and Delbruck, T.,\n\nNeuromorphic sensory systems,\n\nCurrent Opinion in Neurobiology, 20:3(288-295), 2010.\n\nZamarreño-Ramos, C., Linares-Barranco, A., Serrano-Gotarredona, T., Linares-Barranco, B.,\n\nMulti-Casting Mesh AER: A Scalable Assembly Approach for Reconfigurable Neuromorphic Structured AER Systems. Application to ConvNets,\n\nIEEE Trans. Biomed. Circuits Syst., 7(1):82-102, 2013.\n\nLiu, S.-C., Delbruck, T., Indiveri, G., Whatley, A., Douglas, R.,\n\nEvent-Based Neuromorphic Systems,\n\nWiley. ISBN: 978-1-118-92762-5, 2014.\n\nChicca, E., Stefanini, F., Bartolozzi, C., Indiveri, G.,\n\nNeuromorphic Electronic Circuits for Building Autonomous Cognitive Systems,\n\nProc. IEEE, 102(9):1367-1388, 2014.\n\nVanarse, A., Osseiran, A., Rassau, A,\n\nA Review of Current Neuromorphic Approaches for Vision, Auditory, and Olfactory Sensors,\n\nFront. Neurosci. (2016), 10:115.\n\nLiu et al., Signal Process. Mag. 2019,\n\nEvent-Driven Sensing for Efficient Perception: Vision and audition algorithms.\n\nEvent Cameras Tutorial - Tobi Delbruck, version 4.1, Sep. 18, 2020.\n\nKirkland, P., Di Caterina, G., Soraghan, J., Matich, G.,\n\nNeuromorphic technologies for defence and security,\n\nSPIE vol 11540, Emerging Imaging and Sensing Technologies for Security and Defence V; and Advanced Manufacturing Technologies for Micro- and Nanosystems in Security and Defence III; 2020.\n\nDelbruck, T.,\n\nActivity-driven, event-based vision sensors,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2010. PDF.\n\nPosch, C.,\n\nBio-inspired vision,\n\nJ. of Instrumentation, 7 C01054, 2012. Bio-inspired explanation of the DVS and the ATIS. PDF\n\nPosch, C., Serrano-Gotarredona, T., Linares-Barranco, B., Delbruck, T.,\n\nRetinomorphic Event-Based Vision Sensors: Bioinspired Cameras With Spiking Output,\n\nProc. IEEE (2014), 102(10):1470-1484. PDF\n\nPosch, C.,\n\nBioinspired vision sensing,\n\nBiologically Inspired Computer Vision, Wiley-Blackwell, pp. 11-28, 2015. book index\n\nPosch, C., Benosman, R., Etienne-Cummings, R.,\n\nHow Neuromorphic Image Sensors Steal Tricks From the Human Eye, also published as Giving Machines Humanlike Eyes,\n\nIEEE Spectrum, 52(12):44-49, 2015. PDF\n\nCho, D., Lee, T.-J.,\n\nA Review of Bioinspired Vision Sensors and Their Applications,\n\nSensors and Materials, 27(6):447-463, 2015. PDF\n\nSandamirskaya, Y., Kaboli, M., Conradt, J., Celikel, T.,\n\nNeuromorphic computing hardware and neural architectures for robotics,\n\nScience Robotics, 7(67):eabl8419, 2022.\n\nDelbruck, T.,\n\nFun with asynchronous vision sensors and processing.\n\nComputer Vision - ECCV 2012. Workshops and Demonstrations. Springer Berlin/Heidelberg, 2012. A position paper and summary of recent accomplishments of the INI Sensors' group.\n\nDelbruck, T.,\n\nNeuromorophic Vision Sensing and Processing (Invited paper),\n\n46th Eur. Solid-State Device Research Conference (ESSDERC), Lausanne, 2016, pp. 7-14.\n\nLakshmi, A., Chakraborty, A., Thakur, C.S.,\n\nNeuromorphic vision: From sensors to event-based algorithms,\n\nWiley Interdiscip. Rev. Data Min. Knowl. Discov. 9(4), 2019.\n\nSteffen, L. et al., Front. Neurorobot. 2019,\n\nNeuromorphic Stereo Vision: A Survey of Bio-Inspired Sensors and Algorithms.\n\nGallego et al., TPAMI 2020,\n\nEvent-based Vision: A Survey.\n\nChen, G., Cao, H., Conradt, J., Tang, H., Rohrbein, F., Knoll, A.,\n\nEvent-Based Neuromorphic Vision for Autonomous Driving: A Paradigm Shift for Bio-Inspired Visual Sensing and Perception,\n\nIEEE Signal Processing Magazine, 37(4):34-49, 2020.\n\nChen, G., Wang, F., Li, W., Hong, L., Conradt, J., Chen, J., Zhang, Z., Lu, Y., Knoll, A.,\n\nNeuroIV: Neuromorphic Vision Meets Intelligent Vehicle Towards Safe Driving With a New Database and Baseline Evaluations,\n\nIEEE Trans. Intelligent Transportation Systems (TITS), 2020.\n\nTayarani-Najaran, M.-H., Schmuker, M.,\n\nEvent-Based Sensing and Signal Processing in the Visual, Auditory, and Olfactory Domain: A Review,\n\nFront. Neural Circuits 15:610446, 2021.\n\nSun, R. Shi, D., Zhang, Y., Li, R., Li, R.,\n\nData-Driven Technology in Event-Based Vision,\n\nComplexity, vol. 2021, Article ID 6689337.\n\nBartolozzi, C., Indiveri, G., Donati, E.,\n\nEmbodied neuromorphic intelligence,\n\nNat. Commun. 13:1024, 2022.\n\nZou, XL., Huang, T.J., Wu, S.,\n\nTowards a New Paradigm for Brain-inspired Computer Vision,\n\nMach. Intell. Res., 19:412-424, 2022.\n\nGehrig, D., Scaramuzza, D.,\n\nAre High-Resolution Cameras Really Needed?,\n\narXiv, 2022. YouTube, code.\n\nErcan, B., Eker, O., Erdem, A., Erdem, E.,\n\nEVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2023. PDF, Project Page, Suppl., Code.\n\nLitzenberger, M., Posch, C., Bauer, D., Belbachir, A. N., Schon. P., Kohn, B., Garn, H.,\n\nEmbedded Vision System for Real-Time Object Tracking using an Asynchronous Transient Vision Sensor,\n\nIEEE 12th Digital Signal Proc. Workshop and 4th IEEE Signal Proc. Education Workshop, Teton National Park, WY, 2006, pp. 173-178. PDF\n\nLitzenberger, M., Kohn, B., Belbachir, A.N., Donath, N., Gritsch, G., Garn, H., Posch, C., Schraml, S.,\n\nEstimation of Vehicle Speed Based on Asynchronous Data from a Silicon Retina Optical Sensor,\n\nIEEE Intelligent Transportation Systems Conf. (ITSC), 2006, pp. 653-658. PDF\n\nBauer, D., Belbachir, A. N., Donath, N., Gritsch, G., Kohn, B., Litzenberger, M., Posch, C., Schön, P., Schraml, S.,\n\nEmbedded Vehicle Speed Estimation System Using an Asynchronous Temporal Contrast Vision Sensor,\n\nEURASIP J. Embedded Systems, 2007:082174. PDF\n\nLitzenberger, M., Belbachir, N., Schon, P., Posch, C.,\n\nEmbedded Smart Camera for High Speed Vision,\n\nACM/IEEE Int. Conf. on Distributed Smart Cameras, 2007. PDF\n\nNi, Z., Bolopion, A., Agnus, J., Benosman, R., Regnier, S.,\n\nAsynchronous event-based visual shape tracking for stable haptic feedback in microrobotics,\n\nIEEE Trans. Robot. (TRO), 28(5):1081-1089, 2012. PDF\n\nNi, Ph.D. Thesis, 2013,\n\nAsynchronous Event Based Vision: Algorithms and Applications to Microrobotics.\n\nNi, Z., Ieng, S. H., Posch, C., Regnier, S., Benosman, R.,\n\nVisual Tracking Using Neuromorphic Asynchronous Event-Based Cameras,\n\nNeural Computation (2015), 27(4):925-953. PDF, YouTube\n\nPiatkowska, E., Belbachir, A. N., Schraml, S., Gelautz, M.,\n\nSpatiotemporal multiple persons tracking using Dynamic Vision Sensor,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2012, pp. 35-40. PDF\n\nLagorce, X., Ieng, S.-H., Clady, X., Pfeiffer, M., Benosman, R.,\n\nSpatiotemporal features for asynchronous event-based data,\n\nFront. Neurosci. (2015), 9:46.\n\nLagorce, X., Ieng, S. H., Benosman, R.,\n\nEvent-based features for robotic vision,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2013, pp. 4214-4219.\n\nSaner, D., Wang, O., Heinzle, S., Pritch, Y., Smolic, A., Sorkine-Hornung, A., Gross, M.,\n\nHigh-Speed Object Tracking Using an Asynchronous Temporal Contrast Sensor,\n\nInt. Symp. Vision, Modeling and Visualization (VMV), 2014. PDF\n\nLagorce, X., Meyer, C., Ieng, S. H., Filliat, D., Benosman, R.,\n\nAsynchronous Event-Based Multikernel Algorithm for High-Speed Visual Features Tracking,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 26(8):1710-1720, 2015. PDF, YouTube\n\nLagorce, X., Meyer, C., Ieng, S. H., Filliat, D., Benosman, R.,\n\nLive demonstration: Neuromorphic event-based multi-kernel algorithm for high speed visual features tracking,\n\nIEEE Biomedical Circuits and Systems Conference (BioCAS), 2014, pp. 178.\n\nReverter Valeiras, D., Lagorce, X., Clady, X., Bartolozzi, C., Ieng, S., Benosman, R.,\n\nAn Asynchronous Neuromorphic Event-Driven Visual Part-Based Shape Tracking,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 26(12):3045-3059, 2015. PDF, YouTube\n\nLinares-Barranco, A., Gómez-Rodríguez, F., Villanueva, V., Longinotti, L., Delbrück, T.,\n\nA USB3.0 FPGA event-based filtering and tracking framework for dynamic vision sensors,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2015.\n\nLeow, H. S., Nikolic, K.,\n\nMachine vision using combined frame-based and event-based vision sensor,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2015.\n\nLiu, H., Moeys, D. P., Das, G., Neil, D., Liu, S.-C., Delbruck, T.,\n\nCombined frame- and event-based detection and tracking,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2016.\n\nTedaldi, D., Gallego, G., Mueggler, E., Scaramuzza, D.,\n\nFeature detection and tracking with the dynamic and active-pixel vision sensor (DAVIS),\n\nIEEE Int. Conf. Event-Based Control Comm. and Signal Proc. (EBCCSP), 2016. PDF, YouTube\n\nKueng et al., IROS 2016 Low-Latency Visual Odometry using Event-based Feature Tracks.\n\nBraendli, C., Strubel, J., Keller, S., Scaramuzza, D., Delbruck, T.,\n\nELiSeD - An Event-Based Line Segment Detector,\n\nInt. Conf. on Event-Based Control Comm. and Signal Proc. (EBCCSP), 2016. PDF\n\nGlover, A. and Bartolozzi, C.,\n\nEvent-driven ball detection and gaze fixation in clutter,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2016, pp. 2203-2208. YouTube, Code\n\nGlover, A. and Bartolozzi, C.,\n\nRobust Visual Tracking with a Freely-moving Event Camera,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2017. YouTube, Code\n\nGlover, A., Stokes, A.B., Furber, S., Bartolozzi, C.,\n\nATIS + SpiNNaker: a Fully Event-based Visual Tracking Demonstration,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems Workshops (IROSW), 2018. Workshop on Unconventional Sensing and Processing for Robotic Visual Perception.\n\nClady, X., Maro, J.-M., Barré, S., Benosman, R. B.,\n\nA Motion-Based Feature for Event-Based Pattern Recognition.\n\nFront. Neurosci. (2017), 10:594. PDF\n\nZhu, A., Atanasov, N., Daniilidis, K.,\n\nEvent-based Feature Tracking with Probabilistic Data Association,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2017. PDF, YouTube, Code\n\nBarrios-Avilés, J., Iakymchuk, T., Samaniego, J., Medus, L.D., Rosado-Muñoz, A.,\n\nMovement Detection with Event-Based Cameras: Comparison with Frame-Based Cameras in Robot Object Tracking Using Powerlink Communication,\n\nElectronics 2018, 7, 304. PDF pre-print\n\nLi, J., Shi, F., Liu, W., Zou, D., Wang, Q., Park, P.K.J., Ryu, H.,\n\nAdaptive Temporal Pooling for Object Detection using Dynamic Vision Sensor,\n\nBritish Machine Vision Conf. (BMVC), 2017.\n\nPeng, X., Zhao, B., Yan, R., Tang H., Yi, Z.,\n\nBag of Events: An Efficient Probability-Based Feature Extraction Method for AER Image Sensors,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 28(4):791-803, 2017.\n\nRamesh, B., Yang, H., Orchard, G., Le Thi, N.A., Xiang, C,\n\nDART: Distribution Aware Retinal Transform for Event-based Cameras,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2019. PDF\n\nGehrig, D., Rebecq, H., Gallego, G., Scaramuzza, D.,\n\nEKLT: Asynchronous, Photometric Feature Tracking using Events and Frames,\n\nInt. J. Computer Vision (IJCV), 2019. YouTube, Tracking code, Evaluation code\n\nGehrig, D., Rebecq, H., Gallego, G., Scaramuzza, D.,\n\nAsynchronous, Photometric Feature Tracking using Events and Frames,\n\nEuropean Conf. Computer Vision (ECCV), 2018. Poster, YouTube, Oral presentation, Tracking code, Evaluation code\n\nEverding, L., Conradt, J.,\n\nLow-Latency Line Tracking Using Event-Based Dynamic Vision Sensors,\n\nFront. Neurorobot. 12:4, 2018. Videos\n\nLinares-Barranco, A., Liu, H., Rios-Navarro, A., Gomez-Rodriguez, F., Moeys, D., Delbruck, T.\n\nApproaching Retinal Ganglion Cell Modeling and FPGA Implementation for Robotics,\n\nEntropy 2018, 20(6), 475.\n\nMitrokhin, A., Fermüller, C., Parameshwara, C., Aloimonos, Y.,\n\nEvent-based Moving Object Detection and Tracking,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2018. PDF, YouTube, Project page and Dataset\n\nIacono, M., Weber, S., Glover, A., Bartolozzi, C.,\n\nTowards Event-Driven Object Detection with Off-The-Shelf Deep Learning,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2018.\n\nRamesh, B., Zhang, S., Lee, Z.-W., Gao, Z., Orchard, G., Xiang, C.,\n\nLong-term object tracking with a moving event camera,\n\nBritish Machine Vision Conf. (BMVC), 2018. Video\n\nRamesh, B., Zhang, S., Yang, H., Ussa, A., Ong, M., Orchard, G., Xiang, C.,\n\ne-TLD: Event-based Framework for Dynamic Object Tracking,\n\narXiv, 2020.\n\nDardelet, L., Ieng, S.-H., Benosman, R.,\n\nEvent-Based Features Selection and Tracking from Intertwined Estimation of Velocity and Generative Contours,\n\narXiv:1811.07839, 2018.\n\nWu, J., Zhang, K., Zhang, Y., Xie, X., Shi, G.,\n\nHigh-Speed Object Tracking with Dynamic Vision Sensor,\n\nChina High Resolution Earth Observation Conference (CHREOC), 2018.\n\nHuang, J., Wang, S., Guo, M., Chen, S.,\n\nEvent-Guided Structured Output Tracking of Fast-Moving Objects Using a CeleX Sensor,\n\nIEEE Trans. Circuits Syst. Video Technol. (TCSVT), 28(9):2413-2417, 2018.\n\nRenner, A., Evanusa, M., Sandamirskaya, Y.,\n\nEvent-based attention and tracking on neuromorphic hardware,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2019. Video pitch\n\nFoster, B.J., Ye, D.H., Bouman, C.A.,\n\nMulti-target tracking with an event-based vision sensor and a partial-update GMPHD filter,\n\nIS&T International Symposium on Electronic Imaging 2019. Computational Imaging XVII.\n\nAlzugaray, I., Chli, M.,\n\nAsynchronous Multi-Hypothesis Tracking of Features with Event Cameras,\n\nIEEE Int. Conf. 3D Vision (3DV), 2019. PDF, Code, YouTube\n\nLinares-Barranco, A., Perez-Pena, F., Moeys, D.P., Gomez-Rodriguez, F., Jimenez-Moreno, G., Delbruck, T.\n\nLow Latency Event-based Filtering and Feature Extraction for Dynamic Vision Sensors in Real-Time FPGA Applications,\n\nIEEE Access, 7:134926-134942, 2019. Code\n\nLi, K., Shi, D., Zhang, Y., Li, R., Qin, W., Li, R.,\n\nFeature Tracking Based on Line Segments With the Dynamic and Active-Pixel Vision Sensor (DAVIS),\n\nIEEE Access, 7:110874-110883, 2019.\n\nBolten T., Pohle-Fröhlich R., Tönnies K.D.,\n\nApplication of Hierarchical Clustering for Object Tracking with a Dynamic Vision Sensor,\n\nInt. Conf. Computational Science (ICCS) 2019. PDF\n\nChen, H., Wu, Q., Liang, Y., Gao, X., Wang, H.,\n\nAsynchronous Tracking-by-Detection on Adaptive Time Surfaces for Event-based Object Tracking,\n\nACM Int. Conf. on Multimedia (MM), 2019.\n\nReverter Valeiras, D., Clady, X., Ieng, S.-H., Benosman, R.,\n\nEvent-Based Line Fitting and Segment Detection Using a Neuromorphic Visual Sensor,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 30(4):1218-1230, 2019. PDF\n\nLi, H., Shi, L., Robust Event-Based Object Tracking Combining Correlation Filter and CNN Representation,\n\nFront. Neurorobot. 13:82, 2019. Dataset\n\nChen, H., Suter, D., Wu, Q., Wang, H.,\n\nEnd-to-end Learning of Object Motion Estimation from Retinal Events for Event-based Object Tracking,\n\nAAAI Conf. Artificial Intelligence, 2020. PDF, PDF.\n\nMonforte, M., Arriandiaga, A., Glover, A., Bartolozzi, C.,\n\nExploiting Event Cameras for Spatio-Temporal Prediction of Fast-Changing Trajectories,\n\nIEEE Int. Conf. Artificial Intelligence Circuits and Systems (AICAS), 2020.\n\nSengupta, J. P., Kubendran, R., Neftci, E., Andreou, A. G.,\n\nHigh-Speed, Real-Time, Spike-Based Object Tracking and Path Prediction on Google Edge TPU.\n\nIEEE Int. Conf. Artificial Intelligence Circuits and Systems (AICAS), 2020, pp. 134-135.\n\nSeok, H., Lim, J.,\n\nRobust Feature Tracking in DVS Event Stream using Bezier Mapping,\n\nIEEE Winter Conf. Applications of Computer Vision (WACV), 2020. YouTube\n\nXu, L., Xu, W., Golyanik, V., Habermann, M., Fang, L., Theobalt, C.,\n\nEventCap: Monocular 3D Capture of High-Speed Human Motions using an Event Camera,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020. ZDNet news\n\nRodríguez-Gómez, J.P., Gómez Eguíluz, A., Martínez-de Dios, J.R., Ollero, A.,\n\nAsynchronous event-based clustering and tracking for intrusion monitoring,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2020. PDF.\n\nBoettiger, J. P., MSc 2020, A Comparative Evaluation of the Detection and Tracking Capability Between Novel Event-Based and Conventional Frame-Based Sensors.\n\nSarmadi, H., Muñoz-Salinas, R., Olivares-Mendez, M. A., Medina-Carnicer, R.,\n\nDetection of Binary Square Fiducial Markers Using an Event Camera,\n\narXiv, 2020.\n\nAlzugaray, I., Chli, M.,\n\nHASTE: multi-Hypothesis Asynchronous Speeded-up Tracking of Events,\n\nBritish Machine Vision Conf. (BMVC), 2020. PDF, Suppl. Mat., Code, Presentation, Youtube\n\nLiu, Z., Fu, Y.,\n\ne-ACJ: Accurate Junction Extraction For Event Cameras,\n\narXiv, 2021.\n\nDong, Y., Zhang, T.,\n\nStandard and Event Cameras Fusion for Feature Tracking,\n\nInt. Conf. on Machine Vision and Applications (ICMVA), 2021. Code\n\nMondal, A., Shashant, R., Giraldo, J. H., Bouwmans, T., Chowdhury, A. S.,\n\nMoving Object Detection for Event-based Vision using Graph Spectral Clustering,\n\nIEEE Int. Conf. Computer Vision Workshop (ICCVW), 2021. Youtube, Code.\n\nXiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li, Yaowei Wang, Yonghong Tian, Feng Wu,\n\nVisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows,\n\narXiv, 2021. Code\n\nAlzugaray, I., Ph.D. Thesis, 2022,\n\nEvent-driven Feature Detection and Tracking for Visual SLAM.\n\nZhang, J., Zhao, K., Dong, B., Fu, Y., Wang, Y., Yang, X., Yin, B.,\n\nMulti-domain collaborative feature representation for robust visual object tracking,\n\nThe Visual Computer, 2021. PDF, Project.\n\nZhang, J., Yang, X., Fu, Y., Wei, X., Yin, B., Dong, B.,\n\nObject Tracking by Jointly Exploiting Frame and Event Domain,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2021. Project, PDF, code, dataset.\n\nDietsche, A., Cioffi, G., Hidalgo-Carrio, J., Scaramuzza, D.,\n\nPowerline Tracking with Event Cameras,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2021. PDF, dataset, YouTube, code.\n\nLi, H., Stueckler, J.,\n\nTracking 6-DoF Object Motion from Events and Frames,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2021.\n\nZhang, J., Dong, B., Zhang, H., Ding, J., Heide, F., Yin, B., Yang, X.,\n\nSpiking Transformers for Event-based Single Object Tracking,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2022. Project, PDF, code.\n\nGao, et at., FPGA, 2022,\n\nREMOT: A Hardware-Software Architecture for Attention-Guided Multi-Object Tracking with Dynamic Vision Sensors on FPGAs.\n\nEl Shair, Z., Rawashdeh, S.A.,\n\nHigh-Temporal-Resolution Object Detection and Tracking using Images and Events,\n\nJournal of Imaging, 2022. PDF, dataset.\n\nHu, S., Kim, Y., Lim, H., Lee, A., Myung, H.,\n\neCDT: Event Clustering for Simultaneous Feature Detection and Tracking,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2022. YouTube\n\nZhu, Z., Hou, J., Lyu, X.,\n\nLearning Graph-embedded Key-event Back-tracing for Object Tracking in Event Clouds,\n\nThirty-sixth Conference on Neural Information Processing Systems (NeurIPS), 2022. PDF, code.\n\nEl Shair, Z., Rawashdeh, S.A.,\n\nHigh-temporal-resolution event-based vehicle detection and tracking,\n\nOptical Engineering, 2022. dataset.\n\nMessikommer, N., Fang, C., Gehrig, M., Scaramuzza, D.,\n\nData-driven Feature Tracking for Event Cameras,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2023. PDF, YouTube, code.\n\nPedersen, J., Singhal, R., Conradt, J.,\n\nTranslation and Scale Invariance for Event-Based Object tracking,\n\nProc. Annual Neuro-Inspired Computational Elements Conf. (NICE), 2023, pp. 86-91. Website, code, presentation.\n\nZhu, Z., Hou, J., Wu DO.,\n\nCross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers.,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2023., code.\n\nWang, Z., Molloy, T., van Goor, P., Mahony, R.,\n\nEvent Blob Tracking: An Asynchronous Real-Time Algorithm.,\n\narXiv:2307.10593, 2023. PDF, Video, Project page.\n\nNagaraj, M., Liyanagedera, C.M., Roy, K.,\n\nDOTIE - Detecting Objects through Temporal Isolation of Events using a Spiking Architecture.,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2023. Arxiv, CVPR 2023 workshop, Code.\n\nGao et al., ICCV 2023, A 5-Point Minimal Solver for Event Camera Relative Motion Estimation.\n\nGao et al., CVPR 2024, An N-Point Linear Solver for Line and Motion Estimation with Event Cameras.\n\nLi, S., Zhou, Z., Xue, Z., Li, Y., Du, S., Gao, Y.,\n\n3D Feature Tracking via Event Camera,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2024. Code, Dataset.\n\nKang, Y., Caron, G., Ishikawa, R., Escande, A., Chappellet, K., Sagawa, R., Oishi, T.,\n\nDirect 3D model-based object tracking with event camera by motion interpolation.,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2024. Dataset.\n\nClady, X., Ieng, S.-H., Benosman, R.,\n\nAsynchronous event-based corner detection and matching,\n\nNeural Networks (2015), 66:91-106. PDF\n\nVasco, V., Glover, A., Bartolozzi, C.,\n\nFast event-based Harris corner detection exploiting the advantages of event-driven cameras,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2016, pp. 4144-4149. YouTube, Code\n\nMueggler, E., Bartolozzi, C., Scaramuzza, D.,\n\nFast Event-based Corner Detection,\n\nBritish Machine Vision Conf. (BMVC), 2017. YouTube, Code\n\nLiu, H., Kao, W.-T., Delbruck, T.,\n\nLive Demonstration: A Real-time Event-based Fast Corner Detection Demo based on FPGA,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2019.\n\nStandalone Rust implementation, Code\n\nAlzugaray, I., Chli, M.,\n\nAsynchronous Corner Detection and Tracking for Event Cameras in Real Time,\n\nIEEE Robotics and Automation Letters (RA-L), 3(4):3177-3184, Oct. 2018. PDF, YouTube, Code.\n\nAlzugaray, I., Chli, M.,\n\nACE: An Efficient Asynchronous Corner Tracker for Event Cameras,\n\nIEEE Int. Conf. 3D Vision (3DV), 2018. PDF, YouTube\n\nScheerlinck, C., Barnes, N., Mahony, R.,\n\nAsynchronous Spatial Image Convolutions for Event Cameras,\n\nIEEE Robotics and Automation Letters (RA-L), 4(2):816-822, Apr. 2019. PDF, Website\n\nManderscheid, J., Sironi, A., Bourdis, N., Migliore, D., Lepetit, V.,\n\nSpeed Invariant Time Surface for Learning to Detect Corner Points with Event-Based Cameras,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019. PDF\n\nLi, R., Shi, D., Zhang, Y., Li, K., Li, R.,\n\nFA-Harris: A Fast and Asynchronous Corner Detector for Event Cameras,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2019. PDF\n\nMohamed, S. A. S., Yasin, J. N., Haghbayan, M.-H., Miele, A., Heikkonen, J., Tenhunen, H., Plosila, J.,\n\nDynamic Resource-aware Corner Detection for Bio-inspired Vision Sensors,\n\nInt. Conf. Pattern Recognition (ICPR), 2020.\n\nMohamed, S. A. S., Yasin, J. N., Haghbayan, M.-H., Miele, A., Heikkonen, J., Tenhunen, H., Plosila, J.,\n\nAsynchronous Corner Tracking Algorithm based on Lifetime of Events for DAVIS Cameras,\n\nInt. Symposium on Visual Computing (ISVC), 2020.\n\nYılmaz, Ö., Simon-Chane, C., Histace A.,\n\nEvaluation of Event-Based Corner Detectors ,\n\nJ. Imaging, 2021.\n\nChiberre, P., Perot, E., Sironi, A., Lepetit, V.,\n\nDetecting Stable Keypoints From Events Through Image Gradient Prediction,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. YouTube.\n\nChui, J., Klenk, S., Cremers, D.,\n\nEvent-Based Feature Tracking in Continuous Time with Sliding Window Optimization,\n\narXiv preprint arXiv, 2021.\n\nSengupta, J. P., Villemur, M., Andreou, A. G.,\n\nEfficient, event-driven feature extraction and unsupervised object tracking for embedded applications,\n\n55th Annual Conf. on Information Sciences and Systems (CISS), 2021.\n\nAlzugaray, I., Ph.D. Thesis, 2022,\n\nEvent-driven Feature Detection and Tracking for Visual SLAM.\n\nFreeman, A., Mayer-Patel, K., Singh, M.,\n\nAccelerated Event-Based Feature Detection and Compression for Surveillance Video Systems,\n\nACM Multimedia Systems (MMSys), 2024. PDF, Code.\n\nDrazen, D., Lichtsteiner, P., Haefliger, P., Delbruck, T., Jensen, A.,\n\nToward real-time particle tracking using an event-based dynamic vision sensor,\n\nExperiments in Fluids (2011), 51(1):1465-1469. PDF\n\nNi, Z., Pacoret, C., Benosman, R., Ieng, S., Regnier, S.,\n\nAsynchronous event-based high speed vision for microparticle tracking,\n\nJ. Microscopy (2011), 245(3):236-244. PDF\n\nBorer, D., Roesgen, T.,\n\nLarge-scale Particle Tracking with Dynamic Vision Sensors,\n\nISFV16 - 16th Int. Symp. Flow Visualization, Okinawa 2014. Project page, Poster\n\nWang, Y., Idoughi, R., Heidrich, W.,\n\nStereo Event-based Particle Tracking Velocimetry for 3D Fluid Flow Reconstruction,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat.\n\nRyan, C., Sullivan, B. O., Elrasad, A., Lemley, J., Kielty., P., Posch, C., Perot, E.,\n\nReal-Time Face & Eye Tracking and Blink Detection using Event Cameras,\n\narXiv, 2020.\n\nAngelopoulos, A.N., Martel, J.N.P., Kohli, A.P.S., Conradt, J., Wetzstein, G.,\n\nEvent Based, Near-Eye Gaze Tracking Beyond 10,000Hz,\n\nIEEE Trans. Vis. Comput. Graphics (Proc. VR), 2021. YouTube, Dataset, Project page\n\nChen, Q., Wang, Z., Liu, S.-C., Gao, C.,\n\n3ET: Efficient Event-based Eye Tracking using a Change-Based ConvLSTM Network,\n\nIEEE BioCAS Conf., 2023. YouTube, Code\n\nWang, Z., Gao, C., Wu, Z., Conde, M., Timofte, R., Liu, S.-C., Chen, Q., et al.\n\nEvent-based Eye Tracking. AIS 2024 Challenge Survey, IEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2024. Challenge page, Code, Kaggle page\n\nBonazzi, P., Bian, S., Lippolis, G., Sheik, S., Magno, M.\n\nRetina: Low-Power Eye Tracking with Event Camera and Spiking Hardware,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2024. Dataset, Code, PDF.\n\nDelbruck, T.,\n\nFrame-free dynamic digital vision,\n\nInt. Symp. on Secure-Life Electronics, Advanced Electronics for Quality Life and Society, pp. 21-26, 2008. PDF\n\nCook et al., IJCNN 2011,\n\nInteracting maps for fast visual interpretation. (Joint estimation of optical flow, image intensity and angular velocity with a rotating event camera).\n\nBenosman, R., Ieng, S.-H., Clercq, C., Bartolozzi, C., Srinivasan, M.,\n\nAsynchronous Frameless Event-Based Optical Flow,\n\nNeural Networks (2012), 27:32-37. PDF, Suppl. Mat.\n\nOrchard, G., Benosman, R., Etienne-Cummings, R., Thakor, N,\n\nA Spiking Neural Network Architecture for Visual Motion Estimation,\n\nIEEE Biomedical Circuits and Systems Conf. (BioCAS), 2013. PDF, Code\n\nBenosman, R., Clercq, C., Lagorce, X., Ieng, S.-H., Bartolozzi, C.,\n\nEvent-Based Visual Flow,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 25(2):407-417, 2014. PDF, Code (jAER): LocalPlanesFlow\n\nClady et al., Front. Neurosci. 2014,\n\nAsynchronous visual event-based time-to-contact.\n\nE. Mueggler, C. Forster, N. Baumli, G. Gallego, D. Scaramuzza,\n\nLifetime Estimation of Events from Dynamic Vision Sensors,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2015, pp. 4874-4881. PDF, PPT, Code\n\nLee, A. J., Kim, A.,\n\nEvent-based Real-time Optical Flow Estimation,\n\nIEEE Int. Conf. on Control, Automation and Systems (ICCAS), 2017.\n\nAung, M.T., Teo, R., Orchard, G.,\n\nEvent-based Plane-fitting Optical Flow for Dynamic Vision Sensors in FPGA,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2018. Code\n\nBarranco, F., Fermüller, C., Aloimonos, Y.,\n\nContour motion estimation for asynchronous event-driven cameras,\n\nProc. IEEE (2014), 102(10):1537-1556. PDF\n\nLee, J.H., Lee, K., Ryu, H., Park, P.K.J., Shin, C.W., Woo, J., Kim, J.-S.,\n\nReal-time motion estimation based on event-based vision sensor,\n\nIEEE Int. Conf. Image Processing (ICIP), 2014.\n\nRichter, C., Röhrbein, F., Conradt, J.,\n\nBio inspired optic flow detection using neuromorphic hardware,\n\nBernstein Conf. 2014. PDF\n\nBarranco, F., Fermüller, C., Aloimonos, Y.,\n\nBio-inspired Motion Estimation with Event-Driven Sensors,\n\nInt. Work-Conf. Artificial Neural Networks (IWANN) 2015, Advances in Computational Intell., pp. 309-321. PDF\n\nConradt, J.,\n\nOn-Board Real-Time Optic-Flow for Miniature Event-Based Vision Sensors,\n\nIEEE Int. Conf. Robotics and Biomimetics (ROBIO), 2015.\n\nBrosch, T., Tschechne, S., Neumann, H.,\n\nOn event-based optical flow detection,\n\nFront. Neurosci. (2015), 9:137.\n\nTschechne, S., Brosch, T., Sailer, R., von Egloffstein, N., Abdul-Kreem L.I., Neumann, H.,\n\nOn event-based motion detection and integration,\n\nInt. Conf. Bio-inspired Information and Comm. Technol. (BICT), 2014. PDF\n\nTschechne, S., Sailer R., Neumann, H.,\n\nBio-Inspired Optic Flow from Event-Based Neuromorphic Sensor Input,\n\nIAPR Workshop on Artificial Neural Networks in Pattern Recognition (ANNPR) 2014, pp. 171-182.\n\nBrosch, T., Neumann, H.,\n\nEvent-based optical flow on neuromorphic hardware,\n\nInt. Conf. Bio-inspired Information and Comm. Technol. (BICT), 2015. PDF\n\nBrosch, T., Tschechne, S., Neumann, H.,\n\nVisual Processing in Cortical Architecture from Neuroscience to Neuromorphic Computing,\n\nInt. Workshop on Brain-Inspired Computing (BrainComp), 2015. LNCS, vol 10087.\n\nKosiorek, A., Adrian, D., Rausch, J., Conradt, J.,\n\nAn Efficient Event-Based Optical Flow Implementation in C/C++ and CUDA,\n\nTech. Rep. TU Munich, 2015.\n\nMilde et al., EBCCSP 2015,\n\nBioinspired event-driven collision avoidance algorithm based on optic flow.\n\nGiulioni, M., Lagorce, X., Galluppi, F., Benosman, R.,\n\nEvent-Based Computation of Motion Flow on a Neuromorphic Analog Neural Platform,\n\nFront. Neurosci. (2016), 10:35. PDF\n\nHaessig, G., Galluppi, F., Lagorce, X., Benosman, R.,\n\nNeuromorphic networks on the SpiNNaker platform,\n\nIEEE Int. Conf. Artificial Intelligence Circuits and Systems (AICAS), 2019.\n\nRueckauer, B. and Delbruck, T.,\n\nEvaluation of Event-Based Algorithms for Optical Flow with Ground-Truth from Inertial Measurement Sensor,\n\nFront. Neurosci. (2016), 10:176. YouTube\n\nCode (jAER)\n\nBardow, P. A., Davison, A. J., Leutenegger, S.,\n\nSimultaneous Optical Flow and Intensity Estimation from an Event Camera,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2016. YouTube, YouTube 2, Dataset: 4 sequences\n\nStoffregen, T., Kleeman, L.,\n\nSimultaneous Optical Flow and Segmentation (SOFAS) using Dynamic Vision Sensor,\n\nAustralasian Conf. Robotics and Automation (ACRA), 2017. PDF, YouTube\n\nHaessig, G., Cassidy, A. Alvarez, R., Benosman, R., Orchard, G.,\n\nSpiking Optical Flow for Event-based Sensors Using IBM's TrueNorth Neurosynaptic System,\n\nIEEE Trans. Biomed. Circuits Syst., 12(4):860-870, 2018. PDF\n\nGallego et al., CVPR 2018,\n\nA Unifying Contrast Maximization Framework for Event Cameras, with Applications to Motion, Depth and Optical Flow Estimation.\n\nStoffregen, T., Kleeman, L.,\n\nEvent Cameras, Contrast Maximization and Reward Functions: An Analysis,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019.\n\nGallego et al., CVPR 2019,\n\nFocus Is All You Need: Loss Functions For Event-based Vision.\n\nStoffregen et al., ICCV 2019,\n\nEvent-Based Motion Segmentation by Motion Compensation.\n\nGhosh et al., AISY 2022,\n\nMulti-Event-Camera Depth Estimation and Outlier Rejection by Refocused Events Fusion (MCEMVS).\n\nShiba et al., Sensors 2022,\n\nEvent Collapse in Contrast Maximization Frameworks.\n\nShiba et al., AISY 2022,\n\nA Fast Geometric Regularizer to Mitigate Event Collapse in the Contrast Maximization Framework.\n\nShiba et al., ECCV 2022,\n\nSecrets of Event-based Optical Flow.\n\nZhang et al., TPAMI 2023,\n\nFormulating Event-based Image Reconstruction as a Linear Inverse Problem with Deep Regularization using Optical Flow.\n\nGuo et al. TRO 2024, CMax-SLAM: Event-based Rotational-Motion Bundle Adjustment and SLAM System using Contrast Maximization.\n\nShiba et al. TPAMI 2024,\n\nSecrets of Event-based Optical Flow, Depth and Ego-motion Estimation by Contrast Maximization.\n\nZhu, A., Yuan, L., Chaney, K., Daniilidis, K.,\n\nEV-FlowNet: Self-Supervised Optical Flow Estimation for Event-based Cameras,\n\nRobotics: Science and Systems (RSS), 2018. PDF, YouTube, Code\n\nGehrig et al., ICCV 2019,\n\nEnd-to-End Learning of Representations for Asynchronous Event-Based Data.\n\nLiu, M., Delbruck, T.,\n\nAdaptive Time-Slice Block-Matching Optical Flow Algorithm for Dynamic Vision Sensors,\n\nBritish Machine Vision Conf. (BMVC), 2018. Supplementary material, Video\n\nLiu, M., Delbruck, T.,\n\nBlock-Matching Optical Flow for Dynamic Vision Sensors: Algorithm and FPGA Implementation,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2017.\n\nYe, C., Mitrokhin, A., Parameshwara, C., Fermüller, C., Yorke, J. A., Aloimonos,Y,\n\nUnsupervised Learning of Dense Optical Flow, Depth and Egomotion with Event-Based Sensors,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2020. PDF, YouTube, Project page\n\nSeifozzakerini, Ph.D. Thesis, 2018,\n\nAnalysis of object and its motion in event-based videos.\n\nNagata, J., Sekikawa, Y., Hara, K., Aoki, Y.,\n\nFOE-based regularization for optical flow estimation from an in-vehicle event camera,\n\nProc. SPIE 11049, Int. Workshop on Advanced Image Technology (IWAIT), 2019.\n\nParedes-Valles, F., Scheper, K. Y. W., de Croon, G. C. H. E.,\n\nUnsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation: From Events to Global Motion Perception,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2019. PDF, YouTube, Code.\n\nZhu, A. Z., Yuan, L., Chaney, K., Daniilidis, K.,\n\nUnsupervised Event-Based Learning of Optical Flow, Depth, and Egomotion,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019. PDF, YouTube, Patent\n\nZhu, A. Z., Yuan, L., Chaney, K., Daniilidis, K.,\n\nUnsupervised Event-Based Optical Flow Using Motion Compensation,\n\nEuropean Conf. Computer Vision Workshops (ECCVW), 2018. PDF\n\nKhoei, M.A., Benosman, R.,\n\nAsynchronous Event-Based Motion Processing: From Visual Events to Probabilistic Sensory Representation,\n\nNeural Computation (2019), 31(6):1114-1138. PDF\n\nAlmatrafi, M. M., Hirakawa, K.,\n\nDAViS Camera Optical Flow,\n\nIEEE Trans. Comput. Imag. (TCI), 6:396-407, 2019.\n\nAlmatrafi, M., Baldwin, R., Aizawa, K., Hirakawa, K.,\n\nDistance Surface for Event-Based Optical Flow,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2020. PDF, Dataset\n\nLee, C., Kosta, A., Zhu, A.Z., Chaney, K., Daniilidis, K., Roy, K.,\n\nSpike-FlowNet: Event-based Optical Flow Estimation with Energy-Efficient Hybrid Neural Networks,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat., PDF\n\nD'Angelo, G., Janotte, E., Schoepe, T., O'Keeffe, J., Milde, M. B., Chicca, E., Bartolozzi, C.,\n\nEvent-Based Eccentric Motion Detection Exploiting Time Difference Encoding,\n\nFront. Neurosci. (2020), 14:451. Project page\n\nPan, L., Liu, M., Hartley, R.,\n\nSingle Image Optical Flow Estimation with an Event Camera,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020.\n\nLow, W. F., Gao, Z., Xiang, C., Ramesh, B.,\n\nSOFEA: A Non-Iterative and Robust Optical Flow Estimation Algorithm for Dynamic Vision Sensors,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2020. PDF, Suppl. Mat.\n\nAkolkar, H., Ieng, S.-H., Benosman, R.,\n\nReal-time high speed motion prediction using fast aperture-robust event-driven visual flow,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2020. PDF\n\nPivezhandi, M., Jones, P. H., Zambreno, J.,\n\nParaHist: FPGA Implementation of Parallel Event-Based Histogram for Optical Flow Calculation,\n\nIEEE Conf. Application-specific Systems, Architectures and Processors (ASAP), 2020. PDF\n\nKepple, D.R., Lee, D., Prepsius, C., Isler, V., Park, I. M., Lee, D. D.,\n\nJointly learning visual motion and confidence from local patches in event cameras,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat.\n\nNagata, J., Sekikawa, Y., Aoki, Y.,\n\nOptical Flow Estimation by Matching Time Surface with Event-Based Cameras,\n\nSensors 2021, 21, 1150. PDF\n\nParedes-Valles et al., CVPR 2021,\n\nBack to Event Basics: Self-Supervised Learning of Image Reconstruction for Event Cameras via Photometric Constancy.\n\nHagenaars, J. J., Paredes-Valles, F., de Croon, G. C. H. E.,\n\nSelf-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks,\n\nAdvances in Neural Information Processing Systems 34 (NeurIPS), 2021. Project page, PDF, Suppl. Mat., Code.\n\nSikorski, O., Izzo, D., Meoni, G.,\n\nEvent-Based Spacecraft Landing Using Time-To-Contact,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021.\n\nPeveri, F., Testa, S., Sabatini, S. P.,\n\nA Cortically-Inspired Architecture for Event-Based Visual Motion Processing: From Design Principles to Real-World Applications,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. YouTube.\n\nBarbier, T., Teuliere, C., Triesch, J.,\n\nSpike Timing-Based Unsupervised Learning of Orientation, Disparity, and Motion Representations in a Spiking Neural Network,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. Suppl., YouTube.\n\nGehrig, M., Millhäusler, M., Gehrig, D., Scaramuzza, D.,\n\nE-RAFT: Dense Optical Flow from Event Cameras,\n\nIEEE Int. Conf. 3D Vision (3DV), 2021. Code, Dataset, Youtube\n\nShiba, S., Aoki, Y., Gallego, G.,\n\nEvent Collapse in Contrast Maximization Frameworks,\n\nSensors, 2022. PDF, Project page\n\nShiba, S., Klose, Y., Aoki, Y., Gallego, G.,\n\nSecrets of Event-based Optical Flow, Depth and Ego-motion Estimation by Contrast Maximization,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2024. Project page and Code\n\nShiba, S., Aoki, Y., Gallego, G.,\n\nSecrets of Event-based Optical Flow,\n\nEuropen Conf. Computer Vision (ECCV), 2022. YouTube, Poster, Presentation at the PRG Seminar Series U. Maryland (Video), Presentation at the GRASP Laboratory (UPenn) seminar, Project page and Code\n\nShiba, S., Aoki, Y., Gallego, G.,\n\nFast Event-Based Optical Flow Estimation by Triplet Matching,\n\nIEEE Signal Process. Lett. (SPL), 29:2712-2716, 2022. PDF.\n\nBrebion, V., Moreau, J., Davoine, F.,\n\nReal-Time Optical Flow for Vehicular Perception With Low- and High-Resolution Event Cameras,\n\nIEEE Trans. Intell. Transp. Syst. (T-ITS), 2021. PDF, Code, Dataset, YouTube.\n\nLiu, M., Delbruck, T.,\n\nEDFLOW: Event Driven Optical Flow Camera with Keypoint Detection and Adaptive Block Matching,\n\nIEEE Trans. Circuits Syst. Video Technol. (TCSVT), 32(9):5776-5789, 2022. Preprint PDF, Code and Dataset\n\nWan, Z., Dai, Y., Mao, Y.,\n\nLearning Dense and Continuous Optical Flow From an Event Camera,\n\nIEEE Trans. Image Process. (TIP), 31:7237-7251, 2022. PDF, Project page, Code\n\nZheng, Y., Yu, Z., Wang, S., Huang, T.,\n\nSpike-Based Motion Estimation for Object Tracking Through Bio-Inspired Unsupervised Learning,\n\nIEEE Trans. Image Process. (TIP), 32:335-349, 2022.\n\nGehrig, M., Muglikar, M., Scaramuzza, D.,\n\nDense Continuous-Time Optical Flow from Events and Frames,\n\narXiv, 2022.\n\nTian, Y., Andrade-Cetto, J.,\n\nEvent transformer FlowNet for optical flow estimation,\n\nBritish Mach. Vis. Conf., 2022, PDF, Poster, Video, Supplementary.\n\nShiba et al., TPAMI 2023,\n\nEvent-based Background-Oriented Schlieren.\n\nIeng, S.-H., Carneiro, J., Benosman, R.,\n\nEvent-Based 3D Motion Flow Estimation Using 4D Spatio Temporal Subspaces Properties,\n\nFront. Neurosci. (2017), 10:596.\n\nCarneiro, Ph.D. Thesis, 2014,\n\nAsynchronous Event-Based 3D Vision - Chapter 3.\n\nCook, M., Gugelmann, L., Jug, F., Krautz, C., Steger, A.,\n\nInteracting maps for fast visual interpretation,\n\nInt. Joint Conf. on Neural Networks (IJCNN), San Jose, CA, 2011, pp. 770-776. PDF, YouTube\n\nMartel, J. N. P., Cook, M.,\n\nA Framework of Relational Networks to Build Systems with Sensors able to Perform the Joint Approximate Inference of Quantities,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems Workshop (IROSW), 2015. Workshop on Unconventional Computing for Bayesian Inference. PDF\n\nMartel, J. N. P., Chau, M., Dudek, P., Cook, M.,\n\nToward joint approximate inference of visual quantities on cellular processor arrays,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2015.\n\nBelbachir et al., CVPRW 2014,\n\nA Novel HDR Depth Camera for Real-time 3D 360-degree Panoramic Vision.\n\nKim, H., Handa, A., Benosman, R., Ieng, S.-H., Davison, A. J.,\n\nSimultaneous Mosaicing and Tracking with an Event Camera,\n\nBritish Machine Vision Conf. (BMVC), 2014. PDF, YouTube, YouTube 2\n\nCode for intensity reconstruction.\n\nYouTube TU Graz\n\nBarua, S., Miyatani, Y., Veeraraghavan, A.,\n\nDirect face detection and video reconstruction from event cameras,\n\nIEEE Winter Conf. Applications of Computer Vision (WACV), 2016. YouTube\n\nBardow et al., CVPR 2016,\n\nSimultaneous Optical Flow and Intensity Estimation from an Event Camera.\n\nMoeys, D. P., Li, C., Martel, J. N. P., Bamford, S., Longinotti, L., Motsnyi, V., Bello, D. S. S., Delbruck, T.,\n\nColor Temporal Contrast Sensitivity in Dynamic Vision Sensors,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2017. PDF.\n\nMunda, G., Reinbacher, C., Pock, T.,\n\nReal-Time Intensity-Image Reconstruction for Event Cameras Using Manifold Regularisation,\n\nInt. J. of Computer Vision (IJCV), 2018.\n\nReinbacher, C., Graber, G., Pock, T.,\n\nReal-Time Intensity-Image Reconstruction for Event Cameras Using Manifold Regularisation,\n\nBritish Machine Vision Conf. (BMVC), 2016. PDF, YouTube, Code\n\nWatkins, Y., Thresher, A., Mascarenas, D., Kenyon, G.T.,\n\nSparse Coding Enables the Reconstruction of High-Fidelity Images and Video from Retinal Spike Trains,\n\nInt. Conf. Neuromorphic Systems (ICONS), 2018. Article No. 8. PDF\n\nScheerlinck, C., Barnes, N., Mahony, R.,\n\nContinuous-time Intensity Estimation Using Event Cameras,\n\nAsian Conf. Computer Vision (ACCV), 2018. PDF, YouTube, Website\n\nRebecq, H., Ranftl, R., Koltun, V., Scaramuzza, D.,\n\nHigh Speed and High Dynamic Range Video with an Event Camera,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2020. PDF, YouTube, Code, Project page\n\nRebecq, H., Ranftl, R., Koltun, V., Scaramuzza, D.,\n\nEvents-to-Video: Bringing Modern Computer Vision to Event Cameras,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019. PDF, YouTube, Slides, Video pitch.\n\nScheerlinck, C., Rebecq, H., Gehrig, D., Barnes, N., Mahony, R., Scaramuzza, D.,\n\nFast Image Reconstruction with an Event Camera,\n\nIEEE Winter Conf. Applications of Computer Vision (WACV), 2020. PDF, YouTube, Website\n\nStoffregen, T., Scheerlinck, C., Scaramuzza, D., Drummond, T., Barnes, N., Kleeman, L., Mahony, R.,\n\nReducing the Sim-to-Real Gap for Event Cameras,\n\nEuropean Conf. Computer Vision (ECCV), 2020. PDF, Suppl. Mat., YouTube, Project page\n\nMostafavi, M., Wang, L., Yoon, K.J.,\n\nLearning to Reconstruct HDR Images from Events, with Applications to Depth and Flow Prediction,\n\nInt. J. Computer Vision (IJCV), 2021.\n\nMostafavi I., S.M., Wang, L., Ho, Y.S., Yoon, K.J.,\n\nEvent-based High Dynamic Range Image and Very High Frame Rate Video Generation using Conditional Generative Adversarial Networks,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019. PDF\n\nScheerlinck et al., CVPRW 2019,\n\nCED: Color Event Camera Dataset.\n\nNagata, J., Sekikawa, Y., Hara, K., Suzuki, T., Aoki, Y.,\n\nQR-code Reconstruction from Event Data via Optimization in Code Subspace,\n\nIEEE Winter Conf. Applications of Computer Vision (WACV), 2020.\n\nZhang, S., Zhang, Y., Jiang, Z., Zou, D., Ren, J., Zhou, B.,\n\nLearning to See in the Dark with Events,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat.\n\nSu, B., Yu, L., Yang, W.,\n\nEvent-Based High Frame-Rate Video Reconstruction With A Novel Cycle-Event Network,\n\nIEEE Int. Conf. Image Processing (ICIP), 2020.\n\nGantier Cadena, P. R., Qian, Y., Wang, C., Yang, M.,\n\nSPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction,\n\nIEEE Trans. Image Process. (TIP), 30:2488-2500, 2021. Project page\n\nBaldwin et al., TPAMI 2022.\n\nTime-Ordered Recent Event (TORE) Volumes for Event Cameras.\n\nParedes-Valles, F., de Croon, G. C. H. E.,\n\nBack to Event Basics: Self-Supervised Learning of Image Reconstruction for Event Cameras via Photometric Constancy,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021. Project page, PDF, Suppl. Mat., Code.\n\nZou, Y., Zheng, Y., Takatani, T., Fu, Y.,\n\nLearning To Reconstruct High Speed and High Dynamic Range Videos From Events,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021.\n\nYu, L., Zhang, X., Liao, W., Yang, W., Xia, G.-S.,\n\nLearning to See Through with Events,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2022. PDF, Project page, Dataset\n\nZhang, X., Liao, W., Yu, L., Yang, W., Xia, G.-S.,\n\nEvent-Based Synthetic Aperture Imaging With a Hybrid Network,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021. Suppl., PDF, YouTube, Slides\n\nLi, S., Gao, Y., Dai, Q.,\n\nImage De-occlusion via Event-enhanced Multi-modal Fusion Hybrid Network,\n\nMachine Intelligence Research, 2022. Code, Dataset.\n\nCohen Duwek, H., Shalumov, A., Ezra Tsur, E.,\n\nImage Reconstruction From Neuromorphic Event Cameras Using Laplacian-Prediction and Poisson Integration With Spiking and Artificial Neural Networks,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. YouTube.\n\nZhang, Z., Yezzi, A., Gallego, G.,\n\nFormulating Event-based Image Reconstruction as a Linear Inverse Problem with Deep Regularization using Optical Flow,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2022. PDF, Code\n\nZhu, L., Wang, X., Chang, Y., Li, J., Huang T., Tian Y,\n\nEvent-based Video Reconstruction via Potential-assisted Spiking Neural Network,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2022. Project page, PDF, Suppl. Mat., Code.\n\nLiu, S., Dragotti, P.L.,\n\nSensing Diversity and Sparsity Models for Event Generation and Video Reconstruction from Events,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2023. Code, Code for data generation, Code for evaluation\n\nLiu, S., Alexandru, R., Dragotti, P.L.,\n\nConvolutional ISTA Network with Temporal Consistency Constraints for Video Reconstruction from Event Cameras,\n\nIEEE Int. Conf. Acoust., Speech, Signal Proc. (ICASSP), 2022. Code\n\nLiu, S., Dragotti, P.L.,\n\nEnhanced Event-Based Video Reconstruction with Motion Compensation,\n\narxiv, 2024. Code\n\nQu, Q., Shen, Y., Chen, X., Chung, Y.Y., Liu, T.,\n\nE2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning,\n\nAAAI Conf. Artificial Intelligence (AAAI), 2024. Code\n\nErcan, B., Eker, O., Saglam, C., Erdem, A., Erdem, E.,\n\nHyperE2VID: Improving Event-Based Video Reconstruction via Hypernetworks,\n\nIEEE Trans. Image Process. (TIP), 33:1826-1837, 2024. PDF, Project Page, Code, YouTube.\n\nZhang, P., Liu, H., Ge, Z., Wang, C., Lam, E. Y.,\n\nNeuromorphic Imaging with Joint Image Deblurring and Event Denoising,\n\nIEEE Trans. Image Process. (TIP), 2024. PDF, Code\n\nBrandli, C., Muller, L., Delbruck, T.,\n\nReal-time, high-speed video decompression using a frame- and event-based DAVIS sensor,\n\nIEEE Int. Symp. on Circuits and Systems (ISCAS), 2014.\n\nBrandli, Ph.D. Thesis, 2014,\n\nEvent-Based Machine Vision - Section 4.11.\n\nLiu HC., Zhang FL., Marshall D., Shi L., Hu SM.,\n\nHigh-speed Video Generation with an Event Camera,\n\nThe Visual Computer, 2017. PDF.\n\nShedligeri, P.A., Mitra, K.,\n\nPhotorealistic Image Reconstruction from Hybrid Intensity and Event based Sensor,\n\nJ. Electronic Imaging, 28(6), 063012 (2019). PDF\n\nWang, Z. W., Jiang, W., He, K., Shi, B., Katsaggelos, A., Cossairt, O.,\n\nEvent-driven Video Frame Synthesis,\n\nIEEE Int. Conf. Computer Vision Workshops (ICCVW), 2019. PDF\n\nPan, L., Scheerlinck, C., Yu, X., Hartley, R., Liu, M., Dai, Y.,\n\nBringing a Blurry Frame Alive at High Frame-Rate with an Event Camera,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019. PDF. Slides, Video CVPR, Video CVPRW, Code\n\nPan, L., Hartley, R., Scheerlinck, C., Liu, M., Yu, X., Dai, Y.,\n\nHigh Frame Rate Video Reconstruction based on an Event Camera,\n\narXiv, 2019.\n\nOpen-source Rust implementation: davis-EDI-rs\n\nPini, S., Borghi, G., Vezzani, R., Cucchiara, R.,\n\nVideo Synthesis from Intensity and Event Frames,\n\nInt. Conf. Image Analysis and Processing (ICIAP), 2019. LNCS, vol 11751. PDF\n\nPini S., Borghi G., Vezzani R.,\n\nLearn to See by Events: Color Frame Synthesis from Event and RGB Cameras,\n\nInt. Joint Conf. on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP) 2020. PDF\n\nHaoyu, C., Minggui, T., Boxin, S., Yizhou, W., Tiejun, H.,\n\nLearning to Deblur and Generate High Frame Rate Video with an Event Camera,\n\narXiv:2003.00847, 2020.\n\nJiang, Z., Zhang, Y., Zou, D., Ren, J., Lv, J., Liu, Y.,\n\nLearning Event-Based Motion Deblurring,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020.\n\nWang, B., He, J., Yu, L., Xia, G.-S., Yang, W.,\n\nEvent Enhanced High-Quality Image Recovery,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat., Video\n\nLin, S., Zhang, J., Pan, J., Jiang, Z., Zou, D., Wang, Y., Chen, J., Ren, J.,\n\nLearning Event-Driven Video Deblurring and Interpolation,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat.\n\nZhang, L., Zhang, H., Chen, J., Wang, L.,\n\nHybrid Deblur Net: Deep Non-Uniform Deblurring With Event Camera,\n\nIEEE Access, 8:148075-148083, 2020.\n\nJiang, M., Liu, Z., Wang, B., Yu, L., Yang, W.,\n\nRobust Intensity Image Reconstruciton Based On Event Cameras,\n\nIEEE Int. Conf. Image Processing (ICIP), 2020.\n\nZhang, L., Zhang, H., Zhu, C., Guo, S., Chen, J., Wang, L.,\n\nFine-Grained Video Deblurring with Event Camera,\n\nMultiMedia Modeling (MMM) 2021. LNCS, vol 12572.\n\nTulyakov, S., Gehrig, D., Georgoulis, S., Erbach, J., Gehrig, M., Li, Y., Scaramuzza, D.,\n\nTime Lens: Event-Based Video Frame Interpolation,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021. Project page, Suppl., PDF, YouTube, Slides, Code\n\nPaikin, G., Ater, Y., Shaul, R., Soloveichik, E.,\n\nEFI-Net: Video Frame Interpolation from Fusion of Events and Frames,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. YouTube, Suppl., Dataset.\n\nSun, L., Sakaridis, C., Liang, J., Jiang, Q., Yang, K., Sun, P., Ye, Y., Wang, K., Gool, L.,\n\nEvent-Based Fusion for Motion Deblurring with Cross-modal Attention,\n\nEuropean Conf. Computer Vision (ECCV), 2022. PDF, Code, Suppl., Project page\n\nChen, H., Teng, M., Shi, B., Wang, Y., Huang, T.,\n\nA Residual Learning Approach to Deblur and Generate High Frame Rate Video With an Event Camera,\n\nIEEE Trans. Multimedia (TMM), 2022. PDF\n\nGao, Y., Li, S., Li, Y., Guo, Y., Dai, Q.,\n\nSuperFast: 200x Video Frame Interpolation via Event Camera,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2022. Code, Dataset.\n\nXiao, Z., Weng, W., Zhang, Y., Xiong, Z.,\n\nEVA2: Event-Assisted Video Frame Interpolation via Cross-Modal Alignment and Aggregation,\n\nIEEE Trans. Comput. Imag. (TCI), 8:1145-1158, 2022.\n\nTulyakov, S., Bochicchio, A., Gehrig, D., Georgoulis, S., Li, Y., Scaramuzza, D.,\n\nTime Lens++: Event-based Frame Interpolation with Parametric Non-linear Flow and Multi-scale Fusion, IEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2022. PDF, dataset, YouTube.\n\nSun, L., Sakaridis, C., Liang, J., Sun, P., Cao, J., Zhang, K., Jiang, Q., Wang, K., Gool, L.,\n\nEvent-Based Frame Interpolation with Ad-hoc Deblurring,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2023. Code, Project page\n\nFreeman, A., Singh, M., Mayer-Patel, K.,\n\nAn Asynchronous Intensity Representation for Framed and Event Video Sources,\n\nACM Multimedia Systems (MMSys), 2023. PDF, Code.\n\nWang, Z., Ng, Y., Scheerlinck, C., Mahony., R.,\n\nAn Asynchronous Linear Filter Architecture for Hybrid Event-Frame Cameras,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2023. PDF, Project Page, YouTube.\n\nWang, Z., Ng, Y., Scheerlinck, C., Mahony., R.,\n\nAn Asynchronous Kalman Filter for Hybrid Event Cameras,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2021. PDF, Code, YouTube, Suppl.\n\nWang, Z., Hamann, F., Chaney, K., Jiang, W., Gallego, G., Daniilidis, K.,\n\nEvent-based Continuous Color Video Decompression from Single Frames,\n\narxiv, 2023. Project page\n\nChen, J., Zhu, Y., Lian, D., Yang, J., Wang, Y., Zhang, R., Liu, X., Qian, S., Kneip, L., Gao, S.,\n\nRevisiting Event-Based Video Frame Interpolation,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2023. PDF, Project\n\nQi et al., ICCV 2023,\n\nE2NeRF: Event Enhanced Neural Radiance Fields from Blurry Images.\n\nLi, H., Li, G., Shi, L.,\n\nSuper-resolution of spatiotemporal event-stream image,\n\nNeurocomputing, 335:206-214, 2019. PDF pre-print\n\nMostafavi I., S.M., Choi, J., Yoon, K.-J.,\n\nLearning to Super Resolve Intensity Images from Events,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020. PDF, Code\n\nWang, L., Kim, T.-K., Yoon, K.-J.,\n\nEventSR: From Asynchronous Events to Image Reconstruction, Restoration, and Super-Resolution via End-to-End Adversarial Learning,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020. PDF, YouTube, Dataset\n\nJing, Y., Yang, Y., Wang, X., Song, M., Tao, D.,\n\nTurning Frequency to Resolution: Video Super-Resolution via Event Cameras,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021.\n\nDuan, P., Wang, Z. W., Zhou, X., Ma, Y., Shi, B.,\n\nEventZoom: Learning To Denoise and Super Resolve Neuromorphic Events,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021. Project page, Suppl.\n\nHan, J., Yang, Y., Zhou, C., Xu, C., Shi, B.,\n\nEvIntSR-Net: Event Guided Multiple Latent Frames Reconstruction and Super-resolution,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2021. PDF, Suppl.\n\nLi, S., Feng, Y., Li, Y., Jiang, Y., Zou, C., Gao, Y.,\n\nEvent Stream Super-Resolution via Spatiotemporal Constraint Learning,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2021. Code, Dataset.\n\nKai, D., Zhang, Y., Sun, X.,\n\nVideo Super-Resolution Via Event-Driven Temporal Alignment,\n\nIEEE Int. Conf. on Image Processing (ICIP), 2023. Code.\n\nKai, D., Lu, J., Zhang, Y., Sun, X.,\n\nEvTexture: Event-driven Texture Enhancement for Video Super-Resolution,\n\nInt. Conf. on Machine Learning (ICML), 2024. Project, Code.\n\nWang, Z. W., Duan, P., Cossairt, O., Katsaggelos, A., Huang, T., Shi, B.,\n\nJoint Filtering of Intensity Images and Neuromorphic Events for High-Resolution Noise-Robust Imaging,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020. YouTube, Dataset\n\nSimon Chane, C., Ieng, S.-H., Posch, C., Benosman, R.,\n\nEvent-Based Tone Mapping for Asynchronous Time-Based Image Sensor,\n\nFront. Neurosci. (2016), 10:391. PDF\n\nHan, J., Zhou, C., Duan, P., Tang, Y., Xu, C., Xu, C., Huang, T., Shi, B.,\n\nNeuromorphic Camera Guided High Dynamic Range Imaging,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020. PDF, Suppl. Mat.\n\nMessikommer, N., Georgoulis, S., Gehrig, D., Tulyakov, S., Erbach, J., Bochicchio, A., Li, Y., Scaramuzza, D.,\n\nMulti-Bracket High Dynamic Range Imaging with Event Cameras,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2022. PDF, YouTube.\n\nDelbruck, T., Villanueva, V., Longinotti, L.,\n\nIntegration of dynamic vision sensor with inertial measurement unit for electronically stabilized event-based vision,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2014. YouTube, YouTube 2: Stabilizing DVS output with IMU rate gyros, YouTube 3: hallway scene\n\nRodriguez-Gomez, J.P., Gallego, G., Martinez-de Dios, J.R., Ollero, A.,\n\nStabilizing Event Data on Flapping-wing Robots for Simpler Perception,\n\nIEEE Int. Conf. Robotics and Automation (ICRA) Workshop on Challenges of Flapping-wing Aerial Robots, 2022. Slides\n\nMei, H., Wang, Z., Yang, X., Wei, X., Delbruck, T.,\n\nDeep Polarization Reconstruction with PDAVIS Events,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2023. PDF, code.\n\nRebecq, H., Gallego, G., Mueggler, E., Scaramuzza, D.,\n\nEMVS: Event-Based Multi-View Stereo—3D Reconstruction with an Event Camera in Real-Time,\n\nInt. J. of Computer Vision (IJCV), 126(12):1394-1414, 2018. PDF, YouTube, Code.\n\nRebecq, H., Gallego, G., Scaramuzza, D.,\n\nEMVS: Event-based Multi-View Stereo,\n\nBritish Machine Vision Conf. (BMVC), 2016. PDF, YouTube, 3D Reconstruction Experiments from a Train using an Event Camera, Code.\n\nKim et al., ECCV 2016,\n\nReal-Time 3D Reconstruction and 6-DoF Tracking with an Event Camera.\n\nGallego, G., Rebecq, H., Scaramuzza, D.,\n\nA Unifying Contrast Maximization Framework for Event Cameras, with Applications to Motion, Depth and Optical Flow Estimation,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2018. PDF, Poster, YouTube, Spotlight presentation.\n\nHaessig, G., Berthelon, X., Ieng, S.-H., Benosman, R.,\n\nA Spiking Neural Network Model of Depth from Defocus for Event-based Neuromorphic Vision,\n\nScientific Reports 9, Article number: 3744 (2019). PDF\n\nGallego, G., Gehrig, M., Scaramuzza, D.,\n\nFocus Is All You Need: Loss Functions For Event-based Vision,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2019. PDF arXiv, Poster, YouTube\n\nChaney, K., Zhu, A., Daniilidis, K.,\n\nLearning Event-based Height from Plane and Parallax,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2019. PDF, Video pitch,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2019.\n\nZhu et al., CVPR 2019,\n\nUnsupervised Event-Based Learning of Optical Flow, Depth, and Egomotion.\n\nHidalgo-Carrió J., Gehrig D., Scaramuzza, D.,\n\nLearning Monocular Dense Depth from Events,\n\nIEEE Int. Conf. 3D Vision (3DV), 2020. PDF, YouTube, Code, Project Page.\n\nBaudron, A., Wang, Z. W., Cossairt, O., Katsaggelos, A. K.,\n\nE3D: Event-Based 3D Shape Reconstruction,\n\narXiv, 2020. Code.\n\nGehrig, D., Rüegg, M., Gehrig, M., Hidalgo-Carrió J., Scaramuzza, D.,\n\nCombining Events and Frames Using Recurrent Asynchronous Multimodal Networks for Monocular Depth Prediction,\n\nIEEE Robotics and Automation Letters (RA-L), 2021. PDF, Code, Project Page.\n\nMuglikar, M., Bauersfeld, L., Moeys, D., Scaramuzza, D.,\n\nEvent-based Shape from Polarization,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2023. PDF, YouTube, code.\n\nBrebion, V., Moreau, J., Davoine, F.,\n\nLearning to Estimate Two Dense Depths from LiDAR and Event Data,\n\n22nd Scandinavian Conference on Image Analysis (SCIA 2023), 2023. PDF, Project Page (suppl. mat., poster, code, dataset, videos).\n\nKlenk, S., Koestler, L., Scaramuzza, D., Cremers, D.,\n\nE-NeRF: Neural Radiance Fields from a Moving Event Camera,\n\nIEEE Robotics and Automation Letters (RA-L) 8(3):1587-1594, 2023. PDF, Code\n\nBrandli, C., Mantel, T.A., Hutter, M., Hoepflinger, M.A., Berner, R., Siegwart, R., Delbruck, T.,\n\nAdaptive Pulsed Laser Line Extraction for Terrain Reconstruction using a Dynamic Vision Sensor,\n\nFront. Neurosci. (2014), 7:275. PDF, YouTube\n\nMatsuda, N., Cossairt, O., Gupta, M.,\n\nMC3D: Motion Contrast 3D Scanning,\n\nIEEE Conf. Computational Photography (ICCP), 2015. PDF, YouTube, Project page\n\nLeroux, T., Ieng, S.-H., Benosman, R.,\n\nEvent-Based Structured Light for Depth Reconstruction using Frequency Tagged Light Patterns,\n\narXiv:1811.10771, 2018.\n\nMangalore, A. R., Seelamantula, C. S., Thakur, C. S.,\n\nNeuromorphic Fringe Projection Profilometry,\n\nIEEE Signal Process. Lett. (SPL), 27:1510-1514, 2020. Project page\n\nWang et al. JSEN,\n\nTemporal Matrices Mapping Based Calibration Method for Event-Driven Structured Light Systems.\n\nTakatani, T., Ito, Y., Ebisu, A., Zheng, Y., Aoto, T.,\n\nEvent-Based Bispectral Photometry Using Temporally Modulated Illumination,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021. Project page, Suppl. Mat., YouTube.\n\nHuang, X., Zhang, Y., Xiong Z.,\n\nHigh-speed structured light based 3D scanning using an event camera,\n\nOptics Express, 2021. Video.\n\nMuglikar, M., Gallego, G., Scaramuzza, D.,\n\nESL: Event-based Structured Light,\n\nIEEE Int. Conf. 3D Vision (3DV), 2021. Poster, YouTube, Project page and Dataset, Code.\n\nMuglikar, M., Moeys, D., Scaramuzza, D.,\n\nEvent Guided Depth Sensing,\n\nIEEE Int. Conf. 3D Vision (3DV), 2021. YouTube.\n\nWang, H., Liu, T., He, C., Li, C., Liu, J., Yu, L.,\n\nEnhancing Event-based Structured Light Imaging with a Single Frame,\n\nIEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), 2022.\n\nMorgenstern, W., Gard, N., Baumann, S., Hilsmann, A., Eisert, P.,\n\nX-maps: Direct Depth Lookup for Event-based Structured Light Systems,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2023. Project page, Code.\n\nWang, Z., Chaney, K., Daniilidis, K.,\n\nEvAC3D: From Event-based Apparent Contours to 3D Models via Continuous Visual Hulls,\n\nEuropean Conference on Computer Vision (ECCV), 2022. PDF, Project Page.\n\nChen, H., Chung, V., Tan, L., Chen, X.,\n\nDense Voxel 3D Reconstruction Using a Monocular Event Camera,\n\nInt. Conf. Virtual Reality (ICVR), 2023. PDF, Dataset.\n\nQi, Y., Zhu, L., Zhang, Y., Li, J.,\n\nE2NeRF: Event Enhanced Neural Radiance Fields from Blurry Images,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2023. PDF, Project Page, Code. Dataset.\n\nMisha Mahowald’s Stereo Chip - Tobi Delbruck- 2020 Telluride Neuromorphic workshop,\n\nA tour through Misha Mahowald's 1992 stereo fusion work at Caltech in Carver Mead's Physics of Computation lab.\n\nMahowald's PhD thesis, 1992, VLSI Analogs of Neuronal Visual Processing: A Synthesis of Form and Function.\n\nSchraml, C., Schon, P., Milosevic, N.,\n\nSmartcam for real-time stereo vision - address-event based embedded system,\n\nInt. Conf. Computer Vision Theory and Applications (VISAPP), 2007, pp. 466-471.\n\nSchraml, S., Belbachir, A. N., Milosevic, N., Schon, P.,\n\nDynamic stereo vision system for real-time tracking,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2010.\n\nSchraml, S., Belbachir, A. N.,\n\nA spatio-temporal clustering method using real-time motion analysis on event-based 3D vision,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2010. PDF\n\nSchraml, S., Belbachir, A. N., Braendle, N.,\n\nA Real-time Pedestrian Classification Method for Event-based Dynamic Stereo Vision,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2010. PDF\n\nSchraml, S., Belbachir, A. N., Braendle, N.,\n\nReal-time classification of pedestrians and cyclists for intelligent counting of non-motorized traffic,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2010. PDF\n\nKogler, J., Sulzbachner, C., Kubinger, W.,\n\nBio-inspired stereo vision system with silicon retina imagers,\n\nInt. Conf. Computer Vision Systems (ICVS), 2009.\n\nKogler, J., Humenberger, M., Sulzbachner, C.,\n\nEvent-Based Stereo Matching Approaches for Frameless Address Event Stereo Data,\n\nInt. Symp. Visual Computing (ISVC) 2011, Advances in Visual Computing, pp. 674-685.\n\nKogler, J., Sulzbachner, C., Humenberger, M., Eibensteiner, F.,\n\nAddress-Event Based Stereo Vision with Bio-Inspired Silicon Retina Imagers,\n\nAdvances in Theory and Applications of Stereo Vision (2011), pp. 165-188.\n\nKogler, J., Ph.D. Thesis 2016,\n\nDesign and evaluation of stereo matching techniques for silicon retina cameras.\n\nKogler, J., Sulzbachner, C., Eibensteiner, F., Humenberger, M.,\n\nAddress-Event Matching for a Silicon Retina based Stereo Vision System,\n\nInt. Conf. from Scientific Computing to Computational Engineering (IC-SCCE), 2010.\n\nSulzbachner, C., Kogler, J., Eibensteiner, F.,\n\nA novel verification approach for silicon retina stereo matching,\n\nIEEE Int. Symp. Electronics in Marine (ELMAR), 2010.\n\nSulzbachner, C., Zinner, C., Kogler, J.,\n\nAn optimized silicon retina stereo matching algorithm using time-space correlation,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2011. PDF\n\nEibensteiner, F., Kogler, J., Sulzbachner, C., Scharinger, J.,\n\nStereo-Vision Algorithm Based on Bio-Inspired Silicon Retinas for Implementation in Hardware,\n\nInt. Conf. Computer Aided Systems Theory EUROCAST, LNCS, pp. 624–631, 2011.\n\nEibensteiner, F., Kogler, J., Scharinger, J.,\n\nA High-Performance Hardware Architecture for a Frameless Stereo Vision Algorithm Implemented on a FPGA Platform,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2014. PDF\n\nEibensteiner, F., Brachtendorf, H. G., Scharinger, J.,\n\nEvent-driven stereo vision algorithm based on silicon retina sensors,\n\n27th Int. Conf. Radioelektronika, 2017.\n\nBelbachir, A.N., Schraml, S., Nowakoska, A.,\n\nEvent-Driven Stereo Vision for Fall Detection,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2011.\n\nBelbachir, A.N., Nowakoska, A., Schraml, S., Wiesmann, G., Sablatnig, R.,\n\nEvent-Driven Feature Analysis in a 4D Spatiotemporal Representation,\n\nIEEE Int. Conf. Computer Vision Workshops (ICCVW), 2011.\n\nBelbachir, A.N., Litzenberger, M., Schraml, S., Hofstätter, M., Bauer, D., Schön, P., Humenberger, M., Sulzbachner, C., Lunden, T., Merne, M.,\n\nCARE: A dynamic stereo vision sensor system for fall detection,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2012.\n\nHumenberger, M., Schraml, S., Sulzbachner, C., Belbachir, A.N., Srp A., Vajda, F.,\n\nEmbedded Fall Detection with a Neural Network and Bio-inspired Stereo Vision,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2012.\n\nBenosman, R., Ieng, S. H., Rogister, P., Posch, C.,\n\nAsynchronous Event-Based Hebbian Epipolar Geometry,\n\nIEEE Trans. Neural Netw., 22(11):1723-1734, 2011. PDF\n\nRogister, P. , Benosman, R., Ieng, S.-H., Lichtsteiner, P., Delbruck, T.,\n\nAsynchronous Event-Based Binocular Stereo Matching,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 23(2):347-353, 2012. PDF\n\nCarneiro, J., Ieng, S.-H., Posch, C., Benosman, R.,\n\nEvent-based 3D reconstruction from neuromorphic retinas,\n\nNeural Networks (2013), 45:27-38. PDF, YouTube, YouTube, YouTube, YouTube, YouTube, YouTube\n\nCarneiro, Ph.D. Thesis, 2014,\n\nAsynchronous Event-Based 3D Vision.\n\nLee et al., TNNLS 2014\n\nPiatkowska, E., Belbachir, A. N., Gelautz, M.,\n\nCooperative and asynchronous stereo vision for dynamic vision sensors,\n\nMeas. Sci. Technol. (2014), 25(5).\n\nPiatkowska, E., Belbachir, A. N., Gelautz, M.,\n\nAsynchronous Stereo Vision for Event-Driven Dynamic Stereo Sensor Using an Adaptive Cooperative Approach,\n\nIEEE Int. Conf. Computer Vision Workshops (ICCVW), 2013.\n\nPiatkowska, E., Kogler, J., Belbachir, A. N., Gelautz, M.,\n\nImproved Cooperative Stereo Matching for Dynamic Vision Sensors with Ground Truth Evaluation,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2017, pp. 370-377. PDF.\n\nCamuñas-Mesa, L. A., Serrano-Gotarredona, T., Ieng, S. H., Benosman, R. B., Linares-Barranco, B.,\n\nOn the use of orientation filters for 3D reconstruction in event–driven stereo vision,\n\nFront. Neurosci. (2014), 8:48. PDF\n\nCamuñas-Mesa, L. A., Serrano-Gotarredona, T., Linares-Barranco, B., Ieng, S., Benosman, R.,\n\nEvent-Driven Stereo Vision with Orientation Filters,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2014.\n\nKogler, J., Eibensteiner, F., Humenberger, M., Sulzbachner, C., Gelautz, M., Scharinger, J.,\n\nEnhancement of sparse silicon retina-based stereo matching using belief propagation and two-stage postfiltering,\n\nJ. Electronic Imaging, 23(4), 043011 (2014).\n\nKogler, J., Ph.D. Thesis 2016,\n\nDesign and evaluation of stereo matching techniques for silicon retina cameras.\n\nFirouzi, M. and Conradt, J.,\n\nAsynchronous Event-based Cooperative Stereo Matching Using Neuromorphic Silicon Retinas,\n\nNeural Processing Letters, 43(2):311-326, Apr. 2016. PDF\n\nDikov, G., Firouzi, M., Röhrbein, F., Conradt, J., Richter, C.,\n\nSpiking Cooperative Stereo-Matching at 2 ms Latency with Neuromorphic Hardware,\n\nConf. Biomimetic and Biohybrid Systems. Living Machines 2017: Biomimetic and Biohybrid Systems, pp. 119-137. LNCS, vol 10384. Springer, Cham. PDF, Videos\n\nKaiser, J., Weinland, J., Keller, P., Steffen, L., Vasquez Tieck, J.C., Reichard, D., Roennau, A., Conradt, J., Dillmann, R.,\n\nMicrosaccades for Neuromorphic Stereo Vision,\n\nInt. Conf. Artificial Neural Networks (ICANN), 2018.\n\nZou, D., Guo, P., Wang, Q., Wang, X., Shao, G., Shi, F., Li, J., Park, P.K.J.,\n\nContext-Aware Event-driven Stereo Matching,\n\nIEEE Int. Conf. Image Processing (ICIP), 2016.\n\nOsswald, M., Ieng, S.-H., Benosman, R., Indiveri, G.,\n\nA spiking neural network model of 3D perception for event-based neuromorphic stereo vision systems,\n\nScientific Reports 7, Article number: 40703 (2017). PDF\n\nHaessig et al., AICAS 2019,\n\nNeuromorphic networks on the SpiNNaker platform.\n\nZou, D., Shi, F., Liu, W., Li, J., Wang, Q., Park, P.K.J., Shi, C.-W., Roh, Y.J., Ryu, H.,\n\nRobust Dense Depth Map Estimation from Sparse DVS Stereos,\n\nBritish Machine Vision Conf. (BMVC), 2017. Supp. Material.\n\nCamuñas-Mesa, L. A., Serrano-Gotarredona, T., Ieng, S., Benosman, R., Linares-Barranco, B.,\n\nEvent-driven Stereo Visual Tracking Algorithm to Solve Object Occlusion,\n\nIEEE Trans. Neural Netw. Learn. Syst. (TNNLS), 2017.\n\nXie, Z., Chen, S., Orchard, G.\n\nEvent-Based Stereo Depth Estimation Using Belief Propagation,\n\nFront. Neurosci. (2017), 11:535. YouTube\n\nEverding, L., Ph.D. Thesis 2018,\n\nEvent-Based Depth Reconstruction Using Stereo Dynamic Vision Sensors.\n\nKaelber, F., Bachelor Thesis 2016,\n\nA probabilistic method for event stream registration.\n\nGalanis, M., Bachelor Thesis 2016,\n\nDVS event stream registration.\n\nAndreopoulos, A., Kashyap, H.J., Nayak, T.K., Amir, A., Flickner, M.D.,\n\nA Low Power, High Throughput, Fully Event-Based Stereo System,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2018.\n\nStereo Dataset.\n\nIeng, S.-H., Carneiro, J., Osswald, M., Benosman, R.,\n\nNeuromorphic Event-Based Generalized Time-Based Stereovision,\n\nFront. Neurosci. (2018), 12:442.\n\nCarneiro, Ph.D. Thesis, 2014,\n\nAsynchronous Event-Based 3D Vision - Chapter 4.\n\nZhu, A., Chen, Y., Daniilidis, K.,\n\nRealtime Time Synchronized Event-based Stereo,\n\nEuropean Conf. Computer Vision (ECCV), 2018. YouTube\n\nZhou, Y., Gallego, G., Rebecq, H., Kneip, L., Li, H., Scaramuzza, D.,\n\nSemi-Dense 3D Reconstruction with a Stereo Event Camera,\n\nEuropean Conf. Computer Vision (ECCV), 2018. Poster, YouTube.\n\nZhou et al., TRO 2021,\n\nESVO: Event-based Stereo Visual Odometry.\n\nDominguez-Morales, M., Dominguez-Morales, J. P., Jimenez-Fernandez, A., Linares-Barranco, A., Jimenez-Moreno, G.,\n\nStereo Matching in Address-Event-Representation (AER) Bio-Inspired Binocular Systems in a Field-Programmable Gate Array (FPGA),\n\nElectronics 2019, 8(4), 410.\n\nSteffen, L., Reichard, D., Weinland, J., Kaiser, J., Roennau, A., Dillmann, R.,\n\nNeuromorphic Stereo Vision: A Survey of Bio-Inspired Sensors and Algorithms,\n\nFront. Neurorobot. (2019) 13:28.\n\nSteffen, L., Hauck, B., Kaiser, J., Weinland, J., Ulbrich, S., Reichard, D., Roennau, A., Dillmann, R.,\n\nCreating an Obstacle Memory Through Event-Based Stereo Vision and Robotic Proprioception,\n\nIEEE Int. Conf. Automation Science and Engineering (CASE), 2019.\n\nHadviger, A., Markovic, I., Petrovic, I.,\n\nStereo Event Lifetime and Disparity Estimation for Dynamic Vision Sensors,\n\nEuropean Conf. Mobile Robots (ECMR), 2019. PDF arXiv.\n\nTulyakov, S., Fleuret, F., Kiefel, M., Gehler, P., Hirsch., M.,\n\nLearning an event sequence embedding for dense event-based deep stereo,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2019. PDF, Video\n\nSteffen, L., Ulbrich, S., Roennau, A., Dillmann, R.,\n\nMulti-View 3D Reconstruction With Self-Organizing Maps on Event-Based Data,\n\nIEEE Int. Conf. Advanced Robotics (ICAR), 2019.\n\nHadviger, A., Marković, I., Petrović, I.,\n\nStereo Dense Depth Tracking Based on Optical Flow using Frames and Events,\n\nAdvanced Robotics, 2020.\n\nAhmed, S. H., Jang, H. W., Uddin, S. M. N., & Jung, Y. J.,\n\nDeep Event Stereo Leveraged by Event-to-Image Translation,\n\nAAAI Conf. Artificial Intelligence, 2021. PDF, Video, Project page\n\nWang, Z., Pan, L., Ng, Y., Zhuang, Z., Mahony, R.,\n\nStereo Hybrid Event-Frame (SHEF) Cameras for 3D Perception,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2021. PDF, Video, Code and Data.\n\nGhosh, S., Gallego, G.,\n\nMulti-Event-Camera Depth Estimation and Outlier Rejection by Refocused Events Fusion (MCEMVS),\n\nAdvanced Intelligent Systems (AISY), 2022. YouTube, Presentation at IEEE MFI workshop 2022 (YouTube), Slides MFI 2022, Presentation at the GRASP Laboratory (UPenn) seminar, Project page (with Code),\n\nGhosh, S., Gallego, G.,\n\nSilicon retinas to help robots navigate the world,\n\nAdvanced Science News, 2022.\n\nGhosh, S., Gallego, G.,\n\nEvent-based Stereo Depth Estimation from Ego-motion using Ray Density Fusion,\n\n2nd Int. Ego4D Workshop at European Conf. Computer Vision Workshops (ECCVW), 2022.\n\nUddin, S.M.N., Ahmed, S.H., Jung, Y.J.,\n\nUnsupervised Deep Event Stereo for Depth Estimation,\n\nIEEE Trans. Circuits Syst. Video Technol. (TCSVT), 32(11):7489-7504, 2022.\n\nGu, J., Zhou, J., Chu, R.S.W., Chen, Y., Zhang, J., Cheng, X., Zhang, S., Ren, J.S.,\n\nSelf-Supervised Intensity-Event Stereo Matching,\n\nJ. Imaging Sci. Technol. 2023. Project page and Code.\n\nMartel, J.N.P., Mueller, J., Conradt, J., Sandamirskaya, Y.,\n\nAn Active Approach to Solving the Stereo Matching Problem using Event-Based Sensors,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2018.\n\nMartel, J.N.P., Müller, J., Conradt, J., Sandamirskaya, Y.,\n\nLive Demonstration: An Active System for Depth Reconstruction using Event-Based Sensors,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2018.\n\nsmart eye TUCO-3D camera,\n\nStereoscopic panoramic imaging camera based on dynamic vision sensors. PDF\n\nBelbachir, A. N., Pflugfelder, R., Gmeiner, P.,\n\nA Neuromorphic Smart Camera for Real-time 360deg distortion-free Panoramas,\n\nIEEE Conference on Distributed Smart Cameras (ICDSC), 2010. PDF\n\nBelbachir, A.N., Mayerhofer, M., Matolin, D., Colineau, J.,\n\nReal-time 360 degrees Panoramic Views using BiCa360, the Fast Rotating Dynamic Vision Sensor to up to 10 Rotations per Sec,\n\nIEEE Int. Symp. Circuits and Systems (ISCAS), 2012.\n\nBelbachir, A.N., Mayerhofer, M., Matolin, D., Colineau, J.,\n\n360SCAN: High-speed rotating line sensor for real-time 360 degrees panoramic vision,\n\nIEEE Int. Conf. Distributed Smart Cameras (ICDSC), 2012.\n\nBelbachir, A. N., Schraml, S., Mayerhofer, M., Hofstatter, M.,\n\nA Novel HDR Depth Camera for Real-time 3D 360-degree Panoramic Vision,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2014, pp. 419-426. PDF\n\nSchraml, S., Belbachir, A. N., Bischof, H.,\n\nEvent-Driven Stereo Matching for Real-Time 3D Panoramic Vision,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2015, pp. 466-474. PDF. Slides.\n\nSchraml, S., Belbachir, A. N., Bischof, H.,\n\nAn Event-Driven Stereo System for Real-Time 3-D 360° Panoramic Vision,\n\nIEEE Trans. Ind. Electron., 63(1):418-428, 2016.\n\nWeikersdorfer, D. and Conradt, J.,\n\nEvent-based particle filtering for robot self-localization,\n\nIEEE Int. Conf. Robotics and Biomimetics (ROBIO), 2012. PDF\n\nCensi, A., Strubel, J., Brandli, C., Delbruck, T., Scaramuzza, D.,\n\nLow-latency localization by Active LED Markers tracking using a Dynamic Vision Sensor,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2013. PDF, Slides\n\nMueggler, E., Huber, B., Scaramuzza, D.,\n\nEvent-based, 6-DOF Pose Tracking for High-Speed Maneuvers,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), Chicago, IL, 2014, pp. 2761-2768. PDF, YouTube\n\nGallego, G., Forster, C., Mueggler, E., Scaramuzza, D.,\n\nEvent-based Camera Pose Tracking using a Generative Event Model,\n\narXiv:1510.01972, 2015.\n\nMueggler, E., Gallego G., Scaramuzza, D.,\n\nContinuous-Time Trajectory Estimation for Event-based Vision Sensors,\n\nRobotics: Science and Systems (RSS), 2015. PDF, PPT, Poster\n\nReverter Valeiras, D., Orchard, G., Ieng, S.-H., Benosman, R.,\n\nNeuromorphic Event-Based 3D Pose Estimation.\n\nFront. Neurosci. (2016), 9:522. PDF, Suppl. Mat., YouTube\n\nReverter Valeiras, D., Kime, S., Ieng, S.-H., Benosman, R.,\n\nAn Event-Based Solution to the Perspective-n-Point Problem,\n\nFront. Neurosci. (2016), 10:208. PDF, Suppl. Mat.\n\nYuan, W., Ramalingam, S.,\n\nFast Localization and Tracking using Event Sensors,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2016. PDF, Video\n\nMueggler et al., IJRR 2017.\n\nThe Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM.\n\nGallego, G., Lund, J.E.A., Mueggler, E., Rebecq, H., Delbruck, T., Scaramuzza, D.,\n\nEvent-based, 6-DOF Camera Tracking from Photometric Depth Maps,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2018. PDF, YouTube, Datasets\n\nNguyen, A., Do, T.-T., Caldwell, D. G., Tsagarakis, N. G.,\n\nReal-Time 6DOF Pose Relocalization for Event Cameras with Stacked Spatial LSTM Networks,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2019. PDF. Project page. Video pitch\n\nMaqueda et al., CVPR 2018.\n\nEvent-based Vision meets Deep Learning on Steering Prediction for Self-driving Cars.\n\nGallego et al., CVPR 2018,\n\nA Unifying Contrast Maximization Framework for Event Cameras, with Applications to Motion, Depth and Optical Flow Estimation.\n\nBryner, S., Gallego, G., Rebecq, H., Scaramuzza, D.,\n\nEvent-based, Direct Camera Tracking from a Photometric 3D Map using Nonlinear Optimization,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2019. PDF, YouTube, Project page and Datasets\n\nGallego et al., CVPR 2019,\n\nFocus Is All You Need: Loss Functions For Event-based Vision.\n\nZhu et al., CVPR 2019,\n\nUnsupervised Event-Based Learning of Optical Flow, Depth, and Egomotion.\n\nXu, J., Jiang, M., Yu, L., Yang, W., Wang, W.,\n\nRobust Motion Compensation for Event Cameras With Smooth Constraint,\n\nIEEE Trans. Comput. Imag. (TCI), 6:604-614, 2020.\n\nFischer, T., Milford, M.,\n\nEvent-based visual place recognition with ensembles of spatio-temporal windows,\n\nIEEE Robotics and Automation Letters (RA-L), 5(4):6924-6931, 2020. PDF including Suppl. Mat., Code\n\nKreiser, R., Renner, A., Leite, V.R.C., Serhan, B., Bartolozzi, C., Glover, A., Sandamirskaya, Y.,\n\nAn On-chip Spiking Neural Network for Estimation of the Head Pose of the iCub Robot,\n\nFront. Neurosci. (2020), 14:551.\n\nNunes, U.M., Demiris, Y.,\n\nEntropy Minimisation Framework for Event-based Vision Model Estimation,\n\nEuropean Conf. Computer Vision (ECCV), 2020. Suppl. Mat., YouTube, Code\n\nNunes, U.M., Demiris, Y.,\n\nLive Demonstration: Incremental Motion Estimation for Event-Based Cameras by Dispersion Minimisation,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. Code\n\nNunes, U.M., Demiris, Y.,\n\nRobust Event-based Vision Model Estimation by Dispersion Minimisation,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 2021. Suppl. Mat., Code\n\nPeng, X., Wang, Y., Gao, L., Kneip, L.,\n\nGlobally-Optimal Event Camera Motion Estimation,\n\nEuropean Conf. Computer Vision (ECCV), 2020. PDF, Suppl. Mat., YouTube\n\nPeng, X., Gao, L., Wang, Y., Kneip, L.,\n\nGlobally-Optimal Contrast Maximisation for Event Cameras,\n\nIEEE Trans. Pattern Anal. Machine Intell. (TPAMI), 44(7):3479-3495, 2022. PDF\n\nBertrand, J., Yigit, A., Durand, S.,\n\nEmbedded Event-based Visual Odometry,\n\nIEEE Int. Conf. Event-Based Control Comm. and Signal Proc. (EBCCSP), 2020. Code\n\nChamorro, W., Andrade-Cetto, J., Solà, J.,\n\nHigh-Speed Event Camera Tracking,\n\nBritish Machine Vision Conf. (BMVC), 2020. PDF, Suppl. Mat., PDF\n\nChen, G., Chen, W., Yang, Q., Xu, Z., Yang, L., Conradt, J., Knoll, A.,\n\nA Novel Visible Light Positioning System With Event-Based Neuromorphic Vision Sensor,\n\nIEEE Sensors Journal, 20(17):10211-10219, 2020.\n\nKong, D., Fang, Z., Li, H., Hou, K., Coleman, S., Kerr, D.,\n\nEvent-VPR: End-to-End Weakly Supervised Network Architecture for Event-based Visual Place Recognition,\n\narXiv, 2020.\n\nJiao, J., Huang, H., Li, L., He, Z., Zhu, Y., Liu, M.,\n\nComparing Representations in Tracking for Event Camera-Based SLAM,\n\nIEEE Conf. Computer Vision and Pattern Recognition Workshops (CVPRW), 2021. YouTube, Code.\n\nGu, C., Learned-Miller, E., Sheldon, D., Gallego, G., Bideau, P.,\n\nThe Spatio-Temporal Poisson Point Process: A Simple Model for the Alignment of Event Camera Data,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2021. Project page, Code\n\nPeng, X., Xu, W., Yang, J., Kneip, L.,\n\nContinuous Event-Line Constraint for Closed-Form Velocity Initialization,\n\nBritish Machine Vision Conf. (BMVC), 2021, PDF, Video\n\nLee, A. J., Kim, A.,\n\nEventVLAD: Visual Place Recognition with Reconstructed Edges from Event Cameras,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2021, PDF\n\nShiba, S., Aoki, Y., Gallego, G.,\n\nA Fast Geometric Regularizer to Mitigate Event Collapse in the Contrast Maximization Framework,\n\nAdvanced Intelligent Systems, 2022. PDF, YouTube, Project page\n\nChamorro, W. O., Solà, J., Andrade-Cetto, J.,\n\nEvent-based SLAM in real-time,\n\nIEEE Robotics and Automation Letters, 7(3):8146-8153, 2022. PDF, Video\n\nJi, X., Wei, J., Wang, Y., Shang, H., Kneip, L.,\n\nCross-modal Place Recognition in Image Databases using Event-based Sensors,\n\narXiv, 2023.\n\nMuthusamy, R., Ayyad, A., Halwani, M., Swart, D., Gan, D., Seneviratne, L., Zweiri, Y.,\n\nNeuromorphic Eye-in-Hand Visual Servoing,\n\nIEEE Access, 2021. YouTube.\n\nGomez Eguiluz, A., Rodriguez-Gomez, J.P., Martinez-de Dios, J.R., Ollero, A.,\n\nAsynchronous Event-based Line Tracking for Time-to-Contact Maneuvers in UAS,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2020. Youtube.\n\nGomez Eguiluz, A., Rodriguez-Gomez, J.P., Tapia, R., F.J., Maldonado, J.A., Acosta, J.R., Martinez-de Dios, Ollero, A.,\n\nWhy fly blind? Event-based visual guidance for ornithopter robot flight,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2021. PDF, Youtube.\n\nSee Depth Estimation (3D Reconstruction)\n\nCook et al., IJCNN 2011,\n\nInteracting maps for fast visual interpretation. (Joint estimation of optical flow, image intensity and angular velocity with a rotating event camera).\n\nWeikersdorfer, D., Hoffmann, R., Conradt. J.,\n\nSimultaneous localization and mapping for event-based vision systems.\n\nInt. Conf. Computer Vision Systems (ICVS), 2013, pp. 133-142. PDF, Slides\n\nKim et al., BMVC 2014,\n\nSimultaneous Mosaicing and Tracking with an Event Camera.\n\nCensi, A. and Scaramuzza, D.,\n\nLow-latency Event-based Visual Odometry,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2014, pp. 703-710. PDF, Slides\n\nWeikersdorfer, D., Adrian, D. B., Cremers, D., Conradt, J.,\n\nEvent-based 3D SLAM with a depth-augmented dynamic vision sensor,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2014, pp. 359-364.\n\nWeikersdorfer, Ph.D. Thesis, 2014,\n\nEfficiency by Sparsity: Depth-Adaptive Superpixels and Event-based SLAM.\n\nKueng, B., Mueggler, E., Gallego, G., Scaramuzza, D.,\n\nLow-Latency Visual Odometry using Event-based Feature Tracks,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2016, pp. 16-23. PDF. YouTube\n\nKim, H., Leutenegger, S., Davison, A.J.,\n\nReal-Time 3D Reconstruction and 6-DoF Tracking with an Event Camera,\n\nEuropean Conf. Computer Vision (ECCV), 2016, pp. 349-364. PDF, YouTube, YouTube 2\n\nGallego, G. and Scaramuzza, D.,\n\nAccurate Angular Velocity Estimation with an Event Camera,\n\nIEEE Robotics and Automation Letters (RA-L), 2(2):632-639, 2017. PDF, PPT, Youtube.\n\nRebecq, H., Horstschaefer, T., Gallego, G., Scaramuzza, D.,\n\nEVO: A Geometric Approach to Event-based 6-DOF Parallel Tracking and Mapping in Real-time,\n\nIEEE Robotics and Automation Letters (RA-L), 2(2):593-600, 2017. PDF, PPT, Poster, Youtube, Code.\n\nReinbacher, C., Munda, G., Pock, T.,\n\nReal-Time Panoramic Tracking for Event Cameras,\n\nIEEE Int. Conf. Computational Photography (ICCP), 2017. PDF, YouTube, Code\n\nMueggler et al., IJRR 2017.\n\nThe Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM.\n\nZhu, D., Dong, J., Xu, Z., Ye, C., Hu, Y., Su, H., Liu, Z., Chen, G.,\n\nNeuromorphic Visual Odometry System for Intelligent Vehicle Application with Bio-inspired Vision Sensor,\n\nIEEE Int. Conf. Robotics and Biomimetics (ROBIO), 2019. PDF\n\nPark, P.K.J., Kim, J.-S., Shin, C.-W, Lee, H., Liu, W., Wang, Q., Roh, Y., Kim, J., Ater, Y., Soloveichik, E., Ryu, H. E.,\n\nLow-Latency Interactive Sensing for Machine Vision,\n\nIEEE Int. Electron Devices Meeting (IEDM), 2019.\n\nLiu, D., Parra, A., Chin, T.-J.,\n\nGlobally Optimal Contrast Maximisation for Event-based Motion Estimation,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2020. Project page\n\nGehrig, M., Shrestha, S. B., Mouritzen, D., Scaramuzza, D.,\n\nEvent-Based Angular Velocity Regression with Spiking Networks,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2020. PDF, Code\n\nKim, H., Kim, H.J.,\n\nReal-Time Rotational Motion Estimation With Contrast Maximization Over Globally Aligned Events,\n\nIEEE Robotics and Automation Letters (RA-L), 6(3):6016-6023, 2021. Project page and Dataset, YouTube, Code\n\nLiu, D., Parra, A., Chin, T.-J.,\n\nSpatiotemporal Registration for Event-Based Visual Odometry,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2021. Suppl. Mat., PDF, Dataset\n\nWang, Y., Yang, J., Peng, X., Wu, P., Gao, L., Huang, K., Chen, J., Kneip, L.,\n\nVisual Odometry with an Event Camera Using Continuous Ray Warping and Volumetric Contrast Maximization,\n\nSensors 22 (15), 5687.\n\nZuo, Y., Yang, J., Chen, J., Wang, X., Wang, Y., Kneip, L.,\n\nDEVO: Depth-Event Camera Visual Odometry in Challenging Conditions,\n\nIEEE Int. Conf. Robotics and Automation (ICRA), 2022. PDF, YouTube\n\nHidalgo-Carrió J., Gallego, G., Scaramuzza, D.,\n\nEDS: Event-aided Direct Sparse Odometry,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2022. Poster, YouTube, Project page and dataset, Code\n\nGao, L., Su, H., Gehrig, D., Cannici, M., Scaramuzza, D., Kneip, L.,\n\nA 5-Point Minimal Solver for Event Camera Relative Motion Estimation,\n\nIEEE Int. Conf. Computer Vision (ICCV), 2023. Project Webpage, PDF, Poster, Oral Presentation, Code\n\nGao, L., Gehrig, D., Su, H., Scaramuzza, D., Kneip, L.,\n\nAn N-Point Linear Solver for Line and Motion Estimation with Event Cameras,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2024. Project Webpage, PDF, Poster, Oral Presentation, Code\n\nZuo, Y., Xu, W., Wang, X., Wang, Y., Kneip, L.,\n\nCross-Modal Semi-Dense 6-DoF Tracking of an Event Camera in Challenging Conditions,\n\nIEEE Trans. Robot. (TRO), 2024. PDF, Code\n\nXu, W., Zhang, S., Cui, L., Peng, X., Kneip, L.,\n\nEvent-Based Visual Odometry on Non-Holonomic Ground Vehicles,\n\nIEEE Int. Conf. 3D Vision (3DV), 2024. PDF, Code, YouTube\n\nKlenk, S., Motzet, M., Koestler, L., Cremers, D.,\n\nDeep Event Visual Odometry,\n\nIEEE Int. Conf. 3D Vision (3DV), 2024. Code, YouTube\n\nMollica et al., T-ITS 2024,\n\nMA-VIED: A Multisensor Automotive Visual Inertial Event Dataset.\n\nGuo, S. and Gallego, G.,\n\nCMax-SLAM: Event-based Rotational-Motion Bundle Adjustment and SLAM System using Contrast Maximization,\n\nIEEE Trans. Robot. (TRO), 2024. Project page, YouTube, ECRot Dataset\n\nShiba et al. TPAMI 2024,\n\nSecrets of Event-based Optical Flow, Depth and Ego-motion Estimation by Contrast Maximization.\n\nZhou, Y., Gallego, G., Shen, S.,\n\nESVO: Event-based Stereo Visual Odometry,\n\nIEEE Trans. Robot. (TRO), 2021. Project page, PDF, YouTube, Code.\n\nXiao et al., arXiv 2021,\n\nResearch on Event Accumulator Settings for Event-Based SLAM.\n\nShiba et al. TPAMI 2024,\n\nSecrets of Event-based Optical Flow, Depth and Ego-motion Estimation by Contrast Maximization.\n\nMueggler, E., Gallego, G., Rebecq, H., Scaramuzza, D.,\n\nContinuous-Time Visual-Inertial Odometry for Event Cameras,\n\nIEEE Trans. Robot. (TRO), 2018.\n\nMueggler et al., IJRR 2017.\n\nThe Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM.\n\nZhu, A., Atanasov, N., Daniilidis, K.,\n\nEvent-based Visual Inertial Odometry,\n\nIEEE Conf. Computer Vision and Pattern Recognition (CVPR), 2017. PDF, Supplementary material, YouTube, YouTube 2\n\nRebecq, H., Horstschaefer, T., Scaramuzza, D.,\n\nReal-time Visual-Inertial Odometry for Event Cameras using Keyframe-based Nonlinear Optimization,\n\nBritish Machine Vision Conf. (BMVC), 2017. PDF, Appendix, YouTube, Project page, PPT, Oral presentation.\n\nRosinol Vidal, A., Rebecq, H., Horstschaefer, T., Scaramuzza, D.,\n\nUltimate SLAM? Combining Events, Images, and IMU for Robust Visual SLAM in HDR and High Speed Scenarios,\n\nIEEE Robotics and Automation Letters (RA-L), 3(2):994-1001, Apr. 2018. PDF, YouTube, Poster, Project page, ICRA18 video pitch.\n\nNelson, K. J., MSc Thesis 2019,\n\nEvent-Based Visual-Inertial Odometry on a Fixed-Wing Unmanned Aerial Vehicle.\n\nRebecq et al., TPAMI 2020,\n\nHigh Speed and High Dynamic Range Video with an Event Camera.\n\nRebecq et al., CVPR 2019,\n\nEvents-to-Video: Bringing Modern Computer Vision to Event Cameras.\n\nFriedel, Z. P., MSc Thesis 2020,\n\nEvent-Based Visual-Inertial Odometry Using Smart Features.\n\nLe Gentil, C., Tschopp, F., Alzugaray, I., Vidal-Calleja, T., Siegwart, R., Nieto, J.,\n\nIDOL: A Framework for IMU-DVS Odometry using Lines,\n\nIEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), 2020. PDF\n\nXiao, K., Wang, G., Chen, Y., Xie, Y., Li, H.,\n\nResearch on Event Accumulator Settings for Event-Based SLAM,\n\narXiv, 2021. PDF(Monocular VIO ony), Code (VIO and Stereo).\n\nMahlknecht, F., Gehrig, D., Nash, J., Rockenbauer, F., Morrell, B., Delaune, J., Scaramuzza, D.,\n\nExploring Event Camera-based Odometry for Planetary Robots,\n\nIEEE Robotics and Automation Letters (RA-L),2022. PDF, code&dataset, YouTube.\n\nCham"
    }
}