{
    "id": "dbpedia_6549_2",
    "rank": 84,
    "data": {
        "url": "https://eoopenscience.esa.int/page_session40.php",
        "read_more_link": "",
        "language": "en",
        "title": "EO Open Science 2017",
        "top_image": "",
        "meta_img": "",
        "images": [
            "https://eoopenscience.esa.int/files/eo_open_science_app_img.jpg",
            "https://eoopenscience.esa.int/files/video_preview.png",
            "https://eoopenscience.esa.int/files/video_talk_gallery_image.jpg",
            "https://eoopenscience.esa.int/files/video_poster_gallery_image.jpg",
            "https://eoopenscience.esa.int/files/social_media_story.jpg",
            "https://eoopenscience.esa.int/files/EOscience16_website_twitter.jpg",
            "https://eoopenscience.esa.int/files/EOscience16_website_facebook.jpg"
        ],
        "movies": [],
        "keywords": [],
        "meta_keywords": [
            ""
        ],
        "tags": null,
        "authors": [],
        "publish_date": null,
        "summary": "",
        "meta_description": "",
        "meta_lang": "en",
        "meta_favicon": "",
        "meta_site_name": "",
        "canonical_link": null,
        "text": "Visualisation and Virtual labs\n\nBack\n\n2017-09-28 11:00 - 2017-09-28 13:15\n\nChairs: fab, FABRICE (OCEANDATALAB) - Natali, Stefano (SISTEMA gmbH)\n\nPaper 108 - Session title: Visualisation and Virtual labs\n\n12:00 SAMI: High Resolution 3D Visualisation of Earth Observation Satellite Missions\n\nPinol Sole, Montserrat; Zundo, Michele ESA/ESTEC, Netherlands, The\n\nShow abstract\n\nThis paper presents a software application for visualization of high-resolution 3D satellite mission scenarios distributed by the ESA-ESTEC EOP System Support Division to users part of the ESA Earth Observation Earth Explorer and Copernicus satellites community. The SAMI (SAtellite MIssion Editor & Player) application plays stunning high-resolution 3D and 2D animations of ESA Earth Observation satellites. SAMI displays the satellite orbit ground-tracks and footprints of the instruments on-board, flags the entering in area of visibility between the satellite and the ground stations and applies user-selected global Earth map images as layer texture. The realistic Sun illumination allows observing shadow casting from the various satellite model elements. It is possible as well to trigger the deployment sequence of solar arrays and antennas and schedule thruster firing events. The time window in the application can be configured as simulated time (in the past or in the future) or real-time. In addition an endless loop simulation mode is available, with the objective to replay a given sequence. With the editing capabilities of SAMI, the user can drive the various camera views (camera attached to the Earth or to the satellite) and enable disable objects in the scene, generating standalone animation for kiosk type application and export it to HD video or series of snapshots. The missions currently supported are Sentinel 1A/1B, Sentinel 2A/2B, Sentinel 3A/3B, Sentinel5P, SWARM, Cryosat, SMOS and Aeolus. The capability to seamlessly display several satellites simultaneously is one of the stronger features of SAMI. The coherence and accuracy of the orbital and geometrical calculations within the SAMI application is ensured by the use of embedded Earth Observation CFI Software libraries (EOCFI SW). The libraries are used to obtain the satellite position, orbit ground-track, attitude and swath footprint. Typical use cases for this application would be the playback of a scenario in time to observe a particular satellite geometry, export screenshots or video to be used as media content or share it with stakeholders to illustrate mission concepts. The application runs on desktop platforms (Mac OS X, Windows) and mobile platforms (iOS based, e.g. iPad). REFERENCES [REF 1 ] SAMI website: http://eop-cfi.esa.int/index.php/applications/sami\n\nPresentation\n\n[Authors] [ Overview programme]\n\nPaper 125 - Session title: Visualisation and Virtual labs\n\n12:30 The Coastal Waters Research Synergy Framework, For Unlocking Our Potential For Coastal Innovation Growth\n\nTerra-Homem, Miguel (1); Grosso, Nuno (1); Catarino, Nuno (1); Scarrot, Rory (2); Politi, Eirini (2); Cronin, Abigail (2) 1: Deimos Engenharia, Portugal; 2: University College Cork, Ireland\n\nShow abstract\n\nUntil recently, scientists had to deal with the daunting task of mining large datasets for suitable data, and often downloading EO information from various different sources. In addition, as the datasets increased in volume, the processing has become slower and demanding of better computing facilities. The Coastal Waters Research Synergy Framework (Co-ReSyF) project aims to tackle these issues, by developing a platform for combined data access, processing, visualisation and output in one place. The platform is based on cloud computing to maximise processing effort and task orchestration. The platform is to support researchers in the field of monitoring the economic and social coastal activities (e.g. fisheries, harbour operations, ship traffic monitoring, oil spill detection) in a changing world. Co-ReSyF is a 3-year project (2016-2018) funded by the European Union, within the European Union’s Horizon 2020 research and innovation programme under grant agreement No 687289. The project supports research applications using Earth Observation (EO) data for Coastal Water Research. Co-ReSyF will create a cloud platform, which simplifies integration of EO data use into multi-disciplinary research activities. This platform aims to be user friendly and accessible to inexperienced scientists as well as EO and coastal experts. We will reach a wide community of coastal and oceanic researchers, who are offered the opportunity to experience, test and guide the development of the platform, whilst using it as a tool for their own research. The platform will include a set of 5 core Research Applications, developed under the project, and also a set of tools that the researchers can use to build their own applications in a user friendly manner. Additionally other potential tools or applications can be added by the research community for sharing with other reseatchers that may find it useful. The set of core applications to be developed during the project lifetime are: • Bathymetry Determination from SAR Images • Determination of bathymetry, benthic classification and water quality from optical sensors • Vessel and oil spill detection • Time-series processing for hyper-temporal optical data analysis • Ocean coastal altimetry Additionally a group of 8 Master/PhD students have been selected to attend a Summer School where they will learn how to use the platform and will also contribute with their own tools and/or applications to be incorporated into the platform.\n\nPresentation\n\n[Authors] [ Overview programme]\n\nPaper 138 - Session title: Visualisation and Virtual labs\n\n11:45 Space Big Image Tool\n\nIacobellis, Michele; Agrimano, Luigi; Amoruso, Leonardo Planetek Italia s.r.l., Italy\n\nShow abstract\n\nSpaceBIT is a platform whose main purpose is to help the scientist and the algorithm designer to change their way of thinking from \"sequential\" to \"massively parallel\". This is accomplished by creating a processing and visualization pipeline conceived from scratch, entirely devoted to the exploitation of GPUs and next-generation multi-core CPUs. The scientist and the designer are able to prototype and experiment their ideas by writing programs suited for running on GPUs that are injected into the processing pipeline in real-time. The infrastructure takes care of managing the input and output of very large SAR and multi-spectral/hyper-spectral images, collecting results just-in-time and displaying them on a visualization medium, focusing on next generation devices for virtual and augmented reality. By SpaceBIT the user is able to interact with images of tens GB, in standard data formats as HDF5, HDF-EOS, TIFF, JPEG, FITS.\n\nPresentation\n\n[Authors] [ Overview programme]\n\nPaper 153 - Session title: Visualisation and Virtual labs\n\n11:30 NASA Web World Wind taking part in GSoC\n\nKilsedar, Candan Eylül (1); Battaglia, Simone (2); Prestifilippo, Gabriele (1); Balhar, Jakub (3); Hogan, Patrick (4); Brovelli, Maria Antonia (1) 1: Politecnico di Milano, Italy; 2: University of Bologna, Italy; 3: Gisat, Czech Republic; 4: NASA Ames Research Center, CA USA\n\nShow abstract\n\nOpen Source Geospatial Foundation (OSGeo) has participated in Google Summer of Code (GSoC) initiative since the summer of 2007. GSoC is a program that sponsors the development of open source projects by involving university students and letting them work side by side with developers and managers of these projects. In the last two years NASA Web World Wind projects have participated in this venture. NASA Web World Wind is a 3D virtual globe Application Programming Interface (API)-centric SDK (Software Development Kit). This summer of 2017, two projects have been selected that provide additional functionality to NASA Web World Wind. These two 2017 projects are 3D OpenStreetMap (OSM) Plugin and Marker Clustering Plugin. The goal of the 3D OSM Plugin is to provide capability to easily display 3D OSM data in NASA Web World Wind. The first feature of 3D OSM Plugin will be to display buildings, with the ability to further extend this feature. First, OSM data is fetched in real time, based on a bounding box or a URL for OSM data. Then this plugin offers a function to extrude the polygons in the fetched data with an arbitrary height value. The performance of 3D rendering will be optimized by using triangle meshes instead of polygons. Additionally, the project has the ability to incorporate actual heights of buildings using Digital Surface Model (DSM) data and to apply these heights to the extrusion. 3D OSM Plugin will also improve performance via various caching techniques and tiling schemes. In the case of tiling being implemented, a new plugin can be created to also tile any GeoJSON data. The Marker Clustering Plugin improves the functionality of visualizing placemarks (markers) on a map with the possibility of rendering, at run time, a large number of markers without requiring the need for high GPU performance. This is achieved thanks to a clustering algorithm running in the background creating clusters on the fly for the placemarks that need to be rendered. Moreover, the plugin supports a high degree of customization for the markers via an easy-to-use interface.\n\nPresentation\n\n[Authors] [ Overview programme]\n\nPaper 187 - Session title: Visualisation and Virtual labs\n\n12:15 Ocean multisensor synergy from Sentinel 1-2-3\n\nCollard, Fabrice (1); Gaultier, Lucile (1); Herlédan, Sylvain (1); El Khoury Hanna, Ziad (1); Le Seach, Guillaume (1); Guitton, Gilles (1); Konik, Marta (2); Korosov, Anton (3) 1: OCEANDATALAB, France; 2: IOPAN, Poland; 3: NERSC, Norway\n\nShow abstract\n\nThe fully operational Ocean Sentinel-1-2-3 constellation provides a wide range of view angles to the ocean surface from the coast to the open ocean, at various scales and from physical to biological processes. Discovering jointly this huge heterogeneous dataset in a simple, fast and convenient way is now possible using the Ocean Virtual Laboratory portal online or the standalone version. Today, these tools are widely used by the scientific community to better understand and monitor oceanic processes. A collection of use cases will be demonstrated to illustrate the functionalities of these tools: - Collocating Sentinel-1 and Sentinel-3 data enables to detect oceanic fronts and eddies, highlighting strong and energetic ocean currents. - Using jointly Sentinel-1-2 and Sentinel-3 helps to detect oil spills as well as their displacement. - Analyzing overlapping Sentinel-1-2-3 helps to assess ocean wave parameters and their intensification by surface currents or bottom topography. Interactive demo of the tools will also be available on the OceanDataLab booth. Online tool is available at http://ovl.oceandatalab.com\n\n[Authors] [ Overview programme]\n\nPaper 190 - Session title: Visualisation and Virtual labs\n\n12:45 VRE for Aquaculture: how EO data can help the Blue Growth\n\nLongépé, Nicolas (1); Goacolou, Manuel (1); Vadaine, Rodolphe (1); Blondel, Emmanuel (2); Pagano, Pasquale (3); Ellenbroek, Anton (2); Lebras, Jean-Yves (1) 1: CLS, France; 2: FAO, Italy; 3: CNR, Italy\n\nShow abstract\n\nThe EU-funded BlueBRIDGE project deliver Virtual Research Environments (VREs) in various domains (e.g. fisheries, biology, economics, statistics, environment, mathematics, social sciences, natural sciences, computer science) that support knowledge generation from data collection and aggregation to the production of indicators and indices or other information products such as fact-sheets, reports, and data repositories. In the context of the Blue Growth strategy, the need for services that collect and combine Environmental Observation (EO) data with aquaculture data has been identified by the EU. In this context, fundamental services are needed to monitor the spatial distribution of human activities including aquaculture and fishing, allowing for performance analysis based on environmental and socio-economic indicators. This presentation will highlight VREs that support a computing intensive ontology driven feature analysis of SAR and multispectral optical imagery (using Sentinel-1 and -2 data, and Very High Resolution optical imagery), where the results are displayed on maps for human reviewers. A first VRE is specialized in recognizing aquaculture activity in Greece, while the second is specialized in identifying coastal aquaculture ponds in Indonesia.\n\nPresentation\n\n[Authors] [ Overview programme]\n\nPaper 239 - Session title: Visualisation and Virtual labs\n\n13:00 The GEO ECOPOTENTIAL Virtual Laboratory: a virtual research environment for ecosystem open science\n\nNativi, Stefano (1); Mazzetti, Paolo (1); Santoro, Mattia (1); Manakos, Ioannis (2); Kordelas, Georgios (2); Lucas, Richard (3) 1: CNR-IIA, Italy; 2: CERTH-ITI, Greece; 3: UNSW, Australia\n\nShow abstract\n\nThe ECOPOTENTIAL project, funded under the Horizon 2020 Research and Innovation programme aims at building a unified framework for ecosystem studies and management of protected areas. To achieve such objective, open and interoperable access to data and knowledge is assured by the GEO Ecosystem Virtual Laboratory Platform (ECOPOTENTIAL VLab). The concept of ECOPOTENTIAL VLab stems from the need of moving from open data to open science as a new vision of participatory scientific research. Therefore, it aims not only to data sharing but more generally to support the ecosystem community-of-practice in research activities for informed decision-making in ecosystem management. The ECOPOTENTIAL VLab provides multiple entry points to access information at different semantic level depending on the user’s specific interest, ranging from ecosystems, protected areas, storylines (e.g. user scenarios for protected areas study and management), workflows (e.g. business processes necessary for storylines), algorithms (e.g. models and procedures necessary for implementing workflows) and data. All the information artifacts have an open representation and are linked together according to a general ECOPOTENTIAL ontology, allowing users’navigation among different concepts. In particular, users have access to in-situ data from selected campaigns, and from European and global observation networks and programmes, like LTER DEIMS, OBIS, GBIF, LIFEWATCH. They have also access to raw and pre-processed remote-sensing data including Sentinel 1/2 and Landsat. Users have also access to workflows represented as BPMN diagrams, and through the ECOPOTENTIAL VLab they can run workflows selecting input data, to generate essential variables, indicators and indices. Users can share algorithm as code through GitHub, or processing services as OGC WPS and integrate them in new workflows. The architecture of the GEO Ecosystem Virtual Laboratory is based on a set of principles currently shared in the scientific research communities, with particular reference to the GEO initiative, including GEOSS Data Sharing Principles, GEOSS Data Management Principles and GEOSS Architecture Principles. Moreover, since ECOPOTENTIAL participates in the Horizon 2020 pilot action on open access to research data, the activities of the ECOPOTENTIAL Consortium for the definition of the ECOPOTENTIAL Data Management Plan are a fundamental input for the architecture of the ECOPOTENTIAL VLab. The design of the ECOPOTENTIAL Virtual Laboratory puts its basis on past experiences in building System of Systems through a brokering approach. The mature data brokering approach will be complemented with innovative semantic technologies – including concept-based queries and annotations – and support of discovery and invocation of workflows implementing storylines on multiple protected areas contributing to enable the open science vision in ecosystem science.\n\nPresentation\n\n[Authors] [ Overview programme]"
    }
}